{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad0998b7-a501-4f9f-a8c4-2ef01a23fb76",
   "metadata": {},
   "source": [
    "# Automatic weather station examples \n",
    "Eric Gagliano (egagli@uw.edu)   \n",
    "Updated: March 7th, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5106c82f-297d-46bb-a1c0-0818bfb134e3",
   "metadata": {},
   "source": [
    "**Thanks for checking out these examples! The automatic_weather_station module is intended to make it easier to retrieve daily SNOTEL and CCSS data without having to do clunky downloads and conversions. Snow depth / SWE / PRCPSA are in meters, temperatures are in celsius. This module is built on my [snotel_ccss_stations](https://github.com/egagli/snotel_ccss_stations) repository, which uses a github action to auto-update the station data daily.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91007c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3959e4b-74c7-426f-b903-449ebfff068e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%aimport easysnowdata\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import tqdm\n",
    "import contextily as ctx\n",
    "\n",
    "import xarray as xr\n",
    "import glob\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s',level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec527a0-41b1-449e-8a59-8d456073ceca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## View all SNOTEL & CCSS stations\n",
    "- the [SNOwpack TELemetry (SNOTEL) network](https://www.nrcs.usda.gov/wps/portal/wcc/home/aboutUs/monitoringPrograms/automatedSnowMonitoring/) includes over 800 automated weather stations in the Western U.S. for mountain snowpack observation\n",
    "- the [CCSS program](https://water.ca.gov/Programs/Flood-Management/Flood-Data/Snow-Surveys) manages a network of 130 automated snow sensors located in the Szierra Nevada and Shasta-Trinity Mountains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad815f9-c694-4772-b9e8-cdb83f0c9d69",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get an up to date GeoDataFrame of all active SNOTEL and CCSS stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39942764",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_gdf = gpd.read_file('https://github.com/egagli/sar_snowmelt_timing/raw/main/input/shapefiles/mt_rainier.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266d686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stations_gdf = easysnowdata.automatic_weather_stations.get_all_stations(sortby_dist_to_geom=bbox_gdf)\n",
    "all_stations_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea57c735",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ds = easysnowdata.automatic_weather_stations.get_all_stations_all_data(all_stations_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40257d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee0cc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds.drop_vars('geometry').to_netcdf(f'all_stations.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884f8b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b326a915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51882748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43621e35-4326-4cf9-a221-f5f8ea614cbe",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Use geopandas `GeoDataFrame.explore()` on the `all_stations_gdf` geodataframe to interactively view the stations \n",
    "- color by network: red is SNOTEL, blue is CCSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef6caa1-e841-4e46-8989-afb95af787b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_stations_gdf.astype(dict(beginDate=str, endDate=str)).explore(column='network',cmap='bwr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf197e5-7fd4-4c39-8b67-315de019f343",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get data for a singular site: *Is our winter on track with the historical record at the Paradise, WA SNOTEL station?*\n",
    "- check out information about the [SNOTEL station near Mt. Rainier at Paradise, WA](https://wcc.sc.egov.usda.gov/nwcc/site?sitenum=679)\n",
    "- cool plots available at the [Northwest River Forecast Center website](https://www.nwrfc.noaa.gov/snow/snowplot.cgi?AFSW1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbbc606-69e5-4898-b9bc-6bfff881215a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Place a station code (which you can find in this interactive plot, or by other means) in the url: https://raw.githubusercontent.com/egagli/snotel_ccss_stations/main/data/{station_id}.csv\n",
    "- for SNOTEL stations, this will be of the form {unique number}_{two letter state abbreviation}_SNTL (e.g. 679_WA_SNTL).   \n",
    "- for CCSS stations, this will be a three letter code (e.g. BLK).   \n",
    "- use `pd.read_csv()` with `index_col='datetime'` and `parse_dates=True` so we interpret the datetime column as pandas datetime objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c6bd2e-3d27-4908-ab24-6e61772f4e8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "station_id = '679_WA_SNTL'\n",
    "paradise_snotel = pd.read_csv(f'https://raw.githubusercontent.com/egagli/snotel_ccss_stations/main/data/{station_id}.csv',index_col='datetime', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bb24d7-44f9-49a5-b728-312495160f50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "paradise_snotel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc267180-8371-46da-a99d-be42c5837ffc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Try a simple plot of snow depth and SWE\n",
    "- select the column of interest and use pandas built in `Series.plot()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9f9160-7bbb-4424-b58c-97412e814cb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(figsize=(12,5))\n",
    "\n",
    "paradise_snotel['SNWD'].plot(ax=ax,label='snow depth')\n",
    "paradise_snotel['WTEQ'].plot(ax=ax,label='snow water equivalent')\n",
    "\n",
    "ax.set_xlim(pd.to_datetime(['2017-10-01','2018-09-30']))\n",
    "\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "\n",
    "ax.set_xlabel('time')\n",
    "ax.set_ylabel('snow depth / SWE [meters]')\n",
    "ax.set_title('Snow depth and SWE at Paradise, WA \\n(water year 2018)')\n",
    "\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb2f377-5145-44c8-ac10-720f97f0a485",
   "metadata": {},
   "source": [
    "### Try a more complex plot that shows current snow depth against statistics calculated from the entire time series for each day of water year\n",
    "- water year is conceptual 12 month period used to describe when the bulk of precipitation falls, mostly used for hydrology attribution \n",
    "    - in the northern hemisphere, we usually define the water year to start October 1st and go until September 30th (e.g. water year 2017: October 1st, 2016 - September 30th, 2017)\n",
    "    - so October 1st is DOWY 1\n",
    "- try a function like `datetime_to_DOWY()` shown below to convert datetimes to day of water year and add a dedicated DOWY column\n",
    "    - this function should account for leap years\n",
    "- then use pandas groupby functionality to calculate stats per DOWY\n",
    "- plot these stats\n",
    "    - thanks David Shean for the plot inspiration!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e455e0-a690-4c0d-a91d-44e59ad1cb31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def datetime_to_DOWY(date):\n",
    "    try:\n",
    "        if date.month < 10 or (date.month == 10 and date.day < 1):\n",
    "            start_of_water_year = pd.Timestamp(year=date.year-1, month=10, day=1)\n",
    "        else:\n",
    "            start_of_water_year = pd.Timestamp(year=date.year, month=10, day=1)\n",
    "        return (date - start_of_water_year).days + 1\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def datetime_to_WY(date):\n",
    "    if date.month < 10 or (date.month == 10 and date.day < 1):\n",
    "        return date.year\n",
    "    else:\n",
    "        return date.year + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088e07f8-aada-43e7-88eb-836644a04dcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "paradise_snotel['DOWY'] = paradise_snotel.index.map(datetime_to_DOWY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de5d8d8-aaa5-4b44-843a-3ef14b1f1605",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stat_list = ['min','max','mean','std','median']\n",
    "paradise_snotel_DOWY_snwd_stats = paradise_snotel.groupby('DOWY').agg(stat_list)['SNWD']\n",
    "paradise_snotel_DOWY_snwd_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e77ab8-a602-4cfa-8ec3-93481cfca828",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "today = datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "current_WY = slice(f'{int(today[0:4])-1}-10-01',f'{today}')\n",
    "current_WY_paradise_snotel = paradise_snotel[current_WY.start:current_WY.stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c7d252-930b-4b93-b358-cf27ca687585",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(figsize=(12,7))\n",
    "\n",
    "for stat,stat_color in zip(['min','max','mean','median'],['red','blue','mediumpurple','mediumseagreen']):\n",
    "    ax.plot(paradise_snotel_DOWY_snwd_stats.index, paradise_snotel_DOWY_snwd_stats[stat], label=stat, color=stat_color, linewidth=3)\n",
    "    \n",
    "ax.fill_between(paradise_snotel_DOWY_snwd_stats.index, paradise_snotel_DOWY_snwd_stats['mean'] - paradise_snotel_DOWY_snwd_stats['std'], paradise_snotel_DOWY_snwd_stats['mean'] + paradise_snotel_DOWY_snwd_stats['std'], color='mediumpurple', alpha=0.3, label='mean +/- 1 std')\n",
    "\n",
    "ax.scatter(current_WY_paradise_snotel.DOWY,current_WY_paradise_snotel.SNWD, marker='o', color= 'black', label='Current WY')\n",
    "\n",
    "ax.set_xlim([0,366])\n",
    "ax.set_ylim([0,6])\n",
    "\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "\n",
    "ax.set_title(f'Current snow depth against historical snow depth stats by DOWY at Paradise, WA\\n({paradise_snotel.index.min().date()} - {paradise_snotel.index.max().date()})')\n",
    "ax.set_xlabel('Day of Water Year [Oct 1 - Sept 30]')\n",
    "ax.set_ylabel('Snow depth [meters]')\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c69708b-f8a6-4e59-b16e-35276bd4e632",
   "metadata": {},
   "source": [
    "**Looks like we're below the mean for snow depth for today's DOWY.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4acacb-ad0d-4f10-b51f-4d4f076ebe08",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read a variable from multiple CSVs by looping over a list of stations: *Does the SNOTEL network and CCSS network list the same station?*\n",
    "- no controversy here, but i noticed that a station name was repeated\n",
    "- perhaps both networks have data from the same station accessible\n",
    "- might make sense if they are co-managed in some way?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3453278c-989a-4b62-9c43-8becf7f7609f",
   "metadata": {},
   "source": [
    "### Create a list of the stations we are interested in, loop through and add data to a dictionary with the station code as the key, then read into pandas using `pd.DataFrame.from_dict()`\n",
    "- initialize with an empty dict and append to it in the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305e6ba4-a2bf-4a49-8c62-f67e1067a5ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "station_list = ['356_CA_SNTL','BLK']\n",
    "\n",
    "station_dict = {}\n",
    "\n",
    "for station in station_list:\n",
    "    tmp = pd.read_csv(f'https://raw.githubusercontent.com/egagli/snotel_ccss_stations/main/data/{station}.csv',index_col='datetime',parse_dates=True)['WTEQ']\n",
    "    station_dict[station] = tmp\n",
    "\n",
    "stations_swe_df = pd.DataFrame.from_dict(station_dict)#.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a274a2-566b-4238-ae3e-6ad86b1c5eb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stations_swe_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ab35f7-73b8-4a66-b48e-ce064db46aee",
   "metadata": {},
   "source": [
    "### Plot the two stations on the same axis\n",
    "- if we properly set the index as the datetime, and we used `parse_dates=True`, these should line up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34b74cb-88bc-4e39-8341-65299c44049d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(figsize=(20,7))\n",
    "\n",
    "stations_swe_df.plot(ax=ax,color=['red','blue'])\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "ax.set_xlabel('time')\n",
    "ax.set_ylabel('snow water equivalent [meters]')\n",
    "ax.set_title('SNOTEL and CCSS SWE at Blue Lakes, CA \\nmaybe these are the same? :)')\n",
    "\n",
    "f.tight_layout()\n",
    "\n",
    "#ax.set_xlim(['2018-08-01','2020-01-01'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8333d5e-50ac-4eda-9166-c2eef6eaa4cc",
   "metadata": {},
   "source": [
    "### These look oddly similar... let's check out their correlation\n",
    "- convenient built in `DataFrame.corr()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e27d86-474f-4d98-9ab4-1a35f20e78b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stations_swe_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a920aaa2-8d3f-4b92-b909-d5e55612c41e",
   "metadata": {},
   "source": [
    "**These correlation values, along with the time series above, makes me think these are way too similar... no way these would agree this much even if the stations were right next to each other!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ddde04-b5ec-412f-bbaf-86bd57a707cc",
   "metadata": {},
   "source": [
    "### Let's see where they exist spatially\n",
    "- select the stations by index and reproject to UTM 11N\n",
    "- use `contextily` for a basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ba3e2f-d414-49c2-9ad1-1ce27d581891",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(figsize=(7,7))\n",
    "\n",
    "all_stations_gdf[all_stations_gdf.index=='356_CA_SNTL'].to_crs('EPSG:32611').plot(ax=ax, color='red',label='356_CA_SNTL')\n",
    "all_stations_gdf[all_stations_gdf.index=='BLK'].to_crs('EPSG:32611').plot(ax=ax, color='blue',label='BLK')\n",
    "\n",
    "ax.set_xlim([244200,245700])\n",
    "ax.set_ylim([4276900,4278700])\n",
    "\n",
    "ctx.add_basemap(ax, crs='EPSG:32611', source=ctx.providers.Esri.WorldImagery)\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cd6ab7-3d93-4173-b6f5-a424539cbbfb",
   "metadata": {},
   "source": [
    "**Interesting locations :) Based on correlation and location, I'm going to say these are the same! Wonder what those tiny differences are about...**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db512d43-eb14-4f81-8915-ac216c941a51",
   "metadata": {},
   "source": [
    "### Look's like some of the CCSS stations have \"Natural Resources Conservation Service\" as their operator\n",
    "- Let's check which stations these are!\n",
    "- Let's plot these shared stations in red, and not shared in blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2778ec88-f8f4-4226-8e3e-e040ee201f4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q lxml\n",
    "import requests \n",
    "from io import StringIO\n",
    "\n",
    "csv = 'https://cdec.water.ca.gov/misc/SnowSensors.html'\n",
    "response = requests.get(csv)\n",
    "same_stations_df = pd.read_html(StringIO(response.content.decode('utf-8')))[0].set_index('ID').sort_index()\n",
    "same_stations_df = same_stations_df[same_stations_df.nunique(axis=1) > 1]\n",
    "same_stations_gdf = gpd.GeoDataFrame(same_stations_df, geometry=gpd.points_from_xy(same_stations_df['Longitude'], same_stations_df['Latitude']))\n",
    "same_stations_gdf.crs = \"EPSG:4326\"\n",
    "same_stations_gdf = same_stations_gdf[same_stations_gdf['Operator Agency']=='Natural Resources Conservation Service']\n",
    "same_stations_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855de488-09cf-47ad-9c2e-c3fd4dfc5a9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(figsize=(10,10))\n",
    "\n",
    "same_stations_gdf.to_crs(\"EPSG:32611\").plot(ax=ax,color='red',label='CCSS station operated by NRCS')\n",
    "ccss_stations_gdf = all_stations_gdf[all_stations_gdf['network']=='CCSS'].to_crs(\"EPSG:32611\")\n",
    "ccss_stations_gdf[~ccss_stations_gdf.index.isin(same_stations_gdf.index)].plot(ax=ax,color='blue',label='CCSS station not operated by NRCS')\n",
    "\n",
    "ctx.add_basemap(ax, crs='EPSG:32611', source=ctx.providers.Esri.WorldImagery)\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bd4e1e-79ac-48a3-a61e-d7bcaf6cded3",
   "metadata": {},
   "source": [
    "**There are 33 of these! These are likely also listed as SNOTEL stations...**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fcc194-9e9c-4000-bea1-b3a0a9520604",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read a variable from multiple CSVs by looping over a subset of the geodataframe: *How extraordinary was the California 2023 snowpack?*\n",
    "- the Sierra Nevada [received a historic amount of snow in 2023](https://www.nps.gov/articles/000/sien-sierranevadamonitor-spring2023.htm)\n",
    "- let's explore the magnitude of this season by comparing to the median snow pack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4696ca-83e1-42e2-994b-679f8d18efcb",
   "metadata": {},
   "source": [
    "### As before, create a list of the stations we are interested in, loop through and add data to a dictionary with the station code as the key, then read into pandas using `pd.DataFrame.from_dict()`\n",
    "- create a geodataframe `ccss_stations_gdf` of only CCSS stations from `all_stations_gdf` by creating an index where network equals CCSS\n",
    "- loop through the CCSS stations and create a dataframe `ccss_stations_snwd_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d817742-e0f9-43c2-91cd-bbf90ae4ea3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ccss_stations_gdf = all_stations_gdf[all_stations_gdf['network']=='CCSS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0603ad1a-fd87-4623-ad13-40f9296c1d92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ccss_stations_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6688f84-bb5e-45a7-8138-771d40c1cfac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "station_dict = {}\n",
    "\n",
    "for station in tqdm.tqdm(ccss_stations_gdf.index):\n",
    "    try:\n",
    "        tmp = pd.read_csv(f'https://raw.githubusercontent.com/egagli/snotel_ccss_stations/main/data/{station}.csv',index_col='datetime',parse_dates=True)['SNWD']\n",
    "        station_dict[station] = tmp\n",
    "    except:\n",
    "        print(f'failed to retrieve {station}')\n",
    "\n",
    "ccss_stations_snwd_df = pd.DataFrame.from_dict(station_dict).dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4a5224-3312-4e8e-8582-484d5049acca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ccss_stations_snwd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f260815d-ce7e-41e8-8cdc-128321ca6d7d",
   "metadata": {},
   "source": [
    "### Let's check out the percent of normal snow depth for April 1st, 2023\n",
    "- let's add a DOWY column to `ccss_stations_snwd_df` like before, groupby DOWY, apply a median, and divide the observation on April 1st, 2023 by the DOWY 183 (April 1) median\n",
    "    - add these percent normal values back to `ccss_stations_gdf`\n",
    "- will need to do some slight cleaning to get rid of NaNs, Infs, physically impossible values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc86e15-3a39-493f-ba35-43f64541b998",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ccss_stations_snwd_df['DOWY'] = ccss_stations_snwd_df.index.map(datetime_to_DOWY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c215348f-014d-424d-bb00-803cef0335b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ccss_stations_gdf.loc[:,'april2023_percent_norm'] = 100*(ccss_stations_snwd_df['2023-04-01':'2023-04-01'].squeeze() / ccss_stations_snwd_df.groupby('DOWY').median().loc[183])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c0d38e-ff30-4cce-ab78-4cbd6ab4e47f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ccss_stations_gdf = ccss_stations_gdf.dropna(subset='april2023_percent_norm')\n",
    "ccss_stations_gdf = ccss_stations_gdf[ccss_stations_gdf['april2023_percent_norm']<7500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb45566-d843-4e04-b3d2-5a5da0a78dcf",
   "metadata": {},
   "source": [
    "### View the values in order...\n",
    "- use `.sort_values()` function to get an idea of percent normal snow depth values\n",
    "- `DataFrame.head()` and `DataFrame.tail()` to see highest and lowest percent normal snow depth values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a59551c-d698-47b6-bbed-c11199c3628a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ccss_stations_gdf.sort_values('april2023_percent_norm',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1257c492-7476-49be-b16a-19ca097168a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccss_stations_gdf.sort_values('april2023_percent_norm',ascending=False).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e9f20b-529c-4e6d-9e4b-6f5c281c8f54",
   "metadata": {},
   "source": [
    "### Plot the percent of normal snow depths for April 1st, 2023\n",
    "- add elevation plot to the right with horizontal dashed line at 100% (normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22d45d7-94fe-4301-b390-1e61b4135a3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(12,9),gridspec_kw={'width_ratios': [2, 1]})\n",
    "\n",
    "ccss_stations_gdf.to_crs('EPSG:32611').plot(ax=ax[0], column='april2023_percent_norm',legend=True,vmin=0,vmax=500,cmap='gnuplot',edgecolor='black',s=100)\n",
    "\n",
    "ctx.add_basemap(ax[0], crs='EPSG:32611', source=ctx.providers.Esri.WorldImagery, attribution='')\n",
    "\n",
    "ax[0].set_title('station locations')\n",
    "\n",
    "\n",
    "ax[1].scatter(ccss_stations_gdf.elevation_m,ccss_stations_gdf.april2023_percent_norm,c=ccss_stations_gdf.april2023_percent_norm,cmap='gnuplot',vmin=0,vmax=500,edgecolors='black',s=100)\n",
    "ax[1].axhline(y=100,linestyle='--',color='black')\n",
    "\n",
    "ax[1].set_title('station percent normal snow depth vs elevation')\n",
    "ax[1].set_xlabel('elevation [m]')\n",
    "ax[1].set_ylabel('percent of normal snow depth [%]')\n",
    "\n",
    "f.suptitle(f'California percent normal snow depth for April 1st, 2023')\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3673ef28-9a3a-455d-b914-67336aa2036c",
   "metadata": {},
   "source": [
    "**Looks like a lot more snow than usual to me!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f951480-c7fb-4b88-b91c-583767dbc8f0",
   "metadata": {},
   "source": [
    "## Read a variable from all CSVs by looping over the entire geodataframe: *Has the date of maximum SWE changed in the Western US?*\n",
    "- [Snowmelt timing can be an important indicator of regional climate change](https://www.epa.gov/climate-indicators/climate-change-indicators-snowpack), and the snowmelt timing of the Western U.S. is projected to shift earlier in the year by up to 1 month by 2050 ([Barnett et al., 2005](https://www.nature.com/articles/nature04141); [Stewart, 2009](https://onlinelibrary.wiley.com/doi/10.1002/hyp.7128)), with a corresponding snowpack loss equivalent to a 25% decrease in streamflow from snowmelt ([Siirila-Woodburn et al., 2021](https://www.nature.com/articles/s43017-021-00219-y)).  \n",
    "- Let's explore trends in maximum SWE timing using SNOTEL and CCSS stations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b000efc7-0d02-4928-86c5-2c8cd113013d",
   "metadata": {},
   "source": [
    "### This time loop through all stations and and add data to a dictionary with the station code as the key, then read into pandas using `pd.DataFrame.from_dict()`\n",
    "- might take a minute to load in almost 1000 CSVs...\n",
    "- store SWE for all stations in `all_stations_swe_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e81653c-2213-46c5-a6a9-0000d01db1cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "station_dict = {}\n",
    "\n",
    "for station in tqdm.tqdm(all_stations_gdf.index):\n",
    "    try:\n",
    "        tmp = pd.read_csv(f'https://raw.githubusercontent.com/egagli/snotel_ccss_stations/main/data/{station}.csv',index_col='datetime',parse_dates=True)['WTEQ']\n",
    "        station_dict[station] = tmp\n",
    "    except:\n",
    "        print(f'failed to retrieve {station}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42e2679-8649-44a8-b260-8c383adbd6d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_stations_swe_df = pd.DataFrame.from_dict(station_dict)\n",
    "all_stations_swe_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8ac4b9-b803-4e0c-a622-eb383638ee3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prepare the data\n",
    "- prepare and clean `all_stations_swe_df`:\n",
    "    - filter to start in WY 1967 (the first year with more than one station) and end with WY 2023\n",
    "    - add water year column\n",
    "    - remove any negative SWE measurements\n",
    "    - for consistency with similar analyses, following the methodology of [Evan 2019](https://journals.ametsoc.org/view/journals/apme/58/1/jamc-d-18-0150.1.xml) and [US EPA 2021](https://www.epa.gov/sites/default/files/2021-04/documents/snowpack_td.pdf):\n",
    "       - set any change of greater magnitude than 20cm to NaN\n",
    "       - if there are more than 30 days of missing data during November-April, don't use that water year\n",
    "       - if SWE is zero during every day of Jan/Feb/March, don't use that water year\n",
    "       - only use stations with continuous data from WY 1982 \n",
    "           - i do this only for the all data bulk calculation so we have a common reference frame, but for station level analysis i instead impose a 30 year or longer record rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440c4670-4ad1-4683-89b4-c4a729812ca1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_stations_swe_df = all_stations_swe_df.loc[slice('1966-10-01','2023-09-30')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bb2615-508f-409b-afae-fe75fc3fa0da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_stations_swe_df['WY'] = all_stations_swe_df.index.map(datetime_to_WY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faae91d8-2c8c-4bc8-a8e3-a704095e2d7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_stations_swe_df = all_stations_swe_df[all_stations_swe_df>=0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aa2f65-5dcf-4447-b25b-be35aea74e30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_stations_swe_diff_df = all_stations_swe_df.diff().abs()\n",
    "all_stations_swe_df[all_stations_swe_diff_df>0.20] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4518f67f-6b7b-40dc-b100-341673ccfa1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_missing_data(group):\n",
    "    nov_to_apr_mask = group.index.month.isin([11, 12, 1, 2, 3, 4])\n",
    "    filtered_group = group[nov_to_apr_mask]\n",
    "    missing_data_counts = filtered_group.isnull().sum()\n",
    "    columns_to_nan = missing_data_counts[missing_data_counts > 30].index\n",
    "    group[columns_to_nan] = np.nan\n",
    "    return group\n",
    "\n",
    "def check_zero_swe(group):\n",
    "    for month in [1, 2, 3]:\n",
    "        month_mask = group.index.month == month\n",
    "        zero_swe_columns = group[month_mask].eq(0).all()\n",
    "        columns_to_nan = zero_swe_columns[zero_swe_columns].index\n",
    "        group[columns_to_nan] = np.nan\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3c29be-57d5-41b3-8d4a-084168a956a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_stations_swe_df = all_stations_swe_df.groupby('WY').apply(check_missing_data).droplevel(0)\n",
    "all_stations_swe_df = all_stations_swe_df.groupby('WY').apply(check_zero_swe).droplevel(0)\n",
    "all_stations_swe_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efce27d-1fda-4bfc-9d3d-e1a14dd70292",
   "metadata": {},
   "source": [
    "### Calculate and plot trend in DOWY of max SWE for all data \n",
    "- use `DataFrame.groupby()` to find the date of max SWE per year and convert to a DOWY value, store in `all_stations_dowy_max_swe_df`\n",
    "- calculate slope and intercept of linear regression using `np.polyfit()` on a melted version of  \n",
    "- obtain statistics for each year using `DataFrame.describe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e855c2-8996-45a6-a072-55f9d4b6c951",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_stations_dowy_max_swe_df = all_stations_swe_df.groupby('WY').idxmax().applymap(datetime_to_DOWY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167bd398-1418-4efb-b3d3-f58a33434d45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stations_before_WY1982 = all_stations_gdf[all_stations_gdf.beginDate<'1981-10-01']\n",
    "dowy_max_swe_melted = pd.melt(all_stations_dowy_max_swe_df.reset_index(),id_vars='WY').dropna()\n",
    "dowy_max_swe_melted_before_WY1982 = dowy_max_swe_melted[dowy_max_swe_melted['variable'].isin(stations_before_WY1982.index)]\n",
    "slope, intercept = np.polyfit(dowy_max_swe_melted_before_WY1982.WY,dowy_max_swe_melted_before_WY1982.value,1)\n",
    "lr_years = np.unique(dowy_max_swe_melted.WY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35357624-cd15-440b-a9e7-5ff6f650c1ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "describe = all_stations_dowy_max_swe_df.T.describe()\n",
    "describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6326fcde-da43-40d8-8baa-9565d07d5d41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(2,1,figsize=(10,6),sharex=True,gridspec_kw={'height_ratios': [3, 2]})\n",
    "\n",
    "describe.loc['50%'].plot(ax=ax[0],label='median')\n",
    "\n",
    "ax[0].fill_between(describe.columns,describe.loc['25%'],describe.loc['75%'],alpha=0.3,label='IQR')\n",
    "ax[0].plot(lr_years,np.array(lr_years)*slope+intercept,'k--',label=f'Trend (slope={slope:.2f} Days/Year)')\n",
    "#ax[0].set_xlim([1967,2023])\n",
    "\n",
    "ax[0].legend()\n",
    "\n",
    "describe.loc['count'].plot(ax=ax[1])\n",
    "\n",
    "\n",
    "ax[0].set_title('Trend in DOWY of max SWE')\n",
    "ax[1].set_title('Number of active stations')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0006d8-16d4-400a-a1e4-b2cb3b608009",
   "metadata": {},
   "source": [
    "### Check out trend at each station seperately\n",
    "- calculate the linear trend in DOWY of max SWE only for stations with over 30 years of data, store in our original `all_stations_gdf`\n",
    "    - out of 971 stations with SWE data, 645 meet this criteria\n",
    "- plot the trend for each station and plot the trends on a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82771a9-2701-491f-8245-82f2de825c31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_stations_gdf.loc[:,'dowy_max_swe_trend'] = all_stations_dowy_max_swe_df.apply(lambda y: np.polyfit(y.dropna().index.values, y.dropna(), 1)[0] if len(y.dropna()) >= 30 else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49311640-2ffe-4372-ba0d-ea5bdaea87cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(figsize=(10,5.5))\n",
    "\n",
    "all_stations_gdf.plot(column='dowy_max_swe_trend',ax=ax,legend=True,cmap='RdBu_r',edgecolor='k',markersize=20,vmin=-1,vmax=1,legend_kwds={'label':'[days/year]\\n(Red is later in the year, blue is earlier)'})\n",
    "\n",
    "ctx.add_basemap(ax, crs='EPSG:4326', source=ctx.providers.Esri.WorldImagery, attribution='')\n",
    "\n",
    "ax.set_title('Trend in DOWY of max SWE\\n(only stations with 30+ years of data)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000a16c0-7c3f-4d55-8dca-d7f41ac89936",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f,ax=plt.subplots()\n",
    "\n",
    "ax.hist(all_stations_gdf['dowy_max_swe_trend'],bins=50)\n",
    "\n",
    "ax.axvline(x=0,color='red')\n",
    "\n",
    "ax.set_xlim([-1.5,1.5])\n",
    "\n",
    "ax.set_xlabel('trend [days/year]')\n",
    "ax.set_ylabel('count')\n",
    "ax.set_title('Distribution of trends in DOWY of max SWE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd05a5-47b2-439e-8fbf-6d32125672d7",
   "metadata": {},
   "source": [
    "### Let's analyze these trends by mountain range\n",
    "- we can `DataFrame.groupby()` our geodataframe by mountain range to calculate mountain range specific stats, store in `mountain_range_trend_df`\n",
    "- mountain ranges with more stations (and more spatial coverage) are probably more trustworthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7726cc82-2107-4202-b583-fb29191856f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mountain_range_count = all_stations_gdf.dropna().groupby('mountainRange')['dowy_max_swe_trend'].count()\n",
    "mountain_range_median = all_stations_gdf.dropna().groupby('mountainRange')['dowy_max_swe_trend'].median()\n",
    "mountain_range_mean = all_stations_gdf.dropna().groupby('mountainRange')['dowy_max_swe_trend'].mean()\n",
    "mountain_range_std = all_stations_gdf.dropna().groupby('mountainRange')['dowy_max_swe_trend'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee759bff-7821-4d95-8bfd-aa6959db6070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mountain_range_trend_df = pd.concat([mountain_range_count,mountain_range_median,mountain_range_mean,mountain_range_std],axis=1)\n",
    "mountain_range_trend_df.columns = ['station_count','median','mean','std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27258480-1c36-443b-a8fd-f1f4b4b132f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mountain_range_trend_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6f6857-b3e0-4440-8ceb-365371a2e388",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,sharey=True,gridspec_kw={'width_ratios': [1, 3]})\n",
    "\n",
    "mountain_range_trend_df['station_count'].plot.barh(ax=ax[0])\n",
    "mountain_range_trend_df['median'].plot.barh(ax=ax[1],cmap='RdBu')\n",
    "\n",
    "\n",
    "ax[0].set_xlabel('[#]')\n",
    "ax[1].set_xlabel('[days/year]')\n",
    "ax[0].set_ylabel('')\n",
    "ax[0].set_title('station count')\n",
    "ax[1].set_title('trend')\n",
    "\n",
    "f.suptitle('Trend in DOWY of max SWE by mountain range')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d104ee3-3471-4856-a55a-b70e603c5a75",
   "metadata": {},
   "source": [
    "### Let's visualize this on a map \n",
    "- add spatial information to `mountain_range_trend_df` using `DataFrame.join()` with mountain range geometries from [GMBA Mountain Inventory v2](https://www.earthenv.org/mountains)\n",
    "- ceate both a static plot with counts and medians and create an interactive plot so we can explore the trends across mountain ranges and stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960d1a42-be5c-466e-84c4-9fa7fc6a0b4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = f'https://data.earthenv.org/mountains/standard/GMBA_Inventory_v2.0_standard_300.zip'\n",
    "gmba_gdf = gpd.read_file('zip+'+url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5be780-b548-4e93-87e4-89b1198078c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mountain_range_trend_gdf = gpd.GeoDataFrame(mountain_range_trend_df.join(gmba_gdf[['MapName','geometry']].set_index('MapName')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50d14b9-af41-4509-ad4e-50554d205346",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(14,7))\n",
    "\n",
    "mountain_range_trend_gdf.plot(ax=ax[0],column='station_count',vmin=0,vmax=100,cmap='viridis',legend=True,edgecolor='k',legend_kwds={'label':'[#]'})\n",
    "mountain_range_trend_gdf.plot(ax=ax[1],column='median',vmin=-0.3,vmax=0.3,cmap='RdBu_r',legend=True,edgecolor='k',legend_kwds={'label':'[days/year]\\n(Red is later in the year, blue is earlier)'})\n",
    "\n",
    "for axs in ax:\n",
    "    ctx.add_basemap(ax=axs, crs=mountain_range_trend_gdf.crs, source=ctx.providers.Esri.WorldImagery, attribution=False)\n",
    "    ctx.add_basemap(ax=axs, crs=mountain_range_trend_gdf.crs, source=ctx.providers.Esri.WorldImagery, attribution=False)\n",
    "    axs.set_xlim([-125,-104])\n",
    "    axs.set_ylim([27,55])\n",
    "    \n",
    "ax[0].set_title('count')\n",
    "ax[1].set_title('trend')\n",
    "\n",
    "f.suptitle('Trend in DOWY of max SWE by mountain range\\n(only stations with 30+ years of data)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5511d497-be96-4ef1-8862-ee43c0721d54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = mountain_range_trend_gdf.explore(column='median',cmap='RdBu_r',vmin=-0.5,vmax=0.5)\n",
    "all_stations_gdf.astype(dict(beginDate=str, endDate=str)).explore(m=m,column='dowy_max_swe_trend',cmap='RdBu_r',vmin=-0.3,vmax=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5675a599-3e19-4430-873b-f1828fdad55a",
   "metadata": {},
   "source": [
    "**Looks like these trends are different by region, but relatively consistent within region. The majority of regions show the timing of maximum SWE happening earlier in the year, with notable exceptions being mountain ranges in the Pacific Northwest which show a reverse trend with smaller magnitude. Also of importance is the number of stations and their spatial dsitribution in each region, as 2 of the 4 regions (Olympic Mountains and Oregon Coast Range) showing the timing of maximum SWE happening later in the year only have one station each with a 30+ year record.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103249b1-5507-4ede-89e2-cff3d8d60383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d56714b-89c2-4ff7-a0fa-bae9124426e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb09c66b-b74e-41d4-8c6c-ba6a12d3c4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

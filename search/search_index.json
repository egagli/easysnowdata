{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to easysnowdata","text":"<p>package to easily get data relevant to snow</p> <ul> <li>Free software: MIT License</li> <li>Documentation: https://egagli.github.io/easysnowdata</li> </ul>"},{"location":"#features","title":"Features","text":"<ul> <li>TODO</li> </ul>"},{"location":"automatic_weather_stations/","title":"automatic_weather_stations module","text":""},{"location":"automatic_weather_stations/#easysnowdata.automatic_weather_stations.StationCollection","title":"<code> StationCollection        </code>","text":"<p>A collection of automatic weather stations, including SNOTEL and CCSS stations.</p> <p>This class manages a collection of weather stations, allowing for data retrieval, spatial subsetting, and various data processing operations. It supports both SNOTEL and CCSS station types.</p> <p>Parameters:</p> Name Type Description Default <code>snotel_stations</code> <code>bool</code> <p>Whether to include SNOTEL stations in the collection. Default is True.</p> <code>'True'</code> <code>ccss_stations</code> <code>bool</code> <p>Whether to include CCSS stations in the collection. Default is False.</p> <code>'False'</code> <p>Examples:</p> <p>Create a StationCollection with both SNOTEL and CCSS stations:</p> <p>Attributes:</p> Name Type Description <code>all_stations</code> <code>geopandas.GeoDataFrame</code> <p>A GeoDataFrame containing all the stations in the collection.</p> <code>chosen_stations</code> <code>geopandas.GeoDataFrame</code> <p>A GeoDataFrame containing the subset of stations chosen for analysis.</p> Source code in <code>easysnowdata/automatic_weather_stations.py</code> <pre><code>class StationCollection:\n    \"\"\"\n    A collection of automatic weather stations, including SNOTEL and CCSS stations.\n\n    This class manages a collection of weather stations, allowing for data retrieval,\n    spatial subsetting, and various data processing operations. It supports both\n    SNOTEL and CCSS station types.\n\n    Parameters\n    ----------\n    snotel_stations : bool, optional\n        Whether to include SNOTEL stations in the collection. Default is True.\n    ccss_stations : bool, optional\n        Whether to include CCSS stations in the collection. Default is False.\n\n    Attributes\n    ----------\n    all_stations : geopandas.GeoDataFrame\n        A GeoDataFrame containing all the stations in the collection.\n    chosen_stations : geopandas.GeoDataFrame\n        A GeoDataFrame containing the subset of stations chosen for analysis.\n\n    Examples\n    --------\n    Create a StationCollection with both SNOTEL and CCSS stations:\n\n    &gt;&gt;&gt; station_collection = StationCollection(snotel_stations=True, ccss_stations=True)\n    &gt;&gt;&gt; print(station_collection.all_stations)\n\n    Create a StationCollection with only SNOTEL stations and choose stations within a specific bounding box:\n\n    &gt;&gt;&gt; snotel_collection = StationCollection(snotel_stations=True, ccss_stations=False)\n    &gt;&gt;&gt; snotel_collection.choose_stations_by_bbox((-121.94, 46.72, -121.54, 46.99))\n    &gt;&gt;&gt; print(snotel_collection.chosen_stations)\n\n    Notes\n    -----\n    Data sources:\n    SNOTEL: https://www.nrcs.usda.gov/wps/portal/wcc/home/quicklinks/imap\n    CCSS: https://cdec.water.ca.gov/snow/current/snow/\n    \"\"\"\n    def __init__(\n        self,\n        data_available: bool = True,\n        #snotel_stations: bool = True,\n        #ccss_stations: bool = True,\n        sortby_dist_to_geom=None,\n    ):\n\n        self.data_available = data_available\n        #self.snotel_stations = snotel_stations\n        #self.ccss_stations = ccss_stations\n        self.sortby_dist_to_geom = sortby_dist_to_geom\n\n        self.all_stations = None\n        self.stations = None\n\n        self.TAVG = None\n        self.TMIN = None\n        self.TMAX = None\n        self.SNWD = None\n        self.WTEQ = None\n        self.PRCPSA = None\n\n        self.data = None\n\n        self.entire_data_archive = None\n\n        self.get_all_stations()\n\n\n    def get_all_stations(self):\n        \"\"\"\n        Fetches all weather stations from a GeoJSON file hosted on the snotel_ccss_stations GitHub repository.\n\n        This method retrieves station data, filters based on data availability, and optionally sorts stations\n        by distance to a specified geometry.\n\n        Returns\n        -------\n        None\n            Updates the all_stations attribute of the class.\n\n        Notes\n        -----\n        The method prints information about the retrieved stations and available data access methods.\n        \"\"\"\n        # Read the GeoJSON file\n        all_stations_gdf = gpd.read_file(\n            \"https://github.com/egagli/snotel_ccss_stations/raw/main/all_stations.geojson\"\n        ).set_index(\"code\")\n\n        # # Filter based on data availability\n        if self.data_available:\n            all_stations_gdf = all_stations_gdf[all_stations_gdf[\"csvData\"]]\n\n        # # Filter out SNOTEL stations if not required\n        # if not self.snotel_stations:\n        #     all_stations_gdf = all_stations_gdf[all_stations_gdf[\"network\"] != \"SNOTEL\"]\n\n        # # Filter out CCSS stations if not required\n        # if not self.ccss_stations:\n        #     all_stations_gdf = all_stations_gdf[all_stations_gdf[\"network\"] != \"CCSS\"]\n\n        # If a geometry is passed in, calculate the distance to this geometry for each station\n        if self.sortby_dist_to_geom is not None:\n            print(f\"Sorting by distance to given geometry. See dist_km column.\")\n            geom_gdf = convert_bbox_to_geodataframe(self.sortby_dist_to_geom)\n            proj = \"EPSG:32611\"\n            all_stations_gdf[\"dist_km\"] = (\n                all_stations_gdf.to_crs(proj).distance(\n                    geom_gdf.to_crs(proj).geometry[0]\n                )\n                / 1000\n            )\n            all_stations_gdf = all_stations_gdf.sort_values(\"dist_km\")\n\n        self.all_stations = all_stations_gdf\n        print(\n            f\"Geodataframe with all stations has been added to the Station object. Please use the .all_stations attribute to access.\"\n        )\n        print(\n            f\"Use the .get_data(stations=geodataframe/string/list,variables=string/list,start_date=str,end_date=str) method to fetch data for specific stations and variables.\"\n        )\n\n    def choose_stations(self, stations_gdf):\n        \"\"\"\n        Choose specific stations for further analysis.\n\n        This method allows selection of specific stations from the collection\n        for subsequent data processing and analysis.\n\n        Parameters\n        ----------\n        stations_gdf : gpd.GeoDataFrame, str, or list\n            The name(s) or index(es) of the stations to be chosen.\n\n        Returns\n        -------\n        None\n            Updates the stations attribute of the class.\n\n        Examples\n        --------\n        Choose stations by name:\n        &gt;&gt;&gt; station_collection.choose_stations('Paradise')\n\n        Choose multiple stations by index:\n        &gt;&gt;&gt; station_collection.choose_stations([0, 1, 2])\n        \"\"\"\n        if type(stations_gdf) is str:\n            stations_gdf = self.all_stations.loc[[stations_gdf]]\n        if type(stations_gdf) is list:\n            stations_gdf = self.all_stations.loc[stations_gdf]\n\n        self.stations = stations_gdf\n\n    def get_data(self, stations=\"679_WA_SNTL\", variables=None, start_date='1900-01-01', end_date=today):\n        \"\"\"\n        Retrieves data for the specified stations and variables.\n\n        This method fetches data for chosen stations and variables within a specified date range.\n\n        Parameters\n        ----------\n        stations : geodataframe, str, or list, optional\n            The stations to retrieve data for. Default is '679_WA_SNTL'.\n        variables : str or list, optional\n            The variables to retrieve data for. Default is None.\n        start_date : str, optional\n            The start date for the data. Default is '1900-01-01'.\n        end_date : str, optional\n            The end date for the data. Default is today's date.\n\n        Returns\n        -------\n        None\n            Updates the data attribute of the class.\n\n        Notes\n        -----\n        The behavior of this method varies based on the number of stations chosen and the specified variables.\n        \"\"\"\n\n        self.choose_stations(stations)\n\n        if len(self.stations) == 1:\n            if variables is None:\n                print(\n                    f\"Only one station chosen with variables=None. Default behavior fetches all variables for this station.\"\n                )\n                self.get_single_station_data(start_date=start_date, end_date=end_date)\n            else:\n                self.get_single_station_data(variables=variables, start_date=start_date, end_date=end_date)\n        else:\n            if variables is None:\n                print(\n                    f\"Multiple stations chosen with variables=None. Default behavior fetches WTEQ for all stations.\"\n                )\n                self.get_multiple_station_data(start_date=start_date, end_date=end_date)\n            else:\n                self.get_multiple_station_data(variables=variables, start_date=start_date, end_date=end_date)\n\n    def get_single_station_data(\n        self, variables=[\"WTEQ\", \"SNWD\", \"PRCPSA\", \"TAVG\", \"TMIN\", \"TMAX\"], start_date='1900-01-01', end_date=today\n    ):\n        \"\"\"\n        Retrieves data for a single weather station.\n\n        This method fetches data for specified variables from a single station within a given date range.\n\n        Parameters\n        ----------\n        variables : list, optional\n            List of variables to include in the data. Default is ['WTEQ','SNWD','PRCPSA','TAVG','TMIN','TMAX'].\n        start_date : str, optional\n            The start date for the data. Default is '1900-01-01'.\n        end_date : str, optional\n            The end date for the data. Default is today's date.\n\n        Returns\n        -------\n        None\n            Updates the data attribute of the class.\n\n        Notes\n        -----\n        The method prints a message indicating that the data has been added to the Station object.\n        \"\"\"\n\n        single_station_df = pd.read_csv(\n            f\"https://raw.githubusercontent.com/egagli/snotel_ccss_stations/main/data/{self.stations.index.values[0]}.csv\",\n            index_col=\"datetime\",\n            parse_dates=True,\n        )\n\n        columns_to_drop = [\n            col for col in single_station_df.columns if col not in variables\n        ]\n        single_station_df = single_station_df.drop(columns=columns_to_drop).loc[start_date:end_date]\n        self.data = single_station_df\n        print(\n            f\"Dataframe has been added to the Station object. Please use the .data attribute to access.\"\n        )\n\n    def get_multiple_station_data(self, variables=\"WTEQ\", start_date='1900-01-01', end_date=today):\n        \"\"\"\n        Fetches data for multiple stations and specified variables.\n\n        This method retrieves data for multiple stations and specified variables within a given date range.\n\n        Parameters\n        ----------\n        variables : str or list, optional\n            The variable(s) to fetch. Default is 'WTEQ' (water equivalent of snow on the ground).\n        start_date : str, optional\n            The start date for the data. Default is '1900-01-01'.\n        end_date : str, optional\n            The end date for the data. Default is today's date.\n\n        Returns\n        -------\n        None\n            Updates the data attribute of the class with an xarray Dataset.\n\n        Notes\n        -----\n        The method prints messages indicating the progress of data retrieval and processing.\n        \"\"\"\n\n        dataarrays = []\n\n        if isinstance(variables, str):\n            variables = [variables]\n\n        for variable in variables:\n\n            self.station_dict = {}\n\n            for station in tqdm.tqdm(self.stations.index):\n                try:\n                    tmp = pd.read_csv(\n                        f\"https://raw.githubusercontent.com/egagli/snotel_ccss_stations/main/data/{station}.csv\",\n                        index_col=\"datetime\",\n                        parse_dates=True,\n                    )[variable]\n                    self.station_dict[station] = tmp\n                except:\n                    print(f\"failed to retrieve {station}\")\n\n            station_data_df = pd.DataFrame.from_dict(self.station_dict).loc[start_date:end_date]\n\n            setattr(self, f\"{variable}\", station_data_df)\n            print(\n                f\"{variable} dataframe has been added to the Station object. Please use the .{variable} attribute to access the dataframe.\"\n            )\n\n            station_data_da = (\n                station_data_df.to_xarray()\n                .to_dataarray(dim=\"station\")\n                .rename(f\"{variable}\")\n                .rename({\"datetime\": \"time\"})\n            )\n\n            dataarrays.append(station_data_da)\n\n        all_stations_ds = xr.merge(dataarrays)\n\n        for col in self.stations.columns:\n            all_stations_ds = all_stations_ds.assign_coords(\n                {f\"{col}\": (\"station\", self.stations[f\"{col}\"])}\n            )\n\n        all_stations_ds[\"time\"] = pd.to_datetime(all_stations_ds.time)\n\n        water_year = pd.to_datetime(all_stations_ds.time).map(datetime_to_WY)\n        day_of_water_year = pd.to_datetime(all_stations_ds.time).map(datetime_to_DOWY)\n\n        all_stations_ds.coords[\"WY\"] = (\"time\", water_year)\n        all_stations_ds.coords[\"DOWY\"] = (\"time\", day_of_water_year)\n\n        self.data = all_stations_ds\n        print(\n            f\"Full {variables} dataset has been added to the station object. Please use the .data attribute to access the dataset.\"\n        )\n\n    def get_entire_data_archive(self, refresh: bool = True, temp_dir: str = \"/tmp/\") -&gt; xr.Dataset:\n        \"\"\"\n        Downloads, decompresses and processes the entire automatic weather station data archive.\n\n        This method retrieves a compressed file containing all station data, processes it, and creates an xarray Dataset.\n\n        Parameters\n        ----------\n        refresh : bool, optional\n            If True, the compressed data file will be redownloaded. Default is True.\n        temp_dir : str, optional\n            The directory where the compressed data file will be downloaded and decompressed. Default is '/tmp/'.\n\n        Returns\n        -------\n        xarray.Dataset\n            An xarray Dataset containing the processed weather station data for all stations.\n\n        Notes\n        -----\n        The method prints messages indicating the progress of data retrieval, decompression, and processing.\n        \"\"\"\n\n        github_tar_file_path = \"https://github.com/egagli/snotel_ccss_stations/raw/main/data/all_station_data.tar.lzma\"\n        compressed_file_path = pathlib.Path(temp_dir, \"all_station_data.tar.lzma\")\n        decompressed_dir_path = pathlib.Path(temp_dir, \"data\")\n\n        if not compressed_file_path.exists() or refresh:\n            print(\n                f\"Downloading compressed data to a temporary directory ({compressed_file_path})...\"\n            )\n            subprocess.run(\n                [\"wget\", \"-q\", \"-P\", temp_dir, github_tar_file_path], check=True\n            )\n\n        if not decompressed_dir_path.exists() or refresh:\n            print(f\"Decompressing data...\")\n            subprocess.run(\n                [\"tar\", \"--lzma\", \"-xf\", str(compressed_file_path), \"-C\", temp_dir],\n                check=True,\n            )\n\n        print(f\"Creating xarray.Dataset from the uncompressed data...\")\n        list_of_csv_files = glob.glob(str(decompressed_dir_path / \"*.csv\"))\n\n        datasets = []\n        for csv_file in list_of_csv_files:\n\n            logging.info(f\"Working on {csv_file}...\")\n            # Extract station name from the csv file name\n            station_name = csv_file.split(\"/\")[-1].split(\".\")[0]\n\n            # Load the CSV data into a pandas DataFrame\n            station_df = (\n                pd.read_csv(csv_file, parse_dates=True)\n                .rename(columns={\"datetime\": \"time\"})\n                .set_index(\"time\")\n                .sort_index()\n            )\n\n            # Convert the DataFrame into an xarray DataSet and add station coordinate\n            station_ds = station_df.to_xarray()\n            station_ds = station_ds.assign_coords(station=station_name)\n\n            # Add other coordinates from all_stations_gdf\n            for col in self.all_stations.columns:\n                station_ds.coords[col] = self.all_stations.loc[station_name, col]\n\n            datasets.append(station_ds)\n\n        logging.info(f\"Combining all dataarrays into one dataset...\")\n        all_stations_ds = xr.concat(datasets, dim=\"station\", coords=\"all\")\n        all_stations_ds[\"time\"] = pd.to_datetime(all_stations_ds.time)\n\n        water_year = pd.to_datetime(all_stations_ds.time).map(datetime_to_WY)\n        day_of_water_year = pd.to_datetime(all_stations_ds.time).map(datetime_to_DOWY)\n\n        all_stations_ds.coords[\"WY\"] = (\"time\", water_year)\n        all_stations_ds.coords[\"DOWY\"] = (\"time\", day_of_water_year)\n\n        self.entire_data_archive = all_stations_ds\n\n        print(\n            f\"Done! Entire archive dataset has been added to the station object. Please use the .entire_data_archive attribute to access.\"\n        )\n</code></pre>"},{"location":"automatic_weather_stations/#easysnowdata.automatic_weather_stations.StationCollection.choose_stations","title":"<code>choose_stations(self, stations_gdf)</code>","text":"<p>Choose specific stations for further analysis.</p> <p>This method allows selection of specific stations from the collection for subsequent data processing and analysis.</p> <p>Parameters:</p> Name Type Description Default <code>stations_gdf</code> <code>gpd.GeoDataFrame, str, or list</code> <p>The name(s) or index(es) of the stations to be chosen.</p> required <p>Examples:</p> <p>Choose stations by name:</p> <p>Returns:</p> Type Description <code>None</code> <p>Updates the stations attribute of the class.</p> Source code in <code>easysnowdata/automatic_weather_stations.py</code> <pre><code>def choose_stations(self, stations_gdf):\n    \"\"\"\n    Choose specific stations for further analysis.\n\n    This method allows selection of specific stations from the collection\n    for subsequent data processing and analysis.\n\n    Parameters\n    ----------\n    stations_gdf : gpd.GeoDataFrame, str, or list\n        The name(s) or index(es) of the stations to be chosen.\n\n    Returns\n    -------\n    None\n        Updates the stations attribute of the class.\n\n    Examples\n    --------\n    Choose stations by name:\n    &gt;&gt;&gt; station_collection.choose_stations('Paradise')\n\n    Choose multiple stations by index:\n    &gt;&gt;&gt; station_collection.choose_stations([0, 1, 2])\n    \"\"\"\n    if type(stations_gdf) is str:\n        stations_gdf = self.all_stations.loc[[stations_gdf]]\n    if type(stations_gdf) is list:\n        stations_gdf = self.all_stations.loc[stations_gdf]\n\n    self.stations = stations_gdf\n</code></pre>"},{"location":"automatic_weather_stations/#easysnowdata.automatic_weather_stations.StationCollection.get_all_stations","title":"<code>get_all_stations(self)</code>","text":"<p>Fetches all weather stations from a GeoJSON file hosted on the snotel_ccss_stations GitHub repository.</p> <p>This method retrieves station data, filters based on data availability, and optionally sorts stations by distance to a specified geometry.</p> <p>Returns:</p> Type Description <code>None</code> <p>Updates the all_stations attribute of the class.</p> Source code in <code>easysnowdata/automatic_weather_stations.py</code> <pre><code>def get_all_stations(self):\n    \"\"\"\n    Fetches all weather stations from a GeoJSON file hosted on the snotel_ccss_stations GitHub repository.\n\n    This method retrieves station data, filters based on data availability, and optionally sorts stations\n    by distance to a specified geometry.\n\n    Returns\n    -------\n    None\n        Updates the all_stations attribute of the class.\n\n    Notes\n    -----\n    The method prints information about the retrieved stations and available data access methods.\n    \"\"\"\n    # Read the GeoJSON file\n    all_stations_gdf = gpd.read_file(\n        \"https://github.com/egagli/snotel_ccss_stations/raw/main/all_stations.geojson\"\n    ).set_index(\"code\")\n\n    # # Filter based on data availability\n    if self.data_available:\n        all_stations_gdf = all_stations_gdf[all_stations_gdf[\"csvData\"]]\n\n    # # Filter out SNOTEL stations if not required\n    # if not self.snotel_stations:\n    #     all_stations_gdf = all_stations_gdf[all_stations_gdf[\"network\"] != \"SNOTEL\"]\n\n    # # Filter out CCSS stations if not required\n    # if not self.ccss_stations:\n    #     all_stations_gdf = all_stations_gdf[all_stations_gdf[\"network\"] != \"CCSS\"]\n\n    # If a geometry is passed in, calculate the distance to this geometry for each station\n    if self.sortby_dist_to_geom is not None:\n        print(f\"Sorting by distance to given geometry. See dist_km column.\")\n        geom_gdf = convert_bbox_to_geodataframe(self.sortby_dist_to_geom)\n        proj = \"EPSG:32611\"\n        all_stations_gdf[\"dist_km\"] = (\n            all_stations_gdf.to_crs(proj).distance(\n                geom_gdf.to_crs(proj).geometry[0]\n            )\n            / 1000\n        )\n        all_stations_gdf = all_stations_gdf.sort_values(\"dist_km\")\n\n    self.all_stations = all_stations_gdf\n    print(\n        f\"Geodataframe with all stations has been added to the Station object. Please use the .all_stations attribute to access.\"\n    )\n    print(\n        f\"Use the .get_data(stations=geodataframe/string/list,variables=string/list,start_date=str,end_date=str) method to fetch data for specific stations and variables.\"\n    )\n</code></pre>"},{"location":"automatic_weather_stations/#easysnowdata.automatic_weather_stations.StationCollection.get_data","title":"<code>get_data(self, stations='679_WA_SNTL', variables=None, start_date='1900-01-01', end_date='2025-03-03')</code>","text":"<p>Retrieves data for the specified stations and variables.</p> <p>This method fetches data for chosen stations and variables within a specified date range.</p> <p>Parameters:</p> Name Type Description Default <code>stations</code> <code>geodataframe, str, or list</code> <p>The stations to retrieve data for. Default is '679_WA_SNTL'.</p> <code>'679_WA_SNTL'</code> <code>variables</code> <code>str or list</code> <p>The variables to retrieve data for. Default is None.</p> <code>None</code> <code>start_date</code> <code>str</code> <p>The start date for the data. Default is '1900-01-01'.</p> <code>'1900-01-01'</code> <code>end_date</code> <code>str</code> <p>The end date for the data. Default is today's date.</p> <code>'2025-03-03'</code> <p>Returns:</p> Type Description <code>None</code> <p>Updates the data attribute of the class.</p> Source code in <code>easysnowdata/automatic_weather_stations.py</code> <pre><code>def get_data(self, stations=\"679_WA_SNTL\", variables=None, start_date='1900-01-01', end_date=today):\n    \"\"\"\n    Retrieves data for the specified stations and variables.\n\n    This method fetches data for chosen stations and variables within a specified date range.\n\n    Parameters\n    ----------\n    stations : geodataframe, str, or list, optional\n        The stations to retrieve data for. Default is '679_WA_SNTL'.\n    variables : str or list, optional\n        The variables to retrieve data for. Default is None.\n    start_date : str, optional\n        The start date for the data. Default is '1900-01-01'.\n    end_date : str, optional\n        The end date for the data. Default is today's date.\n\n    Returns\n    -------\n    None\n        Updates the data attribute of the class.\n\n    Notes\n    -----\n    The behavior of this method varies based on the number of stations chosen and the specified variables.\n    \"\"\"\n\n    self.choose_stations(stations)\n\n    if len(self.stations) == 1:\n        if variables is None:\n            print(\n                f\"Only one station chosen with variables=None. Default behavior fetches all variables for this station.\"\n            )\n            self.get_single_station_data(start_date=start_date, end_date=end_date)\n        else:\n            self.get_single_station_data(variables=variables, start_date=start_date, end_date=end_date)\n    else:\n        if variables is None:\n            print(\n                f\"Multiple stations chosen with variables=None. Default behavior fetches WTEQ for all stations.\"\n            )\n            self.get_multiple_station_data(start_date=start_date, end_date=end_date)\n        else:\n            self.get_multiple_station_data(variables=variables, start_date=start_date, end_date=end_date)\n</code></pre>"},{"location":"automatic_weather_stations/#easysnowdata.automatic_weather_stations.StationCollection.get_entire_data_archive","title":"<code>get_entire_data_archive(self, refresh=True, temp_dir='/tmp/')</code>","text":"<p>Downloads, decompresses and processes the entire automatic weather station data archive.</p> <p>This method retrieves a compressed file containing all station data, processes it, and creates an xarray Dataset.</p> <p>Parameters:</p> Name Type Description Default <code>refresh</code> <code>bool</code> <p>If True, the compressed data file will be redownloaded. Default is True.</p> <code>True</code> <code>temp_dir</code> <code>str</code> <p>The directory where the compressed data file will be downloaded and decompressed. Default is '/tmp/'.</p> <code>'/tmp/'</code> <p>Returns:</p> Type Description <code>Dataset</code> <p>An xarray Dataset containing the processed weather station data for all stations.</p> Source code in <code>easysnowdata/automatic_weather_stations.py</code> <pre><code>def get_entire_data_archive(self, refresh: bool = True, temp_dir: str = \"/tmp/\") -&gt; xr.Dataset:\n    \"\"\"\n    Downloads, decompresses and processes the entire automatic weather station data archive.\n\n    This method retrieves a compressed file containing all station data, processes it, and creates an xarray Dataset.\n\n    Parameters\n    ----------\n    refresh : bool, optional\n        If True, the compressed data file will be redownloaded. Default is True.\n    temp_dir : str, optional\n        The directory where the compressed data file will be downloaded and decompressed. Default is '/tmp/'.\n\n    Returns\n    -------\n    xarray.Dataset\n        An xarray Dataset containing the processed weather station data for all stations.\n\n    Notes\n    -----\n    The method prints messages indicating the progress of data retrieval, decompression, and processing.\n    \"\"\"\n\n    github_tar_file_path = \"https://github.com/egagli/snotel_ccss_stations/raw/main/data/all_station_data.tar.lzma\"\n    compressed_file_path = pathlib.Path(temp_dir, \"all_station_data.tar.lzma\")\n    decompressed_dir_path = pathlib.Path(temp_dir, \"data\")\n\n    if not compressed_file_path.exists() or refresh:\n        print(\n            f\"Downloading compressed data to a temporary directory ({compressed_file_path})...\"\n        )\n        subprocess.run(\n            [\"wget\", \"-q\", \"-P\", temp_dir, github_tar_file_path], check=True\n        )\n\n    if not decompressed_dir_path.exists() or refresh:\n        print(f\"Decompressing data...\")\n        subprocess.run(\n            [\"tar\", \"--lzma\", \"-xf\", str(compressed_file_path), \"-C\", temp_dir],\n            check=True,\n        )\n\n    print(f\"Creating xarray.Dataset from the uncompressed data...\")\n    list_of_csv_files = glob.glob(str(decompressed_dir_path / \"*.csv\"))\n\n    datasets = []\n    for csv_file in list_of_csv_files:\n\n        logging.info(f\"Working on {csv_file}...\")\n        # Extract station name from the csv file name\n        station_name = csv_file.split(\"/\")[-1].split(\".\")[0]\n\n        # Load the CSV data into a pandas DataFrame\n        station_df = (\n            pd.read_csv(csv_file, parse_dates=True)\n            .rename(columns={\"datetime\": \"time\"})\n            .set_index(\"time\")\n            .sort_index()\n        )\n\n        # Convert the DataFrame into an xarray DataSet and add station coordinate\n        station_ds = station_df.to_xarray()\n        station_ds = station_ds.assign_coords(station=station_name)\n\n        # Add other coordinates from all_stations_gdf\n        for col in self.all_stations.columns:\n            station_ds.coords[col] = self.all_stations.loc[station_name, col]\n\n        datasets.append(station_ds)\n\n    logging.info(f\"Combining all dataarrays into one dataset...\")\n    all_stations_ds = xr.concat(datasets, dim=\"station\", coords=\"all\")\n    all_stations_ds[\"time\"] = pd.to_datetime(all_stations_ds.time)\n\n    water_year = pd.to_datetime(all_stations_ds.time).map(datetime_to_WY)\n    day_of_water_year = pd.to_datetime(all_stations_ds.time).map(datetime_to_DOWY)\n\n    all_stations_ds.coords[\"WY\"] = (\"time\", water_year)\n    all_stations_ds.coords[\"DOWY\"] = (\"time\", day_of_water_year)\n\n    self.entire_data_archive = all_stations_ds\n\n    print(\n        f\"Done! Entire archive dataset has been added to the station object. Please use the .entire_data_archive attribute to access.\"\n    )\n</code></pre>"},{"location":"automatic_weather_stations/#easysnowdata.automatic_weather_stations.StationCollection.get_multiple_station_data","title":"<code>get_multiple_station_data(self, variables='WTEQ', start_date='1900-01-01', end_date='2025-03-03')</code>","text":"<p>Fetches data for multiple stations and specified variables.</p> <p>This method retrieves data for multiple stations and specified variables within a given date range.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>str or list</code> <p>The variable(s) to fetch. Default is 'WTEQ' (water equivalent of snow on the ground).</p> <code>'WTEQ'</code> <code>start_date</code> <code>str</code> <p>The start date for the data. Default is '1900-01-01'.</p> <code>'1900-01-01'</code> <code>end_date</code> <code>str</code> <p>The end date for the data. Default is today's date.</p> <code>'2025-03-03'</code> <p>Returns:</p> Type Description <code>None</code> <p>Updates the data attribute of the class with an xarray Dataset.</p> Source code in <code>easysnowdata/automatic_weather_stations.py</code> <pre><code>def get_multiple_station_data(self, variables=\"WTEQ\", start_date='1900-01-01', end_date=today):\n    \"\"\"\n    Fetches data for multiple stations and specified variables.\n\n    This method retrieves data for multiple stations and specified variables within a given date range.\n\n    Parameters\n    ----------\n    variables : str or list, optional\n        The variable(s) to fetch. Default is 'WTEQ' (water equivalent of snow on the ground).\n    start_date : str, optional\n        The start date for the data. Default is '1900-01-01'.\n    end_date : str, optional\n        The end date for the data. Default is today's date.\n\n    Returns\n    -------\n    None\n        Updates the data attribute of the class with an xarray Dataset.\n\n    Notes\n    -----\n    The method prints messages indicating the progress of data retrieval and processing.\n    \"\"\"\n\n    dataarrays = []\n\n    if isinstance(variables, str):\n        variables = [variables]\n\n    for variable in variables:\n\n        self.station_dict = {}\n\n        for station in tqdm.tqdm(self.stations.index):\n            try:\n                tmp = pd.read_csv(\n                    f\"https://raw.githubusercontent.com/egagli/snotel_ccss_stations/main/data/{station}.csv\",\n                    index_col=\"datetime\",\n                    parse_dates=True,\n                )[variable]\n                self.station_dict[station] = tmp\n            except:\n                print(f\"failed to retrieve {station}\")\n\n        station_data_df = pd.DataFrame.from_dict(self.station_dict).loc[start_date:end_date]\n\n        setattr(self, f\"{variable}\", station_data_df)\n        print(\n            f\"{variable} dataframe has been added to the Station object. Please use the .{variable} attribute to access the dataframe.\"\n        )\n\n        station_data_da = (\n            station_data_df.to_xarray()\n            .to_dataarray(dim=\"station\")\n            .rename(f\"{variable}\")\n            .rename({\"datetime\": \"time\"})\n        )\n\n        dataarrays.append(station_data_da)\n\n    all_stations_ds = xr.merge(dataarrays)\n\n    for col in self.stations.columns:\n        all_stations_ds = all_stations_ds.assign_coords(\n            {f\"{col}\": (\"station\", self.stations[f\"{col}\"])}\n        )\n\n    all_stations_ds[\"time\"] = pd.to_datetime(all_stations_ds.time)\n\n    water_year = pd.to_datetime(all_stations_ds.time).map(datetime_to_WY)\n    day_of_water_year = pd.to_datetime(all_stations_ds.time).map(datetime_to_DOWY)\n\n    all_stations_ds.coords[\"WY\"] = (\"time\", water_year)\n    all_stations_ds.coords[\"DOWY\"] = (\"time\", day_of_water_year)\n\n    self.data = all_stations_ds\n    print(\n        f\"Full {variables} dataset has been added to the station object. Please use the .data attribute to access the dataset.\"\n    )\n</code></pre>"},{"location":"automatic_weather_stations/#easysnowdata.automatic_weather_stations.StationCollection.get_single_station_data","title":"<code>get_single_station_data(self, variables=['WTEQ', 'SNWD', 'PRCPSA', 'TAVG', 'TMIN', 'TMAX'], start_date='1900-01-01', end_date='2025-03-03')</code>","text":"<p>Retrieves data for a single weather station.</p> <p>This method fetches data for specified variables from a single station within a given date range.</p> <p>Parameters:</p> Name Type Description Default <code>variables</code> <code>list</code> <p>List of variables to include in the data. Default is ['WTEQ','SNWD','PRCPSA','TAVG','TMIN','TMAX'].</p> <code>['WTEQ', 'SNWD', 'PRCPSA', 'TAVG', 'TMIN', 'TMAX']</code> <code>start_date</code> <code>str</code> <p>The start date for the data. Default is '1900-01-01'.</p> <code>'1900-01-01'</code> <code>end_date</code> <code>str</code> <p>The end date for the data. Default is today's date.</p> <code>'2025-03-03'</code> <p>Returns:</p> Type Description <code>None</code> <p>Updates the data attribute of the class.</p> Source code in <code>easysnowdata/automatic_weather_stations.py</code> <pre><code>def get_single_station_data(\n    self, variables=[\"WTEQ\", \"SNWD\", \"PRCPSA\", \"TAVG\", \"TMIN\", \"TMAX\"], start_date='1900-01-01', end_date=today\n):\n    \"\"\"\n    Retrieves data for a single weather station.\n\n    This method fetches data for specified variables from a single station within a given date range.\n\n    Parameters\n    ----------\n    variables : list, optional\n        List of variables to include in the data. Default is ['WTEQ','SNWD','PRCPSA','TAVG','TMIN','TMAX'].\n    start_date : str, optional\n        The start date for the data. Default is '1900-01-01'.\n    end_date : str, optional\n        The end date for the data. Default is today's date.\n\n    Returns\n    -------\n    None\n        Updates the data attribute of the class.\n\n    Notes\n    -----\n    The method prints a message indicating that the data has been added to the Station object.\n    \"\"\"\n\n    single_station_df = pd.read_csv(\n        f\"https://raw.githubusercontent.com/egagli/snotel_ccss_stations/main/data/{self.stations.index.values[0]}.csv\",\n        index_col=\"datetime\",\n        parse_dates=True,\n    )\n\n    columns_to_drop = [\n        col for col in single_station_df.columns if col not in variables\n    ]\n    single_station_df = single_station_df.drop(columns=columns_to_drop).loc[start_date:end_date]\n    self.data = single_station_df\n    print(\n        f\"Dataframe has been added to the Station object. Please use the .data attribute to access.\"\n    )\n</code></pre>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v001-date","title":"v0.0.1 - Date","text":"<p>Improvement:</p> <ul> <li>TBD</li> </ul> <p>New Features:</p> <ul> <li>TBD</li> </ul>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/egagli/easysnowdata/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with <code>bug</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with <code>enhancement</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#write-documentation","title":"Write Documentation","text":"<p>easysnowdata could always use more documentation, whether as part of the official easysnowdata docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contributing/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/egagli/easysnowdata/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions are welcome :)</li> </ul>"},{"location":"contributing/#get-started","title":"Get Started!","text":"<p>Ready to contribute? Here's how to set up easysnowdata for local development.</p> <ol> <li> <p>Fork the easysnowdata repo on GitHub.</p> </li> <li> <p>Clone your fork locally:</p> <pre><code>$ git clone git@github.com:your_name_here/easysnowdata.git\n</code></pre> </li> <li> <p>Install your local copy into a virtualenv. Assuming you have     virtualenvwrapper installed, this is how you set up your fork for     local development:</p> <pre><code>$ mkvirtualenv easysnowdata\n$ cd easysnowdata/\n$ python setup.py develop\n</code></pre> </li> <li> <p>Create a branch for local development:</p> <pre><code>$ git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes locally.</p> </li> <li> <p>When you're done making changes, check that your changes pass flake8     and the tests, including testing other Python versions with tox:</p> <pre><code>$ flake8 easysnowdata tests\n$ python setup.py test or pytest\n$ tox\n</code></pre> <p>To get flake8 and tox, just pip install them into your virtualenv.</p> </li> <li> <p>Commit your changes and push your branch to GitHub:</p> <pre><code>$ git add .\n$ git commit -m \"Your detailed description of your changes.\"\n$ git push origin name-of-your-bugfix-or-feature\n</code></pre> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated.     Put your new functionality into a function with a docstring, and add     the feature to the list in README.rst.</li> <li>The pull request should work for Python 3.8 and later, and     for PyPy. Check https://github.com/egagli/easysnowdata/pull_requests and make sure that the tests pass for all     supported Python versions.</li> </ol>"},{"location":"easysnowdata/","title":"easysnowdata module","text":"<p>Main module.</p>"},{"location":"faq/","title":"FAQ","text":""},{"location":"hydroclimatology/","title":"hydrology module","text":""},{"location":"hydroclimatology/#easysnowdata.hydroclimatology.get_era5","title":"<code>get_era5(bbox_input=None, version='ERA5', cadence='HOURLY', source='auto', start_date=None, end_date=None, variables=None, initialize_ee=True)</code>","text":"<p>Retrieves ERA5 reanalysis data using optimal source selection.</p> <p>By default, this function uses Google Earth Engine for most requests, but automatically  switches to the high-resolution ARCO-ERA5 Zarr dataset from Google Cloud Storage for hourly ERA5 data due to its superior performance and coverage for that specific  combination. Please note, these datasets may be different from the original ERA5 data hosted on the Copernicus Climate Data Store (CDS).</p> <p>Parameters:</p> Name Type Description Default <code>bbox_input</code> <code>geopandas.geodataframe.GeoDataFrame | tuple | shapely.geometry.base.BaseGeometry | None</code> <p>The spatial bounding box for subsetting. If None, returns global data.</p> <code>None</code> <code>version</code> <code>str</code> <p>Version of ERA5 data. Options are 'ERA5' or 'ERA5_LAND'. Default is 'ERA5'.</p> <code>'ERA5'</code> <code>cadence</code> <code>str</code> <p>Temporal resolution. Options are 'HOURLY', 'DAILY', or 'MONTHLY'. Default is 'HOURLY'.</p> <code>'HOURLY'</code> <code>source</code> <code>str</code> <p>Data source to use: \"auto\" (smart selection), \"GEE\" (Google Earth Engine), or  \"GCS\" (Google Cloud Storage). Default is \"auto\", which uses GCS for ERA5 hourly data and GEE for everything else.</p> <code>'auto'</code> <code>start_date</code> <code>str | None</code> <p>Start date in 'YYYY-MM-DD' format. If None, uses earliest available date.</p> <code>None</code> <code>end_date</code> <code>str | None</code> <p>End date in 'YYYY-MM-DD' format. If None, uses latest available date.</p> <code>None</code> <code>variables</code> <code>str | list | None</code> <p>Variable(s) to select. If None, returns all variables. Only applicable for GEE source.</p> <code>None</code> <code>initialize_ee</code> <code>bool</code> <p>Whether to initialize Earth Engine. Default is True. Only applicable for GEE source.</p> <code>True</code> <p>Examples:</p> <p>Get hourly ERA5 data (automatically uses ARCO-ERA5 from GCS):</p> <p>Returns:</p> Type Description <code>Dataset</code> <p>An xarray Dataset containing ERA5 reanalysis data for the specified region.</p> Source code in <code>easysnowdata/hydroclimatology.py</code> <pre><code>def get_era5(\n    bbox_input: gpd.GeoDataFrame | tuple | shapely.geometry.base.BaseGeometry | None = None,\n    version: str = \"ERA5\",\n    cadence: str = \"HOURLY\",\n    source: str = \"auto\",  # \"auto\", \"GEE\", or \"GCS\"\n    start_date: str | None = None,\n    end_date: str | None = None,\n    variables: str | list | None = None,\n    initialize_ee: bool = True,\n) -&gt; xr.Dataset:\n    \"\"\"\n    Retrieves ERA5 reanalysis data using optimal source selection.\n\n    By default, this function uses Google Earth Engine for most requests, but automatically \n    switches to the high-resolution ARCO-ERA5 Zarr dataset from Google Cloud Storage for\n    hourly ERA5 data due to its superior performance and coverage for that specific \n    combination. Please note, these datasets may be different from the original ERA5 data\n    hosted on the Copernicus Climate Data Store (CDS).\n\n    Parameters\n    ----------\n    bbox_input : geopandas.GeoDataFrame or tuple or shapely.Geometry, optional\n        The spatial bounding box for subsetting. If None, returns global data.\n    version : str, optional\n        Version of ERA5 data. Options are 'ERA5' or 'ERA5_LAND'. Default is 'ERA5'.\n    cadence : str, optional\n        Temporal resolution. Options are 'HOURLY', 'DAILY', or 'MONTHLY'. Default is 'HOURLY'.\n    source : str, optional\n        Data source to use: \"auto\" (smart selection), \"GEE\" (Google Earth Engine), or \n        \"GCS\" (Google Cloud Storage). Default is \"auto\", which uses GCS for ERA5 hourly data\n        and GEE for everything else.\n    start_date : str, optional\n        Start date in 'YYYY-MM-DD' format. If None, uses earliest available date.\n    end_date : str, optional\n        End date in 'YYYY-MM-DD' format. If None, uses latest available date.\n    variables : str or list, optional\n        Variable(s) to select. If None, returns all variables. Only applicable for GEE source.\n    initialize_ee : bool, optional\n        Whether to initialize Earth Engine. Default is True. Only applicable for GEE source.\n\n    Returns\n    -------\n    xarray.Dataset\n        An xarray Dataset containing ERA5 reanalysis data for the specified region.\n\n    Examples\n    --------\n    Get hourly ERA5 data (automatically uses ARCO-ERA5 from GCS):\n\n    &gt;&gt;&gt; bbox = (-121.94, 46.72, -121.54, 46.99)\n    &gt;&gt;&gt; era5_ds = get_era5(bbox_input=bbox)  # Uses GCS for hourly ERA5\n    &gt;&gt;&gt; era5_ds[\"2m_temperature\"].sel(time=\"2020-05-26\").mean(dim=\"time\").plot()\n\n    Get monthly ERA5 data (uses Google Earth Engine):\n\n    &gt;&gt;&gt; era5_gee = get_era5(\n    ...     bbox_input=bbox,\n    ...     cadence=\"MONTHLY\", \n    ...     start_date=\"2020-01-01\",\n    ...     end_date=\"2020-12-31\",\n    ...     variables=[\"temperature_2m\"]\n    ... )  # Uses GEE for monthly data\n    &gt;&gt;&gt; era5_gee[\"temperature_2m\"].plot()\n\n    Force using GEE for hourly ERA5 data:\n\n    &gt;&gt;&gt; era5_hourly_gee = get_era5(\n    ...     bbox_input=bbox,\n    ...     source=\"GEE\",\n    ...     start_date=\"2020-01-01\",\n    ...     end_date=\"2020-01-02\"\n    ... )  # Explicitly uses GEE for hourly data\n\n    Notes\n    -----\n    - The function automatically selects the optimal data source based on your request\n    - Hourly ERA5 data comes from ARCO-ERA5 on Google Cloud Storage by default\n    - All other combinations use Google Earth Engine\n    - You can override the automatic source selection by explicitly setting the source parameter\n    - Please note, these data are not the original ERA5 data but have been processed and optimized for cloud access. Each dataset will also have an assosciated latency different from the original dataset. The most up-to-date information can be found at: https://cds.climate.copernicus.eu/datasets\n\n\n    Data citations:\n    - GEE+GCS: Hersbach, H., Bell, B., Berrisford, P., et al. (2020). The ERA5 global reanalysis. Quarterly Journal of the Royal Meteorological Society, 146(730), 1999-2049.\n    - GCS: Carver, Robert W, and Merose, Alex. (2023): ARCO-ERA5: An Analysis-Ready Cloud-Optimized Reanalysis Dataset. 22nd Conf. on AI for Env. Science, Denver, CO, Amer. Meteo. Soc, 4A.1, https://ams.confex.com/ams/103ANNUAL/meetingapp.cgi/Paper/415842\n    \"\"\"\n    # Determine the appropriate source based on parameters\n    effective_source = source.upper()\n\n    if effective_source == \"AUTO\":\n        if version == \"ERA5\" and cadence == \"HOURLY\":\n            effective_source = \"GCS\"  # Use ARCO dataset for hourly ERA5\n        else:\n            effective_source = \"GEE\"  # Default to GEE for all other combinations\n\n    # Convert bbox to GeoDataFrame format for consistent handling\n    bbox_gdf = convert_bbox_to_geodataframe(bbox_input) if bbox_input is not None else None\n\n    # Option 1: Google Cloud Storage (GCS) - ARCO-ERA5 Zarr dataset\n    if effective_source == \"GCS\":\n        # Verify we're using ERA5 hourly (the only supported option for GCS)\n        if version != \"ERA5\" or cadence != \"HOURLY\":\n            raise ValueError(f\"GCS source only supports ERA5 hourly data, not {version} {cadence}\")\n\n        era5_ds = xr.open_zarr(\n            'gs://gcp-public-data-arco-era5/ar/full_37-1h-0p25deg-chunk-1.zarr-v3',\n            chunks=None,\n            storage_options=dict(token='anon'),\n        )\n\n        # Apply time filtering if specified\n        if start_date is not None and end_date is not None:\n            era5_ds = era5_ds.sel(time=slice(start_date, end_date))\n        else:\n            era5_ds = era5_ds.sel(time=slice(era5_ds.attrs['valid_time_start'], \n                                            era5_ds.attrs['valid_time_stop']))\n\n        # Set CRS and normalize longitude coordinates\n        era5_ds.rio.write_crs(\"EPSG:4326\", inplace=True)\n        era5_ds = era5_ds.assign_coords(\n            longitude=(((era5_ds.longitude + 180) % 360) - 180)\n        ).sortby('longitude')\n\n        # Add coordinate attributes\n        era5_ds[\"longitude\"].attrs[\"long_name\"] = \"longitude\"\n        era5_ds[\"longitude\"].attrs[\"units\"] = \"degrees_east\"\n\n        # Apply spatial subsetting if specified\n        if bbox_gdf is not None:\n            era5_ds = era5_ds.rio.clip_box(*bbox_gdf.total_bounds, crs=bbox_gdf.crs)\n\n        # Add metadata\n        era5_ds.attrs[\"data_citation\"] = (\n            \"Carver, Robert W, and Merose, Alex. (2023): ARCO-ERA5: An Analysis-Ready \"\n            \"Cloud-Optimized Reanalysis Dataset. 22nd Conf. on AI for Env. Science, \"\n            \"Denver, CO, Amer. Meteo. Soc, 4A.1, \"\n            \"https://ams.confex.com/ams/103ANNUAL/meetingapp.cgi/Paper/415842\"\n        )\n        era5_ds.attrs[\"source\"] = \"Google Cloud Storage (ARCO-ERA5)\"\n        era5_ds.attrs[\"version\"] = version\n        era5_ds.attrs[\"cadence\"] = cadence\n\n        return era5_ds\n\n    # Option 2: Google Earth Engine (GEE)\n    elif effective_source == \"GEE\":\n        # Initialize Earth Engine if requested\n        if initialize_ee:\n            ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')\n        else:\n            print(\"Earth Engine initialization skipped. Please ensure EE is initialized.\")\n\n        # Collection name mapping\n        collection_mapping = {\n            (\"ERA5_LAND\", \"HOURLY\"): \"ECMWF/ERA5_LAND/HOURLY\",\n            (\"ERA5_LAND\", \"DAILY\"): \"ECMWF/ERA5_LAND/DAILY_AGGR\",\n            (\"ERA5_LAND\", \"MONTHLY\"): \"ECMWF/ERA5_LAND/MONTHLY_AGGR\",\n            (\"ERA5\", \"HOURLY\"): \"ECMWF/ERA5/HOURLY\",\n            (\"ERA5\", \"DAILY\"): \"ECMWF/ERA5/DAILY\",\n            (\"ERA5\", \"MONTHLY\"): \"ECMWF/ERA5/MONTHLY\"\n        }\n\n        # Get collection name\n        collection_key = (version, cadence)\n        if collection_key not in collection_mapping:\n            raise ValueError(f\"Invalid combination of version '{version}' and cadence '{cadence}'\")\n\n        collection_name = collection_mapping[collection_key]\n\n        # Initialize image collection\n        image_collection = ee.ImageCollection(collection_name)\n\n        # Apply date filtering if specified\n        if start_date is not None and end_date is not None:\n            end_date = end_date + \"T23:59:59\"  # Include full end date\n            image_collection = image_collection.filterDate(start_date, end_date)\n\n        # Apply variable selection if specified\n        if variables is not None:\n            if isinstance(variables, str):\n                variables = [variables]\n            image_collection = image_collection.select(variables)\n\n        # Get projection from first image\n        image = image_collection.first()\n        projection = image.select(0).projection()\n\n        # Prepare geometry for GEE\n        geometry = None\n        if bbox_gdf is not None:\n            geometry = tuple(bbox_gdf.total_bounds)\n\n        # Load dataset\n        ds = xr.open_dataset(\n            image_collection,\n            engine='ee',\n            geometry=geometry,\n            projection=projection,\n            chunks=None\n        )\n\n        # Clean up dimensions and coordinate names\n        ds = (ds\n              .transpose('time', 'lat', 'lon')\n              .rename({'lat': 'latitude', 'lon': 'longitude'})\n              .rio.set_spatial_dims(x_dim='longitude', y_dim='latitude'))\n\n        # Add metadata\n        ds.attrs['data_citation'] = (\n            \"Hersbach, H., Bell, B., Berrisford, P., et al. (2020). The ERA5 global reanalysis. \"\n            \"Quarterly Journal of the Royal Meteorological Society, 146(730), 1999-2049.\"\n        )\n        ds.attrs['version'] = version\n        ds.attrs['cadence'] = cadence\n        ds.attrs[\"source\"] = \"Google Earth Engine\"\n\n        return ds\n\n    else:\n        raise ValueError(\"Source must be 'auto', 'GEE' (Google Earth Engine), or 'GCS' (Google Cloud Storage)\")\n</code></pre>"},{"location":"hydroclimatology/#easysnowdata.hydroclimatology.get_grdc_major_river_basins_of_the_world","title":"<code>get_grdc_major_river_basins_of_the_world(bbox_input=None)</code>","text":"<p>Retrieves GRDC Major River Basins of the World dataset.</p> <p>This function downloads and loads the Global Runoff Data Centre's (GRDC) Major River Basins  dataset, which contains 520 river/lake basins considered major in size or hydro-political  importance. The basins include both exorheic drainage (flowing to oceans) and endorheic  drainage (inland sinks/lakes) systems.</p> <p>Parameters:</p> Name Type Description Default <code>bbox_input</code> <code>geopandas.geodataframe.GeoDataFrame | tuple | shapely.geometry.base.BaseGeometry | None</code> <p>The bounding box for spatial subsetting. If None, the entire global dataset is returned.</p> <code>None</code> <p>Examples:</p> <p>Get all major river basins...</p> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>A GeoDataFrame containing the GRDC major river basins with associated attributes.</p> Source code in <code>easysnowdata/hydroclimatology.py</code> <pre><code>def get_grdc_major_river_basins_of_the_world(\n    bbox_input: gpd.GeoDataFrame | tuple | shapely.geometry.base.BaseGeometry | None = None,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"\n    Retrieves GRDC Major River Basins of the World dataset.\n\n    This function downloads and loads the Global Runoff Data Centre's (GRDC) Major River Basins \n    dataset, which contains 520 river/lake basins considered major in size or hydro-political \n    importance. The basins include both exorheic drainage (flowing to oceans) and endorheic \n    drainage (inland sinks/lakes) systems.\n\n    Parameters\n    ----------\n    bbox_input : geopandas.GeoDataFrame, tuple, or Shapely Geometry, optional\n        The bounding box for spatial subsetting. If None, the entire global dataset is returned.\n\n    Returns\n    -------\n    geopandas.GeoDataFrame\n        A GeoDataFrame containing the GRDC major river basins with associated attributes.\n\n    Examples\n    --------\n    Get all major river basins...\n\n    &gt;&gt;&gt; basins = get_grdc_basins()\n    &gt;&gt;&gt; basins.plot()\n\n    Get basins for a specific region...\n\n    &gt;&gt;&gt; bbox = (-121.94, 46.72, -121.54, 46.99)\n    &gt;&gt;&gt; regional_basins = get_grdc_basins(bbox_input=bbox)\n    &gt;&gt;&gt; regional_basins.plot()\n\n    Notes\n    -----\n    This dataset incorporates data from HydroSHEDS database which is \u00a9 World Wildlife Fund, Inc. \n    (2006-2013) and has been used under license.\n\n    Data citation:\n    GRDC (2020): GRDC Major River Basins. Global Runoff Data Centre. 2nd, rev. ed. \n    Koblenz: Federal Institute of Hydrology (BfG).\n    \"\"\"\n\n    url = \"https://datacatalogfiles.worldbank.org/ddh-published/0041426/DR0051689/major_basins_of_the_world_0_0_0.zip\"\n\n    # Convert bbox to GeoDataFrame if provided\n    bbox_gdf = convert_bbox_to_geodataframe(bbox_input) if bbox_input is not None else None\n\n    # Load the data\n    basins_gdf = gpd.read_file(\"zip+\" + url)\n\n    # Clip to bbox if provided\n    if bbox_gdf is not None:\n        basins_gdf = basins_gdf.clip(bbox_gdf)\n    else:\n        print(\"No spatial subsetting because bbox_input was not provided.\")\n\n    # Add citation to attributes\n    basins_gdf.attrs[\"data_citation\"] = \"GRDC (2020): GRDC Major River Basins. Global Runoff Data Centre. 2nd, rev. ed. Koblenz: Federal Institute of Hydrology (BfG).\"\n\n    return basins_gdf\n</code></pre>"},{"location":"hydroclimatology/#easysnowdata.hydroclimatology.get_huc_geometries","title":"<code>get_huc_geometries(bbox_input=None, huc_level='02')</code>","text":"<p>Retrieves Hydrologic Unit Code (HUC) geometries within a specified bounding box and HUC level.</p> <p>This function queries the USGS Water Boundary Dataset (WBD) for HUC geometries. It can retrieve HUC geometries at different levels for a specified region defined by a bounding box. If no  bounding box is provided, it retrieves HUC geometries for the entire United States.</p> <p>Parameters:</p> Name Type Description Default <code>bbox_input</code> <code>geopandas.geodataframe.GeoDataFrame | tuple | shapely.geometry.base.BaseGeometry | None</code> <p>The bounding box for spatial subsetting. If None, the entire US dataset is returned.</p> <code>None</code> <code>huc_level</code> <code>str</code> <p>The HUC level to retrieve geometries for. Valid levels are '02', '04', '06', '08', '10', '12'. Default is '02'.</p> <code>'02'</code> <p>Examples:</p> <p>Get HUC geometries for a specific region at HUC level 08...</p> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>A GeoDataFrame containing the retrieved HUC geometries along with associated attributes such as name, area in square kilometers, states, TNMID, and geometry.</p> Source code in <code>easysnowdata/hydroclimatology.py</code> <pre><code>def get_huc_geometries(\n        bbox_input: gpd.GeoDataFrame | tuple | shapely.geometry.base.BaseGeometry | None = None, \n        huc_level: str = \"02\",\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"\n    Retrieves Hydrologic Unit Code (HUC) geometries within a specified bounding box and HUC level.\n\n    This function queries the USGS Water Boundary Dataset (WBD) for HUC geometries. It can retrieve\n    HUC geometries at different levels for a specified region defined by a bounding box. If no \n    bounding box is provided, it retrieves HUC geometries for the entire United States.\n\n    Parameters\n    ----------\n    bbox_input : geopandas.GeoDataFrame, tuple, or Shapely Geometry, optional\n        The bounding box for spatial subsetting. If None, the entire US dataset is returned.\n    huc_level : str, optional\n        The HUC level to retrieve geometries for. Valid levels are '02', '04', '06', '08', '10', '12'.\n        Default is '02'.\n\n    Returns\n    -------\n    geopandas.GeoDataFrame\n        A GeoDataFrame containing the retrieved HUC geometries along with associated attributes\n        such as name, area in square kilometers, states, TNMID, and geometry.\n\n    Examples\n    --------\n    Get HUC geometries for a specific region at HUC level 08...\n\n    &gt;&gt;&gt; huc_data = get_huc_geometries(bbox_input=(-121.94, 46.72, -121.54, 46.99), huc_level=\"08\")\n    &gt;&gt;&gt; huc_data.plot()\n\n    Notes\n    -----\n    This function requires an active Earth Engine session. Make sure to authenticate \n    with Earth Engine before using this function.\n\n    Data citation: \n    Jones, K.A., Niknami, L.S., Buto, S.G., and Decker, D., 2022, \n    Federal standards and procedures for the national Watershed Boundary Dataset (WBD) (5 ed.): \n    U.S. Geological Survey Techniques and Methods 11-A3, 54 p., \n    https://doi.org/10.3133/tm11A3\n    \"\"\"\n\n    ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')\n\n    # Convert bounding box to feature collection to use as region for querying HUC geometries\n    bbox_gdf = convert_bbox_to_geodataframe(bbox_input)\n    bbox_json = bbox_gdf.to_json()\n    featureCollection = ee.FeatureCollection(json.loads(bbox_json))\n\n    # Search Earth Engine USGS WBD collection for HUC geometries\n    huc_gdf = ee.data.listFeatures(\n        {\n            \"assetId\": f\"USGS/WBD/2017/HUC{huc_level}\",\n            \"region\": featureCollection.geometry().getInfo(),\n            \"fileFormat\": \"GEOPANDAS_GEODATAFRAME\",\n        }\n    )\n\n    # Add crs to geodataframe and select relevant columns\n    huc_gdf.crs = \"EPSG:4326\"\n    huc_gdf = huc_gdf[\n        [\n            \"name\",\n            f'huc{huc_level.lstrip(\"0\")}',\n            \"areasqkm\",\n            \"states\",\n            \"tnmid\",\n            \"geometry\",\n        ]\n    ]\n\n    huc_gdf.attrs = {\"Data citation\": \"Jones, K.A., Niknami, L.S., Buto, S.G., and Decker, D., 2022, Federal standards and procedures for the national Watershed Boundary Dataset (WBD) (5 ed.): U.S. Geological Survey Techniques and Methods 11-A3, 54 p., https://doi.org/10.3133/tm11A3\"}\n\n    return huc_gdf\n</code></pre>"},{"location":"hydroclimatology/#easysnowdata.hydroclimatology.get_hydroBASINS","title":"<code>get_hydroBASINS(bbox_input=None, regions='all', level=4)</code>","text":"<p>Retrieves HydroBASINS sub-basin boundaries at specified hierarchical level.</p> <p>This function downloads and loads vectorized polygon layers depicting sub-basin boundaries from the HydroBASINS database. It provides consistently sized and hierarchically nested  sub-basins at different scales, supported by Pfafstetter coding for catchment topology analysis.</p> <p>Parameters:</p> Name Type Description Default <code>bbox_input</code> <code>geopandas.geodataframe.GeoDataFrame | tuple | shapely.geometry.base.BaseGeometry | None</code> <p>The bounding box for spatial subsetting. If None, the entire dataset is returned.</p> <code>None</code> <code>regions</code> <code>str | list</code> <p>Regions to download. Can be 'all' or list of region names. Valid regions are: 'Africa', 'Arctic', 'Asia', 'Australia', 'Europe', 'Greenland', 'North America', 'South America', 'Siberia'. Default is 'all'.</p> <code>'all'</code> <code>level</code> <code>int</code> <p>The hierarchical level (1-12) of sub-basin delineation. Higher levels represent finer subdivisions. Default is 4.</p> <code>4</code> <p>Examples:</p> <p>Get level 4 sub-basins for all regions...</p> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>A GeoDataFrame containing the HydroBASINS sub-basin boundaries with associated attributes.</p> Source code in <code>easysnowdata/hydroclimatology.py</code> <pre><code>def get_hydroBASINS(\n    bbox_input: gpd.GeoDataFrame | tuple | shapely.geometry.base.BaseGeometry | None = None,\n    regions: str | list = \"all\",\n    level: int = 4,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"\n    Retrieves HydroBASINS sub-basin boundaries at specified hierarchical level.\n\n    This function downloads and loads vectorized polygon layers depicting sub-basin boundaries\n    from the HydroBASINS database. It provides consistently sized and hierarchically nested \n    sub-basins at different scales, supported by Pfafstetter coding for catchment topology analysis.\n\n    Parameters\n    ----------\n    bbox_input : geopandas.GeoDataFrame, tuple, or Shapely Geometry, optional\n        The bounding box for spatial subsetting. If None, the entire dataset is returned.\n    regions : str or list, optional\n        Regions to download. Can be 'all' or list of region names. Valid regions are:\n        'Africa', 'Arctic', 'Asia', 'Australia', 'Europe', 'Greenland', 'North America',\n        'South America', 'Siberia'. Default is 'all'.\n    level : int, optional\n        The hierarchical level (1-12) of sub-basin delineation. Higher levels represent\n        finer subdivisions. Default is 4.\n\n    Returns\n    -------\n    geopandas.GeoDataFrame\n        A GeoDataFrame containing the HydroBASINS sub-basin boundaries with associated attributes.\n\n    Examples\n    --------\n    Get level 4 sub-basins for all regions...\n\n    &gt;&gt;&gt; basins = get_hydrobasins()\n    &gt;&gt;&gt; basins.plot()\n\n    Get level 6 sub-basins for North America...\n\n    &gt;&gt;&gt; na_basins = get_hydrobasins(regions=['North America'], level=6)\n    &gt;&gt;&gt; na_basins.plot()\n\n    Notes\n    -----\n    Data citation:\n    Lehner, B., Grill G. (2013). Global river hydrography and network routing: baseline data \n    and new approaches to study the world's large river systems. Hydrological Processes, \n    27(15): 2171\u20132186. https://doi.org/10.1002/hyp.9740\n    \"\"\"\n\n    HYDROBASINS_LEVELS = {\n        1: 'lev01', 2: 'lev02', 3: 'lev03', 4: 'lev04', \n        5: 'lev05', 6: 'lev06', 7: 'lev07', 8: 'lev08',\n        9: 'lev09', 10: 'lev10', 11: 'lev11', 12: 'lev12'\n    }\n\n    HYDROBASINS_REGIONS = {\n        'Africa': 'af', 'Arctic': 'ar', 'Asia': 'as', \n        'Australia': 'au', 'Europe': 'eu', 'Greenland': 'gr',\n        'North America': 'na', 'South America': 'sa', 'Siberia': 'si'\n    }\n\n    # Convert bbox to GeoDataFrame if provided\n    bbox_gdf = convert_bbox_to_geodataframe(bbox_input) if bbox_input is not None else None\n\n    # Handle regions parameter\n    if regions == 'all':\n        regions_to_process = HYDROBASINS_REGIONS\n    else:\n        regions_to_process = {region: HYDROBASINS_REGIONS[region] for region in regions}\n\n    level_code = HYDROBASINS_LEVELS[level]\n    region_gdfs = []\n\n    for region_name, region_code in regions_to_process.items():\n\n        print(f'Getting geometries for {region_name}...')\n        url = f\"https://data.hydrosheds.org/file/hydrobasins/standard/hybas_{region_code}_lev01-12_v1c.zip\"\n\n        if region_name == 'Africa': \n            # Special handling for Africa due to streaming issues\n            print(\"Africa takes a bit longer because we have to temporarily save the file due to read issue...\")\n            with tempfile.TemporaryDirectory() as temp_dir:\n                zip_path = os.path.join(temp_dir, f\"hybas_{region_code}_lev01-12_v1c.zip\")\n\n                response = requests.get(url, stream=True)\n                with open(zip_path, 'wb') as f:\n                    for chunk in response.iter_content(chunk_size=8192):\n                        f.write(chunk)\n\n                with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n                    zip_ref.extractall(temp_dir)\n\n                shp_path = os.path.join(temp_dir, f'hybas_{region_code}_{level_code}_v1c.shp')\n                region_gdf = gpd.read_file(shp_path)\n\n        else:\n\n            region_gdf = gpd.read_file(\"zip+\" + url, layer=f'hybas_{region_code}_{level_code}_v1c')\n\n        region_gdfs.append(region_gdf)\n\n    basins_gdf = pd.concat(region_gdfs)\n\n    # Clip to bbox if provided\n    if bbox_gdf is not None:\n        basins_gdf = basins_gdf.clip(bbox_gdf)\n\n    # Add citation to attributes\n    basins_gdf.attrs[\"data_citation\"] = \"Lehner, B., Grill G. (2013). Global river hydrography and network routing: baseline data and new approaches to study the world's large river systems. Hydrological Processes, 27(15): 2171\u20132186. https://doi.org/10.1002/hyp.9740\"\n\n    return basins_gdf\n</code></pre>"},{"location":"hydroclimatology/#easysnowdata.hydroclimatology.get_koppen_geiger_classes","title":"<code>get_koppen_geiger_classes(bbox_input=None, resolution='0.1 degree')</code>","text":"<p>Retrieves K\u00f6ppen-Geiger climate classification data for a given bounding box and resolution.</p> <p>This function fetches global K\u00f6ppen-Geiger climate classification data from a high-resolution dataset based on constrained CMIP6 projections. It allows for optional spatial subsetting and provides multiple resolution options. The returned DataArray includes a custom plotting function as an attribute.</p> <p>Parameters:</p> Name Type Description Default <code>bbox_input</code> <code>geopandas.geodataframe.GeoDataFrame | tuple | shapely.geometry.base.BaseGeometry | None</code> <p>The bounding box for spatial subsetting. If None, the entire global dataset is returned.</p> <code>None</code> <code>resolution</code> <code>str</code> <p>The spatial resolution of the data. Options are \"1 degree\", \"0.5 degree\", \"0.1 degree\", or \"1 km\". Default is \"0.1 degree\".</p> <code>'0.1 degree'</code> <p>Examples:</p> <p>Get K\u00f6ppen-Geiger climate classification data for the entire globe with a 1-degree resolution, use custom plotting function:</p> <p>Returns:</p> Type Description <code>DataArray</code> <p>A DataArray containing the K\u00f6ppen-Geiger climate classification data, with class information, color map, data citation, and a custom plotting function included as attributes.</p> Source code in <code>easysnowdata/hydroclimatology.py</code> <pre><code>def get_koppen_geiger_classes(\n        bbox_input: gpd.GeoDataFrame | tuple | shapely.geometry.base.BaseGeometry | None = None,\n        resolution: str = \"0.1 degree\",\n) -&gt; xr.DataArray:\n    \"\"\"\n    Retrieves K\u00f6ppen-Geiger climate classification data for a given bounding box and resolution.\n\n    This function fetches global K\u00f6ppen-Geiger climate classification data from a high-resolution dataset\n    based on constrained CMIP6 projections. It allows for optional spatial subsetting and provides\n    multiple resolution options. The returned DataArray includes a custom plotting function as an attribute.\n\n    Parameters\n    ----------\n    bbox_input:\n        The bounding box for spatial subsetting. If None, the entire global dataset is returned.\n    resolution:\n        The spatial resolution of the data. Options are \"1 degree\", \"0.5 degree\", \"0.1 degree\", or \"1 km\".\n        Default is \"0.1 degree\".\n\n    Returns\n    -------\n    xarray.DataArray\n        A DataArray containing the K\u00f6ppen-Geiger climate classification data, with class information,\n        color map, data citation, and a custom plotting function included as attributes.\n\n    Examples\n    --------\n    Get K\u00f6ppen-Geiger climate classification data for the entire globe with a 1-degree resolution, use custom plotting function:\n    &gt;&gt;&gt; koppen_data = get_koppen_geiger_classes(bbox_input=None, resolution=\"1 degree\")\n    &gt;&gt;&gt; koppen_data.attrs['example_plot'](koppen_data)\n    Get K\u00f6ppen-Geiger climate classification data for a specific region with a 1 km resolution, plot using xarray's built-in plotting function\n    &gt;&gt;&gt; koppen_geiger_da = get_koppen_geiger_classes(bbox_input=(-121.94224976, 46.72842173, -121.54136001, 46.99728203), resolution=\"1 km\")\n    &gt;&gt;&gt; koppen_data.plot(cmap=koppen_data.attrs[\"cmap\"])\n\n    Notes\n    -----\n    Data citation:\n\n    Beck, H.E., McVicar, T.R., Vergopolan, N. et al. High-resolution (1 km) K\u00f6ppen-Geiger maps\n    for 1901\u20132099 based on constrained CMIP6 projections. Sci Data 10, 724 (2023).\n    https://doi.org/10.1038/s41597-023-02549-6\n    \"\"\"\n\n    def get_class_info():\n        classes = {\n            1: {\"name\": \"Af\", \"description\": \"Tropical, rainforest\", \"color\": [0, 0, 255]},\n            2: {\"name\": \"Am\", \"description\": \"Tropical, monsoon\", \"color\": [0, 120, 255]},\n            3: {\"name\": \"Aw\", \"description\": \"Tropical, savannah\", \"color\": [70, 170, 250]},\n            4: {\"name\": \"BWh\", \"description\": \"Arid, desert, hot\", \"color\": [255, 0, 0]},\n            5: {\"name\": \"BWk\", \"description\": \"Arid, desert, cold\", \"color\": [255, 150, 150]},\n            6: {\"name\": \"BSh\", \"description\": \"Arid, steppe, hot\", \"color\": [245, 165, 0]},\n            7: {\"name\": \"BSk\", \"description\": \"Arid, steppe, cold\", \"color\": [255, 220, 100]},\n            8: {\"name\": \"Csa\", \"description\": \"Temperate, dry summer, hot summer\", \"color\": [255, 255, 0]},\n            9: {\"name\": \"Csb\", \"description\": \"Temperate, dry summer, warm summer\", \"color\": [200, 200, 0]},\n            10: {\"name\": \"Csc\", \"description\": \"Temperate, dry summer, cold summer\", \"color\": [150, 150, 0]},\n            11: {\"name\": \"Cwa\", \"description\": \"Temperate, dry winter, hot summer\", \"color\": [150, 255, 150]},\n            12: {\"name\": \"Cwb\", \"description\": \"Temperate, dry winter, warm summer\", \"color\": [100, 200, 100]},\n            13: {\"name\": \"Cwc\", \"description\": \"Temperate, dry winter, cold summer\", \"color\": [50, 150, 50]},\n            14: {\"name\": \"Cfa\", \"description\": \"Temperate, no dry season, hot summer\", \"color\": [200, 255, 80]},\n            15: {\"name\": \"Cfb\", \"description\": \"Temperate, no dry season, warm summer\", \"color\": [100, 255, 80]},\n            16: {\"name\": \"Cfc\", \"description\": \"Temperate, no dry season, cold summer\", \"color\": [50, 200, 0]},\n            17: {\"name\": \"Dsa\", \"description\": \"Cold, dry summer, hot summer\", \"color\": [255, 0, 255]},\n            18: {\"name\": \"Dsb\", \"description\": \"Cold, dry summer, warm summer\", \"color\": [200, 0, 200]},\n            19: {\"name\": \"Dsc\", \"description\": \"Cold, dry summer, cold summer\", \"color\": [150, 50, 150]},\n            20: {\"name\": \"Dsd\", \"description\": \"Cold, dry summer, very cold winter\", \"color\": [150, 100, 150]},\n            21: {\"name\": \"Dwa\", \"description\": \"Cold, dry winter, hot summer\", \"color\": [170, 175, 255]},\n            22: {\"name\": \"Dwb\", \"description\": \"Cold, dry winter, warm summer\", \"color\": [90, 120, 220]},\n            23: {\"name\": \"Dwc\", \"description\": \"Cold, dry winter, cold summer\", \"color\": [75, 80, 180]},\n            24: {\"name\": \"Dwd\", \"description\": \"Cold, dry winter, very cold winter\", \"color\": [50, 0, 135]},\n            25: {\"name\": \"Dfa\", \"description\": \"Cold, no dry season, hot summer\", \"color\": [0, 255, 255]},\n            26: {\"name\": \"Dfb\", \"description\": \"Cold, no dry season, warm summer\", \"color\": [55, 200, 255]},\n            27: {\"name\": \"Dfc\", \"description\": \"Cold, no dry season, cold summer\", \"color\": [0, 125, 125]},\n            28: {\"name\": \"Dfd\", \"description\": \"Cold, no dry season, very cold winter\", \"color\": [0, 70, 95]},\n            29: {\"name\": \"ET\", \"description\": \"Polar, tundra\", \"color\": [178, 178, 178]},\n            30: {\"name\": \"EF\", \"description\": \"Polar, frost\", \"color\": [102, 102, 102]}\n        }\n        return classes\n\n\n    def get_class_cmap(classes):\n        colors = {k: [c/255 for c in v[\"color\"]] for k, v in classes.items()}\n        return matplotlib.colors.ListedColormap([colors[i] for i in range(1, 31)])\n\n\n    def plot_classes(self, ax=None, figsize=(8, 10), cbar_orientation='horizontal'):\n        if ax is None:\n            f, ax = plt.subplots(figsize=figsize)\n        else:\n            f = ax.get_figure()\n\n        bounds = np.arange(0.5, 31.5, 1)\n        norm = matplotlib.colors.BoundaryNorm(bounds, self.attrs[\"cmap\"].N)\n\n        im = self.plot(ax=ax, cmap=self.attrs[\"cmap\"], norm=norm, add_colorbar=False)\n\n        ax.set_aspect(\"equal\")\n\n        cbar = f.colorbar(im, ax=ax, orientation=cbar_orientation, aspect=30, pad=0.08)\n\n        cbar.set_ticks(np.arange(1, 31))\n        cbar.set_ticklabels([f\"{v['name']}: {v['description']}\" for k, v in self.attrs[\"class_info\"].items()], fontsize=8)\n\n        if cbar_orientation == 'horizontal':\n            plt.setp(cbar.ax.get_xticklabels(), rotation=60, ha='right', rotation_mode='anchor')\n        else:\n            plt.setp(cbar.ax.get_yticklabels(), rotation=0, ha='right')\n\n        ax.set_xlabel(\"Longitude\")\n        ax.set_ylabel(\"Latitude\")\n        ax.set_title(\"K\u00f6ppen-Geiger climate classification\")\n        f.tight_layout(pad=1.5, w_pad=1.5, h_pad=1.5)\n\n        return f, ax\n\n    bbox_gdf = convert_bbox_to_geodataframe(bbox_input)\n\n    resolution_dict = {\"1 degree\": \"1p0\", \"0.5 degree\": \"0p5\", \"0.1 degree\": \"0p1\", \"1 km\": \"0p00833333\"}\n    resolution = resolution_dict[resolution]\n\n    koppen_geiger_da = rxr.open_rasterio(f\"zip+https://figshare.com/ndownloader/files/45057352/koppen_geiger_tif.zip/1991_2020/koppen_geiger_{resolution}.tif\").squeeze()\n\n    koppen_geiger_da = koppen_geiger_da.rio.clip_box(*bbox_gdf.total_bounds,crs=bbox_gdf.crs)\n\n\n    koppen_geiger_da.attrs[\"class_info\"] = get_class_info()\n    koppen_geiger_da.attrs[\"cmap\"] = get_class_cmap(koppen_geiger_da.attrs[\"class_info\"])\n    koppen_geiger_da.attrs[\"data_citation\"] = \"Beck, H.E., McVicar, T.R., Vergopolan, N. et al. High-resolution (1 km) K\u00f6ppen-Geiger maps for 1901\u20132099 based on constrained CMIP6 projections. Sci Data 10, 724 (2023). https://doi.org/10.1038/s41597-023-02549-6\"\n\n    koppen_geiger_da.attrs['example_plot'] = plot_classes\n\n    return koppen_geiger_da\n</code></pre>"},{"location":"hydroclimatology/#easysnowdata.hydroclimatology.get_ucla_snow_reanalysis","title":"<code>get_ucla_snow_reanalysis(bbox_input=None, variable='SWE_Post', stats='mean', start_date='1984-10-01', end_date='2021-09-30')</code>","text":"<p>Fetches the Margulis UCLA snow reanalysis product for a specified bounding box and time range.</p> <p>This function retrieves snow reanalysis data from the UCLA dataset, allowing users to specify the type of snow data variable, statistical measure, and the temporal range for the data retrieval. The data is then clipped to the specified bounding box and returned as an xarray DataArray.</p> <p>Parameters:</p> Name Type Description Default <code>bbox_input</code> <code>geopandas.geodataframe.GeoDataFrame | tuple | shapely.geometry.base.BaseGeometry | None</code> <p>The bounding box for spatial subsetting. If None, the entire dataset is returned.</p> <code>None</code> <code>variable</code> <code>str</code> <p>The type of snow data variable to retrieve. Options include 'SWE_Post' (Snow Water Equivalent), 'SCA_Post' (Snow Cover Area), and 'SD_Post' (Snow Depth). Default is 'SWE_Post'.</p> <code>'SWE_Post'</code> <code>stats</code> <code>str</code> <p>The ensemble statistic. Options are 'mean', 'std' (standard deviation), 'median', '25pct' (25th percentile), and '75pct' (75th percentile). Default is 'mean'.</p> <code>'mean'</code> <code>start_date</code> <code>str</code> <p>The start date for the data retrieval in 'YYYY-MM-DD' format. Default is '1984-10-01'.</p> <code>'1984-10-01'</code> <code>end_date</code> <code>str</code> <p>The end date for the data retrieval in 'YYYY-MM-DD' format. Default is '2021-09-30'.</p> <code>'2021-09-30'</code> <p>Examples:</p> <p>Get mean Snow Water Equivalent data for a specific region and time period...</p> <p>Returns:</p> Type Description <code>DataArray</code> <p>An xarray DataArray containing the requested snow reanalysis data, clipped to the specified bounding box.</p> Source code in <code>easysnowdata/hydroclimatology.py</code> <pre><code>def get_ucla_snow_reanalysis(bbox_input: gpd.GeoDataFrame | tuple | shapely.geometry.base.BaseGeometry | None = None,\n                             variable: str = 'SWE_Post',\n                             stats: str = 'mean',\n                             start_date: str = '1984-10-01',\n                             end_date: str = '2021-09-30',\n) -&gt; xr.DataArray:\n    \"\"\"\n    Fetches the Margulis UCLA snow reanalysis product for a specified bounding box and time range.\n\n    This function retrieves snow reanalysis data from the UCLA dataset, allowing users to specify\n    the type of snow data variable, statistical measure, and the temporal range for the data retrieval.\n    The data is then clipped to the specified bounding box and returned as an xarray DataArray.\n\n    Parameters\n    ----------\n    bbox_input : geopandas.GeoDataFrame, tuple, or Shapely Geometry, optional\n        The bounding box for spatial subsetting. If None, the entire dataset is returned.\n    variable : str, optional\n        The type of snow data variable to retrieve. Options include 'SWE_Post' (Snow Water Equivalent),\n        'SCA_Post' (Snow Cover Area), and 'SD_Post' (Snow Depth). Default is 'SWE_Post'.\n    stats : str, optional\n        The ensemble statistic. Options are 'mean', 'std' (standard deviation),\n        'median', '25pct' (25th percentile), and '75pct' (75th percentile). Default is 'mean'.\n    start_date : str, optional\n        The start date for the data retrieval in 'YYYY-MM-DD' format. Default is '1984-10-01'.\n    end_date : str, optional\n        The end date for the data retrieval in 'YYYY-MM-DD' format. Default is '2021-09-30'.\n\n    Returns\n    -------\n    xarray.DataArray\n        An xarray DataArray containing the requested snow reanalysis data, clipped to the specified bounding box.\n\n    Examples\n    --------\n    Get mean Snow Water Equivalent data for a specific region and time period...\n\n    &gt;&gt;&gt; swe_reanalysis_da = easysnowdata.hydroclimatology.get_ucla_snow_reanalysis(bbox_input=(-121.94, 46.72, -121.54, 46.99), \n    ...                                     variable='SWE_Post', \n    ...                                     start_date='2000-01-01', \n    ...                                     end_date='2000-12-31')\n    &gt;&gt;&gt; snow_reanalysis_da.isel(time=slice(0, 365, 30)).plot.imshow(col=\"time\",col_wrap=5,cmap=\"Blues\",vmin=0,vmax=3)\n\n    Notes\n    -----\n    Data citation:\n\n    Fang, Y., Liu, Y. &amp; Margulis, S. A. (2022). Western United States UCLA Daily Snow Reanalysis. (WUS_UCLA_SR, Version 1). [Data Set]. Boulder, Colorado USA. NASA National Snow and Ice Data Center Distributed Active Archive Center. https://doi.org/10.5067/PP7T2GBI52I2\n    \"\"\"\n\n    bbox_gdf = convert_bbox_to_geodataframe(bbox_input)\n\n    search = earthaccess.search_data(\n                short_name=\"WUS_UCLA_SR\",\n                cloud_hosted=True,\n                bounding_box=tuple(bbox_gdf.total_bounds),\n                temporal=(start_date, end_date),\n            )\n\n    files = earthaccess.open(search) # cant disable progress bar yet https://github.com/nsidc/earthaccess/issues/612\n    snow_reanalysis_ds = xr.open_mfdataset(files).transpose()\n\n    url = files[0].path\n    date_pattern = r'\\d{4}\\.\\d{2}\\.\\d{2}'\n    WY_start_date = pd.to_datetime(re.search(date_pattern, url).group())\n\n    snow_reanalysis_ds.coords['time'] = (\"Day\", pd.date_range(WY_start_date, periods=snow_reanalysis_ds.sizes['Day']))\n    snow_reanalysis_ds = snow_reanalysis_ds.swap_dims({'Day':'time'})\n\n    snow_reanalysis_ds = snow_reanalysis_ds.sel(time=slice(start_date, end_date))\n\n    stats_dictionary = {'mean':0, 'std':1, 'median':2, '25pct':2, '75pct':3}\n    stats_index = stats_dictionary[stats]\n\n    snow_reanalysis_da = snow_reanalysis_ds[variable].sel(Stats=stats_index)\n    snow_reanalysis_da = snow_reanalysis_da.rio.set_spatial_dims(x_dim=\"Longitude\", y_dim=\"Latitude\")\n    snow_reanalysis_da = snow_reanalysis_da.rio.write_crs(bbox_gdf.crs)\n    snow_reanalysis_da = snow_reanalysis_da.rio.clip_box(*bbox_gdf.total_bounds,crs=bbox_gdf.crs)\n\n\n    snow_reanalysis_da.attrs[\"data_citation\"] = \"Fang, Y., Liu, Y. &amp; Margulis, S. A. (2022). Western United States UCLA Daily Snow Reanalysis. (WUS_UCLA_SR, Version 1). [Data Set]. Boulder, Colorado USA. NASA National Snow and Ice Data Center Distributed Active Archive Center. https://doi.org/10.5067/PP7T2GBI52I2\"\n\n    return snow_reanalysis_da\n</code></pre>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#stable-release","title":"Stable release","text":"<p>easysnowdata is available on pypi and conda-forge. you can install easysnowdata with any of the following...</p> <ul> <li><code>pip install easysnowdata</code></li> <li><code>conda install easysnowdata</code></li> <li><code>mamba install easysnowdata</code></li> </ul>"},{"location":"installation/#from-sources","title":"From sources","text":"<p>To install easysnowdata from sources, run this command in your terminal:</p> <pre><code>pip install git+https://github.com/egagli/easysnowdata\n</code></pre>"},{"location":"remote_sensing/","title":"remote_sensing module","text":""},{"location":"remote_sensing/#easysnowdata.remote_sensing.HLS","title":"<code> HLS        </code>","text":"<p>A class to handle Harmonized Landsat Sentinel (HLS) satellite data.</p> <p>This class provides functionality to search, retrieve, and process HLS data, which combines data from Landsat and Sentinel-2 satellites. It supports various data operations including masking, scaling, and metadata retrieval.</p> <p>Parameters:</p> Name Type Description Default <code>bbox_input</code> <code>geopandas.GeoDataFrame or tuple or Shapely Geometry</code> <p>GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.</p> required <code>start_date</code> <code>str</code> <p>The start date for the data in the format 'YYYY-MM-DD'. Default is '2014-01-01'.</p> <code>'2014-01-01'</code> <code>end_date</code> <code>str</code> <p>The end date for the data in the format 'YYYY-MM-DD'. Default is today's date.</p> <code>'2025-03-03'</code> <code>bands</code> <code>list</code> <p>The bands to be used. Default is all bands.</p> <code>None</code> <code>resolution</code> <code>str</code> <p>The resolution of the data. Defaults to native resolution.</p> <code>None</code> <code>crs</code> <code>str</code> <p>The coordinate reference system. Default is 'utm'.</p> <code>'utm'</code> <code>remove_nodata</code> <code>bool</code> <p>Whether to remove no data values. Default is True.</p> <code>True</code> <code>scale_data</code> <code>bool</code> <p>Whether to scale the data. Default is True.</p> <code>True</code> <code>add_metadata</code> <code>bool</code> <p>Whether to add metadata to the data. Default is True.</p> <code>True</code> <code>add_platform</code> <code>bool</code> <p>Whether to add platform information to the data. Default is True.</p> <code>True</code> <code>groupby</code> <code>str</code> <p>The groupby parameter for the data. Default is \"solar_day\".</p> <code>'solar_day'</code> <p>Attributes:</p> Name Type Description <code>data</code> <code>xarray.Dataset</code> <p>The loaded HLS data.</p> <code>metadata</code> <code>geopandas.GeoDataFrame</code> <p>Metadata for the retrieved HLS scenes.</p> <code>rgb</code> <code>xarray.DataArray</code> <p>RGB composite of the HLS data.</p> <code>ndvi</code> <code>xarray.DataArray</code> <p>Normalized Difference Vegetation Index (NDVI) calculated from the data.</p> <code>Methods</code> <code>None</code> <code>-------</code> <code>None</code> <code>search_data()</code> <code>None</code> <p>Searches for HLS data based on the specified parameters.</p> <code>get_data()</code> <code>None</code> <p>Retrieves the HLS data based on the search results.</p> <code>get_metadata()</code> <code>None</code> <p>Retrieves metadata for the HLS scenes.</p> <code>get_combined_metadata()</code> <code>None</code> <p>Retrieves and combines metadata for both Landsat and Sentinel-2 scenes.</p> <code>remove_nodata_inplace()</code> <code>None</code> <p>Removes no data values from the data.</p> <code>mask_data()</code> <code>None</code> <p>Masks the data based on the Fmask quality layer.</p> <code>scale_data_inplace()</code> <code>None</code> <p>Scales the data to reflectance values.</p> <code>add_platform_inplace()</code> <code>None</code> <p>Adds platform information to the data as coordinates.</p> <code>get_rgb()</code> <code>None</code> <p>Retrieves the RGB composite of the data.</p> <code>get_ndvi()</code> <code>None</code> <p>Calculates the Normalized Difference Vegetation Index (NDVI).</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>class HLS:\n    \"\"\"\n    A class to handle Harmonized Landsat Sentinel (HLS) satellite data.\n\n    This class provides functionality to search, retrieve, and process HLS data, which combines\n    data from Landsat and Sentinel-2 satellites. It supports various data operations including\n    masking, scaling, and metadata retrieval.\n\n    Parameters\n    ----------\n    bbox_input : geopandas.GeoDataFrame or tuple or Shapely Geometry\n        GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.\n    start_date : str, optional\n        The start date for the data in the format 'YYYY-MM-DD'. Default is '2014-01-01'.\n    end_date : str, optional\n        The end date for the data in the format 'YYYY-MM-DD'. Default is today's date.\n    bands : list, optional\n        The bands to be used. Default is all bands.\n    resolution : str, optional\n        The resolution of the data. Defaults to native resolution.\n    crs : str, optional\n        The coordinate reference system. Default is 'utm'.\n    remove_nodata : bool, optional\n        Whether to remove no data values. Default is True.\n    scale_data : bool, optional\n        Whether to scale the data. Default is True.\n    add_metadata : bool, optional\n        Whether to add metadata to the data. Default is True.\n    add_platform : bool, optional\n        Whether to add platform information to the data. Default is True.\n    groupby : str, optional\n        The groupby parameter for the data. Default is \"solar_day\".\n\n    Attributes\n    ----------\n    data : xarray.Dataset\n        The loaded HLS data.\n    metadata : geopandas.GeoDataFrame\n        Metadata for the retrieved HLS scenes.\n    rgb : xarray.DataArray\n        RGB composite of the HLS data.\n    ndvi : xarray.DataArray\n        Normalized Difference Vegetation Index (NDVI) calculated from the data.\n\n    Methods\n    -------\n    search_data()\n        Searches for HLS data based on the specified parameters.\n    get_data()\n        Retrieves the HLS data based on the search results.\n    get_metadata()\n        Retrieves metadata for the HLS scenes.\n    get_combined_metadata()\n        Retrieves and combines metadata for both Landsat and Sentinel-2 scenes.\n    remove_nodata_inplace()\n        Removes no data values from the data.\n    mask_data()\n        Masks the data based on the Fmask quality layer.\n    scale_data_inplace()\n        Scales the data to reflectance values.\n    add_platform_inplace()\n        Adds platform information to the data as coordinates.\n    get_rgb()\n        Retrieves the RGB composite of the data.\n    get_ndvi()\n        Calculates the Normalized Difference Vegetation Index (NDVI).\n    \"\"\"\n\n    # https://lpdaac.usgs.gov/documents/1698/HLS_User_Guide_V2.pdf\n    # https://lpdaac.usgs.gov/documents/842/HLS_Tutorial.html\n\n    def __init__(\n        self,\n        bbox_input,\n        start_date=\"2014-01-01\",\n        end_date=datetime.datetime.now().strftime(\"%Y-%m-%d\"),\n        bands=None,\n        resolution=None,\n        crs=\"utm\",\n        remove_nodata=True,\n        scale_data=True,\n        add_metadata=True,\n        add_platform=True,\n        groupby=\"solar_day\",\n    ):  #'ProducerGranuleId'\n        \"\"\"\n        The constructor for the HLS class.\n\n        Parameters:\n            bbox_input (geopandas.GeoDataFrame or tuple or Shapely Geometry): GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.\n            start_date (str): The start date for the data in the format 'YYYY-MM-DD'. Default is '2014-01-01'.\n            end_date (str): The end date for the data in the format 'YYYY-MM-DD'. Default is today's date.\n            bands (list): The bands to be used. Default is all bands. Must include SCL for data masking. Each band should be a string like 'B01', 'B02', etc.\n            resolution (str): The resolution of the data. Defaults to native resolution, 10m.\n            crs (str): The coordinate reference system. This should be a string like 'EPSG:4326'. Default CRS is UTM zone estimated from bounding box.\n            groupby (str): The groupby parameter for the data. Default is \"solar_day\".\n        \"\"\"\n        # Initialize the attributes\n        self.bbox_input = bbox_input\n        self.start_date = start_date\n        self.end_date = end_date\n        self.bands = bands\n        self.resolution = resolution\n        self.crs = crs\n        self.remove_nodata = remove_nodata\n        self.scale_data = scale_data\n        self.add_metadata = add_metadata\n        self.add_platform = add_platform\n        self.groupby = groupby\n\n        self.bbox_gdf = convert_bbox_to_geodataframe(self.bbox_input)\n\n        if self.crs == None:\n            self.crs = self.bbox_gdf.estimate_utm_crs()\n\n        # Define the band information\n        self.band_info = { # https://github.com/stac-extensions/eo#common-band-names\n            \"coastal\": {\n                \"landsat_band\": \"B01\",\n                \"sentinel_band\": \"B01\",\n                \"description\": \"430-450 nm\",\n                \"data_type\": \"int16\",\n                \"nodata\": \"-9999\",\n                \"scale\": \"0.0001\",\n            },\n            \"blue\": {\n                \"landsat_band\": \"B02\",\n                \"sentinel_band\": \"B02\",\n                \"description\": \"450-510 nm\",\n                \"data_type\": \"int16\",\n                \"nodata\": \"-9999\",\n                \"scale\": \"0.0001\",\n            },\n            \"green\": {\n                \"landsat_band\": \"B03\",\n                \"sentinel_band\": \"B03\",\n                \"description\": \"530-590 nm\",\n                \"data_type\": \"int16\",\n                \"nodata\": \"-9999\",\n                \"scale\": \"0.0001\",\n            },\n            \"red\": {\n                \"landsat_band\": \"B04\",\n                \"sentinel_band\": \"B04\",\n                \"description\": \"640-670 nm\",\n                \"data_type\": \"int16\",\n                \"nodata\": \"-9999\",\n                \"scale\": \"0.0001\",\n            },\n            \"rededge071\": {\n                \"landsat_band\": \"-\",\n                \"sentinel_band\": \"B05\",\n                \"description\": \"690-710 nm\",\n                \"data_type\": \"int16\",\n                \"nodata\": \"-9999\",\n                \"scale\": \"0.0001\",\n            },\n            \"rededge075\": {\n                \"landsat_band\": \"-\",\n                \"sentinel_band\": \"B06\",\n                \"description\": \"730-750 nm\",\n                \"data_type\": \"int16\",\n                \"nodata\": \"-9999\",\n                \"scale\": \"0.0001\",\n            },\n            \"rededge078\": {\n                \"landsat_band\": \"-\",\n                \"sentinel_band\": \"B07\",\n                \"description\": \"770-790 nm\",\n                \"data_type\": \"int16\",\n                \"nodata\": \"-9999\",\n                \"scale\": \"0.0001\",\n            },\n            \"nir\": {\n                \"landsat_band\": \"-\",\n                \"sentinel_band\": \"B08\",\n                \"description\": \"780-880 nm\",\n                \"data_type\": \"int16\",\n                \"nodata\": \"-9999\",\n                \"scale\": \"0.0001\",\n            },\n            \"nir08\": {\n                \"landsat_band\": \"B05\",\n                \"sentinel_band\": \"B8A\",\n                \"description\": \"850-880 nm\",\n                \"data_type\": \"int16\",\n                \"nodata\": \"-9999\",\n                \"scale\": \"0.0001\",\n            },\n            \"swir16\": {\n                \"landsat_band\": \"B06\",\n                \"sentinel_band\": \"B11\",\n                \"description\": \"1570-1650 nm\",\n                \"data_type\": \"int16\",\n                \"nodata\": \"-9999\",\n                \"scale\": \"0.0001\",\n            },\n            \"swir22\": {\n                \"landsat_band\": \"B07\",\n                \"sentinel_band\": \"B12\",\n                \"description\": \"2110-2290 nm\",\n                \"data_type\": \"int16\",\n                \"nodata\": \"-9999\",\n                \"scale\": \"0.0001\",\n            },\n            \"water vapor\": {\n                \"landsat_band\": \"-\",\n                \"sentinel_band\": \"B09\",\n                \"description\": \"930-950 nm\",\n                \"data_type\": \"int16\",\n                \"nodata\": \"-9999\",\n                \"scale\": \"0.0001\",\n            },\n            \"cirrus\": {\n                \"landsat_band\": \"B09\",\n                \"sentinel_band\": \"B10\",\n                \"description\": \"1360-1380 nm\",\n                \"data_type\": \"int16\",\n                \"nodata\": \"-9999\",\n                \"scale\": \"0.0001\",\n            },\n            \"lwir11\": {\n                \"landsat_band\": \"B10\",\n                \"sentinel_band\": \"-\",\n                \"description\": \"10600-11190 nm\",\n                \"data_type\": \"int16\",\n                \"nodata\": \"-9999\",\n                \"scale\": \"0.0001\",\n            },\n            \"lwir12\": {\n                \"landsat_band\": \"B11\",\n                \"sentinel_band\": \"-\",\n                \"description\": \"11500-12510 nm\",\n                \"data_type\": \"int16\",\n                \"nodata\": \"-9999\",\n                \"scale\": \"0.0001\",\n            },\n            \"Fmask\": {\n                \"landsat_band\": \"Fmask\",\n                \"sentinel_band\": \"Fmask\",\n                \"description\": \"quality bits\",\n                \"data_type\": \"uint8\",\n                \"nodata\": \"255\",\n                \"scale\": \"1\",\n            },\n            \"SZA\": {\n                \"landsat_band\": \"SZA\",\n                \"sentinel_band\": \"SZA\",\n                \"description\": \"Sun zenith degrees\",\n                \"data_type\": \"uint16\",\n                \"nodata\": \"40000\",\n                \"scale\": \"0.01\",\n            },\n            \"SAA\": {\n                \"landsat_band\": \"SAA\",\n                \"sentinel_band\": \"SAA\",\n                \"description\": \"Sun azimuth degrees\",\n                \"data_type\": \"uint16\",\n                \"nodata\": \"40000\",\n                \"scale\": \"0.01\",\n            },\n            \"VZA\": {\n                \"landsat_band\": \"VZA\",\n                \"sentinel_band\": \"VZA\",\n                \"description\": \"View zenith degrees\",\n                \"data_type\": \"uint16\",\n                \"nodata\": \"40000\",\n                \"scale\": \"0.01\",\n            },\n            \"VAA\": {\n                \"landsat_band\": \"VAA\",\n                \"sentinel_band\": \"VAA\",\n                \"description\": \"View azimuth degrees\",\n                \"data_type\": \"uint16\",\n                \"nodata\": \"40000\",\n                \"scale\": \"0.01\",\n            },\n        }\n\n        self.Fmask_mask_info = {\n            0: {\"name\": \"Cirrus\", \"bit number\": \"0\"},\n            1: {\"name\": \"Cloud\", \"bit number\": \"1\"},\n            2: {\"name\": \"Adjacent to cloud / shadow\", \"bit number\": \"2\"},\n            3: {\"name\": \"Cloud shadows\", \"bit number\": \"3\"},\n            4: {\"name\": \"Snow / ice\", \"bit number\": \"4\"},\n            5: {\"name\": \"Water\", \"bit number\": \"5\"},\n            6: {\n                \"name\": \"Aerosol level (00:climatology aersol,01:low aerosol,10:moderate aerosol, 11:high aerosol)\",\n                \"bit number\": \"6-7\",\n            },\n        }\n\n        # Initialize the data attributes\n        self.search = None\n        self.data = None\n        self.metadata = None\n\n        self.rgb = None\n        self.ndvi = None\n        self.ndsi = None\n        self.ndwi = None\n        self.evi = None\n        self.ndbi = None\n\n        self.search_data()\n        self.get_data()\n        if self.remove_nodata:\n            self.remove_nodata_inplace()\n        if self.scale_data:\n            self.scale_data_inplace()\n        if self.add_metadata:\n            self.get_combined_metadata()\n        if self.add_platform:\n            self.add_platform_inplace()\n\n    def search_data(self):\n        \"\"\"\n        The method to search the data.\n        \"\"\"\n\n        catalog = pystac_client.Client.open(\n            \"https://cmr.earthdata.nasa.gov/stac/LPCLOUD\"\n        )\n\n        # Search for items within the specified bbox and date range\n        landsat_search = catalog.search(\n            collections=[\"HLSL30_2.0\"],\n            bbox=self.bbox_gdf.total_bounds,\n            datetime=(self.start_date, self.end_date),\n        )\n        sentinel_search = catalog.search(\n            collections=[\"HLSS30_2.0\"],\n            bbox=self.bbox_gdf.total_bounds,\n            datetime=(self.start_date, self.end_date),\n        )\n\n        self.search_landsat = landsat_search\n        self.search_sentinel = sentinel_search\n        print(\n            f\"Data searched. Access the returned seach with the .search_landsat or .search_sentinel attribute.\"\n        )\n\n    def get_data(self):\n        \"\"\"\n        The method to get the data.\n        \"\"\"\n        # Prepare the parameters for odc.stac.load\n        load_params_landsat = {\n            \"items\": self.search_landsat.item_collection(),\n            \"bbox\": self.bbox_gdf.total_bounds,\n            \"chunks\": {\"time\": 1, \"x\": 512, \"y\": 512},\n            \"crs\": self.crs,  # maybe put 'utm'?\n            \"groupby\": self.groupby,\n            \"fail_on_error\": False,\n            \"stac_cfg\": get_stac_cfg(sensor=\"HLSL30_2.0\"),\n        }\n        if self.bands:\n            load_params_landsat[\"bands\"] = self.bands\n        else:\n            load_params_landsat[\"bands\"] = [\n                band\n                for band, info in self.band_info.items()\n                if info[\"landsat_band\"] != \"-\"\n            ]\n        if self.resolution:\n            load_params_landsat[\"resolution\"] = self.resolution\n        else:\n            load_params_landsat[\"resolution\"] = 30\n\n        L30_ds = odc.stac.load(**load_params_landsat)\n\n        load_params_sentinel = {\n            \"items\": self.search_sentinel.item_collection(),\n            \"bbox\": self.bbox_gdf.total_bounds,\n            \"chunks\": {\"time\": 1, \"x\": 512, \"y\": 512},\n            \"crs\": self.crs,\n            \"groupby\": self.groupby,\n            \"fail_on_error\": False,\n            \"stac_cfg\": get_stac_cfg(sensor=\"HLSS30_2.0\"),\n        }\n        if self.bands:\n            load_params_sentinel[\"bands\"] = self.bands\n        else:\n            load_params_sentinel[\"bands\"] = [\n                band\n                for band, info in self.band_info.items()\n                if info[\"sentinel_band\"] != \"-\"\n            ]\n        if self.resolution:\n            load_params_sentinel[\"resolution\"] = self.resolution\n        else:\n            load_params_sentinel[\"resolution\"] = 30\n\n        S30_ds = odc.stac.load(**load_params_sentinel)\n\n        # Load the data lazily using odc.stac\n        self.data = xr.concat((L30_ds, S30_ds), dim=\"time\", fill_value=-9999).sortby(\n            \"time\"\n        )\n\n        self.data.attrs[\"band_info\"] = self.band_info\n        # self.data.attrs['scl_class_info'] = self.scl_class_info\n\n        # if 'scl' in self.data.variables:\n        #    self.data.scl.attrs['scl_class_info'] = self.scl_class_info\n\n        print(\n            f\"Data retrieved. Access with the .data attribute. Data CRS: {self.bbox_gdf.estimate_utm_crs().name}.\"\n        )\n\n    def remove_nodata_inplace(self):\n        \"\"\"\n        The method to remove no data values from the data.\n        \"\"\"\n        data_removed=False\n        for band in self.data.data_vars:\n            nodata_value = self.data[band].attrs.get(\"nodata\")\n            if nodata_value is not None:\n                self.data[band] = self.data[band].where(self.data[band] != nodata_value)\n                data_removed=True\n        if data_removed:\n            print(f\"Nodata values removed from the data. In doing so, all bands converted to float32. To turn this behavior off, set remove_nodata=False.\")\n        else:\n            print(f\"Tried to remove nodata values and set them to nans, but no nodata values found in the data.\")\n\n\n    def mask_data(\n        self,\n        remove_cirrus=True,\n        remove_cloud=True,\n        remove_adj_to_cloud=True,\n        remove_cloud_shadows=True,\n        remove_snow_ice=False,\n        remove_water=False,\n        remove_aerosol_low=False,\n        remove_aerosol_moderate=False,\n        remove_aerosol_high=False,\n        remove_aerosol_climatology=False,\n    ):\n        \"\"\"\n        The method to mask the data using Fmask.\n\n        Parameters:\n            remove_cirrus (bool): Whether to remove cirrus pixels.\n            remove_cloud (bool): Whether to remove cloud pixels.\n            remove_adj_to_cloud (bool): Whether to remove pixels adjacent to clouds.\n            remove_cloud_shadows (bool): Whether to remove cloud shadow pixels.\n            remove_snow_ice (bool): Whether to remove snow and ice pixels.\n            remove_water (bool): Whether to remove water pixels.\n            remove_aerosol_low (bool): Whether to remove low aerosol pixels.\n            remove_aerosol_moderate (bool): Whether to remove moderate aerosol pixels.\n            remove_aerosol_high (bool): Whether to remove high aerosol pixels.\n            remove_aerosol_climatology (bool): Whether to remove climatology aerosol pixels.\n\n\n        \"\"\"\n\n        # Get value of QC bit based on location\n        def get_qc_bit(ar, bit):\n            # taken from Helen's fantastic repo https://github.com/UW-GDA/mekong-water-quality/blob/main/02_pull_hls.ipynb\n            return (ar // (2**bit)) - ((ar // (2**bit)) // 2 * 2)\n\n        mask = xr.DataArray()\n        # Mask the data based on the Fmask values\n        mask_list = []\n        if remove_cirrus:\n            mask_list.append(0)\n        if remove_cloud:\n            mask_list.append(1)\n        if remove_adj_to_cloud:\n            mask_list.append(2)\n        if remove_cloud_shadows:\n            mask_list.append(3)\n        if remove_snow_ice:\n            mask_list.append(4)\n        if remove_water:\n            mask_list.append(5)\n        if (\n            remove_aerosol_climatology\n            | remove_aerosol_low\n            | remove_aerosol_moderate\n            | remove_aerosol_high\n        ):\n            mask_list.append(6)\n            aerosol_mask = (\n                get_qc_bit(self.data[\"Fmask\"], 6)\n                .astype(str)\n                .str.cat(get_qc_bit(self.data[\"Fmask\"], 7).astype(str))\n            )\n            if remove_aerosol_climatology:\n                mask = xr.concat([mask, aerosol_mask == \"00\"], dim=\"masks\")\n            if remove_aerosol_low:\n                mask = xr.concat([mask, aerosol_mask == \"01\"], dim=\"masks\")\n            if remove_aerosol_moderate:\n                mask = xr.concat([mask, aerosol_mask == \"10\"], dim=\"masks\")\n            if remove_aerosol_high:\n                mask = xr.concat([mask, aerosol_mask == \"11\"], dim=\"masks\")\n\n        for val in mask_list:\n            if val != 6:\n                mask = xr.concat(\n                    [mask, get_qc_bit(self.data[\"Fmask\"], val)], dim=\"masks\"\n                )\n\n        mask = mask.sum(dim=\"masks\")\n        self.data = self.data.where(mask == 0)\n\n        print(\n            f\"WARNING: The cloud masking is pretty bad over snow and ice. Use with caution.\"\n        )\n        print(f\"Data masked. Using Fmask, removed pixels classified as:\")\n        for val in mask_list:\n            print(self.Fmask_mask_info[val][\"name\"])\n\n    def get_metadata(self, item_collection):\n\n        HLS_metadata = gpd.GeoDataFrame.from_features(\n            item_collection.to_dict(transform_hrefs=True), \"EPSG:4326\"\n        )\n        HLS_metadata = HLS_metadata.drop(\n            columns=[\"start_datetime\", \"end_datetime\"], inplace=False\n        )\n        HLS_metadata[\"datetime\"] = pd.to_datetime(HLS_metadata[\"datetime\"], utc=True)\n\n        series_list = []\n        for item in item_collection:\n            url = item.assets[\"metadata\"].href\n            series = HLS_xml_url_to_metadata_df(url)\n            series_list.append(series)\n\n        extra_attributes = pd.DataFrame(series_list)\n        extra_attributes[\"Temporal\"] = pd.to_datetime(extra_attributes[\"Temporal\"])\n        extra_attributes[\"Platform\"] = extra_attributes[\"Platform\"].str.title()\n\n        metadata_gdf = gpd.GeoDataFrame(\n            pd.merge_asof(\n                HLS_metadata,\n                extra_attributes,\n                left_on=\"datetime\",\n                right_on=\"Temporal\",\n                direction=\"nearest\",\n                tolerance=pd.Timedelta(\"100ms\"),\n            )\n        ).drop(columns=\"Temporal\")\n        metadata_gdf = metadata_gdf[\n            [\n                \"datetime\",\n                \"ProducerGranuleId\",\n                \"Platform\",\n                \"eo:cloud_cover\",\n                \"AssociatedBrowseImageUrls\",\n                \"geometry\",\n            ]\n        ]\n\n        return metadata_gdf\n\n    def get_combined_metadata(self):\n        L30_metadata = self.get_metadata(self.search_landsat.item_collection())\n        S30_metadata = self.get_metadata(self.search_sentinel.item_collection())\n        combined_metadata_gdf = (\n            pd.concat([L30_metadata, S30_metadata])\n            .sort_values(\"datetime\")\n            .reset_index(drop=True)\n        )\n\n        self.metadata = combined_metadata_gdf\n        print(\n            f\"Metadata retrieved. Access with the .metadata attribute. To turn this behavior off, set add_metadata=False.\"\n        )\n\n    def add_platform_inplace(self):\n        temp_grouped_metadata = self.metadata\n        temp_grouped_metadata[\"cluster\"] = (\n            temp_grouped_metadata[\"datetime\"].diff().dt.total_seconds().gt(60).cumsum()\n        )\n\n        grouped_metadata = pd.DataFrame()\n        grouped_metadata[\"datetime\"] = temp_grouped_metadata.groupby(\"cluster\")[\n            \"datetime\"\n        ].apply(np.mean)\n        grouped_metadata[\"Platforms\"] = temp_grouped_metadata.groupby(\"cluster\")[\n            \"Platform\"\n        ].apply(np.unique)\n        grouped_metadata[\"eo:cloud_cover_avg\"] = (\n            temp_grouped_metadata.groupby(\"cluster\")[\"eo:cloud_cover\"]\n            .apply(np.mean)\n            .astype(int)\n        )\n        grouped_metadata[\"BrowseUrls\"] = self.metadata.groupby(\"cluster\")[\n            \"AssociatedBrowseImageUrls\"\n        ].apply(list)\n        grouped_metadata[\"geometry\"] = (\n            temp_grouped_metadata.groupby(\"cluster\")[\"geometry\"]\n            .apply(list)\n            .apply(shapely.geometry.MultiPolygon)\n        )\n        grouped_metadata_gdf = gpd.GeoDataFrame(grouped_metadata).sort_values(\n            \"datetime\"\n        )\n\n        self.data = self.data.assign_coords(\n            {\n                \"platform\": (\n                    \"time\",\n                    [item[0] for item in grouped_metadata_gdf[\"Platforms\"].values],\n                )\n            }\n        )\n        self.data = self.data.assign_coords(\n            {\n                \"eo:cloud_cover_avg\": (\n                    \"time\",\n                    grouped_metadata_gdf[\"eo:cloud_cover_avg\"].values,\n                )\n            }\n        )\n        self.data = self.data.assign_coords(\n            {\n                \"AssociatedBrowseImageUrls\": (\n                    \"time\",\n                    grouped_metadata_gdf[\"BrowseUrls\"].values,\n                )\n            }\n        )\n        self.data = self.data.assign_coords(\n            {\"geometry\": (\"time\", grouped_metadata_gdf[\"geometry\"].values)}\n        )\n\n        print(\n            f\"Platform, geometry, cloud cover, browse URLs added to data as coordinates. Access with the .data attribute. To turn this behavior off, set add_platform=False.\"\n        )\n\n    def scale_data_inplace(self):\n        \"\"\"\n        The method to scale the data.\n        \"\"\"\n\n        # Define a function to scale a data variable\n        def scale_var(x):\n            band = x.name\n            if band in self.data.band_info:\n                scale_factor_dict = self.data.band_info[band]\n                # Extract the actual scale factor from the dictionary and convert it to a float\n                scale_factor = float(scale_factor_dict[\"scale\"])\n                return x * scale_factor\n            else:\n                return x\n\n        # Apply the function to each data variable in the Dataset\n        self.data = self.data.apply(scale_var, keep_attrs=True)\n        print(\n            f\"Data scaled to reflectance. Access with the .data attribute. To turn this behavior off, set scale_data=False.\"\n        )\n\n    # def get_rgb(self):\n    #     \"\"\"\n    #     The method to get the RGB data.\n\n    #     Returns:\n    #         xarray.DataArray: The RGB data.\n    #     \"\"\"\n    #     # Convert the red, green, and blue bands to an RGB DataArray\n    #     rgb_da = self.data[[\"red\", \"green\", \"blue\"]].to_dataarray(dim=\"band\")\n    #     self.rgb = rgb_da\n\n    #     print(f\"RGB data retrieved. Access with the .rgb attribute.\")\n\n\n    def get_rgb(self, percentile_kwargs={'lower': 2, 'upper': 98}, clahe_kwargs={'clip_limit': 0.03, 'nbins': 256, 'kernel_size': None}):\n        \"\"\"\n        Retrieve RGB data with optional percentile-based contrast stretching and CLAHE enhancement.\n\n        This method calculates and stores three versions of RGB data: raw, percentile-stretched, and CLAHE-enhanced.\n\n        Parameters\n        ----------\n        percentile_kwargs : dict, optional\n            Parameters for percentile-based contrast stretching. Keys are:\n            - 'lower': Lower percentile for contrast stretching (default: 2)\n            - 'upper': Upper percentile for contrast stretching (default: 98)\n        clahe_kwargs : dict, optional\n            Parameters for CLAHE enhancement. Keys are:\n            - 'clip_limit': Clipping limit for CLAHE (default: 0.03)\n            - 'nbins': Number of bins for CLAHE histogram (default: 256)\n            - 'kernel_size': Size of kernel for CLAHE (default: None)\n\n        Returns\n        -------\n        None\n            The method stores results in instance attributes.\n\n        Notes\n        -----\n        Results are stored in the following attributes:\n        - .rgb: Raw RGB data\n        - .rgb_percentile: Percentile-stretched RGB data\n        - .rgb_clahe: CLAHE-enhanced RGB data\n        \"\"\"\n\n        rgba_da = self.data.odc.to_rgba(bands=('red','green','blue'),vmin=-0.30, vmax=1.35)\n        self.rgba = rgba_da\n\n        rgb_da = rgba_da.isel(band=slice(0, 3)) # .where(self.data.scl&gt;=0, other=255) if we want to make no data white\n        self.rgb = rgb_da\n\n        self.rgb_percentile = self.get_rgb_percentile(**percentile_kwargs)\n        self.rgb_clahe = self.get_rgb_clahe(**clahe_kwargs)\n\n        print(f\"RGB data retrieved.\\nAccess with the following attributes:\\n.rgb for raw RGB,\\n.rgba for RGBA,\\n.rgb_percentile for percentile RGB,\\n.rgb_clahe for CLAHE RGB.\\nYou can pass in percentile_kwargs and clahe_kwargs to adjust RGB calculations, check documentation for options.\")\n\n    def get_rgb_percentile(self, **percentile_kwargs):\n        \"\"\"\n        Apply percentile-based contrast stretching to the RGB bands of the Sentinel-2 data.\n\n        This function creates a new DataArray with the contrast-stretched RGB bands.\n\n        Parameters\n        ----------\n        **kwargs : dict\n            Keyword arguments for percentile calculation. Supported keys:\n            - 'lower': Lower percentile for contrast stretching (default: 2)\n            - 'upper': Upper percentile for contrast stretching (default: 98)\n\n        Returns\n        -------\n        xarray.DataArray\n            RGB data with percentile-based contrast stretching applied.\n\n        Notes\n        -----\n        The function clips values to the range [0, 1] and masks areas where SCL &lt; 0.\n        \"\"\"\n        lower_percentile = percentile_kwargs.get('lower', 2)\n        upper_percentile = percentile_kwargs.get('upper', 98)\n\n        def stretch_percentile(da):\n            p_low, p_high = np.nanpercentile(da.values, [lower_percentile, upper_percentile])\n            return (da - p_low) / (p_high - p_low)\n\n        rgb_da = self.rgb.where(self.rgba.isel(band=-1)==255)\n\n        template = xr.zeros_like(rgb_da)\n        rgb_percentile_da = xr.map_blocks(stretch_percentile, rgb_da, template=template)\n        rgb_percentile_da = rgb_percentile_da.clip(0, 1)#.where(self.data.scl&gt;=0)\n\n        return rgb_percentile_da\n\n    def get_rgb_clahe(self, **kwargs):\n        \"\"\"\n        Apply Contrast Limited Adaptive Histogram Equalization (CLAHE) to RGB bands.\n\n        This function creates a new DataArray with CLAHE applied to the RGB bands.\n\n        Parameters\n        ----------\n        **kwargs : dict\n            Keyword arguments for CLAHE. Supported keys:\n            - 'clip_limit': Clipping limit for CLAHE (default: 0.03)\n            - 'nbins': Number of bins for CLAHE histogram (default: 256)\n            - 'kernel_size': Size of kernel for CLAHE (default: None)\n\n        Returns\n        -------\n        xarray.DataArray\n            RGB data with CLAHE enhancement applied.\n\n        Notes\n        -----\n        The function applies CLAHE to each band separately and masks areas where SCL &lt; 0.\n        https://scikit-image.org/docs/stable/api/skimage.exposure.html#skimage.exposure.equalize_adapthist\n        \"\"\"\n\n        # Custom wrapper to preserve xarray metadata\n        def equalize_adapthist_da(da, **kwargs):\n            # Apply the CLAHE function from skimage\n            result = skimage.exposure.equalize_adapthist(da.values, **kwargs)\n            #new_coords = {k: v for k, v in da.coords.items() if k != 'band' or len(v) == 3}\n\n            # Convert the result back to a DataArray, preserving the original metadata\n            return xr.DataArray(result, dims=da.dims, coords=da.coords, attrs=da.attrs)\n\n        rgb_da = self.rgb\n\n        #template = rgb_da.copy(data=np.empty_like(rgb_da).data)\n        template = xr.zeros_like(rgb_da)\n        rgb_clahe_da = xr.map_blocks(equalize_adapthist_da, rgb_da, template=template, kwargs=kwargs)\n        rgb_clahe_da = rgb_clahe_da.where(self.rgba.isel(band=-1)==255)#.where(self.data.scl&gt;=0)\n\n        return rgb_clahe_da\n\n    # Indicies\n\n    def get_ndvi(self):\n        \"\"\"\n        The method to get the NDVI data.\n\n        Returns:\n            ndvi_da (xarray.DataArray): The NDVI data.\n        \"\"\"\n        red = self.data.red\n        nir = self.data.nir\n        ndvi_da = (nir - red) / (nir + red)\n\n        self.ndvi = ndvi_da\n\n        print(f\"NDVI data calculated. Access with the .ndvi attribute.\")\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.HLS.__init__","title":"<code>__init__(self, bbox_input, start_date='2014-01-01', end_date='2025-03-03', bands=None, resolution=None, crs='utm', remove_nodata=True, scale_data=True, add_metadata=True, add_platform=True, groupby='solar_day')</code>  <code>special</code>","text":"<p>The constructor for the HLS class.</p> <p>Parameters:</p> Name Type Description Default <code>bbox_input</code> <code>geopandas.GeoDataFrame or tuple or Shapely Geometry</code> <p>GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.</p> required <code>start_date</code> <code>str</code> <p>The start date for the data in the format 'YYYY-MM-DD'. Default is '2014-01-01'.</p> <code>'2014-01-01'</code> <code>end_date</code> <code>str</code> <p>The end date for the data in the format 'YYYY-MM-DD'. Default is today's date.</p> <code>'2025-03-03'</code> <code>bands</code> <code>list</code> <p>The bands to be used. Default is all bands. Must include SCL for data masking. Each band should be a string like 'B01', 'B02', etc.</p> <code>None</code> <code>resolution</code> <code>str</code> <p>The resolution of the data. Defaults to native resolution, 10m.</p> <code>None</code> <code>crs</code> <code>str</code> <p>The coordinate reference system. This should be a string like 'EPSG:4326'. Default CRS is UTM zone estimated from bounding box.</p> <code>'utm'</code> <code>groupby</code> <code>str</code> <p>The groupby parameter for the data. Default is \"solar_day\".</p> <code>'solar_day'</code> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def __init__(\n    self,\n    bbox_input,\n    start_date=\"2014-01-01\",\n    end_date=datetime.datetime.now().strftime(\"%Y-%m-%d\"),\n    bands=None,\n    resolution=None,\n    crs=\"utm\",\n    remove_nodata=True,\n    scale_data=True,\n    add_metadata=True,\n    add_platform=True,\n    groupby=\"solar_day\",\n):  #'ProducerGranuleId'\n    \"\"\"\n    The constructor for the HLS class.\n\n    Parameters:\n        bbox_input (geopandas.GeoDataFrame or tuple or Shapely Geometry): GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.\n        start_date (str): The start date for the data in the format 'YYYY-MM-DD'. Default is '2014-01-01'.\n        end_date (str): The end date for the data in the format 'YYYY-MM-DD'. Default is today's date.\n        bands (list): The bands to be used. Default is all bands. Must include SCL for data masking. Each band should be a string like 'B01', 'B02', etc.\n        resolution (str): The resolution of the data. Defaults to native resolution, 10m.\n        crs (str): The coordinate reference system. This should be a string like 'EPSG:4326'. Default CRS is UTM zone estimated from bounding box.\n        groupby (str): The groupby parameter for the data. Default is \"solar_day\".\n    \"\"\"\n    # Initialize the attributes\n    self.bbox_input = bbox_input\n    self.start_date = start_date\n    self.end_date = end_date\n    self.bands = bands\n    self.resolution = resolution\n    self.crs = crs\n    self.remove_nodata = remove_nodata\n    self.scale_data = scale_data\n    self.add_metadata = add_metadata\n    self.add_platform = add_platform\n    self.groupby = groupby\n\n    self.bbox_gdf = convert_bbox_to_geodataframe(self.bbox_input)\n\n    if self.crs == None:\n        self.crs = self.bbox_gdf.estimate_utm_crs()\n\n    # Define the band information\n    self.band_info = { # https://github.com/stac-extensions/eo#common-band-names\n        \"coastal\": {\n            \"landsat_band\": \"B01\",\n            \"sentinel_band\": \"B01\",\n            \"description\": \"430-450 nm\",\n            \"data_type\": \"int16\",\n            \"nodata\": \"-9999\",\n            \"scale\": \"0.0001\",\n        },\n        \"blue\": {\n            \"landsat_band\": \"B02\",\n            \"sentinel_band\": \"B02\",\n            \"description\": \"450-510 nm\",\n            \"data_type\": \"int16\",\n            \"nodata\": \"-9999\",\n            \"scale\": \"0.0001\",\n        },\n        \"green\": {\n            \"landsat_band\": \"B03\",\n            \"sentinel_band\": \"B03\",\n            \"description\": \"530-590 nm\",\n            \"data_type\": \"int16\",\n            \"nodata\": \"-9999\",\n            \"scale\": \"0.0001\",\n        },\n        \"red\": {\n            \"landsat_band\": \"B04\",\n            \"sentinel_band\": \"B04\",\n            \"description\": \"640-670 nm\",\n            \"data_type\": \"int16\",\n            \"nodata\": \"-9999\",\n            \"scale\": \"0.0001\",\n        },\n        \"rededge071\": {\n            \"landsat_band\": \"-\",\n            \"sentinel_band\": \"B05\",\n            \"description\": \"690-710 nm\",\n            \"data_type\": \"int16\",\n            \"nodata\": \"-9999\",\n            \"scale\": \"0.0001\",\n        },\n        \"rededge075\": {\n            \"landsat_band\": \"-\",\n            \"sentinel_band\": \"B06\",\n            \"description\": \"730-750 nm\",\n            \"data_type\": \"int16\",\n            \"nodata\": \"-9999\",\n            \"scale\": \"0.0001\",\n        },\n        \"rededge078\": {\n            \"landsat_band\": \"-\",\n            \"sentinel_band\": \"B07\",\n            \"description\": \"770-790 nm\",\n            \"data_type\": \"int16\",\n            \"nodata\": \"-9999\",\n            \"scale\": \"0.0001\",\n        },\n        \"nir\": {\n            \"landsat_band\": \"-\",\n            \"sentinel_band\": \"B08\",\n            \"description\": \"780-880 nm\",\n            \"data_type\": \"int16\",\n            \"nodata\": \"-9999\",\n            \"scale\": \"0.0001\",\n        },\n        \"nir08\": {\n            \"landsat_band\": \"B05\",\n            \"sentinel_band\": \"B8A\",\n            \"description\": \"850-880 nm\",\n            \"data_type\": \"int16\",\n            \"nodata\": \"-9999\",\n            \"scale\": \"0.0001\",\n        },\n        \"swir16\": {\n            \"landsat_band\": \"B06\",\n            \"sentinel_band\": \"B11\",\n            \"description\": \"1570-1650 nm\",\n            \"data_type\": \"int16\",\n            \"nodata\": \"-9999\",\n            \"scale\": \"0.0001\",\n        },\n        \"swir22\": {\n            \"landsat_band\": \"B07\",\n            \"sentinel_band\": \"B12\",\n            \"description\": \"2110-2290 nm\",\n            \"data_type\": \"int16\",\n            \"nodata\": \"-9999\",\n            \"scale\": \"0.0001\",\n        },\n        \"water vapor\": {\n            \"landsat_band\": \"-\",\n            \"sentinel_band\": \"B09\",\n            \"description\": \"930-950 nm\",\n            \"data_type\": \"int16\",\n            \"nodata\": \"-9999\",\n            \"scale\": \"0.0001\",\n        },\n        \"cirrus\": {\n            \"landsat_band\": \"B09\",\n            \"sentinel_band\": \"B10\",\n            \"description\": \"1360-1380 nm\",\n            \"data_type\": \"int16\",\n            \"nodata\": \"-9999\",\n            \"scale\": \"0.0001\",\n        },\n        \"lwir11\": {\n            \"landsat_band\": \"B10\",\n            \"sentinel_band\": \"-\",\n            \"description\": \"10600-11190 nm\",\n            \"data_type\": \"int16\",\n            \"nodata\": \"-9999\",\n            \"scale\": \"0.0001\",\n        },\n        \"lwir12\": {\n            \"landsat_band\": \"B11\",\n            \"sentinel_band\": \"-\",\n            \"description\": \"11500-12510 nm\",\n            \"data_type\": \"int16\",\n            \"nodata\": \"-9999\",\n            \"scale\": \"0.0001\",\n        },\n        \"Fmask\": {\n            \"landsat_band\": \"Fmask\",\n            \"sentinel_band\": \"Fmask\",\n            \"description\": \"quality bits\",\n            \"data_type\": \"uint8\",\n            \"nodata\": \"255\",\n            \"scale\": \"1\",\n        },\n        \"SZA\": {\n            \"landsat_band\": \"SZA\",\n            \"sentinel_band\": \"SZA\",\n            \"description\": \"Sun zenith degrees\",\n            \"data_type\": \"uint16\",\n            \"nodata\": \"40000\",\n            \"scale\": \"0.01\",\n        },\n        \"SAA\": {\n            \"landsat_band\": \"SAA\",\n            \"sentinel_band\": \"SAA\",\n            \"description\": \"Sun azimuth degrees\",\n            \"data_type\": \"uint16\",\n            \"nodata\": \"40000\",\n            \"scale\": \"0.01\",\n        },\n        \"VZA\": {\n            \"landsat_band\": \"VZA\",\n            \"sentinel_band\": \"VZA\",\n            \"description\": \"View zenith degrees\",\n            \"data_type\": \"uint16\",\n            \"nodata\": \"40000\",\n            \"scale\": \"0.01\",\n        },\n        \"VAA\": {\n            \"landsat_band\": \"VAA\",\n            \"sentinel_band\": \"VAA\",\n            \"description\": \"View azimuth degrees\",\n            \"data_type\": \"uint16\",\n            \"nodata\": \"40000\",\n            \"scale\": \"0.01\",\n        },\n    }\n\n    self.Fmask_mask_info = {\n        0: {\"name\": \"Cirrus\", \"bit number\": \"0\"},\n        1: {\"name\": \"Cloud\", \"bit number\": \"1\"},\n        2: {\"name\": \"Adjacent to cloud / shadow\", \"bit number\": \"2\"},\n        3: {\"name\": \"Cloud shadows\", \"bit number\": \"3\"},\n        4: {\"name\": \"Snow / ice\", \"bit number\": \"4\"},\n        5: {\"name\": \"Water\", \"bit number\": \"5\"},\n        6: {\n            \"name\": \"Aerosol level (00:climatology aersol,01:low aerosol,10:moderate aerosol, 11:high aerosol)\",\n            \"bit number\": \"6-7\",\n        },\n    }\n\n    # Initialize the data attributes\n    self.search = None\n    self.data = None\n    self.metadata = None\n\n    self.rgb = None\n    self.ndvi = None\n    self.ndsi = None\n    self.ndwi = None\n    self.evi = None\n    self.ndbi = None\n\n    self.search_data()\n    self.get_data()\n    if self.remove_nodata:\n        self.remove_nodata_inplace()\n    if self.scale_data:\n        self.scale_data_inplace()\n    if self.add_metadata:\n        self.get_combined_metadata()\n    if self.add_platform:\n        self.add_platform_inplace()\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.HLS.get_data","title":"<code>get_data(self)</code>","text":"<p>The method to get the data.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def get_data(self):\n    \"\"\"\n    The method to get the data.\n    \"\"\"\n    # Prepare the parameters for odc.stac.load\n    load_params_landsat = {\n        \"items\": self.search_landsat.item_collection(),\n        \"bbox\": self.bbox_gdf.total_bounds,\n        \"chunks\": {\"time\": 1, \"x\": 512, \"y\": 512},\n        \"crs\": self.crs,  # maybe put 'utm'?\n        \"groupby\": self.groupby,\n        \"fail_on_error\": False,\n        \"stac_cfg\": get_stac_cfg(sensor=\"HLSL30_2.0\"),\n    }\n    if self.bands:\n        load_params_landsat[\"bands\"] = self.bands\n    else:\n        load_params_landsat[\"bands\"] = [\n            band\n            for band, info in self.band_info.items()\n            if info[\"landsat_band\"] != \"-\"\n        ]\n    if self.resolution:\n        load_params_landsat[\"resolution\"] = self.resolution\n    else:\n        load_params_landsat[\"resolution\"] = 30\n\n    L30_ds = odc.stac.load(**load_params_landsat)\n\n    load_params_sentinel = {\n        \"items\": self.search_sentinel.item_collection(),\n        \"bbox\": self.bbox_gdf.total_bounds,\n        \"chunks\": {\"time\": 1, \"x\": 512, \"y\": 512},\n        \"crs\": self.crs,\n        \"groupby\": self.groupby,\n        \"fail_on_error\": False,\n        \"stac_cfg\": get_stac_cfg(sensor=\"HLSS30_2.0\"),\n    }\n    if self.bands:\n        load_params_sentinel[\"bands\"] = self.bands\n    else:\n        load_params_sentinel[\"bands\"] = [\n            band\n            for band, info in self.band_info.items()\n            if info[\"sentinel_band\"] != \"-\"\n        ]\n    if self.resolution:\n        load_params_sentinel[\"resolution\"] = self.resolution\n    else:\n        load_params_sentinel[\"resolution\"] = 30\n\n    S30_ds = odc.stac.load(**load_params_sentinel)\n\n    # Load the data lazily using odc.stac\n    self.data = xr.concat((L30_ds, S30_ds), dim=\"time\", fill_value=-9999).sortby(\n        \"time\"\n    )\n\n    self.data.attrs[\"band_info\"] = self.band_info\n    # self.data.attrs['scl_class_info'] = self.scl_class_info\n\n    # if 'scl' in self.data.variables:\n    #    self.data.scl.attrs['scl_class_info'] = self.scl_class_info\n\n    print(\n        f\"Data retrieved. Access with the .data attribute. Data CRS: {self.bbox_gdf.estimate_utm_crs().name}.\"\n    )\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.HLS.get_ndvi","title":"<code>get_ndvi(self)</code>","text":"<p>The method to get the NDVI data.</p> <p>Returns:</p> Type Description <p>ndvi_da (xarray.DataArray): The NDVI data.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def get_ndvi(self):\n    \"\"\"\n    The method to get the NDVI data.\n\n    Returns:\n        ndvi_da (xarray.DataArray): The NDVI data.\n    \"\"\"\n    red = self.data.red\n    nir = self.data.nir\n    ndvi_da = (nir - red) / (nir + red)\n\n    self.ndvi = ndvi_da\n\n    print(f\"NDVI data calculated. Access with the .ndvi attribute.\")\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.HLS.get_rgb","title":"<code>get_rgb(self, percentile_kwargs={'lower': 2, 'upper': 98}, clahe_kwargs={'clip_limit': 0.03, 'nbins': 256, 'kernel_size': None})</code>","text":"<p>Retrieve RGB data with optional percentile-based contrast stretching and CLAHE enhancement.</p> <p>This method calculates and stores three versions of RGB data: raw, percentile-stretched, and CLAHE-enhanced.</p> <p>Parameters:</p> Name Type Description Default <code>percentile_kwargs</code> <code>dict</code> <p>Parameters for percentile-based contrast stretching. Keys are: - 'lower': Lower percentile for contrast stretching (default: 2) - 'upper': Upper percentile for contrast stretching (default: 98)</p> <code>{'lower': 2, 'upper': 98}</code> <code>clahe_kwargs</code> <code>dict</code> <p>Parameters for CLAHE enhancement. Keys are: - 'clip_limit': Clipping limit for CLAHE (default: 0.03) - 'nbins': Number of bins for CLAHE histogram (default: 256) - 'kernel_size': Size of kernel for CLAHE (default: None)</p> <code>{'clip_limit': 0.03, 'nbins': 256, 'kernel_size': None}</code> <p>Returns:</p> Type Description <code>None</code> <p>The method stores results in instance attributes.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def get_rgb(self, percentile_kwargs={'lower': 2, 'upper': 98}, clahe_kwargs={'clip_limit': 0.03, 'nbins': 256, 'kernel_size': None}):\n    \"\"\"\n    Retrieve RGB data with optional percentile-based contrast stretching and CLAHE enhancement.\n\n    This method calculates and stores three versions of RGB data: raw, percentile-stretched, and CLAHE-enhanced.\n\n    Parameters\n    ----------\n    percentile_kwargs : dict, optional\n        Parameters for percentile-based contrast stretching. Keys are:\n        - 'lower': Lower percentile for contrast stretching (default: 2)\n        - 'upper': Upper percentile for contrast stretching (default: 98)\n    clahe_kwargs : dict, optional\n        Parameters for CLAHE enhancement. Keys are:\n        - 'clip_limit': Clipping limit for CLAHE (default: 0.03)\n        - 'nbins': Number of bins for CLAHE histogram (default: 256)\n        - 'kernel_size': Size of kernel for CLAHE (default: None)\n\n    Returns\n    -------\n    None\n        The method stores results in instance attributes.\n\n    Notes\n    -----\n    Results are stored in the following attributes:\n    - .rgb: Raw RGB data\n    - .rgb_percentile: Percentile-stretched RGB data\n    - .rgb_clahe: CLAHE-enhanced RGB data\n    \"\"\"\n\n    rgba_da = self.data.odc.to_rgba(bands=('red','green','blue'),vmin=-0.30, vmax=1.35)\n    self.rgba = rgba_da\n\n    rgb_da = rgba_da.isel(band=slice(0, 3)) # .where(self.data.scl&gt;=0, other=255) if we want to make no data white\n    self.rgb = rgb_da\n\n    self.rgb_percentile = self.get_rgb_percentile(**percentile_kwargs)\n    self.rgb_clahe = self.get_rgb_clahe(**clahe_kwargs)\n\n    print(f\"RGB data retrieved.\\nAccess with the following attributes:\\n.rgb for raw RGB,\\n.rgba for RGBA,\\n.rgb_percentile for percentile RGB,\\n.rgb_clahe for CLAHE RGB.\\nYou can pass in percentile_kwargs and clahe_kwargs to adjust RGB calculations, check documentation for options.\")\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.HLS.get_rgb_clahe","title":"<code>get_rgb_clahe(self, **kwargs)</code>","text":"<p>Apply Contrast Limited Adaptive Histogram Equalization (CLAHE) to RGB bands.</p> <p>This function creates a new DataArray with CLAHE applied to the RGB bands.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>dict</code> <p>Keyword arguments for CLAHE. Supported keys: - 'clip_limit': Clipping limit for CLAHE (default: 0.03) - 'nbins': Number of bins for CLAHE histogram (default: 256) - 'kernel_size': Size of kernel for CLAHE (default: None)</p> <code>{}</code> <p>Returns:</p> Type Description <code>xarray.DataArray</code> <p>RGB data with CLAHE enhancement applied.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def get_rgb_clahe(self, **kwargs):\n    \"\"\"\n    Apply Contrast Limited Adaptive Histogram Equalization (CLAHE) to RGB bands.\n\n    This function creates a new DataArray with CLAHE applied to the RGB bands.\n\n    Parameters\n    ----------\n    **kwargs : dict\n        Keyword arguments for CLAHE. Supported keys:\n        - 'clip_limit': Clipping limit for CLAHE (default: 0.03)\n        - 'nbins': Number of bins for CLAHE histogram (default: 256)\n        - 'kernel_size': Size of kernel for CLAHE (default: None)\n\n    Returns\n    -------\n    xarray.DataArray\n        RGB data with CLAHE enhancement applied.\n\n    Notes\n    -----\n    The function applies CLAHE to each band separately and masks areas where SCL &lt; 0.\n    https://scikit-image.org/docs/stable/api/skimage.exposure.html#skimage.exposure.equalize_adapthist\n    \"\"\"\n\n    # Custom wrapper to preserve xarray metadata\n    def equalize_adapthist_da(da, **kwargs):\n        # Apply the CLAHE function from skimage\n        result = skimage.exposure.equalize_adapthist(da.values, **kwargs)\n        #new_coords = {k: v for k, v in da.coords.items() if k != 'band' or len(v) == 3}\n\n        # Convert the result back to a DataArray, preserving the original metadata\n        return xr.DataArray(result, dims=da.dims, coords=da.coords, attrs=da.attrs)\n\n    rgb_da = self.rgb\n\n    #template = rgb_da.copy(data=np.empty_like(rgb_da).data)\n    template = xr.zeros_like(rgb_da)\n    rgb_clahe_da = xr.map_blocks(equalize_adapthist_da, rgb_da, template=template, kwargs=kwargs)\n    rgb_clahe_da = rgb_clahe_da.where(self.rgba.isel(band=-1)==255)#.where(self.data.scl&gt;=0)\n\n    return rgb_clahe_da\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.HLS.get_rgb_percentile","title":"<code>get_rgb_percentile(self, **percentile_kwargs)</code>","text":"<p>Apply percentile-based contrast stretching to the RGB bands of the Sentinel-2 data.</p> <p>This function creates a new DataArray with the contrast-stretched RGB bands.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>dict</code> <p>Keyword arguments for percentile calculation. Supported keys: - 'lower': Lower percentile for contrast stretching (default: 2) - 'upper': Upper percentile for contrast stretching (default: 98)</p> required <p>Returns:</p> Type Description <code>xarray.DataArray</code> <p>RGB data with percentile-based contrast stretching applied.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def get_rgb_percentile(self, **percentile_kwargs):\n    \"\"\"\n    Apply percentile-based contrast stretching to the RGB bands of the Sentinel-2 data.\n\n    This function creates a new DataArray with the contrast-stretched RGB bands.\n\n    Parameters\n    ----------\n    **kwargs : dict\n        Keyword arguments for percentile calculation. Supported keys:\n        - 'lower': Lower percentile for contrast stretching (default: 2)\n        - 'upper': Upper percentile for contrast stretching (default: 98)\n\n    Returns\n    -------\n    xarray.DataArray\n        RGB data with percentile-based contrast stretching applied.\n\n    Notes\n    -----\n    The function clips values to the range [0, 1] and masks areas where SCL &lt; 0.\n    \"\"\"\n    lower_percentile = percentile_kwargs.get('lower', 2)\n    upper_percentile = percentile_kwargs.get('upper', 98)\n\n    def stretch_percentile(da):\n        p_low, p_high = np.nanpercentile(da.values, [lower_percentile, upper_percentile])\n        return (da - p_low) / (p_high - p_low)\n\n    rgb_da = self.rgb.where(self.rgba.isel(band=-1)==255)\n\n    template = xr.zeros_like(rgb_da)\n    rgb_percentile_da = xr.map_blocks(stretch_percentile, rgb_da, template=template)\n    rgb_percentile_da = rgb_percentile_da.clip(0, 1)#.where(self.data.scl&gt;=0)\n\n    return rgb_percentile_da\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.HLS.mask_data","title":"<code>mask_data(self, remove_cirrus=True, remove_cloud=True, remove_adj_to_cloud=True, remove_cloud_shadows=True, remove_snow_ice=False, remove_water=False, remove_aerosol_low=False, remove_aerosol_moderate=False, remove_aerosol_high=False, remove_aerosol_climatology=False)</code>","text":"<p>The method to mask the data using Fmask.</p> <p>Parameters:</p> Name Type Description Default <code>remove_cirrus</code> <code>bool</code> <p>Whether to remove cirrus pixels.</p> <code>True</code> <code>remove_cloud</code> <code>bool</code> <p>Whether to remove cloud pixels.</p> <code>True</code> <code>remove_adj_to_cloud</code> <code>bool</code> <p>Whether to remove pixels adjacent to clouds.</p> <code>True</code> <code>remove_cloud_shadows</code> <code>bool</code> <p>Whether to remove cloud shadow pixels.</p> <code>True</code> <code>remove_snow_ice</code> <code>bool</code> <p>Whether to remove snow and ice pixels.</p> <code>False</code> <code>remove_water</code> <code>bool</code> <p>Whether to remove water pixels.</p> <code>False</code> <code>remove_aerosol_low</code> <code>bool</code> <p>Whether to remove low aerosol pixels.</p> <code>False</code> <code>remove_aerosol_moderate</code> <code>bool</code> <p>Whether to remove moderate aerosol pixels.</p> <code>False</code> <code>remove_aerosol_high</code> <code>bool</code> <p>Whether to remove high aerosol pixels.</p> <code>False</code> <code>remove_aerosol_climatology</code> <code>bool</code> <p>Whether to remove climatology aerosol pixels.</p> <code>False</code> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def mask_data(\n    self,\n    remove_cirrus=True,\n    remove_cloud=True,\n    remove_adj_to_cloud=True,\n    remove_cloud_shadows=True,\n    remove_snow_ice=False,\n    remove_water=False,\n    remove_aerosol_low=False,\n    remove_aerosol_moderate=False,\n    remove_aerosol_high=False,\n    remove_aerosol_climatology=False,\n):\n    \"\"\"\n    The method to mask the data using Fmask.\n\n    Parameters:\n        remove_cirrus (bool): Whether to remove cirrus pixels.\n        remove_cloud (bool): Whether to remove cloud pixels.\n        remove_adj_to_cloud (bool): Whether to remove pixels adjacent to clouds.\n        remove_cloud_shadows (bool): Whether to remove cloud shadow pixels.\n        remove_snow_ice (bool): Whether to remove snow and ice pixels.\n        remove_water (bool): Whether to remove water pixels.\n        remove_aerosol_low (bool): Whether to remove low aerosol pixels.\n        remove_aerosol_moderate (bool): Whether to remove moderate aerosol pixels.\n        remove_aerosol_high (bool): Whether to remove high aerosol pixels.\n        remove_aerosol_climatology (bool): Whether to remove climatology aerosol pixels.\n\n\n    \"\"\"\n\n    # Get value of QC bit based on location\n    def get_qc_bit(ar, bit):\n        # taken from Helen's fantastic repo https://github.com/UW-GDA/mekong-water-quality/blob/main/02_pull_hls.ipynb\n        return (ar // (2**bit)) - ((ar // (2**bit)) // 2 * 2)\n\n    mask = xr.DataArray()\n    # Mask the data based on the Fmask values\n    mask_list = []\n    if remove_cirrus:\n        mask_list.append(0)\n    if remove_cloud:\n        mask_list.append(1)\n    if remove_adj_to_cloud:\n        mask_list.append(2)\n    if remove_cloud_shadows:\n        mask_list.append(3)\n    if remove_snow_ice:\n        mask_list.append(4)\n    if remove_water:\n        mask_list.append(5)\n    if (\n        remove_aerosol_climatology\n        | remove_aerosol_low\n        | remove_aerosol_moderate\n        | remove_aerosol_high\n    ):\n        mask_list.append(6)\n        aerosol_mask = (\n            get_qc_bit(self.data[\"Fmask\"], 6)\n            .astype(str)\n            .str.cat(get_qc_bit(self.data[\"Fmask\"], 7).astype(str))\n        )\n        if remove_aerosol_climatology:\n            mask = xr.concat([mask, aerosol_mask == \"00\"], dim=\"masks\")\n        if remove_aerosol_low:\n            mask = xr.concat([mask, aerosol_mask == \"01\"], dim=\"masks\")\n        if remove_aerosol_moderate:\n            mask = xr.concat([mask, aerosol_mask == \"10\"], dim=\"masks\")\n        if remove_aerosol_high:\n            mask = xr.concat([mask, aerosol_mask == \"11\"], dim=\"masks\")\n\n    for val in mask_list:\n        if val != 6:\n            mask = xr.concat(\n                [mask, get_qc_bit(self.data[\"Fmask\"], val)], dim=\"masks\"\n            )\n\n    mask = mask.sum(dim=\"masks\")\n    self.data = self.data.where(mask == 0)\n\n    print(\n        f\"WARNING: The cloud masking is pretty bad over snow and ice. Use with caution.\"\n    )\n    print(f\"Data masked. Using Fmask, removed pixels classified as:\")\n    for val in mask_list:\n        print(self.Fmask_mask_info[val][\"name\"])\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.HLS.remove_nodata_inplace","title":"<code>remove_nodata_inplace(self)</code>","text":"<p>The method to remove no data values from the data.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def remove_nodata_inplace(self):\n    \"\"\"\n    The method to remove no data values from the data.\n    \"\"\"\n    data_removed=False\n    for band in self.data.data_vars:\n        nodata_value = self.data[band].attrs.get(\"nodata\")\n        if nodata_value is not None:\n            self.data[band] = self.data[band].where(self.data[band] != nodata_value)\n            data_removed=True\n    if data_removed:\n        print(f\"Nodata values removed from the data. In doing so, all bands converted to float32. To turn this behavior off, set remove_nodata=False.\")\n    else:\n        print(f\"Tried to remove nodata values and set them to nans, but no nodata values found in the data.\")\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.HLS.scale_data_inplace","title":"<code>scale_data_inplace(self)</code>","text":"<p>The method to scale the data.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def scale_data_inplace(self):\n    \"\"\"\n    The method to scale the data.\n    \"\"\"\n\n    # Define a function to scale a data variable\n    def scale_var(x):\n        band = x.name\n        if band in self.data.band_info:\n            scale_factor_dict = self.data.band_info[band]\n            # Extract the actual scale factor from the dictionary and convert it to a float\n            scale_factor = float(scale_factor_dict[\"scale\"])\n            return x * scale_factor\n        else:\n            return x\n\n    # Apply the function to each data variable in the Dataset\n    self.data = self.data.apply(scale_var, keep_attrs=True)\n    print(\n        f\"Data scaled to reflectance. Access with the .data attribute. To turn this behavior off, set scale_data=False.\"\n    )\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.HLS.search_data","title":"<code>search_data(self)</code>","text":"<p>The method to search the data.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def search_data(self):\n    \"\"\"\n    The method to search the data.\n    \"\"\"\n\n    catalog = pystac_client.Client.open(\n        \"https://cmr.earthdata.nasa.gov/stac/LPCLOUD\"\n    )\n\n    # Search for items within the specified bbox and date range\n    landsat_search = catalog.search(\n        collections=[\"HLSL30_2.0\"],\n        bbox=self.bbox_gdf.total_bounds,\n        datetime=(self.start_date, self.end_date),\n    )\n    sentinel_search = catalog.search(\n        collections=[\"HLSS30_2.0\"],\n        bbox=self.bbox_gdf.total_bounds,\n        datetime=(self.start_date, self.end_date),\n    )\n\n    self.search_landsat = landsat_search\n    self.search_sentinel = sentinel_search\n    print(\n        f\"Data searched. Access the returned seach with the .search_landsat or .search_sentinel attribute.\"\n    )\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.MODIS_snow","title":"<code> MODIS_snow        </code>","text":"<p>A class to handle MODIS snow data.</p> <p>This class provides functionality to search, retrieve, and process MODIS snow cover data. It supports various MODIS snow products and allows for spatial and temporal subsetting.</p> <p>Parameters:</p> Name Type Description Default <code>bbox_input</code> <code>geopandas.GeoDataFrame or tuple or Shapely Geometry</code> <p>GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.</p> <code>None</code> <code>clip_to_bbox</code> <code>bool</code> <p>Whether to clip the data to the bounding box. Default is True.</p> <code>True</code> <code>start_date</code> <code>str</code> <p>The start date for the data in the format 'YYYY-MM-DD'. Default is '2000-01-01'.</p> <code>'2000-01-01'</code> <code>end_date</code> <code>str</code> <p>The end date for the data in the format 'YYYY-MM-DD'. Default is today's date.</p> <code>'2025-03-03'</code> <code>data_product</code> <code>str</code> <p>The MODIS data product to retrieve. Can choose between 'MOD10A1F', 'MOD10A1', or 'MOD10A2'. Default is 'MOD10A2'.</p> <code>'MOD10A2'</code> <code>bands</code> <code>list</code> <p>The bands to be used. Default is all bands.</p> <code>None</code> <code>resolution</code> <code>str</code> <p>The resolution of the data. Defaults to native resolution.</p> <code>None</code> <code>crs</code> <code>str</code> <p>The coordinate reference system. Default is None.</p> <code>None</code> <code>vertical_tile</code> <code>int</code> <p>The vertical tile number for MODIS data. Default is None.</p> <code>None</code> <code>horizontal_tile</code> <code>int</code> <p>The horizontal tile number for MODIS data. Default is None.</p> <code>None</code> <code>mute</code> <code>bool</code> <p>Whether to mute print outputs. Default is False.</p> <code>False</code> <p>Attributes:</p> Name Type Description <code>data</code> <code>xarray.Dataset</code> <p>The loaded MODIS snow data.</p> <code>binary_snow</code> <code>xarray.DataArray</code> <p>Binary snow cover map derived from the data (only for MOD10A2 product).</p> <code>Methods</code> <code>None</code> <code>-------</code> <code>None</code> <code>search_data()</code> <code>None</code> <p>Searches for MODIS snow data based on the specified parameters.</p> <code>get_data()</code> <code>None</code> <p>Retrieves the MODIS snow data based on the search results.</p> <code>get_binary_snow()</code> <code>None</code> <p>Calculates a binary snow cover map from the data (only for MOD10A2 product).</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>class MODIS_snow:\n    \"\"\"\n    A class to handle MODIS snow data.\n\n    This class provides functionality to search, retrieve, and process MODIS snow cover data.\n    It supports various MODIS snow products and allows for spatial and temporal subsetting.\n\n    Parameters\n    ----------\n    bbox_input : geopandas.GeoDataFrame or tuple or Shapely Geometry, optional\n        GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.\n    clip_to_bbox : bool, optional\n        Whether to clip the data to the bounding box. Default is True.\n    start_date : str, optional\n        The start date for the data in the format 'YYYY-MM-DD'. Default is '2000-01-01'.\n    end_date : str, optional\n        The end date for the data in the format 'YYYY-MM-DD'. Default is today's date.\n    data_product : str, optional\n        The MODIS data product to retrieve. Can choose between 'MOD10A1F', 'MOD10A1', or 'MOD10A2'. Default is 'MOD10A2'.\n    bands : list, optional\n        The bands to be used. Default is all bands.\n    resolution : str, optional\n        The resolution of the data. Defaults to native resolution.\n    crs : str, optional\n        The coordinate reference system. Default is None.\n    vertical_tile : int, optional\n        The vertical tile number for MODIS data. Default is None.\n    horizontal_tile : int, optional\n        The horizontal tile number for MODIS data. Default is None.\n    mute : bool, optional\n        Whether to mute print outputs. Default is False.\n\n    Attributes\n    ----------\n    data : xarray.Dataset\n        The loaded MODIS snow data.\n    binary_snow : xarray.DataArray\n        Binary snow cover map derived from the data (only for MOD10A2 product).\n\n    Methods\n    -------\n    search_data()\n        Searches for MODIS snow data based on the specified parameters.\n    get_data()\n        Retrieves the MODIS snow data based on the search results.\n    get_binary_snow()\n        Calculates a binary snow cover map from the data (only for MOD10A2 product).\n\n    Notes\n    -----\n    Available data products:\n    MOD10A1: Daily snow cover, 500m resolution\n    MOD10A2: 8-day maximum snow cover, 500m resolution\n    MOD10A1F: Daily cloud-free snow cover (gap-filled), 500m resolution\n\n    Data citations:\n    MOD10A1F: Hall, D. K. and G. A. Riggs. (2020). MODIS/Terra CGF Snow Cover Daily L3 Global 500m SIN Grid, Version 61 [Data Set]. Boulder, Colorado USA. NASA National Snow and Ice Data Center Distributed Active Archive Center. https://doi.org/10.5067/MODIS/MOD10A1F.061. Date Accessed 03-19-2024.\n    MOD10A1: Hall, D. K. and G. A. Riggs. (2021). MODIS/Terra Snow Cover Daily L3 Global 500m SIN Grid, Version 61 [Data Set]. Boulder, Colorado USA. NASA National Snow and Ice Data Center Distributed Active Archive Center. https://doi.org/10.5067/MODIS/MOD10A1.061. Date Accessed 03-28-2024.\n    MOD10A2: Hall, D. K. and G. A. Riggs. (2021). MODIS/Terra Snow Cover 8-Day L3 Global 500m SIN Grid, Version 61 [Data Set]. Boulder, Colorado USA. NASA National Snow and Ice Data Center Distributed Active Archive Center. https://doi.org/10.5067/MODIS/MOD10A2.061. Date Accessed 03-28-2024.\n    \"\"\"\n\n    def __init__(\n        self,\n        bbox_input=None,\n        clip_to_bbox=True,\n        start_date=\"2000-01-01\",\n        end_date=today,\n        data_product=\"MOD10A2\",\n        bands=None,\n        resolution=None,\n        crs=None,\n        vertical_tile=None,\n        horizontal_tile=None,\n        mute=False,\n    ):\n\n        if mute:\n            blockPrint()\n\n        self.bbox_input = bbox_input\n        self.bbox_gdf = convert_bbox_to_geodataframe(bbox_input)\n        self.clip_to_bbox = clip_to_bbox\n        self.start_date = start_date\n        self.end_date = end_date\n        self.data_product = data_product\n        self.bands = bands\n        self.resolution = resolution\n        self.crs = crs\n        self.vertical_tile = vertical_tile\n        self.horizontal_tile = horizontal_tile\n\n\n        self.search_data()\n        self.get_data()\n\n        if mute:\n            enablePrint()\n\n    def search_data(self):\n\n        if self.data_product == \"MOD10A1\" or self.data_product == \"MOD10A2\":\n            catalog = pystac_client.Client.open(\n                \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n                modifier=planetary_computer.sign_inplace,\n            )\n\n            if self.bbox_input is not None:\n                search = catalog.search(\n                    collections=[f\"modis-{self.data_product[3:]}-061\"],\n                    bbox=self.bbox_gdf.total_bounds,\n                    datetime=(self.start_date, self.end_date),\n                )\n\n            else:\n                search = catalog.search(\n                    collections=[f\"modis-{self.data_product[3:]}-061\"],\n                    datetime=(self.start_date, self.end_date),\n                    query={\n                        \"modis:vertical-tile\": {\"eq\": self.vertical_tile},\n                        \"modis:horizontal-tile\": {\"eq\": self.horizontal_tile},\n                    },\n                )\n\n        elif self.data_product == \"MOD10A1F\":\n            search = earthaccess.search_data(\n                short_name=\"MOD10A1F\",\n                cloud_hosted=False,\n                bounding_box=tuple(self.bbox_gdf.total_bounds),\n                temporal=(self.start_date, self.end_date),\n            )\n\n        else:\n            raise ValueError(\n                \"Data product not recognized. Please choose 'MOD10A1', 'MOD10A2', or 'MOD10A1F'.\"\n            )\n\n        self.search = search\n\n    def get_data(self):\n\n        if self.data_product == \"MOD10A1\" or self.data_product == \"MOD10A2\":\n\n            load_params = {\n                \"items\": self.search.item_collection(),\n                \"chunks\": {\"time\": 1, \"x\": 512, \"y\": 512},\n            }\n            if self.clip_to_bbox:\n                load_params[\"bbox\"] = self.bbox_gdf.total_bounds\n            if self.bands:\n                load_params[\"bands\"] = self.bands\n            if self.crs:\n                load_params[\"crs\"] = self.crs\n            if self.resolution:\n                load_params[\"resolution\"] = self.resolution\n\n            modis_snow = odc.stac.load(**load_params)\n\n        elif self.data_product == \"MOD10A1F\":\n            # files = earthaccess.open(results) # doesn't seem to work for .hdf files...\n            # https://github.com/nsidc/earthaccess/blob/main/docs/tutorials/file-access.ipynb\n            # https://github.com/nsidc/earthaccess/tree/main\n            # https://earthaccess.readthedocs.io/en/latest/tutorials/emit-earthaccess/\n            # https://nbviewer.org/urls/gist.githubusercontent.com/scottyhq/790bf19c7811b5c6243ce37aae252ca1/raw/e2632e928647fd91c797e4a23116d2ac3ff62372/0-load-hdf5.ipynb\n            # https://docs.dask.org/en/latest/array-creation.html#concatenation-and-stacking\n            # https://matthewrocklin.com/blog/work/2018/02/06/hdf-in-the-cloud\n\n            # guess we'll download instead\n            temp_download_fp = \"/tmp/local_folder\"  # do these auto delete, or should i delete when opened explicitly? shutil.rmtree(temp_download_fp)\n\n            files = earthaccess.download(\n                self.search, temp_download_fp\n            )  # can i suppress the print output? https://earthaccess.readthedocs.io/en/latest/user-reference/api/api/\n\n\n            if self.clip_to_bbox:\n                modis_snow = xr.concat(\n                    [\n                        rxr.open_rasterio(\n                            file, variable=\"CGF_NDSI_Snow_Cover\", chunks={}\n                        )[\"CGF_NDSI_Snow_Cover\"]\n                        .squeeze()\n                        .rio.clip_box(*self.bbox_gdf.total_bounds,crs=self.bbox_gdf.crs)\n                        .assign_coords(\n                            time=pd.to_datetime(\n                                rxr.open_rasterio(\n                                    file, variable=\"CGF_NDSI_Snow_Cover\", chunks={}\n                                )\n                                .squeeze()\n                                .attrs[\"RANGEBEGINNINGDATE\"]\n                            )\n                        )\n                        .drop_vars(\"band\")\n                        for file in files\n                    ],\n                    dim=\"time\",\n                )\n\n            else:\n                modis_snow = xr.concat(\n                    [\n                        rxr.open_rasterio(\n                            file, variable=\"CGF_NDSI_Snow_Cover\", chunks={}\n                        )[\"CGF_NDSI_Snow_Cover\"]\n                        .squeeze()\n                        .assign_coords(\n                            time=pd.to_datetime(\n                                rxr.open_rasterio(\n                                    file, variable=\"CGF_NDSI_Snow_Cover\", chunks={}\n                                )\n                                .squeeze()\n                                .attrs[\"RANGEBEGINNINGDATE\"]\n                            )\n                        )\n                        .drop_vars(\"band\")\n                        for file in files\n                    ],\n                    dim=\"time\",\n                )\n\n        else:\n            raise ValueError(\n                \"Data product not recognized. Please choose 'MOD10A1', 'MOD10A2', or 'MOD10A1F'.\"\n            )\n\n        self.data = modis_snow\n\n        if self.data_product == \"MOD10A2\":\n            self.data.attrs[\"class_info\"] = {\n                0: {\"name\": \"missing data\", \"color\": \"#006400\"},\n                1: {\"name\": \"no decision\", \"color\": \"#FFBB22\"},\n                11: {\"name\": \"night\", \"color\": \"#FFFF4C\"},\n                25: {\"name\": \"no snow\", \"color\": \"#F096FF\"},\n                37: {\"name\": \"lake\", \"color\": \"#FA0000\"},\n                39: {\"name\": \"ocean / sparse vegetation\", \"color\": \"#B4B4B4\"},\n                50: {\"name\": \"cloud\", \"color\": \"#F0F0F0\"},\n                100: {\"name\": \"lake ice\", \"color\": \"#0064C8\"},\n                200: {\"name\": \"snow\", \"color\": \"#0096A0\"},\n                254: {\"name\": \"detector saturated\", \"color\": \"#00CF75\"},\n                255: {\"name\": \"fill\", \"color\": \"#FAE6A0\"},\n            }\n\n        print(\"Data retrieved. Access with the .data attribute.\")\n\n    def get_binary_snow(self):\n\n        if self.data_product == \"MOD10A2\":\n            self.binary_snow = xr.where(self.data[\"Maximum_Snow_Extent\"] == 200, 1, 0).rio.write_crs(self.data.rio.crs)\n            print(\"Binary snow map calculated. Access with the .binary_snow attribute.\")\n        else:\n            print(\"This method is only available for the MOD10A2 product.\")\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.Sentinel1","title":"<code> Sentinel1        </code>","text":"<p>A class to handle Sentinel-1 RTC satellite data.</p> <p>This class provides functionality to search, retrieve, and process Sentinel-1 Radiometric Terrain Corrected (RTC) data. It supports various data operations including border noise removal and unit conversion.</p> <p>Parameters:</p> Name Type Description Default <code>bbox_input</code> <code>geopandas.GeoDataFrame or tuple or Shapely Geometry</code> <p>GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.</p> required <code>start_date</code> <code>str</code> <p>The start date for the data in the format 'YYYY-MM-DD'. Default is '2014-01-01'.</p> <code>'2014-01-01'</code> <code>end_date</code> <code>str</code> <p>The end date for the data in the format 'YYYY-MM-DD'. Default is today's date.</p> <code>'2025-03-03'</code> <code>catalog_choice</code> <code>str</code> <p>The catalog choice for the data. Default is 'planetarycomputer'.</p> <code>'planetarycomputer'</code> <code>bands</code> <code>list</code> <p>The bands to be used. Default is all bands.</p> <code>None</code> <code>units</code> <code>str</code> <p>The units of the data. Can be 'dB' or 'linear power'. Default is 'dB'.</p> <code>'dB'</code> <code>resolution</code> <code>str</code> <p>The resolution of the data. Defaults to native resolution.</p> <code>None</code> <code>crs</code> <code>str</code> <p>The coordinate reference system. Default is None.</p> <code>None</code> <code>groupby</code> <code>str</code> <p>The groupby parameter for the data. Default is \"sat:absolute_orbit\".</p> <code>'sat:absolute_orbit'</code> <code>chunks</code> <code>dict</code> <p>The chunk size for dask arrays. Default is {}.</p> <code>{}</code> <code>remove_border_noise</code> <code>bool</code> <p>Whether to remove border noise from the data. Default is True.</p> <code>True</code> <p>Attributes:</p> Name Type Description <code>data</code> <code>xarray.Dataset</code> <p>The loaded Sentinel-1 data.</p> <code>metadata</code> <code>geopandas.GeoDataFrame</code> <p>Metadata for the retrieved Sentinel-1 scenes.</p> <code>Methods</code> <code>None</code> <code>-------</code> <code>None</code> <code>search_data()</code> <code>None</code> <p>Searches for Sentinel-1 data based on the specified parameters.</p> <code>get_data()</code> <code>None</code> <p>Retrieves the Sentinel-1 data based on the search results.</p> <code>get_metadata()</code> <code>None</code> <p>Retrieves metadata for the Sentinel-1 scenes.</p> <code>remove_border_noise()</code> <code>None</code> <p>Removes border noise from the data.</p> <code>linear_to_db()</code> <code>None</code> <p>Converts linear power units to decibels (dB).</p> <code>db_to_linear()</code> <code>None</code> <p>Converts decibels (dB) to linear power units.</p> <code>add_orbit_info()</code> <code>None</code> <p>Adds orbit information to the data as coordinates.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>class Sentinel1:\n    \"\"\"\n    A class to handle Sentinel-1 RTC satellite data.\n\n    This class provides functionality to search, retrieve, and process Sentinel-1 Radiometric Terrain Corrected (RTC) data.\n    It supports various data operations including border noise removal and unit conversion.\n\n    Parameters\n    ----------\n    bbox_input : geopandas.GeoDataFrame or tuple or Shapely Geometry\n        GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.\n    start_date : str, optional\n        The start date for the data in the format 'YYYY-MM-DD'. Default is '2014-01-01'.\n    end_date : str, optional\n        The end date for the data in the format 'YYYY-MM-DD'. Default is today's date.\n    catalog_choice : str, optional\n        The catalog choice for the data. Default is 'planetarycomputer'.\n    bands : list, optional\n        The bands to be used. Default is all bands.\n    units : str, optional\n        The units of the data. Can be 'dB' or 'linear power'. Default is 'dB'.\n    resolution : str, optional\n        The resolution of the data. Defaults to native resolution.\n    crs : str, optional\n        The coordinate reference system. Default is None.\n    groupby : str, optional\n        The groupby parameter for the data. Default is \"sat:absolute_orbit\".\n    chunks : dict, optional\n        The chunk size for dask arrays. Default is {}.\n    remove_border_noise : bool, optional\n        Whether to remove border noise from the data. Default is True.\n\n    Attributes\n    ----------\n    data : xarray.Dataset\n        The loaded Sentinel-1 data.\n    metadata : geopandas.GeoDataFrame\n        Metadata for the retrieved Sentinel-1 scenes.\n\n    Methods\n    -------\n    search_data()\n        Searches for Sentinel-1 data based on the specified parameters.\n    get_data()\n        Retrieves the Sentinel-1 data based on the search results.\n    get_metadata()\n        Retrieves metadata for the Sentinel-1 scenes.\n    remove_border_noise()\n        Removes border noise from the data.\n    linear_to_db()\n        Converts linear power units to decibels (dB).\n    db_to_linear()\n        Converts decibels (dB) to linear power units.\n    add_orbit_info()\n        Adds orbit information to the data as coordinates.\n    \"\"\"\n\n    def __init__(\n        self,\n        bbox_input,\n        start_date=\"2014-01-01\",\n        end_date=today,\n        catalog_choice=\"planetarycomputer\",\n        bands=None,\n        units='dB', # linear power or dB\n        resolution=None,\n        crs=None,\n        groupby=\"sat:absolute_orbit\",\n        chunks={}, # {\"x\": 512, \"y\": 512} or # {\"x\": 512, \"y\": 512, \"time\": -1}\n        remove_border_noise=True,\n    ):\n        \"\"\"\n        The constructor for the Sentinel1 class.\n\n        Parameters:\n            bbox_input (geopandas.GeoDataFrame or tuple or shapely.Geometry): GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.\n            start_date (str): The start date for the data in the format 'YYYY-MM-DD'. Default is '2014-01-01'.\n            end_date (str): The end date for the data in the format 'YYYY-MM-DD'. Default is today's date.\n            catalog_choice (str): The catalog choice for the data. Can choose between 'planetarycomputer' and &lt;unimplemented&gt;, default is 'planetarycomputer'.\n            bands (list): The bands to be used. Default is all bands.\n            resolution (str): The resolution of the data. Defaults to native resolution, 10m.\n            crs (str): The coordinate reference system. This should be a string like 'EPSG:4326'. Default CRS is UTM zone estimated from bounding box.\n            groupby (str): The groupby parameter for the data. Default is \"sat:absolute_orbit\".\n        \"\"\"\n        # Initialize the attributes\n        self.bbox_input = bbox_input\n        self.start_date = start_date\n        self.end_date = end_date\n        self.catalog_choice = catalog_choice\n        self.bands = bands\n        self.resolution = resolution\n        self.crs = crs\n        self.chunks = chunks\n        self.groupby = groupby\n        self.remove_border_noise = remove_border_noise\n\n        #if not self.geobox:\n        self.bbox_gdf = convert_bbox_to_geodataframe(self.bbox_input)\n\n        if self.crs is None:\n            self.crs = self.bbox_gdf.estimate_utm_crs()\n\n        # if resolution == None:\n        #     self.resolution = 10\n\n        self.search = None\n        self.data = None\n        self.metadata = None\n\n        self.search_data()\n        self.get_data()\n        self.get_metadata()\n        if self.remove_border_noise:\n            self.remove_bad_scenes_and_border_noise()\n        self.add_orbit_info()\n        if units == 'dB':\n            self.linear_to_db()\n        else:\n            print('Units remain in linear power. Convert to dB using the .linear_to_db() method.')\n\n    def search_data(self):\n        \"\"\"\n        The method to search the data.\n        \"\"\"\n\n        # Choose the catalog URL based on catalog_choice\n        if self.catalog_choice == \"planetarycomputer\":\n            catalog_url = \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n            catalog = pystac_client.Client.open(\n                catalog_url, modifier=planetary_computer.sign_inplace\n            )\n        # elif self.catalog_choice == \"aws\":\n        #     catalog_url = indigo\n        #     catalog = pystac_client.Client.open(catalog_url)\n        else:\n            raise ValueError(\n                \"Invalid catalog_choice. Choose either 'planetarycomputer' or &lt;unimplemented&gt;.\"\n            )\n\n        # Search for items within the specified bbox and date range\n        search = catalog.search(\n            collections=[\"sentinel-1-rtc\"],\n            bbox=self.bbox_gdf.total_bounds,\n            datetime=(self.start_date, self.end_date),\n        )\n        # elif self.geobox:\n        #     search = catalog.search(\n        #         collections=[\"sentinel-1-rtc\"],\n        #         bbox=np.array(self.geobox.extent.boundingbox.to_crs('epsg:4326')),\n        #         datetime=(self.start_date, self.end_date),\n        #     )\n\n        self.search = search\n        print(f\"Data searched. Access the returned seach with the .search attribute.\")\n\n    def get_data(self):\n        \"\"\"\n        The method to get the data.\n        \"\"\"\n        # Prepare the parameters for odc.stac.load\n        load_params = {\n            \"items\": self.search.items(),\n            \"nodata\": -32768,\n            \"chunks\": self.chunks,\n            \"groupby\": self.groupby,\n        }\n        if self.bands:\n            load_params[\"bands\"] = self.bands\n        load_params[\"crs\"] = self.crs\n        load_params[\"bbox\"] = self.bbox_gdf.total_bounds\n        load_params[\"resolution\"] = self.resolution\n\n        # Load the data lazily using odc.stac\n        self.data = odc.stac.load(**load_params).sortby(\n            \"time\"\n        )  # sorting by time because of known issue in s1 mpc stac catalog\n        self.data.attrs[\"units\"] = \"linear power\"\n        print(\n            f\"Data retrieved. Access with the .data attribute. Data CRS: {self.bbox_gdf.estimate_utm_crs().name}.\"\n        )\n\n    def get_metadata(self):\n        \"\"\"\n        The method to get the metadata.\n        \"\"\"\n        stac_json = self.search.item_collection_as_dict()\n        metadata_gdf = gpd.GeoDataFrame.from_features(stac_json, \"epsg:4326\")\n\n        self.metadata = metadata_gdf\n        print(f\"Metadata retrieved. Access with the .metadata attribute.\")\n\n    # def remove_border_noise(self,threshold=0.001):\n    #     \"\"\"\n    #     The method to remove border noise from the data.\n    #     https://forum.step.esa.int/t/grd-border-noise-and-thermal-noise-removal-are-not-working-anymore-since-march-13-2018/9332\n    #     https://www.mdpi.com/2072-4292/8/4/348\n    #     https://forum.step.esa.int/t/nan-appears-at-the-edge-of-the-scene-after-applying-border-noise-removal-sentinel-1-grd/40627/2\n    #     https://sentiwiki.copernicus.eu/__attachments/1673968/OI-MPC-OTH-MPC-0243%20-%20Sentinel-1%20masking%20no%20value%20pixels%20grd%20products%20note%202023%20-%202.2.pdf?inst-v=534578f3-fc04-48e9-bd69-3a45a681fe67#page=12.58\n    #     https://ieeexplore.ieee.org/document/8255846\n    #     https://www.mdpi.com/2504-3900/2/7/330\n    #     \"\"\"\n    #     self.data.loc[dict(time=slice('2014-01-01','2018-03-14'))] = self.data.sel(time=slice('2014-01-01','2018-03-14')).where(lambda x: x &gt; threshold)\n    #     print(f\"Border noise removed from the data.\")\n\n    def remove_bad_scenes_and_border_noise(self, threshold=0.001):\n        cutoff_date = np.datetime64('2018-03-14')\n\n        original_crs = self.data.rio.crs\n\n        result = xr.where(\n            self.data.time &lt; cutoff_date,\n            self.data.where(self.data &gt; threshold),\n            self.data.where(self.data &gt; 0)\n        )\n\n        result.rio.write_crs(original_crs, inplace=True)\n\n        self.data = result\n        print(f\"Falsely low scenes and border noise removed from the data.\")\n\n    def linear_to_db(self):\n        \"\"\"\n        The method to convert the linear power data to dB.\n        \"\"\"\n        self.data = 10 * np.log10(self.data)\n        self.data.attrs[\"units\"] = \"dB\"\n        print(\n            f\"Linear power units converted to dB. Convert back to linear power units using the .db_to_linear() method.\"\n        )\n\n    def db_to_linear(self):\n        \"\"\"\n        The method to convert the dB data to linear power.\n        \"\"\"\n        self.data = 10 ** (self.data / 10)\n        self.data.attrs[\"units\"] = \"linear power\"\n        print(\n            f\"dB converted to linear power units. Convert back to dB using the .linear_to_db() method.\"\n        )\n\n    def add_orbit_info(self):\n        \"\"\"\n        The method to add the relative orbit number to the data.\n        \"\"\"\n        metadata_groupby_gdf = (\n            self.metadata.groupby([f\"{self.groupby}\"]).first().sort_values(\"datetime\")\n        )\n        self.data = self.data.assign_coords(\n            {\"sat:orbit_state\": (\"time\", metadata_groupby_gdf[\"sat:orbit_state\"])}\n        )\n        self.data = self.data.assign_coords(\n            {\n                \"sat:relative_orbit\": (\n                    \"time\",\n                    metadata_groupby_gdf[\"sat:relative_orbit\"].astype(\"int16\"),\n                )\n            }\n        )\n        print(\n            f\"Added relative orbit number and orbit state as coordinates to the data.\"\n        )\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.Sentinel1.__init__","title":"<code>__init__(self, bbox_input, start_date='2014-01-01', end_date='2025-03-03', catalog_choice='planetarycomputer', bands=None, units='dB', resolution=None, crs=None, groupby='sat:absolute_orbit', chunks={}, remove_border_noise=True)</code>  <code>special</code>","text":"<p>The constructor for the Sentinel1 class.</p> <p>Parameters:</p> Name Type Description Default <code>bbox_input</code> <code>geopandas.GeoDataFrame or tuple or shapely.Geometry</code> <p>GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.</p> required <code>start_date</code> <code>str</code> <p>The start date for the data in the format 'YYYY-MM-DD'. Default is '2014-01-01'.</p> <code>'2014-01-01'</code> <code>end_date</code> <code>str</code> <p>The end date for the data in the format 'YYYY-MM-DD'. Default is today's date.</p> <code>'2025-03-03'</code> <code>catalog_choice</code> <code>str</code> <p>The catalog choice for the data. Can choose between 'planetarycomputer' and , default is 'planetarycomputer'. <code>'planetarycomputer'</code> <code>bands</code> <code>list</code> <p>The bands to be used. Default is all bands.</p> <code>None</code> <code>resolution</code> <code>str</code> <p>The resolution of the data. Defaults to native resolution, 10m.</p> <code>None</code> <code>crs</code> <code>str</code> <p>The coordinate reference system. This should be a string like 'EPSG:4326'. Default CRS is UTM zone estimated from bounding box.</p> <code>None</code> <code>groupby</code> <code>str</code> <p>The groupby parameter for the data. Default is \"sat:absolute_orbit\".</p> <code>'sat:absolute_orbit'</code> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def __init__(\n    self,\n    bbox_input,\n    start_date=\"2014-01-01\",\n    end_date=today,\n    catalog_choice=\"planetarycomputer\",\n    bands=None,\n    units='dB', # linear power or dB\n    resolution=None,\n    crs=None,\n    groupby=\"sat:absolute_orbit\",\n    chunks={}, # {\"x\": 512, \"y\": 512} or # {\"x\": 512, \"y\": 512, \"time\": -1}\n    remove_border_noise=True,\n):\n    \"\"\"\n    The constructor for the Sentinel1 class.\n\n    Parameters:\n        bbox_input (geopandas.GeoDataFrame or tuple or shapely.Geometry): GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.\n        start_date (str): The start date for the data in the format 'YYYY-MM-DD'. Default is '2014-01-01'.\n        end_date (str): The end date for the data in the format 'YYYY-MM-DD'. Default is today's date.\n        catalog_choice (str): The catalog choice for the data. Can choose between 'planetarycomputer' and &lt;unimplemented&gt;, default is 'planetarycomputer'.\n        bands (list): The bands to be used. Default is all bands.\n        resolution (str): The resolution of the data. Defaults to native resolution, 10m.\n        crs (str): The coordinate reference system. This should be a string like 'EPSG:4326'. Default CRS is UTM zone estimated from bounding box.\n        groupby (str): The groupby parameter for the data. Default is \"sat:absolute_orbit\".\n    \"\"\"\n    # Initialize the attributes\n    self.bbox_input = bbox_input\n    self.start_date = start_date\n    self.end_date = end_date\n    self.catalog_choice = catalog_choice\n    self.bands = bands\n    self.resolution = resolution\n    self.crs = crs\n    self.chunks = chunks\n    self.groupby = groupby\n    self.remove_border_noise = remove_border_noise\n\n    #if not self.geobox:\n    self.bbox_gdf = convert_bbox_to_geodataframe(self.bbox_input)\n\n    if self.crs is None:\n        self.crs = self.bbox_gdf.estimate_utm_crs()\n\n    # if resolution == None:\n    #     self.resolution = 10\n\n    self.search = None\n    self.data = None\n    self.metadata = None\n\n    self.search_data()\n    self.get_data()\n    self.get_metadata()\n    if self.remove_border_noise:\n        self.remove_bad_scenes_and_border_noise()\n    self.add_orbit_info()\n    if units == 'dB':\n        self.linear_to_db()\n    else:\n        print('Units remain in linear power. Convert to dB using the .linear_to_db() method.')\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.Sentinel1.add_orbit_info","title":"<code>add_orbit_info(self)</code>","text":"<p>The method to add the relative orbit number to the data.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def add_orbit_info(self):\n    \"\"\"\n    The method to add the relative orbit number to the data.\n    \"\"\"\n    metadata_groupby_gdf = (\n        self.metadata.groupby([f\"{self.groupby}\"]).first().sort_values(\"datetime\")\n    )\n    self.data = self.data.assign_coords(\n        {\"sat:orbit_state\": (\"time\", metadata_groupby_gdf[\"sat:orbit_state\"])}\n    )\n    self.data = self.data.assign_coords(\n        {\n            \"sat:relative_orbit\": (\n                \"time\",\n                metadata_groupby_gdf[\"sat:relative_orbit\"].astype(\"int16\"),\n            )\n        }\n    )\n    print(\n        f\"Added relative orbit number and orbit state as coordinates to the data.\"\n    )\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.Sentinel1.db_to_linear","title":"<code>db_to_linear(self)</code>","text":"<p>The method to convert the dB data to linear power.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def db_to_linear(self):\n    \"\"\"\n    The method to convert the dB data to linear power.\n    \"\"\"\n    self.data = 10 ** (self.data / 10)\n    self.data.attrs[\"units\"] = \"linear power\"\n    print(\n        f\"dB converted to linear power units. Convert back to dB using the .linear_to_db() method.\"\n    )\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.Sentinel1.get_data","title":"<code>get_data(self)</code>","text":"<p>The method to get the data.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def get_data(self):\n    \"\"\"\n    The method to get the data.\n    \"\"\"\n    # Prepare the parameters for odc.stac.load\n    load_params = {\n        \"items\": self.search.items(),\n        \"nodata\": -32768,\n        \"chunks\": self.chunks,\n        \"groupby\": self.groupby,\n    }\n    if self.bands:\n        load_params[\"bands\"] = self.bands\n    load_params[\"crs\"] = self.crs\n    load_params[\"bbox\"] = self.bbox_gdf.total_bounds\n    load_params[\"resolution\"] = self.resolution\n\n    # Load the data lazily using odc.stac\n    self.data = odc.stac.load(**load_params).sortby(\n        \"time\"\n    )  # sorting by time because of known issue in s1 mpc stac catalog\n    self.data.attrs[\"units\"] = \"linear power\"\n    print(\n        f\"Data retrieved. Access with the .data attribute. Data CRS: {self.bbox_gdf.estimate_utm_crs().name}.\"\n    )\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.Sentinel1.get_metadata","title":"<code>get_metadata(self)</code>","text":"<p>The method to get the metadata.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def get_metadata(self):\n    \"\"\"\n    The method to get the metadata.\n    \"\"\"\n    stac_json = self.search.item_collection_as_dict()\n    metadata_gdf = gpd.GeoDataFrame.from_features(stac_json, \"epsg:4326\")\n\n    self.metadata = metadata_gdf\n    print(f\"Metadata retrieved. Access with the .metadata attribute.\")\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.Sentinel1.linear_to_db","title":"<code>linear_to_db(self)</code>","text":"<p>The method to convert the linear power data to dB.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def linear_to_db(self):\n    \"\"\"\n    The method to convert the linear power data to dB.\n    \"\"\"\n    self.data = 10 * np.log10(self.data)\n    self.data.attrs[\"units\"] = \"dB\"\n    print(\n        f\"Linear power units converted to dB. Convert back to linear power units using the .db_to_linear() method.\"\n    )\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.Sentinel1.search_data","title":"<code>search_data(self)</code>","text":"<p>The method to search the data.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def search_data(self):\n    \"\"\"\n    The method to search the data.\n    \"\"\"\n\n    # Choose the catalog URL based on catalog_choice\n    if self.catalog_choice == \"planetarycomputer\":\n        catalog_url = \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n        catalog = pystac_client.Client.open(\n            catalog_url, modifier=planetary_computer.sign_inplace\n        )\n    # elif self.catalog_choice == \"aws\":\n    #     catalog_url = indigo\n    #     catalog = pystac_client.Client.open(catalog_url)\n    else:\n        raise ValueError(\n            \"Invalid catalog_choice. Choose either 'planetarycomputer' or &lt;unimplemented&gt;.\"\n        )\n\n    # Search for items within the specified bbox and date range\n    search = catalog.search(\n        collections=[\"sentinel-1-rtc\"],\n        bbox=self.bbox_gdf.total_bounds,\n        datetime=(self.start_date, self.end_date),\n    )\n    # elif self.geobox:\n    #     search = catalog.search(\n    #         collections=[\"sentinel-1-rtc\"],\n    #         bbox=np.array(self.geobox.extent.boundingbox.to_crs('epsg:4326')),\n    #         datetime=(self.start_date, self.end_date),\n    #     )\n\n    self.search = search\n    print(f\"Data searched. Access the returned seach with the .search attribute.\")\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.Sentinel2","title":"<code> Sentinel2        </code>","text":"<p>A class to handle Sentinel-2 satellite data.</p> <p>This class provides functionality to search, retrieve, and process Sentinel-2 satellite imagery. It supports various data operations including masking, scaling, and calculation of spectral indices.</p> <p>Parameters:</p> Name Type Description Default <code>bbox_input</code> <code>geopandas.GeoDataFrame or tuple or Shapely Geometry</code> <p>GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.</p> required <code>start_date</code> <code>str</code> <p>The start date for the data in the format 'YYYY-MM-DD'. Default is '2014-01-01'.</p> <code>'2014-01-01'</code> <code>end_date</code> <code>str</code> <p>The end date for the data in the format 'YYYY-MM-DD'. Default is today's date.</p> <code>'2025-03-03'</code> <code>catalog_choice</code> <code>str</code> <p>The catalog choice for the data. Can choose between 'planetarycomputer' and 'earthsearch'. Default is 'planetarycomputer'.</p> <code>'planetarycomputer'</code> <code>bands</code> <code>list</code> <p>The bands to be used. Default is all bands. Must include SCL for data masking.</p> <code>None</code> <code>resolution</code> <code>str</code> <p>The resolution of the data. Defaults to native resolution, 10m.</p> <code>None</code> <code>crs</code> <code>str</code> <p>The coordinate reference system. This should be a string like 'EPSG:4326'. Default CRS is UTM zone estimated from bounding box.</p> <code>None</code> <code>remove_nodata</code> <code>bool</code> <p>Whether to remove no data values. Default is True.</p> <code>True</code> <code>harmonize_to_old</code> <code>bool</code> <p>Whether to harmonize new data to the old baseline. Default is True.</p> <code>None</code> <code>scale_data</code> <code>bool</code> <p>Whether to scale the data. Default is True.</p> <code>True</code> <code>groupby</code> <code>str</code> <p>The groupby parameter for the data. Default is \"solar_day\".</p> <code>'solar_day'</code> <p>Attributes:</p> Name Type Description <code>data</code> <code>xarray.Dataset</code> <p>The loaded Sentinel-2 data.</p> <code>metadata</code> <code>geopandas.GeoDataFrame</code> <p>Metadata for the retrieved Sentinel-2 scenes.</p> <code>rgb</code> <code>xarray.DataArray</code> <p>RGB composite of the Sentinel-2 data.</p> <code>ndvi</code> <code>xarray.DataArray</code> <p>Normalized Difference Vegetation Index (NDVI) calculated from the data.</p> <code>ndsi</code> <code>xarray.DataArray</code> <p>Normalized Difference Snow Index (NDSI) calculated from the data.</p> <code>ndwi</code> <code>xarray.DataArray</code> <p>Normalized Difference Water Index (NDWI) calculated from the data.</p> <code>evi</code> <code>xarray.DataArray</code> <p>Enhanced Vegetation Index (EVI) calculated from the data.</p> <code>ndbi</code> <code>xarray.DataArray</code> <p>Normalized Difference Built-up Index (NDBI) calculated from the data.</p> <code>Methods</code> <code>None</code> <code>-------</code> <code>None</code> <code>search_data()</code> <code>None</code> <p>Searches for Sentinel-2 data based on the specified parameters.</p> <code>get_data()</code> <code>None</code> <p>Retrieves the Sentinel-2 data based on the search results.</p> <code>get_metadata()</code> <code>None</code> <p>Retrieves metadata for the Sentinel-2 scenes.</p> <code>remove_nodata_inplace()</code> <code>None</code> <p>Removes no data values from the data.</p> <code>mask_data()</code> <code>None</code> <p>Masks the data based on the Scene Classification Layer (SCL).</p> <code>harmonize_to_old_inplace()</code> <code>None</code> <p>Harmonizes new Sentinel-2 data to the old baseline.</p> <code>scale_data_inplace()</code> <code>None</code> <p>Scales the data to reflectance values.</p> <code>get_rgb()</code> <code>None</code> <p>Retrieves the RGB composite of the data.</p> <code>get_ndvi()</code> <code>None</code> <p>Calculates the Normalized Difference Vegetation Index (NDVI).</p> <code>get_ndsi()</code> <code>None</code> <p>Calculates the Normalized Difference Snow Index (NDSI).</p> <code>get_ndwi()</code> <code>None</code> <p>Calculates the Normalized Difference Water Index (NDWI).</p> <code>get_evi()</code> <code>None</code> <p>Calculates the Enhanced Vegetation Index (EVI).</p> <code>get_ndbi()</code> <code>None</code> <p>Calculates the Normalized Difference Built-up Index (NDBI).</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>class Sentinel2:\n    \"\"\"\n    A class to handle Sentinel-2 satellite data.\n\n    This class provides functionality to search, retrieve, and process Sentinel-2 satellite imagery.\n    It supports various data operations including masking, scaling, and calculation of spectral indices.\n\n    Parameters\n    ----------\n    bbox_input : geopandas.GeoDataFrame or tuple or Shapely Geometry\n        GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.\n    start_date : str, optional\n        The start date for the data in the format 'YYYY-MM-DD'. Default is '2014-01-01'.\n    end_date : str, optional\n        The end date for the data in the format 'YYYY-MM-DD'. Default is today's date.\n    catalog_choice : str, optional\n        The catalog choice for the data. Can choose between 'planetarycomputer' and 'earthsearch'. Default is 'planetarycomputer'.\n    bands : list, optional\n        The bands to be used. Default is all bands. Must include SCL for data masking.\n    resolution : str, optional\n        The resolution of the data. Defaults to native resolution, 10m.\n    crs : str, optional\n        The coordinate reference system. This should be a string like 'EPSG:4326'. Default CRS is UTM zone estimated from bounding box.\n    remove_nodata : bool, optional\n        Whether to remove no data values. Default is True.\n    harmonize_to_old : bool, optional\n        Whether to harmonize new data to the old baseline. Default is True.\n    scale_data : bool, optional\n        Whether to scale the data. Default is True.\n    groupby : str, optional\n        The groupby parameter for the data. Default is \"solar_day\".\n\n    Attributes\n    ----------\n    data : xarray.Dataset\n        The loaded Sentinel-2 data.\n    metadata : geopandas.GeoDataFrame\n        Metadata for the retrieved Sentinel-2 scenes.\n    rgb : xarray.DataArray\n        RGB composite of the Sentinel-2 data.\n    ndvi : xarray.DataArray\n        Normalized Difference Vegetation Index (NDVI) calculated from the data.\n    ndsi : xarray.DataArray\n        Normalized Difference Snow Index (NDSI) calculated from the data.\n    ndwi : xarray.DataArray\n        Normalized Difference Water Index (NDWI) calculated from the data.\n    evi : xarray.DataArray\n        Enhanced Vegetation Index (EVI) calculated from the data.\n    ndbi : xarray.DataArray\n        Normalized Difference Built-up Index (NDBI) calculated from the data.\n\n    Methods\n    -------\n    search_data()\n        Searches for Sentinel-2 data based on the specified parameters.\n    get_data()\n        Retrieves the Sentinel-2 data based on the search results.\n    get_metadata()\n        Retrieves metadata for the Sentinel-2 scenes.\n    remove_nodata_inplace()\n        Removes no data values from the data.\n    mask_data()\n        Masks the data based on the Scene Classification Layer (SCL).\n    harmonize_to_old_inplace()\n        Harmonizes new Sentinel-2 data to the old baseline.\n    scale_data_inplace()\n        Scales the data to reflectance values.\n    get_rgb()\n        Retrieves the RGB composite of the data.\n    get_ndvi()\n        Calculates the Normalized Difference Vegetation Index (NDVI).\n    get_ndsi()\n        Calculates the Normalized Difference Snow Index (NDSI).\n    get_ndwi()\n        Calculates the Normalized Difference Water Index (NDWI).\n    get_evi()\n        Calculates the Enhanced Vegetation Index (EVI).\n    get_ndbi()\n        Calculates the Normalized Difference Built-up Index (NDBI).\n    \"\"\"\n\n    def __init__(\n        self,\n        bbox_input,\n        start_date=\"2014-01-01\",\n        end_date=today,\n        catalog_choice=\"planetarycomputer\",\n        collection= \"sentinel-2-l2a\", # could also choose \"sentinel-2-c1-l2a\" once published to https://github.com/Element84/earth-search\n        bands=None,\n        resolution=None,\n        crs=None,\n        remove_nodata=True,\n        harmonize_to_old=None,\n        scale_data=True,\n        groupby=\"solar_day\",\n    ):\n        \"\"\"\n        The constructor for the Sentinel2 class.\n\n        Parameters:\n            bbox_input (geopandas.GeoDataFrame or tuple or Shapely Geometry): GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.\n            start_date (str): The start date for the data in the format 'YYYY-MM-DD'. Default is '2014-01-01'.\n            end_date (str): The end date for the data in the format 'YYYY-MM-DD'. Default is today's date.\n            catalog_choice (str): The catalog choice for the data. Can choose between 'planetarycomputer' and 'earthsearch', default is 'planetarycomputer'.\n            bands (list): The bands to be used. Default is all bands. Must include SCL for data masking. Each band should be a string like 'B01', 'B02', etc.\n            resolution (str): The resolution of the data. Defaults to native resolution, 10m.\n            crs (str): The coordinate reference system. This should be a string like 'EPSG:4326'. Default CRS is UTM zone estimated from bounding box.\n            groupby (str): The groupby parameter for the data. Default is \"solar_day\".\n        \"\"\"\n        # Initialize the attributes\n        self.bbox_input = bbox_input\n        self.start_date = start_date\n        self.end_date = end_date\n        self.catalog_choice = catalog_choice\n        self.collection = collection\n        self.bands = bands\n        self.resolution = resolution\n        self.crs = crs\n        self.remove_nodata = remove_nodata\n        self.harmonize_to_old = harmonize_to_old\n        self.scale_data = scale_data\n        self.groupby = groupby\n\n        self.bbox_gdf = convert_bbox_to_geodataframe(self.bbox_input)\n\n        if self.crs == None:\n            self.crs = self.bbox_gdf.estimate_utm_crs()\n\n        # Define the band information\n        self.band_info = {\n            \"B01\": {\n                \"name\": \"coastal\",\n                \"description\": \"Coastal aerosol, 442.7 nm (S2A), 442.3 nm (S2B)\",\n                \"resolution\": \"60m\",\n                \"scale\": \"0.0001\",\n            },\n            \"B02\": {\n                \"name\": \"blue\",\n                \"description\": \"Blue, 492.4 nm (S2A), 492.1 nm (S2B)\",\n                \"resolution\": \"10m\",\n                \"scale\": \"0.0001\",\n            },\n            \"B03\": {\n                \"name\": \"green\",\n                \"description\": \"Green, 559.8 nm (S2A), 559.0 nm (S2B)\",\n                \"resolution\": \"10m\",\n                \"scale\": \"0.0001\",\n            },\n            \"B04\": {\n                \"name\": \"red\",\n                \"description\": \"Red, 664.6 nm (S2A), 665.0 nm (S2B)\",\n                \"resolution\": \"10m\",\n                \"scale\": \"0.0001\",\n            },\n            \"B05\": {\n                \"name\": \"rededge\",\n                \"description\": \"Vegetation red edge, 704.1 nm (S2A), 703.8 nm (S2B)\",\n                \"resolution\": \"20m\",\n                \"scale\": \"0.0001\",\n            },\n            \"B06\": {\n                \"name\": \"rededge2\",\n                \"description\": \"Vegetation red edge, 740.5 nm (S2A), 739.1 nm (S2B)\",\n                \"resolution\": \"20m\",\n                \"scale\": \"0.0001\",\n            },\n            \"B07\": {\n                \"name\": \"rededge3\",\n                \"description\": \"Vegetation red edge, 782.8 nm (S2A), 779.7 nm (S2B)\",\n                \"resolution\": \"20m\",\n                \"scale\": \"0.0001\",\n            },\n            \"B08\": {\n                \"name\": \"nir\",\n                \"description\": \"NIR, 832.8 nm (S2A), 833.0 nm (S2B)\",\n                \"resolution\": \"10m\",\n                \"scale\": \"0.0001\",\n            },\n            \"B8A\": {\n                \"name\": \"nir08\",\n                \"description\": \"Narrow NIR, 864.7 nm (S2A), 864.0 nm (S2B)\",\n                \"resolution\": \"20m\",\n                \"scale\": \"0.0001\",\n            },\n            \"B09\": {\n                \"name\": \"nir09\",\n                \"description\": \"Water vapour, 945.1 nm (S2A), 943.2 nm (S2B)\",\n                \"resolution\": \"60m\",\n                \"scale\": \"0.0001\",\n            },\n            \"B11\": {\n                \"name\": \"swir16\",\n                \"description\": \"SWIR, 1613.7 nm (S2A), 1610.4 nm (S2B)\",\n                \"resolution\": \"20m\",\n                \"scale\": \"0.0001\",\n            },\n            \"B12\": {\n                \"name\": \"swir22\",\n                \"description\": \"SWIR, 2202.4 nm (S2A), 2185.7 nm (S2B)\",\n                \"resolution\": \"20m\",\n                \"scale\": \"0.0001\",\n            },\n            \"AOT\": {\n                \"name\": \"aot\",\n                \"description\": \"Aerosol Optical Thickness map, based on Sen2Cor processor\",\n                \"resolution\": \"10m\",\n                \"scale\": \"1\",\n            },\n            \"SCL\": {\n                \"name\": \"scl\",\n                \"description\": \"Scene classification data, based on Sen2Cor processor\",\n                \"resolution\": \"20m\",\n                \"scale\": \"1\",\n            },\n            \"WVP\": {\n                \"name\": \"wvp\",\n                \"description\": \"Water Vapour map\",\n                \"resolution\": \"10m\",\n                \"scale\": \"1\",\n            },\n            \"visual\": {\n                \"name\": \"visual\",\n                \"description\": \"True color image\",\n                \"resolution\": \"10m\",\n                \"scale\": \"0.0001\",\n            },\n        }\n\n        # Define the scene classification information, classes here: https://custom-scripts.sentinel-hub.com/custom-scripts/sentinel-2/scene-classification/\n        self.scl_class_info = {\n            0: {\"name\": \"No Data (Missing data)\", \"color\": \"#000000\"},\n            1: {\"name\": \"Saturated or defective pixel\", \"color\": \"#ff0000\"},\n            2: {\n                \"name\": \"Topographic casted shadows\",\n                \"color\": \"#2f2f2f\",\n            },  # (called 'Dark features/Shadows' for data before 2022-01-25)\n            3: {\"name\": \"Cloud shadows\", \"color\": \"#643200\"},\n            4: {\"name\": \"Vegetation\", \"color\": \"#00a000\"},\n            5: {\"name\": \"Not-vegetated\", \"color\": \"#ffe65a\"},\n            6: {\"name\": \"Water\", \"color\": \"#0000ff\"},\n            7: {\"name\": \"Unclassified\", \"color\": \"#808080\"},\n            8: {\"name\": \"Cloud medium probability\", \"color\": \"#c0c0c0\"},\n            9: {\"name\": \"Cloud high probability\", \"color\": \"#ffffff\"},\n            10: {\"name\": \"Thin cirrus\", \"color\": \"#64c8ff\"},\n            11: {\"name\": \"Snow or ice\", \"color\": \"#ff96ff\"},\n        }\n\n        self.scl_cmap = plt.cm.colors.ListedColormap(\n            [info[\"color\"] for info in self.scl_class_info.values()]\n        )\n\n        # Initialize the data attributes\n        self.search = None\n        self.data = None\n        self.metadata = None\n\n        self.rgb = None\n        self.rgba = None\n        self.rgb_clahe = None\n        self.rgb_percentile = None\n        self.ndvi = None\n        self.ndsi = None\n        self.ndwi = None\n        self.evi = None\n        self.ndbi = None\n\n        self.search_data()\n        self.get_data()\n\n        if self.remove_nodata:\n            self.remove_nodata_inplace()\n\n        if self.harmonize_to_old is None:\n            if self.catalog_choice == \"planetarycomputer\":\n                self.harmonize_to_old = True\n            else:\n                if self.collection == \"sentinel-2-c1-l2a\":\n                    self.harmonize_to_old = True\n                elif self.collection == \"sentinel-2-l2a\":\n                    self.harmonize_to_old = False\n                    print(f\"Since {self.collection} on {self.catalog_choice} is used, harmonization step is not needed.\")\n                else:\n                    raise ValueError(f\"Unknown collection: {self.collection}\")\n\n        if self.harmonize_to_old:\n            self.harmonize_to_old_inplace()\n\n        if self.scale_data:\n            self.scale_data_inplace()\n\n        self.get_metadata()\n\n\n\n        # Add the plot_scl method as an attribute to the SCL data variable\n        if 'scl' in self.data.data_vars:\n            self.data.scl.attrs['example_plot'] = self.plot_scl\n            self.data.scl.attrs['class_info'] = self.scl_class_info\n            self.data.scl.attrs['cmap'] = self.scl_cmap\n\n    def plot_scl(self, scl_data, ax=None, figsize=None, col_wrap=5, legend_kwargs=None):\n\n        if figsize is None:\n            figsize = (8, 10) if scl_data.time.size == 1 else (12, 7)\n\n        class_values = sorted(list(self.scl_class_info.keys()))\n        bounds = [(class_values[i] + class_values[i + 1]) / 2 for i in range(len(class_values) - 1)]\n        bounds = [class_values[0] - 0.5] + bounds + [class_values[-1] + 0.5]\n        norm = matplotlib.colors.BoundaryNorm(bounds, self.scl_cmap.N)\n\n        if scl_data.time.size == 1:\n            # Single image plot\n            if ax is None:\n                f, ax = plt.subplots(figsize=figsize)\n            else:\n                f = ax.get_figure()\n\n            im = scl_data.plot.imshow(ax=ax, cmap=self.scl_cmap, norm=norm, add_colorbar=False)\n            ax.set_aspect(\"equal\")\n\n            local_time = pd.to_datetime(scl_data.time.values).tz_localize('UTC').tz_convert('America/Los_Angeles')\n            ax.set_title(f\"Sentinel-2 Scene Classification Layer (SCL)\\n{local_time.strftime('%B %d, %Y')}\\n{local_time.strftime('%I:%M%p')}\")\n\n        else:\n            # Multiple images plot\n            f = scl_data.plot.imshow(\n                col='time',\n                col_wrap=col_wrap,\n                cmap=self.scl_cmap,\n                norm=matplotlib.colors.BoundaryNorm(bounds, self.scl_cmap.N),\n                add_colorbar=False,\n                #figsize=figsize\n            )\n\n            for ax, time in zip(f.axs.flat, scl_data.time.values):\n                local_time = pd.to_datetime(time).tz_localize('UTC').tz_convert('America/Los_Angeles')\n                ax.set_title(f'{local_time.strftime(\"%B %d, %Y\")}\\n{local_time.strftime(\"%I:%M%p\")}')\n                ax.axis('off')\n                ax.set_aspect('equal')\n\n            f.fig.suptitle('Sentinel-2 SCL time series', fontsize=16, y=1.02)\n\n        # Add legend\n        legend_handles = []\n        class_names = []\n        for class_value, class_info in self.scl_class_info.items():\n            legend_handles.append(\n                plt.Rectangle((0, 0), 1, 1, facecolor=class_info[\"color\"], edgecolor=\"black\")\n            )\n            class_names.append(class_info[\"name\"])\n\n        legend_kwargs = legend_kwargs or {}\n\n        if scl_data.time.size == 1:\n            default_legend_kwargs = {\n                \"bbox_to_anchor\": (0.5, -0.1),\n                \"loc\": \"upper center\",\n                \"ncol\": len(class_names) // 4,\n                \"frameon\": False,\n                \"handlelength\": 3.5,\n                \"handleheight\": 5,\n            }\n        else:\n            default_legend_kwargs = {\n                \"bbox_to_anchor\": (0.5, -0.1),\n                \"loc\": \"upper center\",\n                \"ncol\": len(class_names) // 4,\n                \"frameon\": False,\n                \"handlelength\": 5,\n                \"handleheight\": 6,\n                \"fontsize\": 16,\n            }\n\n        legend_kwargs = {**default_legend_kwargs, **legend_kwargs}\n\n        if scl_data.time.size == 1:\n            ax.legend(legend_handles, class_names, **legend_kwargs)\n            f.tight_layout(pad=1.5, w_pad=1.5, h_pad=1.5)\n            f.dpi = 300\n        else:\n            f.fig.legend(legend_handles, class_names, **legend_kwargs)\n            f.fig.tight_layout(pad=1.5, w_pad=1.5, h_pad=1.5)\n            f.fig.dpi = 300\n\n        return f, ax if scl_data.time.size == 1 else f\n\n    def search_data(self):\n        \"\"\"\n        The method to search the data.\n        \"\"\"\n\n        # Choose the catalog URL based on catalog_choice\n        if self.catalog_choice == \"planetarycomputer\":\n            catalog_url = \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n            catalog = pystac_client.Client.open(\n                catalog_url, modifier=planetary_computer.sign_inplace\n            )\n        elif self.catalog_choice == \"earthsearch\":\n            os.environ[\"AWS_REGION\"] = \"us-west-2\"\n            os.environ[\"GDAL_DISABLE_READDIR_ON_OPEN\"] = \"EMPTY_DIR\"\n            os.environ[\"AWS_NO_SIGN_REQUEST\"] = \"YES\"\n            catalog_url = \"https://earth-search.aws.element84.com/v1\"\n            catalog = pystac_client.Client.open(catalog_url)\n        else:\n            raise ValueError(\n                \"Invalid catalog_choice. Choose either 'planetarycomputer' or 'earthsearch'.\"\n            )\n\n        # Search for items within the specified bbox and date range\n        search = catalog.search(\n            collections=[self.collection],\n            bbox=self.bbox_gdf.total_bounds,\n            datetime=(self.start_date, self.end_date),\n        )\n        self.search = search\n        print(f\"Data searched. Access the returned seach with the .search attribute.\")\n\n    def get_data(self):\n        \"\"\"\n        The method to get the data.\n        \"\"\"\n        # Prepare the parameters for odc.stac.load\n        load_params = {\n            \"items\": self.search.items(),\n            \"bbox\": self.bbox_gdf.total_bounds,\n            \"nodata\": 0,\n            \"chunks\": {},\n            \"crs\": self.crs,\n            \"groupby\": self.groupby,\n            \"stac_cfg\": get_stac_cfg(sensor=\"sentinel-2-l2a\"),\n        }\n        if self.bands:\n            load_params[\"bands\"] = self.bands\n        else:\n            load_params[\"bands\"] = [info[\"name\"] for info in self.band_info.values()]\n        if self.resolution:\n            load_params[\"resolution\"] = self.resolution\n\n        # Load the data lazily using odc.stac\n        self.data = odc.stac.load(**load_params)\n\n        self.data.attrs[\"band_info\"] = self.band_info\n        self.data.attrs[\"scl_class_info\"] = self.scl_class_info\n\n        if \"scl\" in self.data.variables:\n            self.data.scl.attrs[\"scl_class_info\"] = self.scl_class_info\n\n        print(\n            f\"Data retrieved. Access with the .data attribute. Data CRS: {self.bbox_gdf.estimate_utm_crs().name}.\"\n        )\n\n    def get_metadata(self):\n        \"\"\"\n        The method to get the metadata.\n        \"\"\"\n\n        stac_json = self.search.item_collection_as_dict()\n        metadata_gdf = gpd.GeoDataFrame.from_features(stac_json, \"epsg:4326\")\n        if self.catalog_choice == \"earthsearch\":\n            metadata_gdf[\"s2:mgrs_tile\"] = (\n                metadata_gdf[\"mgrs:utm_zone\"].apply(lambda x: f\"{x:02d}\")\n                + metadata_gdf[\"mgrs:latitude_band\"]\n                + metadata_gdf[\"mgrs:grid_square\"]\n            )\n\n        self.metadata = metadata_gdf\n        print(f\"Metadata retrieved. Access with the .metadata attribute.\")\n\n    def remove_nodata_inplace(self):\n        \"\"\"\n        The method to remove no data values from the data.\n        \"\"\"\n        data_removed = False\n        for band in self.data.data_vars:\n            nodata_value = None\n            nodata_value = self.data[band].attrs.get(\"nodata\")\n            if nodata_value is not None:\n                #print(f\"Removing nodata {nodata_value} values for band {band}...\")\n                self.data[band] = self.data[band].where(self.data[band] != nodata_value)\n                data_removed = True\n        if data_removed:\n            print(f\"Nodata values removed from the data. In doing so, all bands converted to float32. To turn this behavior off, set remove_nodata=False.\")\n        else:\n            print(f\"Tried to remove nodata values and set them to nans, but no nodata values found in the data.\")\n\n    def mask_data(\n        self,\n        remove_nodata=True,\n        remove_saturated_defective=True,\n        remove_topo_shadows=True,\n        remove_cloud_shadows=True,\n        remove_vegetation=False,\n        remove_not_vegetated=False,\n        remove_water=False,\n        remove_unclassified=False,\n        remove_medium_prob_clouds=True,\n        remove_high_prob_clouds=True,\n        remove_thin_cirrus_clouds=True,\n        remove_snow_ice=False,\n    ):\n        \"\"\"\n        The method to mask the data.\n\n        Parameters:\n            remove_nodata (bool): Whether to remove no data pixels.\n            remove_saturated_defective (bool): Whether to remove saturated or defective pixels.\n            remove_topo_shadows (bool): Whether to remove topographic shadow pixels.\n            remove_cloud_shadows (bool): Whether to remove cloud shadow pixels.\n            remove_vegetation (bool): Whether to remove vegetation pixels.\n            remove_not_vegetated (bool): Whether to remove not vegetated pixels.\n            remove_water (bool): Whether to remove water pixels.\n            remove_unclassified (bool): Whether to remove unclassified pixels.\n            remove_medium_prob_clouds (bool): Whether to remove medium probability cloud pixels.\n            remove_high_prob_clouds (bool): Whether to remove high probability cloud pixels.\n            remove_thin_cirrus_clouds (bool): Whether to remove thin cirrus cloud pixels.\n            remove_snow_ice (bool): Whether to remove snow or ice pixels.\n        \"\"\"\n\n        # Mask the data based on the Scene Classification (SCL) band (see definitions above)\n        mask_list = []\n        if remove_nodata:\n            mask_list.append(0)\n        if remove_saturated_defective:\n            mask_list.append(1)\n        if remove_topo_shadows:\n            mask_list.append(2)\n        if remove_cloud_shadows:\n            mask_list.append(3)\n        if remove_vegetation:\n            mask_list.append(4)\n        if remove_not_vegetated:\n            mask_list.append(5)\n        if remove_water:\n            mask_list.append(6)\n        if remove_unclassified:\n            mask_list.append(7)\n        if remove_medium_prob_clouds:\n            mask_list.append(8)\n        if remove_high_prob_clouds:\n            mask_list.append(9)\n        if remove_thin_cirrus_clouds:\n            mask_list.append(10)\n        if remove_snow_ice:\n            mask_list.append(11)\n\n        print(f\"Removed pixels with the following scene classification values:\")\n        for val in mask_list:\n            print(self.scl_class_info[val][\"name\"])\n\n        scl = self.data.scl\n        mask = scl.where(scl.isin(mask_list) == False, 0)\n        self.data = self.data.where(mask != 0)\n\n    def harmonize_to_old_inplace(self):\n        \"\"\"\n        Harmonize new Sentinel-2 data to the old baseline.\n        Adapted from: https://planetarycomputer.microsoft.com/dataset/sentinel-2-l2a#Baseline-Change\n        Returns\n        -------\n        harmonized: xarray.Dataset\n            A Dataset with all values harmonized to the old\n            processing baseline.\n        \"\"\"\n        cutoff = datetime.datetime(2022, 1, 25)\n        offset = 1000\n        bands = [\n            \"B01\",\n            \"B02\",\n            \"B03\",\n            \"B04\",\n            \"B05\",\n            \"B06\",\n            \"B07\",\n            \"B08\",\n            \"B8A\",\n            \"B09\",\n            \"B11\",\n            \"B12\",\n        ]\n        bands = [self.data.band_info[band][\"name\"] for band in bands]\n        old = self.data.sel(time=slice(None, cutoff))\n\n        to_process = list(set(bands) &amp; set(self.data.data_vars))\n        new = self.data.sel(time=slice(cutoff, None))\n\n        for band in to_process:\n            if band in new.data_vars:\n                new[band] = new[band].clip(offset) - offset\n\n        self.data = xr.concat([old, new], dim=\"time\")\n\n        print(\n            f\"Data acquired after January 25th, 2022 harmonized to old baseline. To override this behavior, set harmonize_to_old=False.\"\n        )\n\n    def scale_data_inplace(self):\n        \"\"\"\n        The method to scale the data.\n        \"\"\"\n        for band in self.data.data_vars:\n            scale_factor = self.data[band].attrs.get(\"scale\")\n\n            if scale_factor is None:\n                scale_factor = next((info['scale'] for name, info in self.band_info.items() if info['name'] == band), None)\n\n            scale_factor = int(scale_factor) if scale_factor == '1' else float(scale_factor)\n            self.data[band] = self.data[band] * scale_factor\n\n        print(\n            f\"Data scaled to float reflectance. To turn this behavior off, set scale_data=False.\"\n        )\n\n    def get_rgb(self, percentile_kwargs={'lower': 2, 'upper': 98}, clahe_kwargs={'clip_limit': 0.03, 'nbins': 256, 'kernel_size': None}):\n        \"\"\"\n        Retrieve RGB data with optional percentile-based contrast stretching and CLAHE enhancement.\n\n        This method calculates and stores three versions of RGB data: raw, percentile-stretched, and CLAHE-enhanced.\n\n        Parameters\n        ----------\n        percentile_kwargs : dict, optional\n            Parameters for percentile-based contrast stretching. Keys are:\n            - 'lower': Lower percentile for contrast stretching (default: 2)\n            - 'upper': Upper percentile for contrast stretching (default: 98)\n        clahe_kwargs : dict, optional\n            Parameters for CLAHE enhancement. Keys are:\n            - 'clip_limit': Clipping limit for CLAHE (default: 0.03)\n            - 'nbins': Number of bins for CLAHE histogram (default: 256)\n            - 'kernel_size': Size of kernel for CLAHE (default: None)\n\n        Returns\n        -------\n        None\n            The method stores results in instance attributes.\n\n        Notes\n        -----\n        Results are stored in the following attributes:\n        - .rgb: Raw RGB data\n        - .rgb_percentile: Percentile-stretched RGB data\n        - .rgb_clahe: CLAHE-enhanced RGB data\n        \"\"\"\n\n        rgba_da = self.data.odc.to_rgba(bands=('red','green','blue'),vmin=0, vmax=1.7)\n        self.rgba = rgba_da\n\n        rgb_da = rgba_da.isel(band=slice(0, 3))  #.where(self.data.scl&gt;=0, other=255) if we want to make no data white\n        self.rgb = rgb_da\n\n        self.rgb_percentile = self.get_rgb_percentile(**percentile_kwargs)\n        self.rgb_clahe = self.get_rgb_clahe(**clahe_kwargs)\n\n        print(f\"RGB data retrieved.\\nAccess with the following attributes:\\n.rgb for raw RGB,\\n.rgba for RGBA,\\n.rgb_percentile for percentile RGB,\\n.rgb_clahe for CLAHE RGB.\\nYou can pass in percentile_kwargs and clahe_kwargs to adjust RGB calculations, check documentation for options.\")\n\n    def get_rgb_percentile(self, **percentile_kwargs):\n        \"\"\"\n        Apply percentile-based contrast stretching to the RGB bands of the Sentinel-2 data.\n\n        This function creates a new DataArray with the contrast-stretched RGB bands.\n\n        Parameters\n        ----------\n        **kwargs : dict\n            Keyword arguments for percentile calculation. Supported keys:\n            - 'lower': Lower percentile for contrast stretching (default: 2)\n            - 'upper': Upper percentile for contrast stretching (default: 98)\n\n        Returns\n        -------\n        xarray.DataArray\n            RGB data with percentile-based contrast stretching applied.\n\n        Notes\n        -----\n        The function clips values to the range [0, 1] and masks areas where SCL &lt; 0.\n        \"\"\"\n        lower_percentile = percentile_kwargs.get('lower', 2)\n        upper_percentile = percentile_kwargs.get('upper', 98)\n\n        def stretch_percentile(da):\n            p_low, p_high = np.nanpercentile(da.values, [lower_percentile, upper_percentile])\n            return (da - p_low) / (p_high - p_low)\n\n        rgb_da = self.rgb\n\n        template = xr.zeros_like(rgb_da)\n        rgb_percentile_da = xr.map_blocks(stretch_percentile, rgb_da, template=template)\n        rgb_percentile_da = rgb_percentile_da.clip(0, 1).where(self.data.scl&gt;=0)\n\n        return rgb_percentile_da\n\n    def get_rgb_clahe(self, **kwargs):\n        \"\"\"\n        Apply Contrast Limited Adaptive Histogram Equalization (CLAHE) to RGB bands.\n\n        This function creates a new DataArray with CLAHE applied to the RGB bands.\n\n        Parameters\n        ----------\n        **kwargs : dict\n            Keyword arguments for CLAHE. Supported keys:\n            - 'clip_limit': Clipping limit for CLAHE (default: 0.03)\n            - 'nbins': Number of bins for CLAHE histogram (default: 256)\n            - 'kernel_size': Size of kernel for CLAHE (default: None)\n\n        Returns\n        -------\n        xarray.DataArray\n            RGB data with CLAHE enhancement applied.\n\n        Notes\n        -----\n        The function applies CLAHE to each band separately and masks areas where SCL &lt; 0.\n        https://scikit-image.org/docs/stable/api/skimage.exposure.html#skimage.exposure.equalize_adapthist\n        \"\"\"\n\n        # Custom wrapper to preserve xarray metadata\n        def equalize_adapthist_da(da, **kwargs):\n            # Apply the CLAHE function from skimage\n            result = skimage.exposure.equalize_adapthist(da.values, **kwargs)\n            #new_coords = {k: v for k, v in da.coords.items() if k != 'band' or len(v) == 3}\n\n            # Convert the result back to a DataArray, preserving the original metadata\n            return xr.DataArray(result, dims=da.dims, coords=da.coords, attrs=da.attrs)\n\n        rgb_da = self.rgb\n\n        #template = rgb_da.copy(data=np.empty_like(rgb_da).data)\n        template = xr.zeros_like(rgb_da)\n        rgb_clahe_da = xr.map_blocks(equalize_adapthist_da, rgb_da, template=template, kwargs=kwargs)\n        rgb_clahe_da = rgb_clahe_da.where(self.data.scl&gt;=0)\n\n        return rgb_clahe_da\n\n    # Indicies\n    # find indicies Sentinel-2 indicies here: https://www.indexdatabase.de/db/is.php?sensor_id=96 and https://custom-scripts.sentinel-hub.com/custom-scripts/sentinel/sentinel-2/\n\n    def get_ndvi(self):\n        \"\"\"\n        The method to get the NDVI data.\n        S2 NDVI definition: (B08 - B04) / (B08 + B04) [https://www.indexdatabase.de/db/i-single.php?id=58]\n\n        Returns:\n            ndvi_da (xarray.DataArray): The NDVI data.\n        \"\"\"\n        red = self.data.red\n        nir = self.data.nir\n        ndvi_da = (nir - red) / (nir + red)\n\n        self.ndvi = ndvi_da\n\n        print(f\"NDVI data calculated. Access with the .ndvi attribute.\")\n\n    def get_ndsi(self):\n        \"\"\"\n        The method to get the NDSI data.\n        S2 NDSI definition: (B03 - B11) / (B03 + B11)\n\n        Returns:\n            ndsi_da (xarray.DataArray): The NDSI data.\n        \"\"\"\n        green = self.data.green\n        swir16 = self.data.swir16\n        ndsi_da = (green - swir16) / (green + swir16)\n\n        self.ndsi = ndsi_da\n\n        print(f\"NDSI data calculated. Access with the .ndsi attribute.\")\n\n    def get_ndwi(self):\n        \"\"\"\n        The method to get the NDWI data.\n        S2 NDWI definition: (B03 - B08) / (B03 + B08)\n\n        Returns:\n            ndwi_da (xarray.DataArray): The NDWI data.\n        \"\"\"\n        green = self.data.green\n        nir = self.data.nir\n        ndwi_da = (green - nir) / (green + nir)\n\n        self.ndwi = ndwi_da\n\n        print(f\"NDWI data calculated. Access with the .ndwi attribute.\")\n\n    def get_evi(self):\n        \"\"\"\n        The method to get the EVI data.\n        S2 EVI definition: 2.5 * (B08 - B04) / (B08 + 6 * B04 - 7.5 * B02 + 1) [https://www.indexdatabase.de/db/si-single.php?sensor_id=96&amp;rsindex_id=16]\n\n        Returns:\n            xarray.DataArray: The EVI data.\n        \"\"\"\n        red = self.data.red\n        nir = self.data.nir\n        blue = self.data.blue\n\n        evi_da = 2.5 * (nir - red) / (nir + 6 * red - 7.5 * blue + 1)\n\n        self.evi = evi_da\n\n        print(f\"EVI data calculated. Access with the .evi attribute.\")\n\n    def get_ndbi(self):\n        \"\"\"\n        The method to get the NDBI data.\n        S2 NDBI definition: (B08 - B12) / (B08 + B12)\n\n        Returns:\n            xarray.DataArray: The NDBI data.\n        \"\"\"\n        nir = self.data.nir\n        swir22 = self.data.swir22\n        ndbi_da = (nir - swir22) / (nir + swir22)\n\n        self.ndbi = ndbi_da\n\n        print(f\"NDBI data calculated. Access with the .ndbi attribute.\")\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.Sentinel2.__init__","title":"<code>__init__(self, bbox_input, start_date='2014-01-01', end_date='2025-03-03', catalog_choice='planetarycomputer', collection='sentinel-2-l2a', bands=None, resolution=None, crs=None, remove_nodata=True, harmonize_to_old=None, scale_data=True, groupby='solar_day')</code>  <code>special</code>","text":"<p>The constructor for the Sentinel2 class.</p> <p>Parameters:</p> Name Type Description Default <code>bbox_input</code> <code>geopandas.GeoDataFrame or tuple or Shapely Geometry</code> <p>GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.</p> required <code>start_date</code> <code>str</code> <p>The start date for the data in the format 'YYYY-MM-DD'. Default is '2014-01-01'.</p> <code>'2014-01-01'</code> <code>end_date</code> <code>str</code> <p>The end date for the data in the format 'YYYY-MM-DD'. Default is today's date.</p> <code>'2025-03-03'</code> <code>catalog_choice</code> <code>str</code> <p>The catalog choice for the data. Can choose between 'planetarycomputer' and 'earthsearch', default is 'planetarycomputer'.</p> <code>'planetarycomputer'</code> <code>bands</code> <code>list</code> <p>The bands to be used. Default is all bands. Must include SCL for data masking. Each band should be a string like 'B01', 'B02', etc.</p> <code>None</code> <code>resolution</code> <code>str</code> <p>The resolution of the data. Defaults to native resolution, 10m.</p> <code>None</code> <code>crs</code> <code>str</code> <p>The coordinate reference system. This should be a string like 'EPSG:4326'. Default CRS is UTM zone estimated from bounding box.</p> <code>None</code> <code>groupby</code> <code>str</code> <p>The groupby parameter for the data. Default is \"solar_day\".</p> <code>'solar_day'</code> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def __init__(\n    self,\n    bbox_input,\n    start_date=\"2014-01-01\",\n    end_date=today,\n    catalog_choice=\"planetarycomputer\",\n    collection= \"sentinel-2-l2a\", # could also choose \"sentinel-2-c1-l2a\" once published to https://github.com/Element84/earth-search\n    bands=None,\n    resolution=None,\n    crs=None,\n    remove_nodata=True,\n    harmonize_to_old=None,\n    scale_data=True,\n    groupby=\"solar_day\",\n):\n    \"\"\"\n    The constructor for the Sentinel2 class.\n\n    Parameters:\n        bbox_input (geopandas.GeoDataFrame or tuple or Shapely Geometry): GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.\n        start_date (str): The start date for the data in the format 'YYYY-MM-DD'. Default is '2014-01-01'.\n        end_date (str): The end date for the data in the format 'YYYY-MM-DD'. Default is today's date.\n        catalog_choice (str): The catalog choice for the data. Can choose between 'planetarycomputer' and 'earthsearch', default is 'planetarycomputer'.\n        bands (list): The bands to be used. Default is all bands. Must include SCL for data masking. Each band should be a string like 'B01', 'B02', etc.\n        resolution (str): The resolution of the data. Defaults to native resolution, 10m.\n        crs (str): The coordinate reference system. This should be a string like 'EPSG:4326'. Default CRS is UTM zone estimated from bounding box.\n        groupby (str): The groupby parameter for the data. Default is \"solar_day\".\n    \"\"\"\n    # Initialize the attributes\n    self.bbox_input = bbox_input\n    self.start_date = start_date\n    self.end_date = end_date\n    self.catalog_choice = catalog_choice\n    self.collection = collection\n    self.bands = bands\n    self.resolution = resolution\n    self.crs = crs\n    self.remove_nodata = remove_nodata\n    self.harmonize_to_old = harmonize_to_old\n    self.scale_data = scale_data\n    self.groupby = groupby\n\n    self.bbox_gdf = convert_bbox_to_geodataframe(self.bbox_input)\n\n    if self.crs == None:\n        self.crs = self.bbox_gdf.estimate_utm_crs()\n\n    # Define the band information\n    self.band_info = {\n        \"B01\": {\n            \"name\": \"coastal\",\n            \"description\": \"Coastal aerosol, 442.7 nm (S2A), 442.3 nm (S2B)\",\n            \"resolution\": \"60m\",\n            \"scale\": \"0.0001\",\n        },\n        \"B02\": {\n            \"name\": \"blue\",\n            \"description\": \"Blue, 492.4 nm (S2A), 492.1 nm (S2B)\",\n            \"resolution\": \"10m\",\n            \"scale\": \"0.0001\",\n        },\n        \"B03\": {\n            \"name\": \"green\",\n            \"description\": \"Green, 559.8 nm (S2A), 559.0 nm (S2B)\",\n            \"resolution\": \"10m\",\n            \"scale\": \"0.0001\",\n        },\n        \"B04\": {\n            \"name\": \"red\",\n            \"description\": \"Red, 664.6 nm (S2A), 665.0 nm (S2B)\",\n            \"resolution\": \"10m\",\n            \"scale\": \"0.0001\",\n        },\n        \"B05\": {\n            \"name\": \"rededge\",\n            \"description\": \"Vegetation red edge, 704.1 nm (S2A), 703.8 nm (S2B)\",\n            \"resolution\": \"20m\",\n            \"scale\": \"0.0001\",\n        },\n        \"B06\": {\n            \"name\": \"rededge2\",\n            \"description\": \"Vegetation red edge, 740.5 nm (S2A), 739.1 nm (S2B)\",\n            \"resolution\": \"20m\",\n            \"scale\": \"0.0001\",\n        },\n        \"B07\": {\n            \"name\": \"rededge3\",\n            \"description\": \"Vegetation red edge, 782.8 nm (S2A), 779.7 nm (S2B)\",\n            \"resolution\": \"20m\",\n            \"scale\": \"0.0001\",\n        },\n        \"B08\": {\n            \"name\": \"nir\",\n            \"description\": \"NIR, 832.8 nm (S2A), 833.0 nm (S2B)\",\n            \"resolution\": \"10m\",\n            \"scale\": \"0.0001\",\n        },\n        \"B8A\": {\n            \"name\": \"nir08\",\n            \"description\": \"Narrow NIR, 864.7 nm (S2A), 864.0 nm (S2B)\",\n            \"resolution\": \"20m\",\n            \"scale\": \"0.0001\",\n        },\n        \"B09\": {\n            \"name\": \"nir09\",\n            \"description\": \"Water vapour, 945.1 nm (S2A), 943.2 nm (S2B)\",\n            \"resolution\": \"60m\",\n            \"scale\": \"0.0001\",\n        },\n        \"B11\": {\n            \"name\": \"swir16\",\n            \"description\": \"SWIR, 1613.7 nm (S2A), 1610.4 nm (S2B)\",\n            \"resolution\": \"20m\",\n            \"scale\": \"0.0001\",\n        },\n        \"B12\": {\n            \"name\": \"swir22\",\n            \"description\": \"SWIR, 2202.4 nm (S2A), 2185.7 nm (S2B)\",\n            \"resolution\": \"20m\",\n            \"scale\": \"0.0001\",\n        },\n        \"AOT\": {\n            \"name\": \"aot\",\n            \"description\": \"Aerosol Optical Thickness map, based on Sen2Cor processor\",\n            \"resolution\": \"10m\",\n            \"scale\": \"1\",\n        },\n        \"SCL\": {\n            \"name\": \"scl\",\n            \"description\": \"Scene classification data, based on Sen2Cor processor\",\n            \"resolution\": \"20m\",\n            \"scale\": \"1\",\n        },\n        \"WVP\": {\n            \"name\": \"wvp\",\n            \"description\": \"Water Vapour map\",\n            \"resolution\": \"10m\",\n            \"scale\": \"1\",\n        },\n        \"visual\": {\n            \"name\": \"visual\",\n            \"description\": \"True color image\",\n            \"resolution\": \"10m\",\n            \"scale\": \"0.0001\",\n        },\n    }\n\n    # Define the scene classification information, classes here: https://custom-scripts.sentinel-hub.com/custom-scripts/sentinel-2/scene-classification/\n    self.scl_class_info = {\n        0: {\"name\": \"No Data (Missing data)\", \"color\": \"#000000\"},\n        1: {\"name\": \"Saturated or defective pixel\", \"color\": \"#ff0000\"},\n        2: {\n            \"name\": \"Topographic casted shadows\",\n            \"color\": \"#2f2f2f\",\n        },  # (called 'Dark features/Shadows' for data before 2022-01-25)\n        3: {\"name\": \"Cloud shadows\", \"color\": \"#643200\"},\n        4: {\"name\": \"Vegetation\", \"color\": \"#00a000\"},\n        5: {\"name\": \"Not-vegetated\", \"color\": \"#ffe65a\"},\n        6: {\"name\": \"Water\", \"color\": \"#0000ff\"},\n        7: {\"name\": \"Unclassified\", \"color\": \"#808080\"},\n        8: {\"name\": \"Cloud medium probability\", \"color\": \"#c0c0c0\"},\n        9: {\"name\": \"Cloud high probability\", \"color\": \"#ffffff\"},\n        10: {\"name\": \"Thin cirrus\", \"color\": \"#64c8ff\"},\n        11: {\"name\": \"Snow or ice\", \"color\": \"#ff96ff\"},\n    }\n\n    self.scl_cmap = plt.cm.colors.ListedColormap(\n        [info[\"color\"] for info in self.scl_class_info.values()]\n    )\n\n    # Initialize the data attributes\n    self.search = None\n    self.data = None\n    self.metadata = None\n\n    self.rgb = None\n    self.rgba = None\n    self.rgb_clahe = None\n    self.rgb_percentile = None\n    self.ndvi = None\n    self.ndsi = None\n    self.ndwi = None\n    self.evi = None\n    self.ndbi = None\n\n    self.search_data()\n    self.get_data()\n\n    if self.remove_nodata:\n        self.remove_nodata_inplace()\n\n    if self.harmonize_to_old is None:\n        if self.catalog_choice == \"planetarycomputer\":\n            self.harmonize_to_old = True\n        else:\n            if self.collection == \"sentinel-2-c1-l2a\":\n                self.harmonize_to_old = True\n            elif self.collection == \"sentinel-2-l2a\":\n                self.harmonize_to_old = False\n                print(f\"Since {self.collection} on {self.catalog_choice} is used, harmonization step is not needed.\")\n            else:\n                raise ValueError(f\"Unknown collection: {self.collection}\")\n\n    if self.harmonize_to_old:\n        self.harmonize_to_old_inplace()\n\n    if self.scale_data:\n        self.scale_data_inplace()\n\n    self.get_metadata()\n\n\n\n    # Add the plot_scl method as an attribute to the SCL data variable\n    if 'scl' in self.data.data_vars:\n        self.data.scl.attrs['example_plot'] = self.plot_scl\n        self.data.scl.attrs['class_info'] = self.scl_class_info\n        self.data.scl.attrs['cmap'] = self.scl_cmap\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.Sentinel2.get_data","title":"<code>get_data(self)</code>","text":"<p>The method to get the data.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def get_data(self):\n    \"\"\"\n    The method to get the data.\n    \"\"\"\n    # Prepare the parameters for odc.stac.load\n    load_params = {\n        \"items\": self.search.items(),\n        \"bbox\": self.bbox_gdf.total_bounds,\n        \"nodata\": 0,\n        \"chunks\": {},\n        \"crs\": self.crs,\n        \"groupby\": self.groupby,\n        \"stac_cfg\": get_stac_cfg(sensor=\"sentinel-2-l2a\"),\n    }\n    if self.bands:\n        load_params[\"bands\"] = self.bands\n    else:\n        load_params[\"bands\"] = [info[\"name\"] for info in self.band_info.values()]\n    if self.resolution:\n        load_params[\"resolution\"] = self.resolution\n\n    # Load the data lazily using odc.stac\n    self.data = odc.stac.load(**load_params)\n\n    self.data.attrs[\"band_info\"] = self.band_info\n    self.data.attrs[\"scl_class_info\"] = self.scl_class_info\n\n    if \"scl\" in self.data.variables:\n        self.data.scl.attrs[\"scl_class_info\"] = self.scl_class_info\n\n    print(\n        f\"Data retrieved. Access with the .data attribute. Data CRS: {self.bbox_gdf.estimate_utm_crs().name}.\"\n    )\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.Sentinel2.get_evi","title":"<code>get_evi(self)</code>","text":"<p>The method to get the EVI data.</p> <p>S2 EVI definition: 2.5 * (B08 - B04) / (B08 + 6 * B04 - 7.5 * B02 + 1) [https://www.indexdatabase.de/db/si-single.php?sensor_id=96&amp;rsindex_id=16]</p> <p>Returns:</p> Type Description <code>xarray.DataArray</code> <p>The EVI data.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def get_evi(self):\n    \"\"\"\n    The method to get the EVI data.\n    S2 EVI definition: 2.5 * (B08 - B04) / (B08 + 6 * B04 - 7.5 * B02 + 1) [https://www.indexdatabase.de/db/si-single.php?sensor_id=96&amp;rsindex_id=16]\n\n    Returns:\n        xarray.DataArray: The EVI data.\n    \"\"\"\n    red = self.data.red\n    nir = self.data.nir\n    blue = self.data.blue\n\n    evi_da = 2.5 * (nir - red) / (nir + 6 * red - 7.5 * blue + 1)\n\n    self.evi = evi_da\n\n    print(f\"EVI data calculated. Access with the .evi attribute.\")\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.Sentinel2.get_metadata","title":"<code>get_metadata(self)</code>","text":"<p>The method to get the metadata.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def get_metadata(self):\n    \"\"\"\n    The method to get the metadata.\n    \"\"\"\n\n    stac_json = self.search.item_collection_as_dict()\n    metadata_gdf = gpd.GeoDataFrame.from_features(stac_json, \"epsg:4326\")\n    if self.catalog_choice == \"earthsearch\":\n        metadata_gdf[\"s2:mgrs_tile\"] = (\n            metadata_gdf[\"mgrs:utm_zone\"].apply(lambda x: f\"{x:02d}\")\n            + metadata_gdf[\"mgrs:latitude_band\"]\n            + metadata_gdf[\"mgrs:grid_square\"]\n        )\n\n    self.metadata = metadata_gdf\n    print(f\"Metadata retrieved. Access with the .metadata attribute.\")\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.Sentinel2.get_ndbi","title":"<code>get_ndbi(self)</code>","text":"<p>The method to get the NDBI data.</p> <p>S2 NDBI definition: (B08 - B12) / (B08 + B12)</p> <p>Returns:</p> Type Description <code>xarray.DataArray</code> <p>The NDBI data.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def get_ndbi(self):\n    \"\"\"\n    The method to get the NDBI data.\n    S2 NDBI definition: (B08 - B12) / (B08 + B12)\n\n    Returns:\n        xarray.DataArray: The NDBI data.\n    \"\"\"\n    nir = self.data.nir\n    swir22 = self.data.swir22\n    ndbi_da = (nir - swir22) / (nir + swir22)\n\n    self.ndbi = ndbi_da\n\n    print(f\"NDBI data calculated. Access with the .ndbi attribute.\")\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.Sentinel2.get_ndsi","title":"<code>get_ndsi(self)</code>","text":"<p>The method to get the NDSI data.</p> <p>S2 NDSI definition: (B03 - B11) / (B03 + B11)</p> <p>Returns:</p> Type Description <p>ndsi_da (xarray.DataArray): The NDSI data.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def get_ndsi(self):\n    \"\"\"\n    The method to get the NDSI data.\n    S2 NDSI definition: (B03 - B11) / (B03 + B11)\n\n    Returns:\n        ndsi_da (xarray.DataArray): The NDSI data.\n    \"\"\"\n    green = self.data.green\n    swir16 = self.data.swir16\n    ndsi_da = (green - swir16) / (green + swir16)\n\n    self.ndsi = ndsi_da\n\n    print(f\"NDSI data calculated. Access with the .ndsi attribute.\")\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.Sentinel2.get_ndvi","title":"<code>get_ndvi(self)</code>","text":"<p>The method to get the NDVI data.</p> <p>S2 NDVI definition: (B08 - B04) / (B08 + B04) [https://www.indexdatabase.de/db/i-single.php?id=58]</p> <p>Returns:</p> Type Description <p>ndvi_da (xarray.DataArray): The NDVI data.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def get_ndvi(self):\n    \"\"\"\n    The method to get the NDVI data.\n    S2 NDVI definition: (B08 - B04) / (B08 + B04) [https://www.indexdatabase.de/db/i-single.php?id=58]\n\n    Returns:\n        ndvi_da (xarray.DataArray): The NDVI data.\n    \"\"\"\n    red = self.data.red\n    nir = self.data.nir\n    ndvi_da = (nir - red) / (nir + red)\n\n    self.ndvi = ndvi_da\n\n    print(f\"NDVI data calculated. Access with the .ndvi attribute.\")\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.Sentinel2.get_ndwi","title":"<code>get_ndwi(self)</code>","text":"<p>The method to get the NDWI data.</p> <p>S2 NDWI definition: (B03 - B08) / (B03 + B08)</p> <p>Returns:</p> Type Description <p>ndwi_da (xarray.DataArray): The NDWI data.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def get_ndwi(self):\n    \"\"\"\n    The method to get the NDWI data.\n    S2 NDWI definition: (B03 - B08) / (B03 + B08)\n\n    Returns:\n        ndwi_da (xarray.DataArray): The NDWI data.\n    \"\"\"\n    green = self.data.green\n    nir = self.data.nir\n    ndwi_da = (green - nir) / (green + nir)\n\n    self.ndwi = ndwi_da\n\n    print(f\"NDWI data calculated. Access with the .ndwi attribute.\")\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.Sentinel2.get_rgb","title":"<code>get_rgb(self, percentile_kwargs={'lower': 2, 'upper': 98}, clahe_kwargs={'clip_limit': 0.03, 'nbins': 256, 'kernel_size': None})</code>","text":"<p>Retrieve RGB data with optional percentile-based contrast stretching and CLAHE enhancement.</p> <p>This method calculates and stores three versions of RGB data: raw, percentile-stretched, and CLAHE-enhanced.</p> <p>Parameters:</p> Name Type Description Default <code>percentile_kwargs</code> <code>dict</code> <p>Parameters for percentile-based contrast stretching. Keys are: - 'lower': Lower percentile for contrast stretching (default: 2) - 'upper': Upper percentile for contrast stretching (default: 98)</p> <code>{'lower': 2, 'upper': 98}</code> <code>clahe_kwargs</code> <code>dict</code> <p>Parameters for CLAHE enhancement. Keys are: - 'clip_limit': Clipping limit for CLAHE (default: 0.03) - 'nbins': Number of bins for CLAHE histogram (default: 256) - 'kernel_size': Size of kernel for CLAHE (default: None)</p> <code>{'clip_limit': 0.03, 'nbins': 256, 'kernel_size': None}</code> <p>Returns:</p> Type Description <code>None</code> <p>The method stores results in instance attributes.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def get_rgb(self, percentile_kwargs={'lower': 2, 'upper': 98}, clahe_kwargs={'clip_limit': 0.03, 'nbins': 256, 'kernel_size': None}):\n    \"\"\"\n    Retrieve RGB data with optional percentile-based contrast stretching and CLAHE enhancement.\n\n    This method calculates and stores three versions of RGB data: raw, percentile-stretched, and CLAHE-enhanced.\n\n    Parameters\n    ----------\n    percentile_kwargs : dict, optional\n        Parameters for percentile-based contrast stretching. Keys are:\n        - 'lower': Lower percentile for contrast stretching (default: 2)\n        - 'upper': Upper percentile for contrast stretching (default: 98)\n    clahe_kwargs : dict, optional\n        Parameters for CLAHE enhancement. Keys are:\n        - 'clip_limit': Clipping limit for CLAHE (default: 0.03)\n        - 'nbins': Number of bins for CLAHE histogram (default: 256)\n        - 'kernel_size': Size of kernel for CLAHE (default: None)\n\n    Returns\n    -------\n    None\n        The method stores results in instance attributes.\n\n    Notes\n    -----\n    Results are stored in the following attributes:\n    - .rgb: Raw RGB data\n    - .rgb_percentile: Percentile-stretched RGB data\n    - .rgb_clahe: CLAHE-enhanced RGB data\n    \"\"\"\n\n    rgba_da = self.data.odc.to_rgba(bands=('red','green','blue'),vmin=0, vmax=1.7)\n    self.rgba = rgba_da\n\n    rgb_da = rgba_da.isel(band=slice(0, 3))  #.where(self.data.scl&gt;=0, other=255) if we want to make no data white\n    self.rgb = rgb_da\n\n    self.rgb_percentile = self.get_rgb_percentile(**percentile_kwargs)\n    self.rgb_clahe = self.get_rgb_clahe(**clahe_kwargs)\n\n    print(f\"RGB data retrieved.\\nAccess with the following attributes:\\n.rgb for raw RGB,\\n.rgba for RGBA,\\n.rgb_percentile for percentile RGB,\\n.rgb_clahe for CLAHE RGB.\\nYou can pass in percentile_kwargs and clahe_kwargs to adjust RGB calculations, check documentation for options.\")\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.Sentinel2.get_rgb_clahe","title":"<code>get_rgb_clahe(self, **kwargs)</code>","text":"<p>Apply Contrast Limited Adaptive Histogram Equalization (CLAHE) to RGB bands.</p> <p>This function creates a new DataArray with CLAHE applied to the RGB bands.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>dict</code> <p>Keyword arguments for CLAHE. Supported keys: - 'clip_limit': Clipping limit for CLAHE (default: 0.03) - 'nbins': Number of bins for CLAHE histogram (default: 256) - 'kernel_size': Size of kernel for CLAHE (default: None)</p> <code>{}</code> <p>Returns:</p> Type Description <code>xarray.DataArray</code> <p>RGB data with CLAHE enhancement applied.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def get_rgb_clahe(self, **kwargs):\n    \"\"\"\n    Apply Contrast Limited Adaptive Histogram Equalization (CLAHE) to RGB bands.\n\n    This function creates a new DataArray with CLAHE applied to the RGB bands.\n\n    Parameters\n    ----------\n    **kwargs : dict\n        Keyword arguments for CLAHE. Supported keys:\n        - 'clip_limit': Clipping limit for CLAHE (default: 0.03)\n        - 'nbins': Number of bins for CLAHE histogram (default: 256)\n        - 'kernel_size': Size of kernel for CLAHE (default: None)\n\n    Returns\n    -------\n    xarray.DataArray\n        RGB data with CLAHE enhancement applied.\n\n    Notes\n    -----\n    The function applies CLAHE to each band separately and masks areas where SCL &lt; 0.\n    https://scikit-image.org/docs/stable/api/skimage.exposure.html#skimage.exposure.equalize_adapthist\n    \"\"\"\n\n    # Custom wrapper to preserve xarray metadata\n    def equalize_adapthist_da(da, **kwargs):\n        # Apply the CLAHE function from skimage\n        result = skimage.exposure.equalize_adapthist(da.values, **kwargs)\n        #new_coords = {k: v for k, v in da.coords.items() if k != 'band' or len(v) == 3}\n\n        # Convert the result back to a DataArray, preserving the original metadata\n        return xr.DataArray(result, dims=da.dims, coords=da.coords, attrs=da.attrs)\n\n    rgb_da = self.rgb\n\n    #template = rgb_da.copy(data=np.empty_like(rgb_da).data)\n    template = xr.zeros_like(rgb_da)\n    rgb_clahe_da = xr.map_blocks(equalize_adapthist_da, rgb_da, template=template, kwargs=kwargs)\n    rgb_clahe_da = rgb_clahe_da.where(self.data.scl&gt;=0)\n\n    return rgb_clahe_da\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.Sentinel2.get_rgb_percentile","title":"<code>get_rgb_percentile(self, **percentile_kwargs)</code>","text":"<p>Apply percentile-based contrast stretching to the RGB bands of the Sentinel-2 data.</p> <p>This function creates a new DataArray with the contrast-stretched RGB bands.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>dict</code> <p>Keyword arguments for percentile calculation. Supported keys: - 'lower': Lower percentile for contrast stretching (default: 2) - 'upper': Upper percentile for contrast stretching (default: 98)</p> required <p>Returns:</p> Type Description <code>xarray.DataArray</code> <p>RGB data with percentile-based contrast stretching applied.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def get_rgb_percentile(self, **percentile_kwargs):\n    \"\"\"\n    Apply percentile-based contrast stretching to the RGB bands of the Sentinel-2 data.\n\n    This function creates a new DataArray with the contrast-stretched RGB bands.\n\n    Parameters\n    ----------\n    **kwargs : dict\n        Keyword arguments for percentile calculation. Supported keys:\n        - 'lower': Lower percentile for contrast stretching (default: 2)\n        - 'upper': Upper percentile for contrast stretching (default: 98)\n\n    Returns\n    -------\n    xarray.DataArray\n        RGB data with percentile-based contrast stretching applied.\n\n    Notes\n    -----\n    The function clips values to the range [0, 1] and masks areas where SCL &lt; 0.\n    \"\"\"\n    lower_percentile = percentile_kwargs.get('lower', 2)\n    upper_percentile = percentile_kwargs.get('upper', 98)\n\n    def stretch_percentile(da):\n        p_low, p_high = np.nanpercentile(da.values, [lower_percentile, upper_percentile])\n        return (da - p_low) / (p_high - p_low)\n\n    rgb_da = self.rgb\n\n    template = xr.zeros_like(rgb_da)\n    rgb_percentile_da = xr.map_blocks(stretch_percentile, rgb_da, template=template)\n    rgb_percentile_da = rgb_percentile_da.clip(0, 1).where(self.data.scl&gt;=0)\n\n    return rgb_percentile_da\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.Sentinel2.harmonize_to_old_inplace","title":"<code>harmonize_to_old_inplace(self)</code>","text":"<p>Harmonize new Sentinel-2 data to the old baseline.</p> <p>Adapted from: https://planetarycomputer.microsoft.com/dataset/sentinel-2-l2a#Baseline-Change</p> <p>Returns:</p> Type Description <code>xarray.Dataset</code> <p>A Dataset with all values harmonized to the old processing baseline.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def harmonize_to_old_inplace(self):\n    \"\"\"\n    Harmonize new Sentinel-2 data to the old baseline.\n    Adapted from: https://planetarycomputer.microsoft.com/dataset/sentinel-2-l2a#Baseline-Change\n    Returns\n    -------\n    harmonized: xarray.Dataset\n        A Dataset with all values harmonized to the old\n        processing baseline.\n    \"\"\"\n    cutoff = datetime.datetime(2022, 1, 25)\n    offset = 1000\n    bands = [\n        \"B01\",\n        \"B02\",\n        \"B03\",\n        \"B04\",\n        \"B05\",\n        \"B06\",\n        \"B07\",\n        \"B08\",\n        \"B8A\",\n        \"B09\",\n        \"B11\",\n        \"B12\",\n    ]\n    bands = [self.data.band_info[band][\"name\"] for band in bands]\n    old = self.data.sel(time=slice(None, cutoff))\n\n    to_process = list(set(bands) &amp; set(self.data.data_vars))\n    new = self.data.sel(time=slice(cutoff, None))\n\n    for band in to_process:\n        if band in new.data_vars:\n            new[band] = new[band].clip(offset) - offset\n\n    self.data = xr.concat([old, new], dim=\"time\")\n\n    print(\n        f\"Data acquired after January 25th, 2022 harmonized to old baseline. To override this behavior, set harmonize_to_old=False.\"\n    )\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.Sentinel2.mask_data","title":"<code>mask_data(self, remove_nodata=True, remove_saturated_defective=True, remove_topo_shadows=True, remove_cloud_shadows=True, remove_vegetation=False, remove_not_vegetated=False, remove_water=False, remove_unclassified=False, remove_medium_prob_clouds=True, remove_high_prob_clouds=True, remove_thin_cirrus_clouds=True, remove_snow_ice=False)</code>","text":"<p>The method to mask the data.</p> <p>Parameters:</p> Name Type Description Default <code>remove_nodata</code> <code>bool</code> <p>Whether to remove no data pixels.</p> <code>True</code> <code>remove_saturated_defective</code> <code>bool</code> <p>Whether to remove saturated or defective pixels.</p> <code>True</code> <code>remove_topo_shadows</code> <code>bool</code> <p>Whether to remove topographic shadow pixels.</p> <code>True</code> <code>remove_cloud_shadows</code> <code>bool</code> <p>Whether to remove cloud shadow pixels.</p> <code>True</code> <code>remove_vegetation</code> <code>bool</code> <p>Whether to remove vegetation pixels.</p> <code>False</code> <code>remove_not_vegetated</code> <code>bool</code> <p>Whether to remove not vegetated pixels.</p> <code>False</code> <code>remove_water</code> <code>bool</code> <p>Whether to remove water pixels.</p> <code>False</code> <code>remove_unclassified</code> <code>bool</code> <p>Whether to remove unclassified pixels.</p> <code>False</code> <code>remove_medium_prob_clouds</code> <code>bool</code> <p>Whether to remove medium probability cloud pixels.</p> <code>True</code> <code>remove_high_prob_clouds</code> <code>bool</code> <p>Whether to remove high probability cloud pixels.</p> <code>True</code> <code>remove_thin_cirrus_clouds</code> <code>bool</code> <p>Whether to remove thin cirrus cloud pixels.</p> <code>True</code> <code>remove_snow_ice</code> <code>bool</code> <p>Whether to remove snow or ice pixels.</p> <code>False</code> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def mask_data(\n    self,\n    remove_nodata=True,\n    remove_saturated_defective=True,\n    remove_topo_shadows=True,\n    remove_cloud_shadows=True,\n    remove_vegetation=False,\n    remove_not_vegetated=False,\n    remove_water=False,\n    remove_unclassified=False,\n    remove_medium_prob_clouds=True,\n    remove_high_prob_clouds=True,\n    remove_thin_cirrus_clouds=True,\n    remove_snow_ice=False,\n):\n    \"\"\"\n    The method to mask the data.\n\n    Parameters:\n        remove_nodata (bool): Whether to remove no data pixels.\n        remove_saturated_defective (bool): Whether to remove saturated or defective pixels.\n        remove_topo_shadows (bool): Whether to remove topographic shadow pixels.\n        remove_cloud_shadows (bool): Whether to remove cloud shadow pixels.\n        remove_vegetation (bool): Whether to remove vegetation pixels.\n        remove_not_vegetated (bool): Whether to remove not vegetated pixels.\n        remove_water (bool): Whether to remove water pixels.\n        remove_unclassified (bool): Whether to remove unclassified pixels.\n        remove_medium_prob_clouds (bool): Whether to remove medium probability cloud pixels.\n        remove_high_prob_clouds (bool): Whether to remove high probability cloud pixels.\n        remove_thin_cirrus_clouds (bool): Whether to remove thin cirrus cloud pixels.\n        remove_snow_ice (bool): Whether to remove snow or ice pixels.\n    \"\"\"\n\n    # Mask the data based on the Scene Classification (SCL) band (see definitions above)\n    mask_list = []\n    if remove_nodata:\n        mask_list.append(0)\n    if remove_saturated_defective:\n        mask_list.append(1)\n    if remove_topo_shadows:\n        mask_list.append(2)\n    if remove_cloud_shadows:\n        mask_list.append(3)\n    if remove_vegetation:\n        mask_list.append(4)\n    if remove_not_vegetated:\n        mask_list.append(5)\n    if remove_water:\n        mask_list.append(6)\n    if remove_unclassified:\n        mask_list.append(7)\n    if remove_medium_prob_clouds:\n        mask_list.append(8)\n    if remove_high_prob_clouds:\n        mask_list.append(9)\n    if remove_thin_cirrus_clouds:\n        mask_list.append(10)\n    if remove_snow_ice:\n        mask_list.append(11)\n\n    print(f\"Removed pixels with the following scene classification values:\")\n    for val in mask_list:\n        print(self.scl_class_info[val][\"name\"])\n\n    scl = self.data.scl\n    mask = scl.where(scl.isin(mask_list) == False, 0)\n    self.data = self.data.where(mask != 0)\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.Sentinel2.remove_nodata_inplace","title":"<code>remove_nodata_inplace(self)</code>","text":"<p>The method to remove no data values from the data.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def remove_nodata_inplace(self):\n    \"\"\"\n    The method to remove no data values from the data.\n    \"\"\"\n    data_removed = False\n    for band in self.data.data_vars:\n        nodata_value = None\n        nodata_value = self.data[band].attrs.get(\"nodata\")\n        if nodata_value is not None:\n            #print(f\"Removing nodata {nodata_value} values for band {band}...\")\n            self.data[band] = self.data[band].where(self.data[band] != nodata_value)\n            data_removed = True\n    if data_removed:\n        print(f\"Nodata values removed from the data. In doing so, all bands converted to float32. To turn this behavior off, set remove_nodata=False.\")\n    else:\n        print(f\"Tried to remove nodata values and set them to nans, but no nodata values found in the data.\")\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.Sentinel2.scale_data_inplace","title":"<code>scale_data_inplace(self)</code>","text":"<p>The method to scale the data.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def scale_data_inplace(self):\n    \"\"\"\n    The method to scale the data.\n    \"\"\"\n    for band in self.data.data_vars:\n        scale_factor = self.data[band].attrs.get(\"scale\")\n\n        if scale_factor is None:\n            scale_factor = next((info['scale'] for name, info in self.band_info.items() if info['name'] == band), None)\n\n        scale_factor = int(scale_factor) if scale_factor == '1' else float(scale_factor)\n        self.data[band] = self.data[band] * scale_factor\n\n    print(\n        f\"Data scaled to float reflectance. To turn this behavior off, set scale_data=False.\"\n    )\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.Sentinel2.search_data","title":"<code>search_data(self)</code>","text":"<p>The method to search the data.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def search_data(self):\n    \"\"\"\n    The method to search the data.\n    \"\"\"\n\n    # Choose the catalog URL based on catalog_choice\n    if self.catalog_choice == \"planetarycomputer\":\n        catalog_url = \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n        catalog = pystac_client.Client.open(\n            catalog_url, modifier=planetary_computer.sign_inplace\n        )\n    elif self.catalog_choice == \"earthsearch\":\n        os.environ[\"AWS_REGION\"] = \"us-west-2\"\n        os.environ[\"GDAL_DISABLE_READDIR_ON_OPEN\"] = \"EMPTY_DIR\"\n        os.environ[\"AWS_NO_SIGN_REQUEST\"] = \"YES\"\n        catalog_url = \"https://earth-search.aws.element84.com/v1\"\n        catalog = pystac_client.Client.open(catalog_url)\n    else:\n        raise ValueError(\n            \"Invalid catalog_choice. Choose either 'planetarycomputer' or 'earthsearch'.\"\n        )\n\n    # Search for items within the specified bbox and date range\n    search = catalog.search(\n        collections=[self.collection],\n        bbox=self.bbox_gdf.total_bounds,\n        datetime=(self.start_date, self.end_date),\n    )\n    self.search = search\n    print(f\"Data searched. Access the returned seach with the .search attribute.\")\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.authenticate_all","title":"<code>authenticate_all()</code>","text":"<p>Authenticates with all potential data providers.</p> <p>This function authenticates with NASA EarthData, Planetary Computer, and Earth Engine. It prints the authentication status for each provider.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def authenticate_all():\n    \"\"\"\n    Authenticates with all potential data providers.\n\n    This function authenticates with NASA EarthData, Planetary Computer, and Earth Engine.\n    It prints the authentication status for each provider.\n    \"\"\"\n    print(\"Authenticating for all potential data providers...\")\n\n    print(\"Authenticating for NASA EarthData...\")\n    earthaccess.login(persist=True)\n    # print(\"Authenticating for Planetary Computer...\")\n    # planetary_computer.set_subscription_key()\n    print(\"Authenticating for Earth Engine...\")\n    ee.Authenticate()\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.get_esa_worldcover","title":"<code>get_esa_worldcover(bbox_input=None, version='v200', mask_nodata=False)</code>","text":"<p>Fetches 10m ESA WorldCover global land cover data (2020 v100 or 2021 v200) for a given bounding box.</p> <p>Description: The discrete classification maps provide 11 classes defined using the Land Cover Classification System (LCCS) developed by the United Nations (UN) Food and Agriculture Organization (FAO).</p> <p>Parameters:</p> Name Type Description Default <code>bbox_input</code> <code>geopandas.geodataframe.GeoDataFrame | tuple | shapely.geometry.base.BaseGeometry | None</code> <p>GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.</p> <code>None</code> <code>version</code> <code>str</code> <p>Version of the WorldCover data. The two versions are v100 (2020) and v200 (2021). Default is 'v200'.</p> <code>'v200'</code> <code>mask_nodata</code> <code>bool</code> <p>Whether to mask no data values. Default is False. If False: (dtype=uint8, rio.nodata=0, rio.encoded_nodata=None) If True: (dtype=float32, rio.nodata=nan, rio.encoded_nodata=0)</p> <code>False</code> <p>Returns:</p> Type Description <code>DataArray</code> <p>WorldCover DataArray with class information in attributes.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def get_esa_worldcover(\n    bbox_input: gpd.GeoDataFrame | tuple | shapely.geometry.base.BaseGeometry | None = None,\n    version: str = \"v200\", mask_nodata: bool = False,\n) -&gt; xr.DataArray:\n    \"\"\"\n    Fetches 10m ESA WorldCover global land cover data (2020 v100 or 2021 v200) for a given bounding box.\n\n    Description:\n    The discrete classification maps provide 11 classes defined using the Land Cover Classification System (LCCS)\n    developed by the United Nations (UN) Food and Agriculture Organization (FAO).\n\n    Parameters\n    ----------\n    bbox_input : geopandas.GeoDataFrame or tuple or Shapely Geometry\n        GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.\n    version : str, optional\n        Version of the WorldCover data. The two versions are v100 (2020) and v200 (2021). Default is 'v200'.\n    mask_nodata : bool, optional\n        Whether to mask no data values. Default is False.\n        If False: (dtype=uint8, rio.nodata=0, rio.encoded_nodata=None)\n        If True: (dtype=float32, rio.nodata=nan, rio.encoded_nodata=0)\n\n    Returns\n    -------\n    xarray.DataArray\n        WorldCover DataArray with class information in attributes.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import geopandas as gpd\n    &gt;&gt;&gt; import easysnowdata\n    &gt;&gt;&gt; \n    &gt;&gt;&gt; # Define a bounding box for Mount Rainier\n    &gt;&gt;&gt; bbox = (-121.94, 46.72, -121.54, 46.99)\n    &gt;&gt;&gt; \n    &gt;&gt;&gt; # Fetch WorldCover data for the area\n    &gt;&gt;&gt; worldcover_da = easysnowdata.remote_sensing.get_esa_worldcover(bbox)\n    &gt;&gt;&gt; \n    &gt;&gt;&gt; # Plot the data using the example plot function\n    &gt;&gt;&gt; f, ax = worldcover_da.attrs['example_plot'](worldcover_da)\n\n    Notes\n    -----\n    Data citation:\n    Zanaga, D., Van De Kerchove, R., De Keersmaecker, W., Souverijns, N., Brockmann, C., Quast, R., Wevers, J., Grosu, A.,\n    Paccini, A., Vergnaud, S., Cartus, O., Santoro, M., Fritz, S., Georgieva, I., Lesiv, M., Carter, S., Herold, M., Li, Linlin,\n    Tsendbazar, N.E., Ramoino, F., Arino, O. (2021). ESA WorldCover 10 m 2020 v100. doi:10.5281/zenodo.5571936.\n    \"\"\"\n\n    def get_class_info():\n        classes = {\n            10: {\"name\": \"Tree cover\", \"color\": \"#006400\"},\n            20: {\"name\": \"Shrubland\", \"color\": \"#FFBB22\"},\n            30: {\"name\": \"Grassland\", \"color\": \"#FFFF4C\"},\n            40: {\"name\": \"Cropland\", \"color\": \"#F096FF\"},\n            50: {\"name\": \"Built-up\", \"color\": \"#FA0000\"},\n            60: {\"name\": \"Bare / sparse vegetation\", \"color\": \"#B4B4B4\"},\n            70: {\"name\": \"Snow and ice\", \"color\": \"#F0F0F0\"},\n            80: {\"name\": \"Permanent water bodies\", \"color\": \"#0064C8\"},\n            90: {\"name\": \"Herbaceous wetland\", \"color\": \"#0096A0\"},\n            95: {\"name\": \"Mangroves\", \"color\": \"#00CF75\"},\n            100: {\"name\": \"Moss and lichen\", \"color\": \"#FAE6A0\"},\n        }\n        return classes\n\n    def get_class_cmap(classes):\n        cmap = plt.cm.colors.ListedColormap(\n            [classes[key][\"color\"] for key in classes.keys()]\n        )\n        return cmap\n\n    def plot_classes(self, ax=None, figsize=(8, 10), legend_kwargs=None):\n        if ax is None:\n            f, ax = plt.subplots(figsize=figsize)\n        else:\n            f = ax.get_figure()\n\n        class_values = sorted(list(self.attrs[\"class_info\"].keys()))\n        bounds = [\n            (class_values[i] + class_values[i + 1]) / 2 for i in range(len(class_values) - 1)\n        ]\n        bounds = [class_values[0] - 0.5] + bounds + [class_values[-1] + 0.5]\n        norm = matplotlib.colors.BoundaryNorm(bounds, self.attrs[\"cmap\"].N)\n\n        im = self.plot.imshow(ax=ax, cmap=self.attrs[\"cmap\"], norm=norm, add_colorbar=False)\n        #ax.set_aspect(\"equal\")\n\n        legend_handles = []\n        class_names = []\n        for class_value, class_info in self.attrs[\"class_info\"].items():\n            legend_handles.append(\n                plt.Rectangle((0, 0), 1, 1, facecolor=class_info[\"color\"], edgecolor=\"black\")\n            )\n            class_names.append(class_info[\"name\"])\n\n        legend_kwargs = legend_kwargs or {}\n        default_legend_kwargs = {\n            \"bbox_to_anchor\": (0.5, -0.1),\n            \"loc\": \"upper center\",\n            \"ncol\": len(class_names) // 3,\n            \"frameon\": False,\n            \"handlelength\": 3.5,\n            \"handleheight\": 5,\n        }\n        legend_kwargs = {**default_legend_kwargs, **legend_kwargs}\n\n        ax.legend(legend_handles, class_names, **legend_kwargs)\n\n        ax.set_xlabel(\"Longitude\")\n        ax.set_ylabel(\"Latitude\")\n        ax.set_title(f\"ESA WorldCover\\n{version} ({version_year})\")\n        f.tight_layout(pad=5.5, w_pad=5.5, h_pad=1.5)\n        f.dpi = 300\n\n        return f, ax\n\n    # Convert the input to a GeoDataFrame if it's not already one\n    bbox_gdf = convert_bbox_to_geodataframe(bbox_input)\n\n    if version == \"v100\":\n        version_year = \"2020\"\n    elif version == \"v200\":\n        version_year = \"2021\"\n    else:\n        raise ValueError(\"Incorrect version number. Please provide 'v100' or 'v200'.\")\n\n    catalog = pystac_client.Client.open(\n        \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n        modifier=planetary_computer.sign_inplace,\n    )\n    search = catalog.search(collections=[\"esa-worldcover\"], bbox=bbox_gdf.total_bounds)\n    worldcover_da = (\n        odc.stac.load(\n            search.items(), bbox=bbox_gdf.total_bounds, bands=\"map\", chunks={}\n        )[\"map\"]\n        .sel(time=version_year)\n        .squeeze()\n    )\n\n    if mask_nodata:\n        worldcover_da = worldcover_da.where(worldcover_da&gt;0)\n        worldcover_da.rio.write_nodata(0, encoded=True, inplace=True)\n\n    worldcover_da.attrs[\"class_info\"] = get_class_info()\n    worldcover_da.attrs[\"cmap\"] = get_class_cmap(worldcover_da.attrs[\"class_info\"])\n    worldcover_da.attrs['data_citation'] = \"Zanaga, D., Van De Kerchove, R., De Keersmaecker, W., Souverijns, N., Brockmann, C., Quast, R., Wevers, J., Grosu, A., Paccini, A., Vergnaud, S., Cartus, O., Santoro, M., Fritz, S., Georgieva, I., Lesiv, M., Carter, S., Herold, M., Li, Linlin, Tsendbazar, N.E., Ramoino, F., Arino, O. (2021). ESA WorldCover 10 m 2020 v100. doi:10.5281/zenodo.5571936.\"\n\n    worldcover_da.attrs['example_plot'] = plot_classes\n\n    return worldcover_da\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.get_forest_cover_fraction","title":"<code>get_forest_cover_fraction(bbox_input=None, mask_nodata=False)</code>","text":"<p>Fetches ~100m forest cover fraction data for a given bounding box.</p> <p>Description: The data is obtained from the Copernicus Global Land Service: Land Cover 100m: collection 3: epoch 2019: Globe dataset. The specific layer used is the Tree-CoverFraction-layer, which provides the fractional cover (%) for the forest class.</p> <p>Parameters:</p> Name Type Description Default <code>bbox_input</code> <code>geopandas.geodataframe.GeoDataFrame | tuple | shapely.geometry.base.BaseGeometry | None</code> <p>GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.</p> <code>None</code> <code>mask_nodata</code> <code>bool</code> <p>Whether to mask no data values. Default is False. If False: (dtype=uint8, rio.nodata=255, rio.encoded_nodata=None) If True: (dtype=float32, rio.nodata=nan, rio.encoded_nodata=255)</p> <code>False</code> <p>Returns:</p> Type Description <code>DataArray</code> <p>Forest cover fraction DataArray.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def get_forest_cover_fraction(bbox_input: gpd.GeoDataFrame | tuple | shapely.geometry.base.BaseGeometry | None = None, mask_nodata: bool = False,\n) -&gt; xr.DataArray:\n    \"\"\"\n    Fetches ~100m forest cover fraction data for a given bounding box.\n\n    Description:\n    The data is obtained from the Copernicus Global Land Service: Land Cover 100m: collection 3: epoch 2019: Globe dataset.\n    The specific layer used is the Tree-CoverFraction-layer, which provides the fractional cover (%) for the forest class.\n\n    Parameters\n    ----------\n    bbox_input : geopandas.GeoDataFrame or tuple or shapely.Geometry\n        GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.\n    mask_nodata : bool, optional\n        Whether to mask no data values. Default is False.\n        If False: (dtype=uint8, rio.nodata=255, rio.encoded_nodata=None)\n        If True: (dtype=float32, rio.nodata=nan, rio.encoded_nodata=255)\n\n    Returns\n    -------\n    xarray.DataArray\n        Forest cover fraction DataArray.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import geopandas as gpd\n    &gt;&gt;&gt; from easysnowdata import remote_sensing\n    &gt;&gt;&gt; \n    &gt;&gt;&gt; # Define a bounding box for an area of interest\n    &gt;&gt;&gt; bbox = (-122.5, 47.0, -121.5, 48.0)\n    &gt;&gt;&gt; \n    &gt;&gt;&gt; # Fetch forest cover fraction data\n    &gt;&gt;&gt; forest_cover = remote_sensing.get_forest_cover_fraction(bbox)\n    &gt;&gt;&gt; \n    &gt;&gt;&gt; # Plot the data using the example plot function\n    &gt;&gt;&gt; f, ax = forest_cover.attrs['example_plot'](forest_cover)\n\n    Notes\n    -----\n    Data citation:\n    Marcel Buchhorn, Bruno Smets, Luc Bertels, Bert De Roo, Myroslava Lesiv, Nandin-Erdene Tsendbazar, Martin Herold, &amp; Steffen Fritz. (2020).\n    Copernicus Global Land Service: Land Cover 100m: collection 3: epoch 2019: Globe (V3.0.1) [Data set]. Zenodo. https://doi.org/10.5281/zenodo.3939050\n    \"\"\"\n\n    def plot_forest_cover(self, ax=None, figsize=(8, 10), legend_kwargs=None):\n        if ax is None:\n            f, ax = plt.subplots(figsize=figsize)\n        else:\n            f = ax.get_figure()\n\n        cmap = matplotlib.colormaps.get_cmap('Greens').copy()\n        cmap.set_over('white')  # Set values over 100 (i.e., 255) to white\n\n        im = self.plot.imshow(ax=ax, cmap=cmap, vmin=0, vmax=100, add_colorbar=False)\n\n        cbar = plt.colorbar(im, ax=ax, extend='max')\n        cbar.set_label('Forest Cover Fraction (%)')\n\n        ax.set_xlabel(\"Longitude\")\n        ax.set_ylabel(\"Latitude\")\n        ax.set_title(\"Copernicus Global Land Service Forest Cover Fraction\\nLand Cover 100m: collection 3: epoch 2019\")\n        f.tight_layout(pad=1.5, w_pad=1.5, h_pad=1.5)\n        f.dpi = 300\n\n        return f, ax\n\n    # Convert the input to a GeoDataFrame if it's not already one\n    bbox_gdf = convert_bbox_to_geodataframe(bbox_input)\n\n    fcf_da = rxr.open_rasterio(\n        \"https://zenodo.org/record/3939050/files/PROBAV_LC100_global_v3.0.1_2019-nrt_Tree-CoverFraction-layer_EPSG-4326.tif\",\n        chunks=True,\n        mask_and_scale=mask_nodata,\n    )\n\n    fcf_da = fcf_da.rio.clip_box(*bbox_gdf.total_bounds,crs=bbox_gdf.crs).squeeze()\n\n\n\n    fcf_da.attrs['example_plot'] = plot_forest_cover\n    fcf_da.attrs['data_citation'] = \"Marcel Buchhorn, Bruno Smets, Luc Bertels, Bert De Roo, Myroslava Lesiv, Nandin-Erdene Tsendbazar, Martin Herold, &amp; Steffen Fritz. (2020). Copernicus Global Land Service: Land Cover 100m: collection 3: epoch 2019: Globe (V3.0.1) [Data set]. Zenodo. https://doi.org/10.5281/zenodo.3939050\"\n\n    return fcf_da\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.get_nlcd_landcover","title":"<code>get_nlcd_landcover(bbox_input=None, layer='landcover', initialize_ee=True)</code>","text":"<p>Fetches National Land Cover Database (NLCD) data for a given bounding box.</p> <p>Description: The National Land Cover Database (NLCD) provides nationwide data on land cover and land cover change  at a 30m resolution. The dataset includes various layers such as land cover classification,  impervious surfaces, and urban intensity. Projection is an albers equal area conic projection.</p> <p>Parameters:</p> Name Type Description Default <code>bbox_input</code> <code>geopandas.geodataframe.GeoDataFrame | tuple | shapely.geometry.base.BaseGeometry | None</code> <p>GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.</p> <code>None</code> <code>layer</code> <code>str</code> <p>The NLCD layer to retrieve. Options are: - 'landcover' - 'impervious' - 'impervious_descriptor' - 'science_products_land_cover_change_count' - 'science_products_land_cover_change_first_disturbance_date' - 'science_products_land_cover_change_index' - 'science_products_land_cover_science_product' - 'science_products_forest_disturbance_date' Default is 'landcover'.</p> <code>'landcover'</code> <code>initialize_ee</code> <code>bool</code> <p>Whether to initialize Earth Engine. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>DataArray</code> <p>NLCD DataArray for the specified region and layer.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def get_nlcd_landcover(bbox_input: gpd.GeoDataFrame | tuple | shapely.geometry.base.BaseGeometry | None = None, \n             layer: str = 'landcover',\n             initialize_ee: bool = True) -&gt; xr.DataArray:\n    \"\"\"\n    Fetches National Land Cover Database (NLCD) data for a given bounding box.\n\n    Description:\n    The National Land Cover Database (NLCD) provides nationwide data on land cover and land cover change \n    at a 30m resolution. The dataset includes various layers such as land cover classification, \n    impervious surfaces, and urban intensity. Projection is an albers equal area conic projection.\n\n    Parameters\n    ----------\n    bbox_input : geopandas.GeoDataFrame or tuple or shapely.Geometry\n        GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.\n    layer : str, optional\n        The NLCD layer to retrieve. Options are:\n        - 'landcover'\n        - 'impervious'\n        - 'impervious_descriptor'\n        - 'science_products_land_cover_change_count'\n        - 'science_products_land_cover_change_first_disturbance_date'\n        - 'science_products_land_cover_change_index'\n        - 'science_products_land_cover_science_product'\n        - 'science_products_forest_disturbance_date'\n        Default is 'landcover'.\n    initialize_ee : bool, optional\n        Whether to initialize Earth Engine. Default is True.\n\n    Returns\n    -------\n    xarray.DataArray\n        NLCD DataArray for the specified region and layer.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import geopandas as gpd\n    &gt;&gt;&gt; import easysnowdata\n    &gt;&gt;&gt; \n    &gt;&gt;&gt; # Define a bounding box for an area of interest\n    &gt;&gt;&gt; bbox = (-122.5, 47.0, -121.5, 48.0)\n    &gt;&gt;&gt; \n    &gt;&gt;&gt; # Fetch NLCD land cover data\n    &gt;&gt;&gt; nlcd_landcover_da = easysnowdata.remote_sensing.get_nlcd_landcover(bbox, layer='landcover')\n    &gt;&gt;&gt; \n    &gt;&gt;&gt; # Plot the data\n    &gt;&gt;&gt; nlcd_landcover_da.attrs['example_plot'](nlcd_landcover_da)\n\n\n    Notes\n    -----\n    - NLCD data is only available for the contiguous United States\n    - The latest version (2021) includes data from 2001-2021\n    - Resolution is 30 meters\n\n    Data citation:\n    Dewitz, J., 2023, National Land Cover Database (NLCD) 2021 Products: U.S. Geological Survey data release, doi:10.5066/P9JZ7AO3\n    \"\"\"\n    # Initialize Earth Engine with high-volume endpoint\n    if initialize_ee:\n        ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')\n    else:\n        print(\"Initialization turned off. If you haven't already, please sign in to Google Earth Engine by running:\\n\\nimport ee\\nee.Authenticate()\\nee.Initialize()\\n\\n\")\n\n    # Convert the input to a GeoDataFrame if it's not already one\n    bbox_gdf = convert_bbox_to_geodataframe(bbox_input)\n\n    image_collection = ee.ImageCollection('USGS/NLCD_RELEASES/2021_REL/NLCD')\n    image = image_collection.first()\n\n    projection = image.select(0).projection()\n\n    ds = xr.open_dataset(\n        image_collection, \n        engine='ee', \n        geometry=tuple(bbox_gdf.total_bounds), \n        projection=projection,\n        chunks={},\n    ).squeeze().transpose().rename({'X':'x','Y':'y'}).rio.set_spatial_dims(x_dim='x', y_dim='y').astype('uint8')\n\n    nlcd_da = ds[layer]\n\n    # would be nice for them to come in as ints\n    # https://github.com/google/Xee/issues/86\n    # https://github.com/google/Xee/issues/146\n\n\n    def get_class_info():\n        info = image.getInfo()['properties']\n\n        if layer == 'landcover':\n            return {\n                value: {\n                    \"name\": name.split(':')[0],\n                    \"color\": f\"#{palette}\"\n                } for value, name, palette in zip(\n                    info['landcover_class_values'],\n                    info['landcover_class_names'],\n                    info['landcover_class_palette']\n                )\n            }\n        elif layer == 'impervious':\n            return None  \n        elif layer == 'impervious_descriptor':\n            return {\n                value: {\n                    \"name\": name.split('.')[0],\n                    \"color\": f\"#{palette}\"\n                } for value, name, palette in zip(\n                    info['impervious_descriptor_class_values'],\n                    info['impervious_descriptor_class_names'],\n                    info['impervious_descriptor_class_palette']\n                )\n            }\n        elif layer.startswith('science_products'):\n            return {\n                value: {\n                    \"name\": name,\n                    \"color\": f\"#{palette}\"\n                } for value, name, palette in zip(\n                    info[f'{layer}_class_values'],\n                    info[f'{layer}_class_names'],\n                    info[f'{layer}_class_palette']\n                )\n            }\n\n    def get_class_cmap(classes):\n        if classes is None: \n            return plt.cm.YlOrRd\n        return plt.cm.colors.ListedColormap([classes[key][\"color\"] for key in classes.keys()])\n\n    def plot_classes(self, ax=None, figsize=(8, 10), legend_kwargs=None):\n        if ax is None:\n            f, ax = plt.subplots(figsize=figsize)\n        else:\n            f = ax.get_figure()\n\n        if self.name != 'impervious':\n            class_values = sorted(list(self.attrs[\"class_info\"].keys()))\n            bounds = [(class_values[i] + class_values[i + 1]) / 2 for i in range(len(class_values) - 1)]\n            bounds = [class_values[0] - 0.5] + bounds + [class_values[-1] + 0.5]\n            norm = matplotlib.colors.BoundaryNorm(bounds, self.attrs[\"cmap\"].N)\n\n            im = self.plot.imshow(ax=ax, cmap=self.attrs[\"cmap\"], norm=norm, add_colorbar=False)\n\n            legend_handles = []\n            class_names = []\n            for class_value, class_info in self.attrs[\"class_info\"].items():\n                legend_handles.append(\n                    plt.Rectangle((0, 0), 1, 1, facecolor=class_info[\"color\"], edgecolor=\"black\")\n                )\n                class_names.append(class_info[\"name\"])\n\n            legend_kwargs = legend_kwargs or {}\n            default_legend_kwargs = {\n                \"bbox_to_anchor\": (0.5, -0.1),\n                \"loc\": \"upper center\",\n                \"ncols\": 4,\n                \"frameon\": False,\n                \"handlelength\": 3.5,\n                \"handleheight\": 5,\n            }\n            legend_kwargs = {**default_legend_kwargs, **legend_kwargs}\n            ax.legend(legend_handles, class_names, **legend_kwargs)\n\n        else: \n            im = self.plot.imshow(ax=ax, cmap=self.attrs[\"cmap\"], add_colorbar=False)\n            f.colorbar(im, ax=ax, label='Percent impervious surface [%]')\n\n        ax.set_xlabel(\"x\")\n        ax.set_ylabel(\"y\")\n        #ax.axis('equal')\n        ax.set_title(f\"NLCD {self.name.title()} (2021)\")\n        #f.tight_layout(pad=0, w_pad=0, h_pad=0)\n        f.dpi = 300\n\n        return f, ax\n\n    class_info = get_class_info()\n    nlcd_da.attrs[\"class_info\"] = class_info\n    nlcd_da.attrs[\"cmap\"] = get_class_cmap(class_info)\n    nlcd_da.attrs[\"example_plot\"] = plot_classes\n\n    nlcd_da.attrs['data_citation'] = \"Dewitz, J., 2023, National Land Cover Database (NLCD) 2021 Products: U.S. Geological Survey data release, doi:10.5066/P9JZ7AO3\"\n\n\n    return nlcd_da\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.get_seasonal_mountain_snow_mask","title":"<code>get_seasonal_mountain_snow_mask(bbox_input=None, data_product='mountain_snow', mask_nodata=False)</code>","text":"<p>Fetches ~1km static global seasonal (mountain snow / snow) mask for a given bounding box.</p> <p>Description: Seasonal Mountain Snow (SMS) mask derived from MODIS MOD10A2 snow cover extent and GTOPO30 digital elevation model produced at 30 arcsecond spatial resolution.</p> <p>Parameters:</p> Name Type Description Default <code>bbox_input</code> <code>geopandas.geodataframe.GeoDataFrame | tuple | shapely.geometry.base.BaseGeometry | None</code> <p>GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.</p> <code>None</code> <code>data_product</code> <code>str</code> <p>Data product to fetch. Choose from 'snow' or 'mountain_snow'. Default is 'mountain_snow'.</p> <code>'mountain_snow'</code> <code>mask_nodata</code> <code>bool</code> <p>Whether to mask no data values. Default is False. If False: (dtype=uint8, rio.nodata=255, rio.encoded_nodata=None) If True: (dtype=float32, rio.nodata=nan, rio.encoded_nodata=255)</p> <code>False</code> <p>Returns:</p> Type Description <code>DataArray</code> <p>Mountain snow DataArray with class information in attributes.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def get_seasonal_mountain_snow_mask(\n    bbox_input: gpd.GeoDataFrame | tuple | shapely.geometry.base.BaseGeometry | None = None, data_product: str = \"mountain_snow\", mask_nodata: bool = False,\n) -&gt; xr.DataArray:\n    \"\"\"\n    Fetches ~1km static global seasonal (mountain snow / snow) mask for a given bounding box.\n\n    Description:\n    Seasonal Mountain Snow (SMS) mask derived from MODIS MOD10A2 snow cover extent and GTOPO30 digital elevation model\n    produced at 30 arcsecond spatial resolution.\n\n    Parameters\n    ----------\n    bbox_input : geopandas.GeoDataFrame or tuple or shapely.Geometry\n        GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.\n    data_product : str, optional\n        Data product to fetch. Choose from 'snow' or 'mountain_snow'. Default is 'mountain_snow'.\n    mask_nodata : bool, optional\n        Whether to mask no data values. Default is False.\n        If False: (dtype=uint8, rio.nodata=255, rio.encoded_nodata=None)\n        If True: (dtype=float32, rio.nodata=nan, rio.encoded_nodata=255)\n\n    Returns\n    -------\n    xarray.DataArray\n        Mountain snow DataArray with class information in attributes.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import geopandas as gpd\n    &gt;&gt;&gt; import easysnowdata\n    &gt;&gt;&gt; \n    &gt;&gt;&gt; # Define a bounding box for a mountainous area\n    &gt;&gt;&gt; bbox = (-106.0, 39.0, -105.0, 40.0)\n    &gt;&gt;&gt; \n    &gt;&gt;&gt; # Fetch mountain snow mask data\n    &gt;&gt;&gt; mountain_snow_da = easysnowdata.remote_sensing.get_seasonal_mountain_snow_mask(bbox)\n    &gt;&gt;&gt; \n    &gt;&gt;&gt; # Plot the data using the example plot function\n    &gt;&gt;&gt; f, ax = mountain_snow_da.attrs['example_plot'](mountain_snow_da)\n\n    Notes\n    -----\n    Data citation:\n    Wrzesien, M., Pavelsky, T., Durand, M., Lundquist, J., &amp; Dozier, J. (2019).\n    Global Seasonal Mountain Snow Mask from MODIS MOD10A2 [Data set]. Zenodo. https://doi.org/10.5281/zenodo.2626737\n    \"\"\"\n\n    def get_class_info(data_product):\n        if data_product == \"snow\":\n            classes = {\n                0: {\"name\": \"Little-to-no snow\", \"color\": \"#030303\"},\n                1: {\"name\": \"Indeterminate due to clouds\", \"color\": \"#755F4A\"},\n                2: {\"name\": \"Ephemeral snow\", \"color\": \"#792B8E\"},\n                3: {\"name\": \"Seasonal snow\", \"color\": \"#679ACF\"},\n                255: {\"name\": \"Fill\", \"color\": \"#ffffff\"},\n            }\n        elif data_product == \"mountain_snow\":\n            classes = {\n                0: {\"name\": \"Mountains with little-to-no snow\", \"color\": \"#030303\"},\n                1: {\"name\": \"Indeterminate due to clouds\", \"color\": \"#755F4A\"},\n                2: {\"name\": \"Mountains with ephemeral snow\", \"color\": \"#792B8E\"},\n                3: {\"name\": \"Mountains with seasonal snow\", \"color\": \"#679ACF\"},\n                255: {\"name\": \"Fill\", \"color\": \"#ffffff\"},\n            }\n        else:\n            raise ValueError('Invalid data_product. Choose from \"snow\" or \"mountain_snow\".')\n        return classes\n\n    def get_class_cmap(classes):\n        cmap = plt.cm.colors.ListedColormap(\n            [classes[key][\"color\"] for key in classes.keys()]\n        )\n        return cmap\n\n    def plot_classes(self, ax=None, figsize=(8, 10), legend_kwargs=None):\n        if ax is None:\n            f, ax = plt.subplots(figsize=figsize)\n        else:\n            f = ax.get_figure()\n\n        class_values = sorted(list(self.attrs[\"class_info\"].keys()))\n        bounds = [\n            (class_values[i] + class_values[i + 1]) / 2 for i in range(len(class_values) - 1)\n        ]\n        bounds = [class_values[0] - 0.5] + bounds + [class_values[-1] + 0.5]\n        norm = matplotlib.colors.BoundaryNorm(bounds, self.attrs[\"cmap\"].N)\n\n        im = self.plot.imshow(ax=ax, cmap=self.attrs[\"cmap\"], norm=norm, add_colorbar=False)\n        #ax.set_aspect(\"equal\")\n\n        legend_handles = []\n        class_names = []\n        for class_value, class_info in self.attrs[\"class_info\"].items():\n            legend_handles.append(\n                plt.Rectangle((0, 0), 1, 1, facecolor=class_info[\"color\"], edgecolor=\"black\")\n            )\n            class_names.append(class_info[\"name\"])\n\n        legend_kwargs = legend_kwargs or {}\n        default_legend_kwargs = {\n            \"bbox_to_anchor\": (0.5, -0.1),\n            \"loc\": \"upper center\",\n            \"ncol\": len(class_names) // 2,\n            \"frameon\": False,\n            \"handlelength\": 3.5,\n            \"handleheight\": 5,\n        }\n        legend_kwargs = {**default_legend_kwargs, **legend_kwargs}\n\n        ax.legend(legend_handles, class_names, **legend_kwargs)\n\n        ax.set_xlabel(\"Longitude\")\n        ax.set_ylabel(\"Latitude\")\n        ax.set_title(f\"Global seasonal {'mountain ' if data_product == 'mountain_snow' else ''}snow mask\\nfrom Wrzesien et al 2019\")\n        f.tight_layout(pad=5.5, w_pad=5.5, h_pad=1.5)\n        f.dpi = 300\n\n        return f, ax\n\n    print(f'This function takes a moment, getting zipped file from zenodo...')\n    # Convert the input to a GeoDataFrame if it's not already one\n    bbox_gdf = convert_bbox_to_geodataframe(bbox_input)\n\n    url = f\"zip+https://zenodo.org/records/2626737/files/MODIS_{'mtnsnow' if data_product == 'mountain_snow' else 'snow'}_classes.zip!/MODIS_{'mtnsnow' if data_product == 'mountain_snow' else 'snow'}_classes.tif\"\n\n    mountain_snow_da = rxr.open_rasterio(\n        url,\n        chunks=True,\n        mask_and_scale=mask_nodata,\n    ).rio.clip_box(*bbox_gdf.total_bounds, crs=bbox_gdf.crs).squeeze()\n\n    # looks like the creators accidently set no data to 256 and 265 instead of 255, therefore unmasked the data is of type uint32 :(\n    # attempt to fix this by setting all invalid values to 255, then converting types\n    mask = mountain_snow_da &gt; 3\n    mountain_snow_da = mountain_snow_da.where(~mask, 255)\n\n    if mask_nodata:\n        mountain_snow_da = mountain_snow_da.astype(\"float32\").rio.write_nodata(255, encoded=True)\n    else:\n        mountain_snow_da = mountain_snow_da.astype(\"uint8\").rio.set_nodata(255)\n\n\n    mountain_snow_da.attrs[\"class_info\"] = get_class_info(data_product)\n    mountain_snow_da.attrs[\"cmap\"] = get_class_cmap(mountain_snow_da.attrs[\"class_info\"])\n    mountain_snow_da.attrs['data_citation'] = \"Wrzesien, M., Pavelsky, T., Durand, M., Lundquist, J., &amp; Dozier, J. (2019). Global Seasonal Mountain Snow Mask from MODIS MOD10A2 [Data set]. Zenodo. https://doi.org/10.5281/zenodo.2626737\"\n\n    mountain_snow_da.attrs['example_plot'] = plot_classes\n\n    return mountain_snow_da\n</code></pre>"},{"location":"remote_sensing/#easysnowdata.remote_sensing.get_seasonal_snow_classification","title":"<code>get_seasonal_snow_classification(bbox_input=None, mask_nodata=False)</code>","text":"<p>Fetches 10arcsec (~300m) Sturm &amp; Liston 2021 seasonal snow classification data for a given bounding box.</p> <p>Description: This dataset consists of global, seasonal snow classifications determined from air temperature, precipitation, and wind speed climatologies. This is the 10 arcsec (~300m) product in EPSG:4326.</p> <p>Parameters:</p> Name Type Description Default <code>bbox_input</code> <code>geopandas.geodataframe.GeoDataFrame | tuple | shapely.geometry.base.BaseGeometry | None</code> <p>GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.</p> <code>None</code> <code>mask_nodata</code> <code>bool</code> <p>Whether to mask no data values. Default is False. If False: (dtype=uint8, rio.nodata=9, rio.encoded_nodata=None) If True: (dtype=float32, rio.nodata=nan, rio.encoded_nodata=9)</p> <code>False</code> <p>Returns:</p> Type Description <code>DataArray</code> <p>Seasonal snow class DataArray with class information in attributes.</p> Source code in <code>easysnowdata/remote_sensing.py</code> <pre><code>def get_seasonal_snow_classification(bbox_input: gpd.GeoDataFrame | tuple | shapely.geometry.base.BaseGeometry | None = None, mask_nodata: bool = False,\n) -&gt; xr.DataArray:\n    \"\"\"\n    Fetches 10arcsec (~300m) Sturm &amp; Liston 2021 seasonal snow classification data for a given bounding box.\n\n    Description:\n    This dataset consists of global, seasonal snow classifications determined from air temperature,\n    precipitation, and wind speed climatologies. This is the 10 arcsec (~300m) product in EPSG:4326.\n\n    Parameters\n    ----------\n    bbox_input : geopandas.GeoDataFrame or tuple or Shapely Geometry\n        GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.\n    mask_nodata : bool, optional\n        Whether to mask no data values. Default is False.\n        If False: (dtype=uint8, rio.nodata=9, rio.encoded_nodata=None)\n        If True: (dtype=float32, rio.nodata=nan, rio.encoded_nodata=9)\n\n    Returns\n    -------\n    xarray.DataArray\n        Seasonal snow class DataArray with class information in attributes.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import geopandas as gpd\n    &gt;&gt;&gt; import easysnowdata\n    &gt;&gt;&gt; \n    &gt;&gt;&gt; # Define a bounding box for an area of interest\n    &gt;&gt;&gt; bbox = (-120.0, 40.0, -118.0, 42.0)\n    &gt;&gt;&gt; \n    &gt;&gt;&gt; # Fetch seasonal snow classification data\n    &gt;&gt;&gt; snow_classification_da = easysnowdata.remote_sensing.get_seasonal_snow_classification(bbox)\n    &gt;&gt;&gt; \n    &gt;&gt;&gt; # Plot the data using the example plot function\n    &gt;&gt;&gt; f,ax = snow_classification_da.attrs['example_plot'](snow_classification_da)\n\n    Notes\n    -----\n    Data citation:\n    Liston, G. E. and M. Sturm. (2021). Global Seasonal-Snow Classification, Version 1 [Data Set].\n    Boulder, Colorado USA. National Snow and Ice Data Center. https://doi.org/10.5067/99FTCYYYLAQ0. Date Accessed 03-06-2024.\n    \"\"\"\n\n    def get_class_info():\n        classes = {\n            1: {\"name\": \"Tundra\", \"color\": \"#a100c8\"},\n            2: {\"name\": \"Boreal Forest\", \"color\": \"#00a0fe\"},\n            3: {\"name\": \"Maritime\", \"color\": \"#fe0000\"},\n            4: {\"name\": \"Ephemeral (includes no snow)\", \"color\": \"#e7dc32\"},\n            5: {\"name\": \"Prairie\", \"color\": \"#f08328\"},\n            6: {\"name\": \"Montane Forest\", \"color\": \"#00dc00\"},\n            7: {\"name\": \"Ice (glaciers and ice sheets)\", \"color\": \"#aaaaaa\"},\n            8: {\"name\": \"Ocean\", \"color\": \"#0000ff\"},\n            9: {\"name\": \"Fill\", \"color\": \"#ffffff\"},\n        }\n        return classes\n\n    def get_class_cmap(classes):\n        cmap = plt.cm.colors.ListedColormap(\n            [classes[key][\"color\"] for key in classes.keys()]\n        )\n        return cmap\n\n    def plot_classes(self, ax=None, figsize=(8, 10), legend_kwargs=None):\n        if ax is None:\n            f, ax = plt.subplots(figsize=figsize)\n        else:\n            f = ax.get_figure()\n\n        class_values = sorted(list(self.attrs[\"class_info\"].keys()))\n        bounds = [\n            (class_values[i] + class_values[i + 1]) / 2 for i in range(len(class_values) - 1)\n        ]\n        bounds = [class_values[0] - 0.5] + bounds + [class_values[-1] + 0.5]\n        norm = matplotlib.colors.BoundaryNorm(bounds, self.attrs[\"cmap\"].N)\n\n        im = self.plot.imshow(ax=ax, cmap=self.attrs[\"cmap\"], norm=norm, add_colorbar=False)\n        #ax.set_aspect(\"equal\")\n\n\n        legend_handles = []\n        class_names = []\n        for class_value, class_info in self.attrs[\"class_info\"].items():\n            legend_handles.append(\n                plt.Rectangle((0, 0), 1, 1, facecolor=class_info[\"color\"], edgecolor=\"black\")\n            )\n            class_names.append(class_info[\"name\"])\n\n        legend_kwargs = legend_kwargs or {}\n        default_legend_kwargs = {\n            \"bbox_to_anchor\": (0.5, -0.1),\n            \"loc\": \"upper center\",\n            \"ncol\": len(class_names) // 3,\n            \"frameon\": False,\n            \"handlelength\": 3.5,\n            \"handleheight\": 5,\n        }\n        legend_kwargs = {**default_legend_kwargs, **legend_kwargs}\n\n        ax.legend(legend_handles, class_names, **legend_kwargs)\n\n        ax.set_xlabel(\"Longitude\")\n        ax.set_ylabel(\"Latitude\")\n        ax.set_title(\"Seasonal snow classification\\nfrom Sturm &amp; Liston 2021\")\n        f.tight_layout(pad=1.5, w_pad=1.5, h_pad=1.5)\n        f.dpi = 300\n\n        return f, ax\n\n    # Convert the input to a GeoDataFrame if it's not already one\n    bbox_gdf = convert_bbox_to_geodataframe(bbox_input)\n\n    snow_classification_da = rxr.open_rasterio(\n        \"https://snowmelt.blob.core.windows.net/snowmelt/eric/snow_classification/SnowClass_GL_300m_10.0arcsec_2021_v01.0.tif\",\n        chunks=True,\n        mask_and_scale=mask_nodata,\n    )\n    snow_classification_da = (\n        snow_classification_da.rio.clip_box(*bbox_gdf.total_bounds,crs=bbox_gdf.crs).squeeze()\n    )\n\n    if mask_nodata:\n        snow_classification_da.rio.write_nodata(9, encoded=True, inplace=True)\n    else:\n        snow_classification_da.rio.set_nodata(9, inplace=True)\n\n    snow_classification_da.attrs[\"class_info\"] = get_class_info()\n    snow_classification_da.attrs[\"cmap\"] = get_class_cmap(snow_classification_da.attrs[\"class_info\"])\n    snow_classification_da.attrs['data_citation'] = \"Liston, G. E. and M. Sturm. (2021). Global Seasonal-Snow Classification, Version 1 [Data Set]. Boulder, Colorado USA. National Snow and Ice Data Center. https://doi.org/10.5067/99FTCYYYLAQ0. Date Accessed 03-06-2024.\"\n\n    snow_classification_da.attrs['example_plot'] = plot_classes\n\n    return snow_classification_da\n</code></pre>"},{"location":"topography/","title":"topography module","text":""},{"location":"topography/#easysnowdata.topography.get_chili","title":"<code>get_chili(bbox_input=None, initialize_ee=True)</code>","text":"<p>Fetches Continuous Heat-Insolation Load Index (CHILI) data for a given bounding box. </p> <p>Description: CHILI is a topographic index that quantifies the combined effect of solar radiation and surface temperature. It is derived from the ALOS World 3D - 30m (AW3D30) dataset and is available globally between 70\u00b0N and 70\u00b0S. The values range from 0 to 1, with classifications warm (0.767,1], cool [0,0.448), and neutral [0.448,0.767].</p> <p>Parameters:</p> Name Type Description Default <code>bbox_input</code> <code>geopandas.geodataframe.GeoDataFrame | tuple | shapely.geometry.base.BaseGeometry | None</code> <p>GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataArray</code> <p>CHILI DataArray for the specified region.</p> Source code in <code>easysnowdata/topography.py</code> <pre><code>def get_chili(bbox_input: gpd.GeoDataFrame | tuple | shapely.geometry.base.BaseGeometry | None = None, initialize_ee: bool = True,\n) -&gt; xr.DataArray:\n    \"\"\"\n    Fetches Continuous Heat-Insolation Load Index (CHILI) data for a given bounding box. \n\n    Description:\n    CHILI is a topographic index that quantifies the combined effect of solar radiation and surface temperature.\n    It is derived from the ALOS World 3D - 30m (AW3D30) dataset and is available globally between 70\u00b0N and 70\u00b0S.\n    The values range from 0 to 1, with classifications warm (0.767,1], cool [0,0.448), and neutral [0.448,0.767].\n\n    Parameters\n    ----------\n    bbox_input : geopandas.GeoDataFrame or tuple or shapely.Geometry\n        GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.\n\n    Returns\n    -------\n    xarray.DataArray\n        CHILI DataArray for the specified region.\n\n    Examples\n    --------\n    &gt;&gt;&gt; import geopandas as gpd\n    &gt;&gt;&gt; easysnowdata\n    &gt;&gt;&gt; \n    &gt;&gt;&gt; # Define a bounding box for an area of interest\n    &gt;&gt;&gt; bbox = (-122.5, 47.0, -121.5, 48.0)\n    &gt;&gt;&gt; \n    &gt;&gt;&gt; # Fetch CHILI data\n    &gt;&gt;&gt; chili_data = easysnowdata.remote_sensing.get_chili(bbox)\n    &gt;&gt;&gt; \n    &gt;&gt;&gt; # Plot the data\n    &gt;&gt;&gt; chili_data.plot(cmap='viridis')\n\n    Notes\n    -----\n    - CHILI data is only available for latitudes between 70\u00b0N and 70\u00b0S.\n    - The function uses Google Earth Engine to access the dataset.\n\n    Data citation:\n    Theobald, D.M., Harrison-Atlas, D., Monahan, W.B., Albano, C.M. (2015).\n    Ecologically-Relevant Maps of Landforms and Physiographic Diversity for Climate Adaptation Planning.\n    PLoS ONE 10(12): e0143619. https://doi.org/10.1371/journal.pone.0143619\n    \"\"\"\n\n    # Initialize Earth Engine with high-volume endpoint\n    if initialize_ee == True:\n        ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')\n    else:\n        print(f'Initialization turned off. If you haven\\'t already, please sign in to Google Earth Engine by running the following code:\\n\\nimport ee\\nee.Authenticate()\\nee.Initialize()\\n\\n')\n\n    # Convert the input to a GeoDataFrame if it's not already one\n    bbox_gdf = convert_bbox_to_geodataframe(bbox_input)\n    # Access the CHILI dataset\n    image = ee.Image(\"CSP/ERGo/1_0/Global/ALOS_CHILI\")\n    image_collection = ee.ImageCollection(image)\n\n    # Get projection information\n    crs = image.projection().getInfo()['crs']\n    transform = image.projection().getInfo()['transform']\n\n    # Load the data using xarray and Earth Engine\n    chili_da = xr.open_dataset(image_collection, engine='ee', geometry=tuple(bbox_gdf.total_bounds), projection=ee.Projection(crs=crs,transform=transform)).drop_vars('time').squeeze()['constant'].squeeze().transpose().rio.set_spatial_dims(x_dim='lon', y_dim='lat')\n    # maybe add chunks={} here to lazy load data\n\n    # Clip the data to the bounding box\n    chili_da = chili_da.rio.clip_box(*bbox_gdf.total_bounds, crs=bbox_gdf.crs)\n\n    # Check if data is available for the specified region\n    if chili_da.isnull().all().item():\n        print(\"No CHILI data available for this location. CHILI data is only available for latitudes between 70\u00b0N and 70\u00b0S.\")\n\n    chili_da = (chili_da - chili_da.min()) / (chili_da.max() - chili_da.min())\n\n    chili_da.attrs['data_citation'] = \"Theobald, D.M., Harrison-Atlas, D., Monahan, W.B., Albano, C.M. (2015). Ecologically-Relevant Maps of Landforms and Physiographic Diversity for Climate Adaptation Planning. PLoS ONE 10(12): e0143619. https://doi.org/10.1371/journal.pone.0143619\"\n\n    return chili_da\n</code></pre>"},{"location":"topography/#easysnowdata.topography.get_copernicus_dem","title":"<code>get_copernicus_dem(bbox_input=None, resolution=30)</code>","text":"<p>Fetches 30m or 90m Copernicus DEM from Microsoft Planetary Computer.</p> <p>This function retrieves the Copernicus Digital Elevation Model (DEM) data for a specified bounding box and resolution. The DEM represents the surface of the Earth including buildings, infrastructure, and vegetation.</p> <p>Parameters:</p> Name Type Description Default <code>bbox_input</code> <code>geopandas.geodataframe.GeoDataFrame | tuple | shapely.geometry.base.BaseGeometry | None</code> <p>GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.</p> <code>None</code> <code>resolution</code> <code>int</code> <p>The resolution of the DEM, either 30 or 90 meters. Default is 30.</p> <code>30</code> <p>Exceptions:</p> Type Description <code>ValueError</code> <p>If the resolution is not 30 or 90 meters.</p> <p>Returns:</p> Type Description <code>DataArray</code> <p>A DataArray containing the Copernicus DEM data for the specified area.</p> Source code in <code>easysnowdata/topography.py</code> <pre><code>def get_copernicus_dem(bbox_input: gpd.GeoDataFrame | tuple | shapely.geometry.base.BaseGeometry | None = None,\n                       resolution: int = 30\n) -&gt; xr.DataArray:\n    \"\"\"\n    Fetches 30m or 90m Copernicus DEM from Microsoft Planetary Computer.\n\n    This function retrieves the Copernicus Digital Elevation Model (DEM) data for a specified\n    bounding box and resolution. The DEM represents the surface of the Earth including buildings,\n    infrastructure, and vegetation.\n\n    Parameters\n    ----------\n    bbox_input : geopandas.GeoDataFrame or tuple or Shapely Geometry\n        GeoDataFrame containing the bounding box, or a tuple of (xmin, ymin, xmax, ymax), or a Shapely geometry.\n    resolution : int, optional\n        The resolution of the DEM, either 30 or 90 meters. Default is 30.\n\n    Returns\n    -------\n    xarray.DataArray\n        A DataArray containing the Copernicus DEM data for the specified area.\n\n    Raises\n    ------\n    ValueError\n        If the resolution is not 30 or 90 meters.\n\n    Notes\n    -----\n    The Copernicus DEM is a Digital Surface Model (DSM) derived from the WorldDEM, with additional\n    editing applied to water bodies, coastlines, and other special features.\n\n    Data citation:\n    European Space Agency, Sinergise (2021). Copernicus Global Digital Elevation Model.\n    Distributed by OpenTopography. https://doi.org/10.5069/G9028PQB. Accessed: 2024-03-18\n    \"\"\"\n    if resolution != 30 and resolution != 90:\n        raise ValueError(\"Copernicus DEM resolution is available in 30m and 90m. Please select either 30 or 90.\")\n\n    # Convert the input to a GeoDataFrame if it's not already one\n    bbox_gdf =  convert_bbox_to_geodataframe(bbox_input)\n\n    catalog = pystac_client.Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\",modifier=planetary_computer.sign_inplace)\n    search = catalog.search(collections=[f\"cop-dem-glo-{resolution}\"],bbox=bbox_gdf.total_bounds)\n    cop_dem_da = odc.stac.load(search.items(),bbox=bbox_gdf.total_bounds,chunks={})['data'].squeeze()\n    cop_dem_da = cop_dem_da.rio.write_nodata(-32767,encoded=True)\n\n    return cop_dem_da\n</code></pre>"},{"location":"usage/","title":"Usage","text":"<p>To use easysnowdata in a project:</p> <pre><code>import easysnowdata\n</code></pre> <p>Check out the examples tab for demo notebooks.</p>"},{"location":"utils/","title":"utils module","text":"<p>The utils module contains common functions and classes used by the other modules.</p>"},{"location":"utils/#easysnowdata.utils.HLS_xml_url_to_metadata_df","title":"<code>HLS_xml_url_to_metadata_df(url)</code>","text":"<p>Extracts metadata from an HLS XML file URL and converts it to a pandas DataFrame.</p> <p>This function retrieves XML metadata for Harmonized Landsat Sentinel (HLS) data and extracts relevant information into a structured format.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL of the XML file containing HLS metadata.</p> required <p>Returns:</p> Type Description <code>pandas.DataFrame</code> <p>A DataFrame containing extracted metadata information.</p> Source code in <code>easysnowdata/utils.py</code> <pre><code>def HLS_xml_url_to_metadata_df(url):\n    \"\"\"\n    Extracts metadata from an HLS XML file URL and converts it to a pandas DataFrame.\n\n    This function retrieves XML metadata for Harmonized Landsat Sentinel (HLS) data\n    and extracts relevant information into a structured format.\n\n    Parameters\n    ----------\n    url : str\n        The URL of the XML file containing HLS metadata.\n\n    Returns\n    -------\n    pandas.DataFrame\n        A DataFrame containing extracted metadata information.\n    \"\"\"\n    # URL of the XML file\n\n    # Send a GET request to the URL\n    response = requests.get(url)\n\n    # Parse the XML content of the response with BeautifulSoup\n    soup = BeautifulSoup(\n        response.content, \"lxml-xml\"\n    )  # 'lxml-xml' parser is used for parsing XML\n\n    # Create a dictionary to hold the data\n    data = {}\n\n    # Iterate over all tags in the soup object\n    for tag in soup.find_all():\n        # If the tag has a text value, add it to the dictionary\n        if tag.text.strip():\n            data[tag.name] = tag.text.strip().replace(\"\\n\", \" \")\n\n    # Convert the dictionary to a DataFrame\n    df = pd.DataFrame([data]).iloc[0][\n        [\"ProducerGranuleId\", \"Temporal\", \"Platform\", \"AssociatedBrowseImageUrls\"]\n    ]\n\n    df[\"Platform\"] = df[\"Platform\"].split(\" \")[0]\n    df[\"AssociatedBrowseImageUrls\"] = df[\"AssociatedBrowseImageUrls\"].split(\" \")[0]\n    df[\"Temporal\"] = df[\"Temporal\"].split(\" \")[0]\n\n    return df\n</code></pre>"},{"location":"utils/#easysnowdata.utils.blockPrint","title":"<code>blockPrint()</code>","text":"<p>Disables print output to the console.</p> <p>This function redirects stdout to a null device, effectively silencing any print statements.</p> Source code in <code>easysnowdata/utils.py</code> <pre><code>def blockPrint():\n    \"\"\"\n    Disables print output to the console.\n\n    This function redirects stdout to a null device, effectively silencing any print statements.\n    \"\"\"\n    sys.stdout = open(os.devnull, \"w\")\n</code></pre>"},{"location":"utils/#easysnowdata.utils.convert_bbox_to_geodataframe","title":"<code>convert_bbox_to_geodataframe(bbox_input)</code>","text":"<p>Converts the input to a GeoDataFrame.</p> <p>This function takes various input formats representing a bounding box and converts them to a standardized GeoDataFrame format.</p> <p>Parameters:</p> Name Type Description Default <code>bbox_input</code> <code>GeoDataFrame or tuple or Shapely geometry or None</code> <p>The input bounding box in various formats.</p> required <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>The converted bounding box as a GeoDataFrame.</p> Source code in <code>easysnowdata/utils.py</code> <pre><code>def convert_bbox_to_geodataframe(bbox_input):\n    \"\"\"\n    Converts the input to a GeoDataFrame.\n\n    This function takes various input formats representing a bounding box and converts them\n    to a standardized GeoDataFrame format.\n\n    Parameters\n    ----------\n    bbox_input : GeoDataFrame or tuple or Shapely geometry or None\n        The input bounding box in various formats.\n\n    Returns\n    -------\n    GeoDataFrame\n        The converted bounding box as a GeoDataFrame.\n\n    Notes\n    -----\n    If no bounding box is provided (None), it returns a GeoDataFrame representing the entire world.\n    \"\"\"\n    if bbox_input is None:\n        # If no bounding box is provided, use the entire world\n        print(\"No spatial subsetting because bbox_input was not provided.\")\n        bbox_input = gpd.GeoDataFrame(\n            geometry=[shapely.geometry.box(-180, -90, 180, 90)], crs=\"EPSG:4326\"\n        )\n    if isinstance(bbox_input, gpd.GeoDataFrame):\n        # If it's already a GeoDataFrame, return it\n        return bbox_input\n    if isinstance(bbox_input, tuple) and len(bbox_input) == 4:\n        # If it's a tuple of four elements, treat it as (xmin, ymin, xmax, ymax)\n        bbox_input = gpd.GeoDataFrame(\n            geometry=[shapely.geometry.box(*bbox_input)], crs=\"EPSG:4326\"\n        )\n    elif isinstance(bbox_input, shapely.geometry.base.BaseGeometry):\n        # If it's a Shapely geometry, convert it to a GeoDataFrame\n        bbox_input = gpd.GeoDataFrame(geometry=[bbox_input], crs=\"EPSG:4326\")\n\n    return bbox_input\n</code></pre>"},{"location":"utils/#easysnowdata.utils.datetime_to_DOWY","title":"<code>datetime_to_DOWY(date, hemisphere='northern')</code>","text":"<p>Convert a datetime-like object to the day of water year (DOWY).</p> <p>Parameters:</p> Name Type Description Default <code>date</code> <code>datetime-like</code> <p>The date to convert.</p> required <code>hemisphere</code> <code>str</code> <p>The hemisphere ('northern' or 'southern'). Default is 'northern'.</p> <code>'northern'</code> <p>Returns:</p> Type Description <code>int</code> <p>The day of the water year, or np.nan if the date is not valid.</p> Source code in <code>easysnowdata/utils.py</code> <pre><code>def datetime_to_DOWY(date, hemisphere=\"northern\"):\n    \"\"\"\n    Convert a datetime-like object to the day of water year (DOWY).\n\n    Parameters\n    ----------\n    date : datetime-like\n        The date to convert.\n    hemisphere : str, optional\n        The hemisphere ('northern' or 'southern'). Default is 'northern'.\n\n    Returns\n    -------\n    int\n        The day of the water year, or np.nan if the date is not valid.\n    \"\"\"\n    try:\n        date = pd.to_datetime(date)\n        start = get_water_year_start(date, hemisphere)\n        return (date - start).days + 1\n    except Exception as e:\n        print(f'A problem occurred: {e}')\n        return np.nan\n</code></pre>"},{"location":"utils/#easysnowdata.utils.datetime_to_WY","title":"<code>datetime_to_WY(date, hemisphere='northern')</code>","text":"<p>Convert a datetime-like object to the water year (WY).</p> <p>Parameters:</p> Name Type Description Default <code>date</code> <code>datetime-like</code> <p>The date to convert.</p> required <code>hemisphere</code> <code>str</code> <p>The hemisphere ('northern' or 'southern'). Default is 'northern'.</p> <code>'northern'</code> <p>Returns:</p> Type Description <code>int</code> <p>The water year.</p> Source code in <code>easysnowdata/utils.py</code> <pre><code>def datetime_to_WY(date, hemisphere=\"northern\"):\n    \"\"\"\n    Convert a datetime-like object to the water year (WY).\n\n    Parameters\n    ----------\n    date : datetime-like\n        The date to convert.\n    hemisphere : str, optional\n        The hemisphere ('northern' or 'southern'). Default is 'northern'.\n\n    Returns\n    -------\n    int\n        The water year.\n    \"\"\"\n    try:\n        date = pd.to_datetime(date)\n        start = get_water_year_start(date, hemisphere)\n        return start.year + (1 if hemisphere == \"northern\" else 0)\n    except Exception as e:\n        print(f'A problem occurred: {e}')\n        return np.nan\n</code></pre>"},{"location":"utils/#easysnowdata.utils.enablePrint","title":"<code>enablePrint()</code>","text":"<p>Restores print output to the console.</p> <p>This function restores stdout to its original state, allowing print statements to function normally.</p> Source code in <code>easysnowdata/utils.py</code> <pre><code>def enablePrint():\n    \"\"\"\n    Restores print output to the console.\n\n    This function restores stdout to its original state, allowing print statements to function normally.\n    \"\"\"\n    sys.stdout = sys.__stdout__\n</code></pre>"},{"location":"utils/#easysnowdata.utils.get_stac_cfg","title":"<code>get_stac_cfg(sensor='sentinel-2-l2a')</code>","text":"<p>Retrieves the STAC configuration for a given sensor.</p> <p>This function returns a YAML configuration for STAC (SpatioTemporal Asset Catalog) metadata for different satellite sensors.</p> <p>Parameters:</p> Name Type Description Default <code>sensor</code> <code>str</code> <p>The sensor type. Options are \"sentinel-2-l2a\", \"HLSL30.v2.0\", or \"HLSS30.v2.0\". Default is \"sentinel-2-l2a\".</p> <code>'sentinel-2-l2a'</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the STAC configuration for the specified sensor.</p> Source code in <code>easysnowdata/utils.py</code> <pre><code>def get_stac_cfg(sensor=\"sentinel-2-l2a\"):\n    \"\"\"\n    Retrieves the STAC configuration for a given sensor.\n\n    This function returns a YAML configuration for STAC (SpatioTemporal Asset Catalog) metadata\n    for different satellite sensors.\n\n    Parameters\n    ----------\n    sensor : str, optional\n        The sensor type. Options are \"sentinel-2-l2a\", \"HLSL30.v2.0\", or \"HLSS30.v2.0\".\n        Default is \"sentinel-2-l2a\".\n\n    Returns\n    -------\n    dict\n        A dictionary containing the STAC configuration for the specified sensor.\n    \"\"\"\n    if sensor == \"sentinel-2-l2a\":\n        cfg = \"\"\"---\n        sentinel-2-l2a:\n            assets:\n                '*':\n                    data_type: uint16\n                    nodata: 0\n                    unit: '1'\n                scl:\n                    data_type: uint8\n                    nodata: 0\n                    unit: '1'\n                visual:\n                    data_type: uint8\n                    nodata: 0\n                    unit: '1'\n            aliases:  # Alias -&gt; Canonical Name\n                costal: B01\n                blue: B02\n                green: B03\n                red: B04\n                rededge1: B05\n                rededge2: B06\n                rededge3: B07\n                nir: B08\n                nir08: B8A\n                nir09: B09\n                swir16: B11\n                swir22: B12\n                scl: SCL\n                aot: AOT\n                wvp: WVP\n        \"\"\"\n    elif sensor == \"HLSL30_2.0\":\n        cfg = \"\"\"---\n        HLSL30_2.0:\n            assets:\n                '*':\n                    data_type: int16\n                    nodata: -9999\n                    scale: 0.0001\n                Fmask:\n                    data_type: uint8\n                    nodata: 255\n                    scale: 1\n                SZA:\n                    data_type: uint16\n                    nodata: 40000\n                    scale: 0.01\n                SAA:\n                    data_type: uint16\n                    nodata: 40000\n                    scale: 0.01\n                VZA:\n                    data_type: uint16\n                    nodata: 40000\n                    scale: 0.01\n                VAA:\n                    data_type: uint16\n                    nodata: 40000\n                    scale: 0.01\n                thermal infrared 1:\n                    data_type: int16\n                    nodata: -9999\n                    scale: 0.01\n                thermal:\n                    data_type: int16\n                    nodata: -9999\n                    scale: 0.01\n            aliases:\n                coastal: B01\n                blue: B02\n                green: B03\n                red: B04\n                nir08: B05\n                swir16: B06\n                swir22: B07\n                cirrus: B09\n                lwir11: B10\n                lwir12: B11\n        \"\"\"\n    elif sensor == \"HLSS30_2.0\":\n        cfg = \"\"\"---\n        HLSS30_2.0:\n            assets:\n                '*':\n                    data_type: int16\n                    nodata: -9999\n                    scale: 0.0001\n                Fmask:\n                    data_type: uint8\n                    nodata: 255\n                    scale: 1\n                SZA:\n                    data_type: uint16\n                    nodata: 40000\n                    scale: 0.01\n                SAA:\n                    data_type: uint16\n                    nodata: 40000\n                    scale: 0.01\n                VZA:\n                    data_type: uint16\n                    nodata: 40000\n                    scale: 0.01\n                VAA:\n                    data_type: uint16\n                    nodata: 40000\n                    scale: 0.01\n            aliases:\n                coastal: B01\n                blue: B02\n                green: B03\n                red: B04\n                rededge071: B05\n                rededge075: B06\n                rededge078: B07\n                nir: B08\n                nir08: B8A\n                water vapor: B09\n                cirrus: B10\n                swir16: B11\n                swir22: B12\n        \"\"\"\n    cfg = yaml.load(cfg, Loader=yaml.CSafeLoader)\n\n    return cfg\n</code></pre>"},{"location":"utils/#easysnowdata.utils.get_water_year_start","title":"<code>get_water_year_start(date, hemisphere)</code>","text":"<p>Determines the start date of the water year for a given date and hemisphere.</p> <p>Parameters:</p> Name Type Description Default <code>date</code> <code>datetime-like</code> <p>The date for which to determine the water year start.</p> required <code>hemisphere</code> <code>str</code> <p>The hemisphere ('northern' or 'southern').</p> required <p>Returns:</p> Type Description <code>pandas.Timestamp</code> <p>The start date of the water year.</p> Source code in <code>easysnowdata/utils.py</code> <pre><code>def get_water_year_start(date, hemisphere):\n    \"\"\"\n    Determines the start date of the water year for a given date and hemisphere.\n\n    Parameters\n    ----------\n    date : datetime-like\n        The date for which to determine the water year start.\n    hemisphere : str\n        The hemisphere ('northern' or 'southern').\n\n    Returns\n    -------\n    pandas.Timestamp\n        The start date of the water year.\n    \"\"\"\n    year = date.year\n    month = 10 if hemisphere == \"northern\" else 4\n    if (hemisphere == \"northern\" and date.month &lt; 10) or (\n        hemisphere == \"southern\" and date.month &lt; 4\n    ):\n        year -= 1\n    return pd.Timestamp(year=year, month=month, day=1)\n</code></pre>"},{"location":"examples/automatic_weather_station_examples/","title":"Automatic weather station examples","text":"<p>Thanks for checking out these examples! The automatic_weather_station module is intended to make it easier to retrieve daily SNOTEL and CCSS data without having to do clunky downloads and conversions. Snow depth / SWE / PRCPSA are in meters, temperatures are in celsius. This module is built on my snotel_ccss_stations repository, which uses a github action to auto-update the station data daily.</p> In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n</pre> %load_ext autoreload %autoreload 2 In\u00a0[2]: Copied! <pre>%aimport easysnowdata\n\nimport pandas as pd\nimport geopandas as gpd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport datetime\nimport tqdm\nimport contextily as ctx\n\nimport xarray as xr\nimport glob\n\nimport requests \nfrom io import StringIO\n</pre> %aimport easysnowdata  import pandas as pd import geopandas as gpd import numpy as np import matplotlib.pyplot as plt import datetime import tqdm import contextily as ctx  import xarray as xr import glob  import requests  from io import StringIO In\u00a0[3]: Copied! <pre># bbox_gdf = gpd.read_file('https://github.com/egagli/sar_snowmelt_timing/raw/main/input/shapefiles/mt_rainier.geojson')\n</pre> # bbox_gdf = gpd.read_file('https://github.com/egagli/sar_snowmelt_timing/raw/main/input/shapefiles/mt_rainier.geojson') In\u00a0[4]: Copied! <pre>StationCollection = easysnowdata.automatic_weather_stations.StationCollection()\n</pre> StationCollection = easysnowdata.automatic_weather_stations.StationCollection() <pre>Geodataframe with all stations has been added to the Station object. Please use the .all_stations attribute to access.\nUse the .get_data(stations=geodataframe/string/list,variables=string/list,start_date=str,end_date=str) method to fetch data for specific stations and variables.\n</pre> In\u00a0[5]: Copied! <pre>StationCollection.all_stations\n</pre> StationCollection.all_stations Out[5]: name network elevation_m latitude longitude state HUC mgrs mountainRange beginDate endDate csvData geometry code 301_CA_SNTL Adin Mtn SNOTEL 1886.712036 41.235828 -120.791924 California 180200021403 10TFL Great Basin Ranges 1983-10-01 2100-01-01 True POINT (-120.79192 41.23583) 907_UT_SNTL Agua Canyon SNOTEL 2712.719971 37.522171 -112.271179 Utah 160300020301 12SUG Colorado Plateau 1994-10-01 2100-01-01 True POINT (-112.27118 37.52217) 916_MT_SNTL Albro Lake SNOTEL 2529.840088 45.597229 -111.959023 Montana 100200050701 12TVR Central Montana Rocky Mountains 1996-09-01 2100-01-01 True POINT (-111.95902 45.59723) 1267_AK_SNTL Alexander Lake SNOTEL 48.768002 61.749668 -150.889664 Alaska 190205051106 05VPJ None 2014-08-28 2100-01-01 True POINT (-150.88966 61.74967) 908_WA_SNTL Alpine Meadows SNOTEL 1066.800049 47.779572 -121.698471 Washington 171100100501 10TET Cascade Range 1994-09-01 2100-01-01 True POINT (-121.69847 47.77957) ... ... ... ... ... ... ... ... ... ... ... ... ... ... SLT Slate Creek CCSS 1737.360000 41.043980 -122.480103 California 180200050304 10TEL Klamath Mountains 2004-10-01 2024-04-02 True POINT (-122.48010 41.04398) SLI Slide Canyon CCSS 2804.160000 38.091234 -119.431881 California 180400090501 11SKC Sierra Nevada 2005-10-01 2024-04-02 True POINT (-119.43188 38.09123) SLK South Lake CCSS 2926.080000 37.175903 -118.562660 California 180901020601 11SLB Sierra Nevada 2004-10-01 2024-04-02 True POINT (-118.56266 37.17590) STL State Lakes CCSS 3169.920000 36.926483 -118.573250 California 180300100305 11SLA Sierra Nevada 2018-11-01 2024-04-02 True POINT (-118.57325 36.92648) TMR Tamarack Summit CCSS 2301.240000 37.163750 -119.200531 California 180400060903 11SLB Sierra Nevada 2011-01-01 2024-04-02 True POINT (-119.20053 37.16375) <p>969 rows \u00d7 13 columns</p> In\u00a0[6]: Copied! <pre>StationCollection.all_stations.astype(dict(beginDate=str, endDate=str)).explore(\n    column=\"network\", cmap=\"bwr\"\n)\n</pre> StationCollection.all_stations.astype(dict(beginDate=str, endDate=str)).explore(     column=\"network\", cmap=\"bwr\" ) Out[6]: Make this Notebook Trusted to load map: File -&gt; Trust Notebook In\u00a0[7]: Copied! <pre>ParadiseSNOTEL = easysnowdata.automatic_weather_stations.StationCollection()\n</pre> ParadiseSNOTEL = easysnowdata.automatic_weather_stations.StationCollection() <pre>Geodataframe with all stations has been added to the Station object. Please use the .all_stations attribute to access.\nUse the .get_data(stations=geodataframe/string/list,variables=string/list,start_date=str,end_date=str) method to fetch data for specific stations and variables.\n</pre> In\u00a0[8]: Copied! <pre>ParadiseSNOTEL.get_data(\"679_WA_SNTL\")\n</pre> ParadiseSNOTEL.get_data(\"679_WA_SNTL\") <pre>Only one station chosen with variables=None. Default behavior fetches all variables for this station.\nDataframe has been added to the Station object. Please use the .data attribute to access.\n</pre> In\u00a0[9]: Copied! <pre>f, ax = plt.subplots()\n\nParadiseSNOTEL.stations.plot(ax=ax, color=\"red\")\n\nax.set_xlim(-122, -121.5)\nax.set_ylim(46.6, 47.1)\n\nctx.add_basemap(\n    ax, crs=ParadiseSNOTEL.stations.crs, source=ctx.providers.Esri.WorldImagery\n)\n</pre> f, ax = plt.subplots()  ParadiseSNOTEL.stations.plot(ax=ax, color=\"red\")  ax.set_xlim(-122, -121.5) ax.set_ylim(46.6, 47.1)  ctx.add_basemap(     ax, crs=ParadiseSNOTEL.stations.crs, source=ctx.providers.Esri.WorldImagery ) In\u00a0[10]: Copied! <pre>ParadiseSNOTEL.data\n</pre> ParadiseSNOTEL.data Out[10]: TAVG TMIN TMAX SNWD WTEQ PRCPSA datetime 1980-10-01 NaN NaN NaN NaN 0.0000 0.0000 1980-10-02 NaN NaN NaN NaN 0.0000 0.0000 1980-10-03 NaN NaN NaN NaN 0.0000 0.0000 1980-10-04 NaN NaN NaN NaN 0.0000 0.0000 1980-10-05 NaN NaN NaN NaN 0.0000 0.0000 ... ... ... ... ... ... ... 2024-03-28 -1.0 -2.2 1.9 3.0480 1.4376 0.0102 2024-03-29 0.2 -3.5 5.7 3.1750 1.4478 0.0000 2024-03-30 1.5 -3.2 8.3 3.1242 1.4478 0.0025 2024-03-31 1.1 -3.4 6.9 3.1242 1.4503 0.0000 2024-04-01 NaN NaN NaN 3.0734 1.4453 NaN <p>15889 rows \u00d7 6 columns</p> In\u00a0[11]: Copied! <pre>f, ax = plt.subplots(figsize=(12, 5))\n\nParadiseSNOTEL.data[\"SNWD\"].plot(ax=ax, label=\"snow depth\")\nParadiseSNOTEL.data[\"WTEQ\"].plot(ax=ax, label=\"snow water equivalent\")\n\nax.set_xlim(pd.to_datetime([\"2017-10-01\", \"2018-09-30\"]))\n\nax.grid()\nax.legend()\n\nax.set_xlabel(\"time\")\nax.set_ylabel(\"snow depth / SWE [meters]\")\nax.set_title(\"Snow depth and SWE at Paradise, WA \\n(water year 2018)\")\n\nf.tight_layout()\n</pre> f, ax = plt.subplots(figsize=(12, 5))  ParadiseSNOTEL.data[\"SNWD\"].plot(ax=ax, label=\"snow depth\") ParadiseSNOTEL.data[\"WTEQ\"].plot(ax=ax, label=\"snow water equivalent\")  ax.set_xlim(pd.to_datetime([\"2017-10-01\", \"2018-09-30\"]))  ax.grid() ax.legend()  ax.set_xlabel(\"time\") ax.set_ylabel(\"snow depth / SWE [meters]\") ax.set_title(\"Snow depth and SWE at Paradise, WA \\n(water year 2018)\")  f.tight_layout() In\u00a0[12]: Copied! <pre>ParadiseSNOTEL.data[\"DOWY\"] = ParadiseSNOTEL.data.index.map(\n    easysnowdata.utils.datetime_to_DOWY\n)\nParadiseSNOTEL.data[\"WY\"] = ParadiseSNOTEL.data.index.map(\n    easysnowdata.utils.datetime_to_WY\n)\n</pre> ParadiseSNOTEL.data[\"DOWY\"] = ParadiseSNOTEL.data.index.map(     easysnowdata.utils.datetime_to_DOWY ) ParadiseSNOTEL.data[\"WY\"] = ParadiseSNOTEL.data.index.map(     easysnowdata.utils.datetime_to_WY ) In\u00a0[13]: Copied! <pre>ParadiseSNOTEL.data\n</pre> ParadiseSNOTEL.data Out[13]: TAVG TMIN TMAX SNWD WTEQ PRCPSA DOWY WY datetime 1980-10-01 NaN NaN NaN NaN 0.0000 0.0000 1 1981 1980-10-02 NaN NaN NaN NaN 0.0000 0.0000 2 1981 1980-10-03 NaN NaN NaN NaN 0.0000 0.0000 3 1981 1980-10-04 NaN NaN NaN NaN 0.0000 0.0000 4 1981 1980-10-05 NaN NaN NaN NaN 0.0000 0.0000 5 1981 ... ... ... ... ... ... ... ... ... 2024-03-28 -1.0 -2.2 1.9 3.0480 1.4376 0.0102 180 2024 2024-03-29 0.2 -3.5 5.7 3.1750 1.4478 0.0000 181 2024 2024-03-30 1.5 -3.2 8.3 3.1242 1.4478 0.0025 182 2024 2024-03-31 1.1 -3.4 6.9 3.1242 1.4503 0.0000 183 2024 2024-04-01 NaN NaN NaN 3.0734 1.4453 NaN 184 2024 <p>15889 rows \u00d7 8 columns</p> In\u00a0[14]: Copied! <pre>stat_list = [\"min\", \"max\", \"mean\", \"std\", \"median\"]\nparadise_snotel_DOWY_snwd_stats = ParadiseSNOTEL.data.groupby(\"DOWY\").agg(stat_list)[\n    \"SNWD\"\n]\nparadise_snotel_DOWY_snwd_stats\n</pre> stat_list = [\"min\", \"max\", \"mean\", \"std\", \"median\"] paradise_snotel_DOWY_snwd_stats = ParadiseSNOTEL.data.groupby(\"DOWY\").agg(stat_list)[     \"SNWD\" ] paradise_snotel_DOWY_snwd_stats Out[14]: min max mean std median DOWY 1 0.0 0.2286 0.014111 0.053862 0.0 2 0.0 0.2032 0.011289 0.047895 0.0 3 0.0 0.2286 0.014111 0.053862 0.0 4 0.0 0.1270 0.012700 0.032888 0.0 5 0.0 0.1270 0.012700 0.034022 0.0 ... ... ... ... ... ... 362 0.0 0.0254 0.001411 0.005987 0.0 363 0.0 0.0254 0.001411 0.005987 0.0 364 0.0 0.0254 0.002822 0.008214 0.0 365 0.0 0.0762 0.005644 0.018595 0.0 366 0.0 0.0000 0.000000 0.000000 0.0 <p>366 rows \u00d7 5 columns</p> In\u00a0[15]: Copied! <pre>today = datetime.datetime.today().strftime(\"%Y-%m-%d\")\ncurrent_WY = slice(f\"{int(today[0:4])-1}-10-01\", f\"{today}\")\ncurrent_WY_paradise_snotel = ParadiseSNOTEL.data[current_WY.start : current_WY.stop]\n</pre> today = datetime.datetime.today().strftime(\"%Y-%m-%d\") current_WY = slice(f\"{int(today[0:4])-1}-10-01\", f\"{today}\") current_WY_paradise_snotel = ParadiseSNOTEL.data[current_WY.start : current_WY.stop] In\u00a0[16]: Copied! <pre>f, ax = plt.subplots(figsize=(12, 7))\n\nfor stat, stat_color in zip(\n    [\"min\", \"max\", \"mean\", \"median\"], [\"red\", \"blue\", \"mediumpurple\", \"mediumseagreen\"]\n):\n    ax.plot(\n        paradise_snotel_DOWY_snwd_stats.index,\n        paradise_snotel_DOWY_snwd_stats[stat],\n        label=stat,\n        color=stat_color,\n        linewidth=3,\n    )\n\nax.fill_between(\n    paradise_snotel_DOWY_snwd_stats.index,\n    paradise_snotel_DOWY_snwd_stats[\"mean\"] - paradise_snotel_DOWY_snwd_stats[\"std\"],\n    paradise_snotel_DOWY_snwd_stats[\"mean\"] + paradise_snotel_DOWY_snwd_stats[\"std\"],\n    color=\"mediumpurple\",\n    alpha=0.3,\n    label=\"mean +/- 1 std\",\n)\n\nax.scatter(\n    current_WY_paradise_snotel.DOWY,\n    current_WY_paradise_snotel.SNWD,\n    marker=\"o\",\n    color=\"black\",\n    label=\"Current WY\",\n)\n\nax.set_xlim([0, 366])\nax.set_ylim([0, 6])\n\nax.grid()\nax.legend()\n\nax.set_title(\n    f\"Current snow depth against historical snow depth stats by DOWY at Paradise, WA\\n({ParadiseSNOTEL.data.index.min().date()} - {ParadiseSNOTEL.data.index.max().date()})\"\n)\nax.set_xlabel(\"Day of Water Year [Oct 1 - Sept 30]\")\nax.set_ylabel(\"Snow depth [meters]\")\nf.tight_layout()\n</pre> f, ax = plt.subplots(figsize=(12, 7))  for stat, stat_color in zip(     [\"min\", \"max\", \"mean\", \"median\"], [\"red\", \"blue\", \"mediumpurple\", \"mediumseagreen\"] ):     ax.plot(         paradise_snotel_DOWY_snwd_stats.index,         paradise_snotel_DOWY_snwd_stats[stat],         label=stat,         color=stat_color,         linewidth=3,     )  ax.fill_between(     paradise_snotel_DOWY_snwd_stats.index,     paradise_snotel_DOWY_snwd_stats[\"mean\"] - paradise_snotel_DOWY_snwd_stats[\"std\"],     paradise_snotel_DOWY_snwd_stats[\"mean\"] + paradise_snotel_DOWY_snwd_stats[\"std\"],     color=\"mediumpurple\",     alpha=0.3,     label=\"mean +/- 1 std\", )  ax.scatter(     current_WY_paradise_snotel.DOWY,     current_WY_paradise_snotel.SNWD,     marker=\"o\",     color=\"black\",     label=\"Current WY\", )  ax.set_xlim([0, 366]) ax.set_ylim([0, 6])  ax.grid() ax.legend()  ax.set_title(     f\"Current snow depth against historical snow depth stats by DOWY at Paradise, WA\\n({ParadiseSNOTEL.data.index.min().date()} - {ParadiseSNOTEL.data.index.max().date()})\" ) ax.set_xlabel(\"Day of Water Year [Oct 1 - Sept 30]\") ax.set_ylabel(\"Snow depth [meters]\") f.tight_layout() <p>Looks like we're slightly below the mean for snow depth for today's DOWY.</p> In\u00a0[17]: Copied! <pre>station_list = [\"356_CA_SNTL\", \"BLK\"]\n\nTwoStations = easysnowdata.automatic_weather_stations.StationCollection()\n</pre> station_list = [\"356_CA_SNTL\", \"BLK\"]  TwoStations = easysnowdata.automatic_weather_stations.StationCollection() <pre>Geodataframe with all stations has been added to the Station object. Please use the .all_stations attribute to access.\nUse the .get_data(stations=geodataframe/string/list,variables=string/list,start_date=str,end_date=str) method to fetch data for specific stations and variables.\n</pre> In\u00a0[18]: Copied! <pre>TwoStations.get_data(station_list, variables=\"WTEQ\")\n</pre> TwoStations.get_data(station_list, variables=\"WTEQ\") <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:00&lt;00:00,  2.31it/s]</pre> <pre>WTEQ dataframe has been added to the Station object. Please use the .WTEQ attribute to access the dataframe.\nFull ['WTEQ'] dataset has been added to the station object. Please use the .data attribute to access the dataset.\n</pre> <pre>\n</pre> In\u00a0[19]: Copied! <pre>TwoStations.WTEQ\n</pre> TwoStations.WTEQ Out[19]: 356_CA_SNTL BLK datetime 1980-07-09 NaN NaN 1980-07-10 NaN NaN 1980-07-11 NaN NaN 1980-07-12 NaN NaN 1980-07-13 NaN NaN ... ... ... 2024-03-29 0.8204 0.8204 2024-03-30 0.8433 0.8433 2024-03-31 0.8484 0.8484 2024-04-01 0.8534 0.8534 2024-04-02 NaN 0.8534 <p>15974 rows \u00d7 2 columns</p> In\u00a0[20]: Copied! <pre>f, ax = plt.subplots(figsize=(20, 7))\n\nTwoStations.WTEQ.plot(ax=ax, color=[\"red\", \"blue\"])\n\nax.legend()\n\nax.set_xlabel(\"time\")\nax.set_ylabel(\"snow water equivalent [meters]\")\nax.set_title(\"SNOTEL and CCSS SWE at Blue Lakes, CA \\nmaybe these are the same? :)\")\n\nf.tight_layout()\n</pre> f, ax = plt.subplots(figsize=(20, 7))  TwoStations.WTEQ.plot(ax=ax, color=[\"red\", \"blue\"])  ax.legend()  ax.set_xlabel(\"time\") ax.set_ylabel(\"snow water equivalent [meters]\") ax.set_title(\"SNOTEL and CCSS SWE at Blue Lakes, CA \\nmaybe these are the same? :)\")  f.tight_layout() In\u00a0[21]: Copied! <pre>TwoStations.WTEQ.corr()\n</pre> TwoStations.WTEQ.corr() Out[21]: 356_CA_SNTL BLK 356_CA_SNTL 1.000000 0.999056 BLK 0.999056 1.000000 <p>These correlation values, along with the time series above, makes me think these are way too similar... no way these would agree this much even if the stations were right next to each other!</p> In\u00a0[22]: Copied! <pre>TwoStations.stations\n</pre> TwoStations.stations Out[22]: name network elevation_m latitude longitude state HUC mgrs mountainRange beginDate endDate csvData geometry code 356_CA_SNTL Blue Lakes SNOTEL 2458.821533 38.608002 -119.92437 California 180400120101 11SKC Sierra Nevada 1980-10-01 2100-01-01 True POINT (-119.92437 38.60800) BLK Blue Lakes CCSS 2438.400000 38.613000 -119.93100 California 180400120101 11SKC Sierra Nevada 2004-10-01 2024-04-02 True POINT (-119.93100 38.61300) In\u00a0[23]: Copied! <pre>f, ax = plt.subplots(figsize=(7, 7))\n\n\nTwoStations.stations.to_crs(\"EPSG:32611\").loc[['356_CA_SNTL']].plot(ax=ax, color='red',label='356_CA_SNTL')\nTwoStations.stations.to_crs(\"EPSG:32611\").loc[['BLK']].plot(ax=ax, color='blue',label='BLK')\n\n\nax.set_xlim([244200, 245700])\nax.set_ylim([4276900, 4278700])\n\nctx.add_basemap(ax, crs=\"EPSG:32611\", source=ctx.providers.Esri.WorldImagery)\n\nax.legend() # add labels here\n\nf.tight_layout()\n</pre> f, ax = plt.subplots(figsize=(7, 7))   TwoStations.stations.to_crs(\"EPSG:32611\").loc[['356_CA_SNTL']].plot(ax=ax, color='red',label='356_CA_SNTL') TwoStations.stations.to_crs(\"EPSG:32611\").loc[['BLK']].plot(ax=ax, color='blue',label='BLK')   ax.set_xlim([244200, 245700]) ax.set_ylim([4276900, 4278700])  ctx.add_basemap(ax, crs=\"EPSG:32611\", source=ctx.providers.Esri.WorldImagery)  ax.legend() # add labels here  f.tight_layout() <p>Interesting locations :) Based on correlation and location, I'm going to say these are the same! Wonder what those tiny differences are about...</p> In\u00a0[24]: Copied! <pre>csv = 'https://cdec.water.ca.gov/misc/SnowSensors.html'\nresponse = requests.get(csv)\nsame_stations_df = pd.read_html(StringIO(response.content.decode('utf-8')))[0].set_index('ID').sort_index()\nsame_stations_df = same_stations_df[same_stations_df.nunique(axis=1) &gt; 1]\nsame_stations_gdf = gpd.GeoDataFrame(same_stations_df, geometry=gpd.points_from_xy(same_stations_df['Longitude'], same_stations_df['Latitude']))\nsame_stations_gdf.crs = \"EPSG:4326\"\nsame_stations_gdf = same_stations_gdf[same_stations_gdf['Operator Agency']=='Natural Resources Conservation Service']\nsame_stations_gdf\n</pre> csv = 'https://cdec.water.ca.gov/misc/SnowSensors.html' response = requests.get(csv) same_stations_df = pd.read_html(StringIO(response.content.decode('utf-8')))[0].set_index('ID').sort_index() same_stations_df = same_stations_df[same_stations_df.nunique(axis=1) &gt; 1] same_stations_gdf = gpd.GeoDataFrame(same_stations_df, geometry=gpd.points_from_xy(same_stations_df['Longitude'], same_stations_df['Latitude'])) same_stations_gdf.crs = \"EPSG:4326\" same_stations_gdf = same_stations_gdf[same_stations_gdf['Operator Agency']=='Natural Resources Conservation Service'] same_stations_gdf Out[24]: Name Elev (feet) Latitude Longitude April 1 Avg (inches) Operator Agency geometry ID ADM ADIN MOUNTAIN 6200 41.237 -120.792 13.6 Natural Resources Conservation Service POINT (-120.79200 41.23700) BLK BLUE LAKES 8000 38.613 -119.931 33.1 Natural Resources Conservation Service POINT (-119.93100 38.61300) BMW BIG MEADOWS (SCS) 8700 39.458 -119.946 25.7 Natural Resources Conservation Service POINT (-119.94600 39.45800) BSK BURNSIDE LAKE 8129 38.719 -119.894 -9999.0 Natural Resources Conservation Service POINT (-119.89400 38.71900) CDP CEDAR PASS 7100 41.583 -120.303 18.1 Natural Resources Conservation Service POINT (-120.30300 41.58300) CSL CENT SIERRA SNOW LAB 6900 39.325 -120.367 33.6 Natural Resources Conservation Service POINT (-120.36700 39.32500) CWF CROWDER FLAT 5100 41.893 -120.752 -9999.0 Natural Resources Conservation Service POINT (-120.75200 41.89300) CXS CARSON PASS 8353 38.692 -120.002 -9999.0 Natural Resources Conservation Service POINT (-120.00200 38.69200) DSS DISMAL SWAMP 7050 41.993 -120.165 29.2 Natural Resources Conservation Service POINT (-120.16500 41.99300) EBB EBBETTS PASS 8700 38.561 -119.808 38.8 Natural Resources Conservation Service POINT (-119.80800 38.56100) EP5 ECHO PEAK 5 7800 38.849 -120.079 39.5 Natural Resources Conservation Service POINT (-120.07900 38.84900) FLL FALLEN LEAF LAKE 6250 38.932 -120.056 7.0 Natural Resources Conservation Service POINT (-120.05600 38.93200) HGM HAGANS MEADOW 8000 38.853 -119.940 16.5 Natural Resources Conservation Service POINT (-119.94000 38.85300) HVN HEAVENLY VALLEY 8800 38.929 -119.917 28.1 Natural Resources Conservation Service POINT (-119.91700 38.92900) IDC INDEPENDENCE CAMP 7000 39.453 -120.299 21.8 Natural Resources Conservation Service POINT (-120.29900 39.45300) IDP INDEPENDENCE LAKE (SCS) 8450 39.435 -120.322 41.4 Natural Resources Conservation Service POINT (-120.32200 39.43500) INN INDEPENDENCE CREEK 6500 39.494 -120.293 12.7 Natural Resources Conservation Service POINT (-120.29300 39.49400) LBD LOBDELL LAKE 9200 38.440 -119.377 17.3 Natural Resources Conservation Service POINT (-119.37700 38.44000) LVM LEAVITT MEADOWS 7200 38.305 -119.552 8.0 Natural Resources Conservation Service POINT (-119.55200 38.30500) LVT LEAVITT LAKE 9600 38.282 -119.621 -9999.0 Natural Resources Conservation Service POINT (-119.62100 38.28200) MNT MONITOR PASS 8350 38.670 -119.615 -9999.0 Natural Resources Conservation Service POINT (-119.61500 38.67000) MRL MARLETTE LAKE 8000 39.173 -119.905 21.1 Natural Resources Conservation Service POINT (-119.90500 39.17300) MSK MOUNT ROSE SKI AREA 8900 39.326 -119.902 38.5 Natural Resources Conservation Service POINT (-119.90200 39.32600) PSN POISON FLAT 7900 38.501 -119.631 16.2 Natural Resources Conservation Service POINT (-119.63100 38.50100) RP2 RUBICON PEAK 2 7500 39.001 -120.140 29.1 Natural Resources Conservation Service POINT (-120.14000 39.00100) SDW SUMMIT MEADOW 9313 38.398 -119.536 -9999.0 Natural Resources Conservation Service POINT (-119.53600 38.39800) SPS SONORA PASS BRIDGE 8750 38.318 -119.601 26.0 Natural Resources Conservation Service POINT (-119.60100 38.31800) SPT SPRATT CREEK 6150 38.666 -119.817 4.5 Natural Resources Conservation Service POINT (-119.81700 38.66600) SQV SQUAW VALLEY GOLD COAST 8200 39.194 -120.276 46.5 Natural Resources Conservation Service POINT (-120.27600 39.19400) TCC TAHOE CITY CROSS 6750 39.171 -120.155 16.0 Natural Resources Conservation Service POINT (-120.15500 39.17100) TK2 TRUCKEE 2 6400 39.300 -120.194 14.3 Natural Resources Conservation Service POINT (-120.19400 39.30000) VRG VIRGINIA LAKES RIDGE 9300 38.077 -119.234 20.3 Natural Resources Conservation Service POINT (-119.23400 38.07700) WC3 WARD CREEK 3 6750 39.136 -120.219 39.4 Natural Resources Conservation Service POINT (-120.21900 39.13600) In\u00a0[25]: Copied! <pre>f, ax = plt.subplots(figsize=(10, 10))\n\nsame_stations_gdf.to_crs(\"EPSG:32611\").plot(\n    ax=ax, color=\"red\", label=\"CCSS station operated by NRCS\"\n)\nccss_stations_gdf = TwoStations.all_stations[\n    TwoStations.all_stations[\"network\"] == \"CCSS\"\n].to_crs(\"EPSG:32611\")\nccss_stations_gdf[~ccss_stations_gdf.index.isin(same_stations_gdf.index)].plot(\n    ax=ax, color=\"blue\", label=\"CCSS station not operated by NRCS\"\n)\n\nctx.add_basemap(ax, crs=\"EPSG:32611\", source=ctx.providers.Esri.WorldImagery)\n\nax.legend()\n\nf.tight_layout()\n</pre> f, ax = plt.subplots(figsize=(10, 10))  same_stations_gdf.to_crs(\"EPSG:32611\").plot(     ax=ax, color=\"red\", label=\"CCSS station operated by NRCS\" ) ccss_stations_gdf = TwoStations.all_stations[     TwoStations.all_stations[\"network\"] == \"CCSS\" ].to_crs(\"EPSG:32611\") ccss_stations_gdf[~ccss_stations_gdf.index.isin(same_stations_gdf.index)].plot(     ax=ax, color=\"blue\", label=\"CCSS station not operated by NRCS\" )  ctx.add_basemap(ax, crs=\"EPSG:32611\", source=ctx.providers.Esri.WorldImagery)  ax.legend()  f.tight_layout() <p>There are 33 of these! These are likely also listed as SNOTEL stations...</p> In\u00a0[6]: Copied! <pre>ccssStations = easysnowdata.automatic_weather_stations.StationCollection()\n</pre> ccssStations = easysnowdata.automatic_weather_stations.StationCollection() <pre>Geodataframe with all stations has been added to the Station object. Please use the .all_stations attribute to access.\nUse the .get_data(stations=geodataframe/string/list,variables=string/list,start_date=str,end_date=str) method to fetch data for specific stations and variables.\n</pre> In\u00a0[7]: Copied! <pre>ccss_only = ccssStations.all_stations[ccssStations.all_stations.network == \"CCSS\"]\n</pre> ccss_only = ccssStations.all_stations[ccssStations.all_stations.network == \"CCSS\"] In\u00a0[9]: Copied! <pre>ccssStations.get_data(stations=ccss_only,variables=\"WTEQ\")\n</pre> ccssStations.get_data(stations=ccss_only,variables=\"WTEQ\") <pre>  0%|          | 0/130 [00:00&lt;?, ?it/s]</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 130/130 [00:41&lt;00:00,  3.17it/s]\n</pre> <pre>WTEQ dataframe has been added to the Station object. Please use the .WTEQ attribute to access the dataframe.\nFull ['WTEQ'] dataset has been added to the station object. Please use the .data attribute to access the dataset.\n</pre> In\u00a0[10]: Copied! <pre>ccssStations.WTEQ[\"DOWY\"] = ccssStations.WTEQ.index.map(\n    easysnowdata.utils.datetime_to_DOWY\n)\nccssStations.WTEQ[\"WY\"] = ccssStations.WTEQ.index.map(easysnowdata.utils.datetime_to_WY)\n</pre> ccssStations.WTEQ[\"DOWY\"] = ccssStations.WTEQ.index.map(     easysnowdata.utils.datetime_to_DOWY ) ccssStations.WTEQ[\"WY\"] = ccssStations.WTEQ.index.map(easysnowdata.utils.datetime_to_WY) In\u00a0[11]: Copied! <pre>ccssStations.stations.loc[:, \"april2023_percent_norm\"] = 100 * (\n    ccssStations.WTEQ[\"2023-04-01\":\"2023-04-01\"].squeeze()\n    / ccssStations.WTEQ.groupby(\"DOWY\").median().loc[183]\n)\n</pre> ccssStations.stations.loc[:, \"april2023_percent_norm\"] = 100 * (     ccssStations.WTEQ[\"2023-04-01\":\"2023-04-01\"].squeeze()     / ccssStations.WTEQ.groupby(\"DOWY\").median().loc[183] ) <pre>/home/eric/miniconda3/envs/easysnowdata/lib/python3.12/site-packages/geopandas/geodataframe.py:1525: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\n</pre> In\u00a0[12]: Copied! <pre>ccssStations.stations = ccssStations.stations.dropna(subset=\"april2023_percent_norm\")\nccssStations.stations = ccssStations.stations[\n    ccssStations.stations[\"april2023_percent_norm\"] &lt; 7500\n]\n</pre> ccssStations.stations = ccssStations.stations.dropna(subset=\"april2023_percent_norm\") ccssStations.stations = ccssStations.stations[     ccssStations.stations[\"april2023_percent_norm\"] &lt; 7500 ] In\u00a0[13]: Copied! <pre>ccssStations.stations.sort_values(\"april2023_percent_norm\", ascending=False).head()\n</pre> ccssStations.stations.sort_values(\"april2023_percent_norm\", ascending=False).head() Out[13]: name network elevation_m latitude longitude state HUC mgrs mountainRange beginDate endDate csvData geometry april2023_percent_norm code BCH Beach Meadows CCSS 2331.7200 36.126095 -118.293457 California 180300010403 11SLV Sierra Nevada 2004-10-01 2024-04-03 True POINT (-118.29346 36.12609) 7365.789474 FLL Fallen Leaf Lake CCSS 1905.0000 38.932000 -120.056000 California 160501010401 10SGJ None 2004-10-01 2024-04-03 True POINT (-120.05600 38.93200) 4525.764192 LVM Leavitt Meadows CCSS 2194.5600 38.305000 -119.552000 California 160503020104 11SKC Sierra Nevada 2004-10-01 2024-04-03 True POINT (-119.55200 38.30500) 706.728704 GNF Giant Forest (Usace) CCSS 1950.7200 36.562867 -118.770283 California 180300070402 11SLA Sierra Nevada NaT 2024-04-03 True POINT (-118.77028 36.56287) 700.401606 DPO Devils Postpile CCSS 2307.0312 37.629410 -119.084671 California 180400060402 11SLB Sierra Nevada 2007-10-01 2024-04-03 True POINT (-119.08467 37.62941) 642.842557 In\u00a0[14]: Copied! <pre>ccssStations.stations.sort_values(\"april2023_percent_norm\", ascending=False).tail()\n</pre> ccssStations.stations.sort_values(\"april2023_percent_norm\", ascending=False).tail() Out[14]: name network elevation_m latitude longitude state HUC mgrs mountainRange beginDate endDate csvData geometry april2023_percent_norm code CDP Cedar Pass CCSS 2164.0800 41.583000 -120.303000 California 180200020603 10TGM Great Basin Ranges NaT 2024-04-03 True POINT (-120.30300 41.58300) 165.316340 SQV Palisades Tahoe Snotel CCSS 2499.3600 39.194000 -120.276000 California 160501020202 10SGJ Sierra Nevada 2004-10-01 2024-04-03 True POINT (-120.27600 39.19400) 165.202219 DSS Dismal Swamp CCSS 2148.8400 41.993000 -120.165000 California 171200070304 10TGM Great Basin Ranges NaT 2024-04-03 True POINT (-120.16500 41.99300) 148.136711 LLP Lower Lassen Peak CCSS 2541.4224 40.466602 -121.508110 California 180201560301 10TFK Cascade Range 2004-10-01 2024-04-03 True POINT (-121.50811 40.46660) 146.590403 SHM Shimmy Lake CCSS 1950.7200 41.005299 -122.801598 California 180102110501 10TEL Klamath Mountains 2005-10-01 2024-01-23 True POINT (-122.80160 41.00530) 123.362639 In\u00a0[15]: Copied! <pre>f, ax = plt.subplots(1, 2, figsize=(12, 9), gridspec_kw={\"width_ratios\": [2, 1]})\n\nccssStations.stations.to_crs(\"EPSG:32611\").plot(\n    ax=ax[0],\n    column=\"april2023_percent_norm\",\n    legend=True,\n    vmin=0,\n    vmax=500,\n    cmap=\"gnuplot\",\n    edgecolor=\"black\",\n    s=100,\n)\n\nctx.add_basemap(\n    ax[0], crs=\"EPSG:32611\", source=ctx.providers.Esri.WorldImagery, attribution=\"\"\n)\n\nax[0].set_title(\"station locations\")\n\n\nax[1].scatter(\n    ccssStations.stations.elevation_m,\n    ccssStations.stations.april2023_percent_norm,\n    c=ccssStations.stations.april2023_percent_norm,\n    cmap=\"gnuplot\",\n    vmin=0,\n    vmax=500,\n    edgecolors=\"black\",\n    s=100,\n)\nax[1].axhline(y=100, linestyle=\"--\", color=\"black\")\n\nax[1].set_title(\"station percent normal snow depth vs elevation\")\nax[1].set_xlabel(\"elevation [m]\")\nax[1].set_ylabel(\"percent of normal snow depth [%]\")\n\nax[1].set_ylim([0, 1000])\n\nf.suptitle(f\"California percent normal snow depth for April 1st, 2023\")\nf.tight_layout()\n</pre> f, ax = plt.subplots(1, 2, figsize=(12, 9), gridspec_kw={\"width_ratios\": [2, 1]})  ccssStations.stations.to_crs(\"EPSG:32611\").plot(     ax=ax[0],     column=\"april2023_percent_norm\",     legend=True,     vmin=0,     vmax=500,     cmap=\"gnuplot\",     edgecolor=\"black\",     s=100, )  ctx.add_basemap(     ax[0], crs=\"EPSG:32611\", source=ctx.providers.Esri.WorldImagery, attribution=\"\" )  ax[0].set_title(\"station locations\")   ax[1].scatter(     ccssStations.stations.elevation_m,     ccssStations.stations.april2023_percent_norm,     c=ccssStations.stations.april2023_percent_norm,     cmap=\"gnuplot\",     vmin=0,     vmax=500,     edgecolors=\"black\",     s=100, ) ax[1].axhline(y=100, linestyle=\"--\", color=\"black\")  ax[1].set_title(\"station percent normal snow depth vs elevation\") ax[1].set_xlabel(\"elevation [m]\") ax[1].set_ylabel(\"percent of normal snow depth [%]\")  ax[1].set_ylim([0, 1000])  f.suptitle(f\"California percent normal snow depth for April 1st, 2023\") f.tight_layout() <p>Looks like a lot more snow than usual to me!</p> In\u00a0[35]: Copied! <pre>%%time \n\nWesternUS = easysnowdata.automatic_weather_stations.StationCollection()\nWesternUS.get_data(WesternUS.all_stations,variables=\"WTEQ\")\n</pre> %%time   WesternUS = easysnowdata.automatic_weather_stations.StationCollection() WesternUS.get_data(WesternUS.all_stations,variables=\"WTEQ\") <pre>Geodataframe with all stations has been added to the Station object. Please use the .all_stations attribute to access.\nUse the .get_data(stations=geodataframe/string/list,variables=string/list,start_date=str,end_date=str) method to fetch data for specific stations and variables.\n</pre> <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 969/969 [09:40&lt;00:00,  1.67it/s]\n</pre> <pre>WTEQ dataframe has been added to the Station object. Please use the .WTEQ attribute to access the dataframe.\nFull ['WTEQ'] dataset has been added to the station object. Please use the .data attribute to access the dataset.\nCPU times: user 14.4 s, sys: 1.24 s, total: 15.6 s\nWall time: 9min 44s\n</pre> In\u00a0[36]: Copied! <pre>all_stations_swe_df = WesternUS.WTEQ\nall_stations_swe_df\n</pre> all_stations_swe_df = WesternUS.WTEQ all_stations_swe_df Out[36]: 301_CA_SNTL 907_UT_SNTL 916_MT_SNTL 1267_AK_SNTL 908_WA_SNTL 1189_AK_SNTL 1062_AK_SNTL 1070_AK_SNTL 302_OR_SNTL 1000_OR_SNTL ... QUA LLP FOR GEM WTM SLT SLI SLK STL TMR datetime 1909-04-13 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 1954-12-01 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN NaN NaN NaN NaN 0.0635 NaN 1954-12-02 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN NaN NaN NaN NaN 0.0635 NaN 1954-12-03 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN NaN NaN NaN NaN 0.0635 NaN 1954-12-04 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN NaN NaN NaN NaN 0.1143 NaN ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 2024-03-29 0.4267 0.2896 0.3175 0.2464 0.8839 0.1448 0.3251 0.3327 0.3937 1.1354 ... NaN 2.4755 0.4846 NaN 0.5893 1.0119 0.8110 0.3155 0.6106 0.7503 2024-03-30 0.4318 0.2896 0.3175 0.2489 0.8865 0.1448 0.3251 0.3378 0.3962 1.1379 ... NaN 2.5098 0.4953 NaN 0.6017 1.0363 0.8364 0.3338 0.6243 0.7777 2024-03-31 0.4318 0.2972 0.3200 0.2692 0.8865 0.1448 0.3327 0.3454 0.3988 1.1379 ... NaN 2.5240 0.5080 NaN 0.6078 1.0516 0.8407 0.3399 0.6314 0.7930 2024-04-01 0.4191 0.3048 0.3353 0.2692 0.8839 0.1448 0.3378 0.3556 0.3962 1.1328 ... NaN 2.5250 0.5182 NaN 0.6081 1.0668 0.8461 0.3459 0.6342 0.7960 2024-04-02 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ... NaN 2.5385 0.5182 NaN 0.6081 1.0729 0.8471 0.3459 0.6345 0.7991 <p>23842 rows \u00d7 969 columns</p> In\u00a0[37]: Copied! <pre>all_stations_swe_df = all_stations_swe_df.loc[slice(\"1966-10-01\", \"2023-09-30\")]\n</pre> all_stations_swe_df = all_stations_swe_df.loc[slice(\"1966-10-01\", \"2023-09-30\")] In\u00a0[38]: Copied! <pre>all_stations_swe_df[\"WY\"] = all_stations_swe_df.index.map(easysnowdata.utils.datetime_to_WY)\n</pre> all_stations_swe_df[\"WY\"] = all_stations_swe_df.index.map(easysnowdata.utils.datetime_to_WY) <pre>/tmp/ipykernel_25570/369461795.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  all_stations_swe_df[\"WY\"] = all_stations_swe_df.index.map(easysnowdata.utils.datetime_to_WY)\n</pre> In\u00a0[39]: Copied! <pre>all_stations_swe_df = all_stations_swe_df[all_stations_swe_df &gt;= 0]\n</pre> all_stations_swe_df = all_stations_swe_df[all_stations_swe_df &gt;= 0] In\u00a0[40]: Copied! <pre>all_stations_swe_diff_df = all_stations_swe_df.diff().abs()\nall_stations_swe_df[all_stations_swe_diff_df &gt; 0.20] = np.nan\n</pre> all_stations_swe_diff_df = all_stations_swe_df.diff().abs() all_stations_swe_df[all_stations_swe_diff_df &gt; 0.20] = np.nan In\u00a0[41]: Copied! <pre>def check_missing_data(group):\n    nov_to_apr_mask = group.index.month.isin([11, 12, 1, 2, 3, 4])\n    filtered_group = group[nov_to_apr_mask]\n    missing_data_counts = filtered_group.isnull().sum()\n    columns_to_nan = missing_data_counts[missing_data_counts &gt; 30].index\n    group[columns_to_nan] = np.nan\n    return group\n\n\ndef check_zero_swe(group):\n    for month in [1, 2, 3]:\n        month_mask = group.index.month == month\n        zero_swe_columns = group[month_mask].eq(0).all()\n        columns_to_nan = zero_swe_columns[zero_swe_columns].index\n        group[columns_to_nan] = np.nan\n    return group\n</pre> def check_missing_data(group):     nov_to_apr_mask = group.index.month.isin([11, 12, 1, 2, 3, 4])     filtered_group = group[nov_to_apr_mask]     missing_data_counts = filtered_group.isnull().sum()     columns_to_nan = missing_data_counts[missing_data_counts &gt; 30].index     group[columns_to_nan] = np.nan     return group   def check_zero_swe(group):     for month in [1, 2, 3]:         month_mask = group.index.month == month         zero_swe_columns = group[month_mask].eq(0).all()         columns_to_nan = zero_swe_columns[zero_swe_columns].index         group[columns_to_nan] = np.nan     return group In\u00a0[42]: Copied! <pre>all_stations_swe_df = (\n    all_stations_swe_df.groupby(\"WY\").apply(check_missing_data).droplevel(0)\n)\nall_stations_swe_df = (\n    all_stations_swe_df.groupby(\"WY\").apply(check_zero_swe).droplevel(0)\n)\nall_stations_swe_df\n</pre> all_stations_swe_df = (     all_stations_swe_df.groupby(\"WY\").apply(check_missing_data).droplevel(0) ) all_stations_swe_df = (     all_stations_swe_df.groupby(\"WY\").apply(check_zero_swe).droplevel(0) ) all_stations_swe_df <pre>/tmp/ipykernel_25570/72793946.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  all_stations_swe_df.groupby(\"WY\").apply(check_missing_data).droplevel(0)\n/tmp/ipykernel_25570/72793946.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  all_stations_swe_df.groupby(\"WY\").apply(check_zero_swe).droplevel(0)\n</pre> Out[42]: 301_CA_SNTL 907_UT_SNTL 916_MT_SNTL 1267_AK_SNTL 908_WA_SNTL 1189_AK_SNTL 1062_AK_SNTL 1070_AK_SNTL 302_OR_SNTL 1000_OR_SNTL ... LLP FOR GEM WTM SLT SLI SLK STL TMR WY datetime 1966-10-01 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN NaN NaN NaN NaN NaN 1967.0 1966-10-02 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN NaN NaN NaN NaN NaN 1967.0 1966-10-03 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN NaN NaN NaN NaN NaN 1967.0 1966-10-04 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN NaN NaN NaN NaN NaN 1967.0 1966-10-05 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ... NaN NaN NaN NaN NaN NaN NaN NaN NaN 1967.0 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 2023-09-26 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0051 0.0 ... 0.0 0.0 NaN 0.0 0.0 NaN 0.0 NaN 0.0 2023.0 2023-09-27 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0051 0.0 ... 0.0 0.0 NaN 0.0 0.0 NaN 0.0 NaN 0.0 2023.0 2023-09-28 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0051 0.0 ... 0.0 0.0 NaN 0.0 0.0 NaN 0.0 NaN 0.0 2023.0 2023-09-29 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0051 0.0 ... 0.0 0.0 NaN 0.0 0.0 NaN 0.0 NaN 0.0 2023.0 2023-09-30 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0051 0.0 ... 0.0 0.0 NaN 0.0 0.0 NaN 0.0 NaN 0.0 2023.0 <p>20763 rows \u00d7 970 columns</p> In\u00a0[43]: Copied! <pre>all_stations_dowy_max_swe_df = (\n    all_stations_swe_df.groupby(\"WY\").idxmax().map(easysnowdata.utils.datetime_to_DOWY)\n)\n</pre> all_stations_dowy_max_swe_df = (     all_stations_swe_df.groupby(\"WY\").idxmax().map(easysnowdata.utils.datetime_to_DOWY) ) In\u00a0[44]: Copied! <pre>stations_before_WY1982 = WesternUS.all_stations[WesternUS.all_stations.beginDate &lt; \"1981-10-01\"]\ndowy_max_swe_melted = pd.melt(\n    all_stations_dowy_max_swe_df.reset_index(), id_vars=\"WY\"\n).dropna()\ndowy_max_swe_melted_before_WY1982 = dowy_max_swe_melted[\n    dowy_max_swe_melted[\"variable\"].isin(stations_before_WY1982.index)\n]\nslope, intercept = np.polyfit(\n    dowy_max_swe_melted_before_WY1982.WY, dowy_max_swe_melted_before_WY1982.value, 1\n)\nlr_years = np.unique(dowy_max_swe_melted.WY)\n</pre> stations_before_WY1982 = WesternUS.all_stations[WesternUS.all_stations.beginDate &lt; \"1981-10-01\"] dowy_max_swe_melted = pd.melt(     all_stations_dowy_max_swe_df.reset_index(), id_vars=\"WY\" ).dropna() dowy_max_swe_melted_before_WY1982 = dowy_max_swe_melted[     dowy_max_swe_melted[\"variable\"].isin(stations_before_WY1982.index) ] slope, intercept = np.polyfit(     dowy_max_swe_melted_before_WY1982.WY, dowy_max_swe_melted_before_WY1982.value, 1 ) lr_years = np.unique(dowy_max_swe_melted.WY) In\u00a0[45]: Copied! <pre>describe = all_stations_dowy_max_swe_df.T.describe()\ndescribe\n</pre> describe = all_stations_dowy_max_swe_df.T.describe() describe Out[45]: WY 1967.0 1968.0 1969.0 1970.0 1971.0 1972.0 1973.0 1974.0 1975.0 1976.0 ... 2014.0 2015.0 2016.0 2017.0 2018.0 2019.0 2020.0 2021.0 2022.0 2023.0 count 15.000000 23.00000 31.000000 39.000000 40.000000 40.000000 48.000000 50.000000 53.000000 55.000000 ... 891.000000 870.000000 896.000000 926.000000 922.000000 929.000000 932.000000 928.000000 928.000000 920.000000 mean 211.600000 196.73913 185.741935 197.641026 188.050000 186.375000 195.729167 195.720000 213.000000 194.800000 ... 179.783389 156.452874 175.334821 179.018359 183.367679 185.812702 182.918455 180.346983 176.734914 192.546739 std 13.113788 19.17199 14.906302 25.243537 29.203047 33.502918 18.525129 17.996644 11.560876 18.673015 ... 28.288029 36.552523 27.632212 25.712310 18.666580 19.338004 26.485426 18.764201 36.686443 13.905714 min 188.000000 170.00000 158.000000 148.000000 106.000000 94.000000 134.000000 161.000000 187.000000 154.000000 ... 55.000000 33.000000 88.000000 104.000000 84.000000 95.000000 60.000000 119.000000 89.000000 86.000000 25% 208.500000 179.50000 176.000000 167.000000 179.000000 159.500000 184.750000 186.250000 207.000000 184.500000 ... 164.000000 133.000000 167.000000 159.000000 175.000000 170.000000 183.000000 175.000000 162.000000 187.000000 50% 215.000000 204.00000 182.000000 210.000000 191.500000 202.000000 197.000000 193.000000 216.000000 202.000000 ... 188.000000 156.000000 181.000000 180.000000 180.000000 186.000000 190.000000 178.000000 174.000000 189.000000 75% 218.500000 209.00000 191.500000 212.500000 209.250000 211.250000 207.000000 200.000000 221.000000 211.000000 ... 190.000000 177.000000 185.000000 202.000000 200.000000 199.000000 200.000000 189.250000 205.000000 205.000000 max 228.000000 238.00000 219.000000 227.000000 235.000000 226.000000 225.000000 238.000000 240.000000 218.000000 ... 238.000000 239.000000 232.000000 235.000000 224.000000 247.000000 229.000000 228.000000 250.000000 234.000000 <p>8 rows \u00d7 57 columns</p> In\u00a0[46]: Copied! <pre>f, ax = plt.subplots(\n    2, 1, figsize=(10, 6), sharex=True, gridspec_kw={\"height_ratios\": [3, 2]}\n)\n\ndescribe.loc[\"50%\"].plot(ax=ax[0], label=\"median\")\n\nax[0].fill_between(\n    describe.columns, describe.loc[\"25%\"], describe.loc[\"75%\"], alpha=0.3, label=\"IQR\"\n)\nax[0].plot(\n    lr_years,\n    np.array(lr_years) * slope + intercept,\n    \"k--\",\n    label=f\"Trend (slope={slope:.2f} Days/Year)\",\n)\n# ax[0].set_xlim([1967,2023])\n\nax[0].legend()\n\ndescribe.loc[\"count\"].plot(ax=ax[1])\n\n\nax[0].set_title(\"Trend in DOWY of max SWE\")\nax[1].set_title(\"Number of active stations\")\n</pre> f, ax = plt.subplots(     2, 1, figsize=(10, 6), sharex=True, gridspec_kw={\"height_ratios\": [3, 2]} )  describe.loc[\"50%\"].plot(ax=ax[0], label=\"median\")  ax[0].fill_between(     describe.columns, describe.loc[\"25%\"], describe.loc[\"75%\"], alpha=0.3, label=\"IQR\" ) ax[0].plot(     lr_years,     np.array(lr_years) * slope + intercept,     \"k--\",     label=f\"Trend (slope={slope:.2f} Days/Year)\", ) # ax[0].set_xlim([1967,2023])  ax[0].legend()  describe.loc[\"count\"].plot(ax=ax[1])   ax[0].set_title(\"Trend in DOWY of max SWE\") ax[1].set_title(\"Number of active stations\") Out[46]: <pre>Text(0.5, 1.0, 'Number of active stations')</pre> In\u00a0[47]: Copied! <pre>WesternUS.all_stations.loc[:, \"dowy_max_swe_trend\"] = all_stations_dowy_max_swe_df.apply(\n    lambda y: (\n        np.polyfit(y.dropna().index.values, y.dropna(), 1)[0]\n        if len(y.dropna()) &gt;= 30\n        else np.nan\n    )\n)\n</pre> WesternUS.all_stations.loc[:, \"dowy_max_swe_trend\"] = all_stations_dowy_max_swe_df.apply(     lambda y: (         np.polyfit(y.dropna().index.values, y.dropna(), 1)[0]         if len(y.dropna()) &gt;= 30         else np.nan     ) ) In\u00a0[48]: Copied! <pre>f, ax = plt.subplots(figsize=(10, 5.5))\n\nWesternUS.all_stations.plot(\n    column=\"dowy_max_swe_trend\",\n    ax=ax,\n    legend=True,\n    cmap=\"RdBu_r\",\n    edgecolor=\"k\",\n    markersize=20,\n    vmin=-1,\n    vmax=1,\n    legend_kwds={\"label\": \"[days/year]\\n(Red is later in the year, blue is earlier)\"},\n)\n\nctx.add_basemap(\n    ax, crs=\"EPSG:4326\", source=ctx.providers.Esri.WorldImagery, attribution=\"\"\n)\n\nax.set_title(\"Trend in DOWY of max SWE\\n(only stations with 30+ years of data)\")\n</pre> f, ax = plt.subplots(figsize=(10, 5.5))  WesternUS.all_stations.plot(     column=\"dowy_max_swe_trend\",     ax=ax,     legend=True,     cmap=\"RdBu_r\",     edgecolor=\"k\",     markersize=20,     vmin=-1,     vmax=1,     legend_kwds={\"label\": \"[days/year]\\n(Red is later in the year, blue is earlier)\"}, )  ctx.add_basemap(     ax, crs=\"EPSG:4326\", source=ctx.providers.Esri.WorldImagery, attribution=\"\" )  ax.set_title(\"Trend in DOWY of max SWE\\n(only stations with 30+ years of data)\") Out[48]: <pre>Text(0.5, 1.0, 'Trend in DOWY of max SWE\\n(only stations with 30+ years of data)')</pre> In\u00a0[49]: Copied! <pre>f, ax = plt.subplots()\n\nax.hist(WesternUS.all_stations[\"dowy_max_swe_trend\"], bins=50)\n\nax.axvline(x=0, color=\"red\")\n\nax.set_xlim([-1.5, 1.5])\n\nax.set_xlabel(\"trend [days/year]\")\nax.set_ylabel(\"count\")\nax.set_title(\"Distribution of trends in DOWY of max SWE\")\n</pre> f, ax = plt.subplots()  ax.hist(WesternUS.all_stations[\"dowy_max_swe_trend\"], bins=50)  ax.axvline(x=0, color=\"red\")  ax.set_xlim([-1.5, 1.5])  ax.set_xlabel(\"trend [days/year]\") ax.set_ylabel(\"count\") ax.set_title(\"Distribution of trends in DOWY of max SWE\") Out[49]: <pre>Text(0.5, 1.0, 'Distribution of trends in DOWY of max SWE')</pre> In\u00a0[50]: Copied! <pre>mountain_range_count = (\n    WesternUS.all_stations.dropna().groupby(\"mountainRange\")[\"dowy_max_swe_trend\"].count()\n)\nmountain_range_median = (\n    WesternUS.all_stations.dropna().groupby(\"mountainRange\")[\"dowy_max_swe_trend\"].median()\n)\nmountain_range_mean = (\n    WesternUS.all_stations.dropna().groupby(\"mountainRange\")[\"dowy_max_swe_trend\"].mean()\n)\nmountain_range_std = (\n    WesternUS.all_stations.dropna().groupby(\"mountainRange\")[\"dowy_max_swe_trend\"].std()\n)\n</pre> mountain_range_count = (     WesternUS.all_stations.dropna().groupby(\"mountainRange\")[\"dowy_max_swe_trend\"].count() ) mountain_range_median = (     WesternUS.all_stations.dropna().groupby(\"mountainRange\")[\"dowy_max_swe_trend\"].median() ) mountain_range_mean = (     WesternUS.all_stations.dropna().groupby(\"mountainRange\")[\"dowy_max_swe_trend\"].mean() ) mountain_range_std = (     WesternUS.all_stations.dropna().groupby(\"mountainRange\")[\"dowy_max_swe_trend\"].std() ) In\u00a0[51]: Copied! <pre>mountain_range_trend_df = pd.concat(\n    [\n        mountain_range_count,\n        mountain_range_median,\n        mountain_range_mean,\n        mountain_range_std,\n    ],\n    axis=1,\n)\nmountain_range_trend_df.columns = [\"station_count\", \"median\", \"mean\", \"std\"]\n</pre> mountain_range_trend_df = pd.concat(     [         mountain_range_count,         mountain_range_median,         mountain_range_mean,         mountain_range_std,     ],     axis=1, ) mountain_range_trend_df.columns = [\"station_count\", \"median\", \"mean\", \"std\"] In\u00a0[52]: Copied! <pre>mountain_range_trend_df\n</pre> mountain_range_trend_df Out[52]: station_count median mean std mountainRange Alaska Intermountain Ranges 5 -0.298031 -0.266592 0.112821 Cascade Range 63 0.072125 0.138312 0.346018 Central Montana Rocky Mountains 48 -0.083318 -0.100606 0.193399 Colorado Plateau 37 -0.282213 -0.348372 0.205635 Columbia Mountains 7 0.143695 0.082937 0.164431 Columbia Plateau 24 -0.138161 -0.029927 0.309255 Great Basin Ranges 37 -0.209381 -0.238700 0.206061 Greater Yellowstone Rockies 51 -0.044327 -0.064588 0.175889 Idaho-Bitterroot Rocky Mountains 57 -0.036092 -0.021299 0.242944 Klamath Mountains 5 -0.122516 0.019894 0.407079 Olympic Mountains 1 0.267235 0.267235 NaN Oregon Coast Range 1 0.163264 0.163264 NaN Sierra Nevada 81 -0.177622 -0.176293 0.283223 South-Central Alaska 7 -0.073497 -0.029532 0.230334 Southern Rocky Mountains 90 -0.275773 -0.277181 0.258862 Southwest Basins and Ranges 4 -0.752793 -0.740468 0.252450 Western Rocky Mountains 58 -0.191897 -0.171475 0.199642 In\u00a0[53]: Copied! <pre>f, ax = plt.subplots(1, 2, sharey=True, gridspec_kw={\"width_ratios\": [1, 3]})\n\nmountain_range_trend_df[\"station_count\"].plot.barh(ax=ax[0])\nmountain_range_trend_df[\"median\"].plot.barh(ax=ax[1], cmap=\"RdBu\")\n\n\nax[0].set_xlabel(\"[#]\")\nax[1].set_xlabel(\"[days/year]\")\nax[0].set_ylabel(\"\")\nax[0].set_title(\"station count\")\nax[1].set_title(\"trend\")\n\nf.suptitle(\"Trend in DOWY of max SWE by mountain range\")\n</pre> f, ax = plt.subplots(1, 2, sharey=True, gridspec_kw={\"width_ratios\": [1, 3]})  mountain_range_trend_df[\"station_count\"].plot.barh(ax=ax[0]) mountain_range_trend_df[\"median\"].plot.barh(ax=ax[1], cmap=\"RdBu\")   ax[0].set_xlabel(\"[#]\") ax[1].set_xlabel(\"[days/year]\") ax[0].set_ylabel(\"\") ax[0].set_title(\"station count\") ax[1].set_title(\"trend\")  f.suptitle(\"Trend in DOWY of max SWE by mountain range\") Out[53]: <pre>Text(0.5, 0.98, 'Trend in DOWY of max SWE by mountain range')</pre> In\u00a0[54]: Copied! <pre>url = (\n    f\"https://data.earthenv.org/mountains/standard/GMBA_Inventory_v2.0_standard_300.zip\"\n)\ngmba_gdf = gpd.read_file(\"zip+\" + url)\n</pre> url = (     f\"https://data.earthenv.org/mountains/standard/GMBA_Inventory_v2.0_standard_300.zip\" ) gmba_gdf = gpd.read_file(\"zip+\" + url) In\u00a0[55]: Copied! <pre>mountain_range_trend_gdf = gpd.GeoDataFrame(\n    mountain_range_trend_df.join(gmba_gdf[[\"MapName\", \"geometry\"]].set_index(\"MapName\"))\n)\n</pre> mountain_range_trend_gdf = gpd.GeoDataFrame(     mountain_range_trend_df.join(gmba_gdf[[\"MapName\", \"geometry\"]].set_index(\"MapName\")) ) In\u00a0[56]: Copied! <pre>f, ax = plt.subplots(1, 2, figsize=(14, 7))\n\nmountain_range_trend_gdf.plot(\n    ax=ax[0],\n    column=\"station_count\",\n    vmin=0,\n    vmax=100,\n    cmap=\"viridis\",\n    legend=True,\n    edgecolor=\"k\",\n    legend_kwds={\"label\": \"[#]\"},\n)\nmountain_range_trend_gdf.plot(\n    ax=ax[1],\n    column=\"median\",\n    vmin=-0.3,\n    vmax=0.3,\n    cmap=\"RdBu_r\",\n    legend=True,\n    edgecolor=\"k\",\n    legend_kwds={\"label\": \"[days/year]\\n(Red is later in the year, blue is earlier)\"},\n)\n\nfor axs in ax:\n    ctx.add_basemap(\n        ax=axs,\n        crs=mountain_range_trend_gdf.crs,\n        source=ctx.providers.Esri.WorldImagery,\n        attribution=False,\n    )\n    ctx.add_basemap(\n        ax=axs,\n        crs=mountain_range_trend_gdf.crs,\n        source=ctx.providers.Esri.WorldImagery,\n        attribution=False,\n    )\n    axs.set_xlim([-125, -104])\n    axs.set_ylim([27, 55])\n\nax[0].set_title(\"count\")\nax[1].set_title(\"trend\")\n\nf.suptitle(\n    \"Trend in DOWY of max SWE by mountain range\\n(only stations with 30+ years of data)\"\n)\n</pre> f, ax = plt.subplots(1, 2, figsize=(14, 7))  mountain_range_trend_gdf.plot(     ax=ax[0],     column=\"station_count\",     vmin=0,     vmax=100,     cmap=\"viridis\",     legend=True,     edgecolor=\"k\",     legend_kwds={\"label\": \"[#]\"}, ) mountain_range_trend_gdf.plot(     ax=ax[1],     column=\"median\",     vmin=-0.3,     vmax=0.3,     cmap=\"RdBu_r\",     legend=True,     edgecolor=\"k\",     legend_kwds={\"label\": \"[days/year]\\n(Red is later in the year, blue is earlier)\"}, )  for axs in ax:     ctx.add_basemap(         ax=axs,         crs=mountain_range_trend_gdf.crs,         source=ctx.providers.Esri.WorldImagery,         attribution=False,     )     ctx.add_basemap(         ax=axs,         crs=mountain_range_trend_gdf.crs,         source=ctx.providers.Esri.WorldImagery,         attribution=False,     )     axs.set_xlim([-125, -104])     axs.set_ylim([27, 55])  ax[0].set_title(\"count\") ax[1].set_title(\"trend\")  f.suptitle(     \"Trend in DOWY of max SWE by mountain range\\n(only stations with 30+ years of data)\" ) Out[56]: <pre>Text(0.5, 0.98, 'Trend in DOWY of max SWE by mountain range\\n(only stations with 30+ years of data)')</pre> In\u00a0[57]: Copied! <pre>m = mountain_range_trend_gdf.explore(\n    column=\"median\", cmap=\"RdBu_r\", vmin=-0.5, vmax=0.5\n)\nWesternUS.all_stations.astype(dict(beginDate=str, endDate=str)).explore(\n    m=m, column=\"dowy_max_swe_trend\", cmap=\"RdBu_r\", vmin=-0.3, vmax=0.3\n)\n</pre> m = mountain_range_trend_gdf.explore(     column=\"median\", cmap=\"RdBu_r\", vmin=-0.5, vmax=0.5 ) WesternUS.all_stations.astype(dict(beginDate=str, endDate=str)).explore(     m=m, column=\"dowy_max_swe_trend\", cmap=\"RdBu_r\", vmin=-0.3, vmax=0.3 ) Out[57]: Make this Notebook Trusted to load map: File -&gt; Trust Notebook <p>Looks like these trends are different by region, but relatively consistent within region. The majority of regions show the timing of maximum SWE happening earlier in the year, with notable exceptions being mountain ranges in the Pacific Northwest which show a reverse trend with smaller magnitude. Also of importance is the number of stations and their spatial dsitribution in each region, as 2 of the 4 regions (Olympic Mountains and Oregon Coast Range) showing the timing of maximum SWE happening later in the year only have one station each with a 30+ year record.</p> In\u00a0[3]: Copied! <pre>AllStations = easysnowdata.automatic_weather_stations.StationCollection()\n</pre> AllStations = easysnowdata.automatic_weather_stations.StationCollection() <pre>Geodataframe with all stations has been added to the Station object. Please use the .all_stations attribute to access.\nUse the .get_data(stations=geodataframe/string/list,variables=string/list,start_date=str,end_date=str) method to fetch data for specific stations and variables.\n</pre> In\u00a0[4]: Copied! <pre>AllStations.get_entire_data_archive()\n</pre> AllStations.get_entire_data_archive() <pre>Downloading compressed data to a temporary directory (/tmp/all_station_data.tar.lzma)...\nDecompressing data...\nCreating xarray.Dataset from the uncompressed data...\nDone! Entire archive dataset has been added to the station object. Please use the .entire_data_archive attribute to access.\n</pre> In\u00a0[5]: Copied! <pre>AllStations.entire_data_archive\n</pre> AllStations.entire_data_archive Out[5]: <pre>&lt;xarray.Dataset&gt; Size: 1GB\nDimensions:        (time: 23826, station: 969)\nCoordinates: (12/16)\n  * time           (time) datetime64[ns] 191kB 1909-04-13 ... 2024-03-17\n    name           (station) &lt;U24 93kB 'New Crescent Lake' ... 'Paradise Meadow'\n    network        (station) &lt;U6 23kB 'SNOTEL' 'SNOTEL' ... 'CCSS' 'CCSS'\n    elevation_m    (station) float64 8kB 1.497e+03 2.621e+03 ... 2.332e+03\n    latitude       (station) float64 8kB 43.51 40.21 37.65 ... 38.48 39.62 38.05\n    longitude      (station) float64 8kB -122.0 -105.6 -107.8 ... -120.7 -119.7\n    ...             ...\n    beginDate      (station) datetime64[ns] 8kB 1979-10-01 ... 2005-10-01\n    endDate        (station) datetime64[ns] 8kB 2024-04-03 ... 2024-04-03\n    csvData        (station) bool 969B True True True True ... True True True\n    geometry       (station) object 8kB POINT (-121.97982025146484 43.5118484...\n    WY             (time) int64 191kB 1909 1955 1955 1955 ... 2024 2024 2024\n    DOWY           (time) int64 191kB 195 62 63 64 65 66 ... 165 166 167 168 169\nDimensions without coordinates: station\nData variables:\n    TAVG           (station, time) float64 185MB nan nan nan ... -1.1 0.0 nan\n    TMIN           (station, time) float64 185MB nan nan nan ... -3.9 -5.0 nan\n    TMAX           (station, time) float64 185MB nan nan nan nan ... 3.3 7.2 nan\n    SNWD           (station, time) float64 185MB nan nan nan ... 2.286 2.235\n    WTEQ           (station, time) float64 185MB nan nan nan ... 0.8352 0.8354\n    PRCPSA         (station, time) float64 185MB nan nan nan nan ... nan nan nan</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>time: 23826</li><li>station: 969</li></ul></li><li>Coordinates: (16)<ul><li>time(time)datetime64[ns]1909-04-13 ... 2024-03-17<pre>array(['1909-04-13T00:00:00.000000000', '1954-12-01T00:00:00.000000000',\n       '1954-12-02T00:00:00.000000000', ..., '2024-03-15T00:00:00.000000000',\n       '2024-03-16T00:00:00.000000000', '2024-03-17T00:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li><li>name(station)&lt;U24'New Crescent Lake' ... 'Paradis...<pre>array(['New Crescent Lake', 'Copeland Lake', 'Cascade', 'Mount Gardner',\n       'Tamarack Summit', 'Fairbanks F.O.', 'Saddle Mountain',\n       'Lake Lois', 'Calvert Creek', 'Timber Creek', 'Trial Lake',\n       'ONeil Creek', 'Bloody Dick', 'Ivanhoe', 'Ebbetts Pass',\n       'Redden Mine Lwr', 'East Rim Divide', 'Upper Burnt Corral',\n       'Santiam Jct.', 'Cloud Peak Reservoir', 'Ward Mountain',\n       'Lower Kibbie Ridge', 'Burts Miller Ranch', 'Cold Springs',\n       'Beaver Head', 'Timberline', 'Windy Peak', 'Frohner Meadow',\n       'Virginia Lakes Ridge', 'Calamity', 'Garver Creek',\n       'Mt Rose Ski Area', 'Trinchera', 'Mores Creek Summit', 'Golconda',\n       'Thaynes Canyon', 'Buffalo Park', 'Red Rock Mountain', 'Dry Lake',\n       'Cayuse Pass', 'Clayton Springs', 'Casa Vieja Meadows',\n       'Cole Canyon', 'Heber', 'Trinity', 'Gooseberry RS', 'Vacas Locas',\n       'Lost-Wood Divide', 'Rabbit Ears', 'Takka Wiiya', 'Blacktail Mtn',\n       'Buckboard Flat', 'Schofield Pass', 'Slagamelt Lakes',\n       'Gianelli Meadow', 'Parrish Creek', 'Big Goose', 'Blazed Alder',\n       'Fry', 'Dana Meadows', 'Upper Nome Creek', 'Meadow Lake',\n       'Smiley Mountain', 'Beach Meadows', 'Clackamas Lake', 'Marquette',\n       'Sheep Mtn.', 'George Creek', 'Little Meadows',\n       'Red River Pass #2', 'Silver Creek Divide', 'Bear Creek',\n...\n       'Emigrant Summit', 'Lone Mountain', 'Beaver Creek', 'Indian Pass',\n       'Dupuyer Creek', 'Spratt Creek', 'Beaver Divide', 'Barker Lakes',\n       'Red Mountain Pass', 'Paradise', 'Soldier Park', 'Tower',\n       'Lewis Lake Divide', 'Currant Creek', 'Forestdale Creek',\n       'Panguitch Lake RS', 'Snow Mountain', 'Smith  Morehouse',\n       'Molas Lake', 'Marlette Lake', 'Copper Camp', 'Carrot Basin',\n       'Whiskey Park', 'Daniels-Strawberry', 'Fisher Creek',\n       'Bear Canyon', 'Mill Creek Summit', 'Columbine Pass',\n       'Loomis Park', 'Taos Powderhorn', 'Heen Latinee', 'MF Nooksack',\n       'Spruce Springs', 'Cent Sierra Snow Lab',\n       'Tioga Pass Entry Station', 'Cascade Mountain', 'Galena Summit',\n       'Bostetter R.S.', 'Red Hill', 'Frisco Divide', 'Diamond Peak',\n       'Box Canyon', 'Seine Creek', 'Quartz Peak', 'Galena', 'Muckamuck',\n       'Mcknight Cabin', 'Hayden Pass', 'Trapper Lake', 'Parker Peak',\n       'Lone Cone', 'Deadman Creek', 'Heavenly Valley', 'Bison Lake',\n       'Rock Creek', 'Thumb Divide', 'Four Trees', 'Indian Canyon',\n       'Baker Butte', 'Morgan Creek', 'Caples Lake', 'Kimberly Mine',\n       'Touchet', 'Kalamazoo', 'Upper San Juan', 'Mc Clure Pass',\n       'Lasal Mountain', 'Robinson Cow Camp', 'Paradise Meadow'],\n      dtype='&lt;U24')</pre></li><li>network(station)&lt;U6'SNOTEL' 'SNOTEL' ... 'CCSS' 'CCSS'<pre>array(['SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'CCSS', 'SNOTEL', 'SNOTEL',\n       'CCSS', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL',\n       'CCSS', 'SNOTEL', 'SNOTEL', 'CCSS', 'SNOTEL', 'SNOTEL', 'SNOTEL',\n       'CCSS', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL',\n       'CCSS', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL',\n       'SNOTEL', 'SNOTEL', 'CCSS', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'CCSS',\n       'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL',\n       'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'CCSS',\n       'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'CCSS', 'SNOTEL', 'SNOTEL',\n       'SNOTEL', 'CCSS', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL',\n       'SNOTEL', 'SNOTEL', 'SNOTEL', 'CCSS', 'SNOTEL', 'SNOTEL', 'SNOTEL',\n       'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL',\n       'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL',\n       'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'CCSS', 'CCSS', 'CCSS',\n       'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'CCSS', 'SNOTEL', 'SNOTEL',\n       'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'CCSS', 'SNOTEL',\n       'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL',\n       'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL',\n       'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'CCSS',\n       'SNOTEL', 'CCSS', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL',\n...\n       'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL',\n       'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'CCSS', 'SNOTEL', 'SNOTEL',\n       'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL',\n       'SNOTEL', 'CCSS', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL',\n       'CCSS', 'CCSS', 'SNOTEL', 'CCSS', 'CCSS', 'SNOTEL', 'SNOTEL',\n       'SNOTEL', 'SNOTEL', 'CCSS', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL',\n       'SNOTEL', 'CCSS', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL',\n       'CCSS', 'CCSS', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL',\n       'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL',\n       'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'CCSS', 'SNOTEL',\n       'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL',\n       'SNOTEL', 'SNOTEL', 'SNOTEL', 'CCSS', 'SNOTEL', 'SNOTEL', 'SNOTEL',\n       'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL',\n       'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL',\n       'SNOTEL', 'CCSS', 'CCSS', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL',\n       'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL',\n       'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'CCSS',\n       'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'CCSS', 'SNOTEL', 'SNOTEL',\n       'SNOTEL', 'CCSS', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL', 'SNOTEL',\n       'SNOTEL', 'CCSS', 'CCSS'], dtype='&lt;U6')</pre></li><li>elevation_m(station)float641.497e+03 2.621e+03 ... 2.332e+03<pre>array([1496.56799316, 2621.2800293 , 2706.62402344,  890.01599121,\n       2301.24      ,  137.16000366,  947.92797852, 2621.28      ,\n       1959.86401367, 2423.15991211, 3045.56152344, 1987.29602051,\n       2316.47998047, 3169.91992188, 2651.76      , 2600.55371094,\n       2417.06396484, 2956.56      , 1139.95202637, 3005.32788086,\n       2804.15991211, 2042.16      , 2438.39990234, 2935.22412109,\n       2435.35205078, 2662.73291016, 2407.91992188, 1975.10400391,\n       2834.64      ,  762.        , 1295.40002441, 2682.54492188,\n       3310.12792969, 1859.2800293 , 2016.5567627 , 2813.30395508,\n       2816.35205078, 2042.16      , 2560.32006836, 1597.15197754,\n       3062.93530273, 2529.84      , 1801.36804199, 2328.67211914,\n        893.06402588, 2421.33129883, 2836.46875   , 2407.91992188,\n       2865.12011719, 2780.38549805, 1722.11999512, 2720.03515625,\n       3261.36010742, 2627.37597656, 2560.32      , 2359.15209961,\n       2435.35205078, 1112.52001953, 2194.56005859, 2987.04      ,\n        768.0960083 , 2788.91992188, 2901.69604492, 2331.72      ,\n       1036.31994629, 2670.0480957 , 2026.92004395, 2732.22729492,\n       1225.29602051, 3002.2800293 , 2743.19995117, 2450.59204102,\n       1645.92      , 3048.        , 2651.76000977, 1271.01599121,\n       2248.50952148, 2112.26391602,  868.67999268,  426.72000122,\n...\n       2901.08642578, 2451.8112793 ,  213.36000061, 2662.12329102,\n       2621.2800293 , 2578.60791016, 2334.76806641, 3020.56811523,\n       2252.47192383, 2706.62402344, 2392.67993164,  716.2800293 ,\n       1752.59997559, 1874.52      , 2523.74389648, 2514.60009766,\n       3413.76000977, 1563.62402344, 2657.85595703, 3200.39990234,\n       2392.67993164, 2412.49194336, 2443.58154297, 2545.08007812,\n       1813.56      , 2325.92871094, 3200.39990234, 2403.04321289,\n       2118.36010742, 2743.19995117, 2727.95996094, 2440.83837891,\n       2773.67993164, 2407.91992188, 2682.23999023, 2865.12011719,\n       2511.55200195, 3370.17358398,  629.4119873 , 1514.85595703,\n       1737.35998535, 2103.12      , 3031.236     , 2369.51513672,\n       2676.14404297, 2286.        , 1344.16796875, 2438.39990234,\n       2443.58154297, 2033.01599121,  627.88800049, 1432.56005859,\n       2276.85595703, 1362.45605469, 2816.35205078, 3267.45605469,\n       2956.56005859, 2865.12011719, 2926.08007812, 2819.4       ,\n       2601.16308594, 3316.22412109, 2403.65283203, 2432.30395508,\n       1585.5696    , 2795.32080078, 2225.04003906, 2316.47998047,\n       2438.4       , 2773.98486328, 1685.54394531, 2369.82006836,\n       3108.95996094, 2895.60009766, 2919.37451172, 1975.104     ,\n       2331.72      ])</pre></li><li>latitude(station)float6443.51 40.21 37.65 ... 39.62 38.05<pre>array([43.51184845, 40.20777893, 37.65082932, 47.35768127, 37.16375   ,\n       64.84999847, 45.54476929, 38.921036  , 45.88380051, 44.02740097,\n       40.6780014 , 41.86420059, 45.16506958, 39.29201889, 38.561     ,\n       40.67504883, 43.13097   , 37.183296  , 44.43503189, 44.40343094,\n       39.13241959, 38.033024  , 40.9849205 , 43.2767601 , 33.69144058,\n       39.67712021, 42.28020096, 46.43545151, 38.077     , 45.90362167,\n       48.97523117, 39.31573105, 37.35327911, 43.93199921, 40.88357925,\n       40.62350082, 40.22861099, 41.023621  , 40.53396988, 46.86954117,\n       37.97249985, 36.198097  , 44.4863205 , 34.31201935, 48.0746994 ,\n       38.80033875, 36.02634811, 43.82432175, 40.36782837, 39.74103928,\n       47.98287964, 37.86943054, 39.01522064, 45.36526108, 38.204308  ,\n       40.93416977, 44.57923889, 45.42869949, 35.07297134, 37.896162  ,\n       65.36710358, 44.43655014, 43.72718048, 36.126095  , 45.09658051,\n       44.30160141, 43.21030045, 41.9156189 , 44.61296844, 36.69924927,\n       33.37105942, 41.83383942, 41.16914   , 36.71630859, 39.29721832,\n       47.04439926, 40.18537903, 41.75067139, 65.09999847, 60.61713028,\n       46.92832947, 44.14424896, 44.57461929, 40.53215027, 42.86983871,\n       45.17367172, 48.1747818 , 45.98210144, 42.43582916, 39.25259018,\n       46.54740906, 45.18832016, 41.237     , 39.001     , 38.932     ,\n       44.12612152, 38.85189819, 60.39027023, 42.76477814, 38.943947  ,\n...\n       38.8365    , 39.23802948, 44.71960831, 48.15678024, 48.19797897,\n       37.457275  , 41.22869873, 61.11483002, 45.24010086, 38.99076843,\n       48.12672043, 38.7194    , 35.70429993, 48.95159912, 46.84233856,\n       45.50381088, 43.11265182, 41.591389  , 38.318     , 39.30229187,\n       48.69092178, 38.50809097, 40.73899841, 39.92975998, 60.25965118,\n       38.8818512 , 45.01787949, 35.23332977, 42.70991898, 40.03522873,\n       42.36054993, 45.27412033, 44.94966125, 61.06766891, 48.06341171,\n       38.66627   , 40.61233139, 46.09712982, 37.89179993, 46.78264999,\n       44.34846878, 40.53742981, 44.20861816, 40.35747147, 38.68244934,\n       37.70463181, 40.778809  , 40.78931046, 37.74932098, 39.16395187,\n       47.08158112, 44.96192169, 41.00289154, 40.29529953, 45.06235123,\n       43.74367142, 44.47211838, 38.41794968, 43.17387009, 36.58203125,\n       58.69652176, 48.82453156, 46.18286896, 39.325     , 37.91087   ,\n       40.28300095, 43.87496948, 42.16442108, 45.46429825, 33.73646164,\n       39.56361008, 45.27190018, 45.52687836, 47.87926865, 43.87722015,\n       48.58525848, 33.00812149, 38.29325867, 39.99884033, 44.7339592 ,\n       37.89183044, 38.331596  , 38.92430878, 39.76486969, 40.54875183,\n       44.36917114, 39.81278   , 39.89165878, 34.45660019, 44.84236908,\n       38.710793  , 38.4838295 , 46.11867905, 39.55789948, 37.48575974,\n       39.1289711 , 38.48226166, 39.621864  , 38.046117  ])</pre></li><li>longitude(station)float64-122.0 -105.6 ... -120.7 -119.7<pre>array([-121.97982025, -105.56861115, -107.80602264, -121.56812286,\n       -119.200531  , -147.80000305, -123.37315369, -120.204445  ,\n       -113.32553101, -109.17878723, -110.94873047, -115.0831604 ,\n       -113.50099182, -106.54923248, -119.808     , -111.21765137,\n       -110.20230103, -118.938293  , -121.94502258, -107.06056976,\n       -114.95574951, -119.879245  , -110.85075378, -109.44584656,\n       -109.21656799, -110.43395233, -105.57816315, -112.19277191,\n       -119.234     , -122.21633148, -115.81915283, -119.89472961,\n       -105.23233032, -115.6658783 , -117.58811951, -111.53321838,\n       -106.59528351, -122.886627  , -106.78130341, -121.53430176,\n       -111.8335495 , -118.267685  , -104.41056824, -110.75431061,\n       -120.84929657, -111.68332672, -106.81362152, -114.26402283,\n       -106.74037933, -113.98262024, -114.35430145, -109.44716644,\n       -107.04876709, -113.71833801, -119.893188  , -111.8137207 ,\n       -107.20068359, -121.85604858, -111.84374237, -119.25726   ,\n       -146.59199524, -113.31815338, -113.83402252, -118.293457  ,\n       -121.75443268, -109.2401886 , -111.68791962, -113.41153717,\n       -122.22564697, -105.34124756, -108.70617676, -115.45278168,\n       -121.939827  , -106.26348114, -106.60694122, -121.94032288,\n       -111.35971069, -117.5318222 , -144.9331665 , -149.53128052,\n...\n       -109.67279816, -111.63108826, -149.34228516, -112.24915314,\n       -111.84559631, -108.26667023, -118.63210297, -105.54425812,\n       -111.56085205, -111.42691803, -111.35852051, -149.47950745,\n       -112.75730133, -119.81742   , -111.09781647, -113.13037872,\n       -107.71341705, -121.74765015, -107.01360321, -106.67680359,\n       -110.66628265, -111.08992767, -119.95970154, -112.65036774,\n       -121.782677  , -111.09191895, -107.68865967, -119.89672089,\n       -112.72955322, -111.29402924, -106.90847778, -111.25676727,\n       -109.94487762, -113.93797302, -114.48992157, -108.38249207,\n       -110.14006805, -105.45610809, -134.86448669, -121.92951202,\n       -117.54154968, -120.367     , -119.258507  , -111.60991669,\n       -114.71363068, -114.19271851, -121.70427704, -108.94502258,\n       -115.84420776, -110.24903107, -123.29856873, -117.08937836,\n       -114.67250061, -119.86624146, -107.86975098, -105.85050201,\n       -107.23619843, -109.9148407 , -108.1954422 , -119.654114  ,\n       -119.91641235, -107.35681152, -110.69291687, -110.57717133,\n       -121.32168   , -110.74604034, -111.40643311, -114.26870728,\n       -120.04158   , -112.39273071, -117.85050201, -114.62761688,\n       -106.83535004, -107.28806305, -109.27198029, -120.679871  ,\n       -119.671748  ])</pre></li><li>state(station)&lt;U12'Oregon' ... 'California'<pre>array(['Oregon', 'Colorado', 'Colorado', 'Washington', 'California',\n       'Alaska', 'Oregon', 'California', 'Montana', 'Wyoming', 'Utah',\n       'Nevada', 'Montana', 'Colorado', 'California', 'Utah', 'Wyoming',\n       'California', 'Oregon', 'Wyoming', 'Nevada', 'California', 'Utah',\n       'Wyoming', 'Arizona', 'Utah', 'Wyoming', 'Montana', 'California',\n       'Washington', 'Montana', 'Nevada', 'Colorado', 'Idaho', 'Nevada',\n       'Utah', 'Colorado', 'California', 'Colorado', 'Washington', 'Utah',\n       'California', 'Wyoming', 'Arizona', 'Washington', 'Utah',\n       'New Mexico', 'Idaho', 'Colorado', 'Utah', 'Montana', 'Utah',\n       'Colorado', 'Montana', 'California', 'Utah', 'Wyoming', 'Oregon',\n       'Arizona', 'California', 'Alaska', 'Idaho', 'Idaho', 'California',\n       'Oregon', 'Wyoming', 'Idaho', 'Utah', 'Oregon', 'New Mexico',\n       'New Mexico', 'Nevada', 'California', 'New Mexico', 'Colorado',\n       'Washington', 'Utah', 'Nevada', 'Alaska', 'Alaska', 'Washington',\n       'Oregon', 'Wyoming', 'Colorado', 'Wyoming', 'Montana', 'Montana',\n       'Oregon', 'Wyoming', 'Nevada', 'Washington', 'Oregon',\n       'California', 'California', 'California', 'Wyoming', 'California',\n       'Alaska', 'Idaho', 'California', 'Oregon', 'Utah', 'Montana',\n       'Idaho', 'Oregon', 'Oregon', 'Montana', 'California', 'Washington',\n       'Montana', 'Utah', 'Oregon', 'Wyoming', 'Alaska', 'Utah',\n...\n       'California', 'Utah', 'Montana', 'Utah', 'Idaho', 'New Mexico',\n       'California', 'California', 'Idaho', 'California', 'California',\n       'Utah', 'Wyoming', 'Montana', 'Washington', 'California', 'Nevada',\n       'Alaska', 'Montana', 'Colorado', 'Montana', 'California',\n       'New Mexico', 'Washington', 'Montana', 'Montana', 'Wyoming',\n       'California', 'California', 'Utah', 'Washington', 'Utah', 'Utah',\n       'Utah', 'Alaska', 'Utah', 'Montana', 'New Mexico', 'Oregon',\n       'Colorado', 'Idaho', 'Montana', 'Montana', 'Alaska', 'Montana',\n       'California', 'Utah', 'Montana', 'Colorado', 'Washington',\n       'Wyoming', 'Colorado', 'Wyoming', 'Utah', 'California', 'Utah',\n       'California', 'Utah', 'Colorado', 'Nevada', 'Montana', 'Montana',\n       'Wyoming', 'Utah', 'Montana', 'Idaho', 'Idaho', 'Colorado',\n       'Wyoming', 'New Mexico', 'Alaska', 'Washington', 'Washington',\n       'California', 'California', 'Utah', 'Idaho', 'Idaho', 'Oregon',\n       'New Mexico', 'Nevada', 'Montana', 'Oregon', 'Washington', 'Idaho',\n       'Washington', 'New Mexico', 'Colorado', 'Colorado', 'Wyoming',\n       'Colorado', 'California', 'California', 'Colorado', 'Utah',\n       'Wyoming', 'California', 'Utah', 'Arizona', 'Idaho', 'California',\n       'Utah', 'Washington', 'Nevada', 'Colorado', 'Colorado', 'Utah',\n       'California', 'California'], dtype='&lt;U12')</pre></li><li>HUC(station)&lt;U12'170703020205' ... '180400090503'<pre>array(['170703020205', '101900050202', '140801040201', '171100120103',\n       '180400060903', '190803060907', '170900100201', '180201280201',\n       '100200040801', '100800090210', '160202030102', '170402130106',\n       '100200011002', '140100040501', '160502010104', '160201010103',\n       '170401030203', '180300100603', '170900040201', '100902060301',\n       '150100110105', '180400090303', '160101010105', '100800010702',\n       '150601010107', '140600070903', '101800080802', '100301011305',\n       '160503010103', '170800020603', '170101030202', '160501020304',\n       '130100020601', '170501110503', '160401080102', '160201020101',\n       '140100010706', '180102110501', '140500010409', '171100140301',\n       '160300020501', '180300010401', '101202030302', '150200100201',\n       '170200110302', '160300030405', '130202020102', '170402190304',\n       '140500010402', '160203060804', '170102080302', '140802030103',\n       '140100040701', '100200040308', '180400100501', '160201020501',\n       '100901010103', '170800010102', '150602020501', '180400090102',\n       '190804020304', '170602040101', '170402180102', '180300010403',\n       '170900110301', '100800130303', '170402050304', '170402100401',\n       '170900060301', '130201010301', '150400040605', '170501020301',\n       '180200040208', '130201021401', '140100040504', '171100140103',\n       '160202020304', '160401090502', '190803060102', '190203020401',\n...\n       '140600100802', '160202020601', '190203020902', '160300051307',\n       '100200070803', '130202070203', '171200030107', '101900050401',\n       '160102020206', '100200080201', '100200070402', '190203020701',\n       '100302010501', '160502010107', '160202030105', '170102010304',\n       '140801040103', '171100150104', '100902060103', '140500010407',\n       '170401010104', '140600040401', '160502010301', '160300010402',\n       '180200031103', '160201010203', '140801040302', '160501010201',\n       '170102030103', '100200080105', '140500030102', '140600040101',\n       '100700060202', '170402180101', '170602010501', '140200050202',\n       '140401010201', '130201010701', '190103010401', '171100040303',\n       '170601030201', '180201250602', '180400090102', '160202030505',\n       '170402190101', '170402120201', '170701050505', '150400040303',\n       '160600051503', '100700020902', '170900100203', '170103080302',\n       '170402190101', '170200062001', '130302020103', '130100030301',\n       '140500050101', '100700010502', '140300030302', '180400100203',\n       '160501010302', '140100011401', '140600030304', '100700010409',\n       '180201210801', '140600040701', '150602030206', '170602030901',\n       '180201290101', '160300030104', '170701020303', '160600080700',\n       '140801010203', '140200040203', '140300050404', '180201250102',\n       '180400090503'], dtype='&lt;U12')</pre></li><li>mgrs(station)&lt;U5'10TEP' '13TDE' ... '10SFJ' '11SKC'<pre>array(['10TEP', '13TDE', '13SBB', '10TFT', '11SLB', '06WVS', '10TDR',\n       '10SGJ', '12TUR', '12TXP', '12TWL', '11TPG', '12TUR', '13SCD',\n       '11SKC', '12TVL', '12TWN', '11SLB', '10TEQ', '13TCK', '11SPD',\n       '11SKC', '12TWL', '12TXN', '12SXC', '12SWJ', '13TDG', '12TVS',\n       '11SLC', '10TER', '11UNQ', '11SKD', '13SDB', '11TPJ', '11TMF',\n       '12TVK', '13TCE', '10TEL', '13TCE', '10TFS', '12SVH', '11SLA',\n       '13TEK', '12SWC', '10UFU', '12SVH', '13SCV', '11TQJ', '13TCE',\n       '12STK', '11TPP', '12SXG', '13SCD', '12TTR', '11SKC', '12TVL',\n       '13TCK', '10TER', '12SVD', '11SLB', '06WWT', '12TUQ', '12TTP',\n       '11SLV', '10TEQ', '12TXQ', '12TVN', '12TUM', '10TEQ', '13SDA',\n       '12SYB', '11TPG', '10TEL', '13SCA', '13SCD', '10TET', '12TVK',\n       '11TMG', '06WWT', '06VUN', '10TES', '10TFP', '13TCK', '13TDE',\n       '12TXN', '12TTR', '12UXU', '11TML', '13TDG', '11SKD', '10TFS',\n       '10TFR', '10TFL', '10SGJ', '10SGJ', '12TWP', '11SKD', '06VUM',\n       '11TNH', '10SGJ', '10TEQ', '12STG', '12UUU', '11TNK', '11TLK',\n       '11TKK', '12TVS', '11SKB', '11ULQ', '12TVR', '12SVJ', '11TMK',\n       '13TCF', '05VMH', '12SVH', '13SCC', '12TVL', '10UFU', '10TFT',\n       '12TTT', '10UEV', '10TFM', '11TPF', '13SDD', '13TCF', '11UNP',\n       '12TWQ', '10SGH', '11TPG', '10SGJ', '13TCF', '12TVQ', '13TDF',\n       '11TPE', '12SYG', '12SVJ', '12SUG', '10TFT', '11TNK', '12STG',\n...\n       '13SCD', '10UFU', '11SKD', '13SCC', '12TUS', '13TCK', '11TLL',\n       '13TCK', '10TFS', '13SCC', '13SCB', '11SPA', '12TVM', '13TCK',\n       '13TDE', '10TEN', '12SWC', '11SLB', '12SUG', '11TPG', '10UFU',\n       '10TEQ', '10TFT', '10SGJ', '13SDV', '12SVD', '12TTT', '11SKC',\n       '12TWL', '12TUQ', '12SUG', '11TPM', '13SDA', '10SGH', '11SKB',\n       '11TNJ', '11SKB', '11SKD', '12SVJ', '12TWQ', '12UTU', '10UFU',\n       '11SLB', '11TNF', '06VUN', '12TXR', '13SCD', '11UPP', '11SKC',\n       '13SDV', '11ULQ', '12TUS', '12TWR', '12TWN', '10TFM', '11SKC',\n       '12SVJ', '10UEU', '12SVH', '12TXL', '12SVK', '06VUM', '12SUJ',\n       '12TVQ', '12SYE', '11TLH', '13TDE', '12TVM', '12TVR', '12TVQ',\n       '06VUN', '12UUU', '11SKC', '12TVK', '12TUS', '13SBB', '10TES',\n       '13TCK', '13TCE', '12TWP', '12TVK', '11SKC', '12SUG', '10TFL',\n       '12TVL', '13SBB', '11SKD', '12TUT', '12TVQ', '13TCF', '12TVK',\n       '12TWQ', '12TTP', '11TPK', '12SYH', '12TWN', '13SDA', '08VNL',\n       '10UEV', '11TMM', '10SGJ', '11SLB', '12TVK', '11TPJ', '11TQG',\n       '10TFR', '12SXC', '11SND', '12TWR', '10TDR', '11TMP', '11TPJ',\n       '11UKP', '13SBS', '13SDC', '13SCE', '12TWQ', '12SYG', '11SKC',\n       '11SKD', '13SBE', '12TWK', '12TWQ', '10SFK', '12SWK', '12SVD',\n       '11TQK', '10SGH', '12SUH', '11TMM', '11SQD', '13SCB', '13SCD',\n       '12SXH', '10SFJ', '11SKC'], dtype='&lt;U5')</pre></li><li>mountainRange(station)object'Cascade Range' ... 'Sierra Nevada'<pre>array(['Cascade Range', 'Southern Rocky Mountains',\n       'Southern Rocky Mountains', 'Cascade Range', 'Sierra Nevada', None,\n       'Oregon Coast Range', 'Sierra Nevada', None,\n       'Greater Yellowstone Rockies', 'Western Rocky Mountains',\n       'Great Basin Ranges', 'Idaho-Bitterroot Rocky Mountains',\n       'Southern Rocky Mountains', 'Sierra Nevada',\n       'Western Rocky Mountains', None, 'Sierra Nevada', 'Cascade Range',\n       'Greater Yellowstone Rockies', 'Great Basin Ranges',\n       'Sierra Nevada', None, 'Greater Yellowstone Rockies',\n       'Colorado Plateau', 'Colorado Plateau', 'Southern Rocky Mountains',\n       'Central Montana Rocky Mountains', 'Sierra Nevada',\n       'Cascade Range', 'Columbia Mountains', 'Sierra Nevada',\n       'Southern Rocky Mountains', 'Idaho-Bitterroot Rocky Mountains',\n       'Great Basin Ranges', 'Western Rocky Mountains',\n       'Southern Rocky Mountains', 'Klamath Mountains',\n       'Southern Rocky Mountains', 'Cascade Range', None, 'Sierra Nevada',\n       'Black Hills', None, 'Cascade Range', 'Colorado Plateau',\n       'Colorado Plateau', 'Idaho-Bitterroot Rocky Mountains',\n       'Southern Rocky Mountains', 'Great Basin Ranges',\n       'Central Montana Rocky Mountains', 'Colorado Plateau',\n...\n       'Southern Rocky Mountains', 'Western Rocky Mountains',\n       'Greater Yellowstone Rockies', 'Idaho-Bitterroot Rocky Mountains',\n       'Idaho-Bitterroot Rocky Mountains', 'Colorado Plateau',\n       'Greater Yellowstone Rockies', 'Southern Rocky Mountains',\n       'Coast Mountains', 'Cascade Range', 'Columbia Plateau',\n       'Sierra Nevada', 'Sierra Nevada', 'Western Rocky Mountains',\n       'Idaho-Bitterroot Rocky Mountains', 'Great Basin Ranges',\n       'Cascade Range', 'Colorado Plateau', 'Great Basin Ranges',\n       'Greater Yellowstone Rockies', 'Oregon Coast Range',\n       'Columbia Mountains', 'Idaho-Bitterroot Rocky Mountains',\n       'Cascade Range', 'Southwest Basins and Ranges',\n       'Southern Rocky Mountains', 'Southern Rocky Mountains',\n       'Greater Yellowstone Rockies', 'Southern Rocky Mountains',\n       'Sierra Nevada', 'Sierra Nevada', 'Southern Rocky Mountains',\n       'Western Rocky Mountains', None, 'Sierra Nevada',\n       'Colorado Plateau', 'Colorado Plateau',\n       'Idaho-Bitterroot Rocky Mountains', 'Sierra Nevada',\n       'Colorado Plateau', 'Columbia Plateau', 'Great Basin Ranges',\n       'Southern Rocky Mountains', 'Southern Rocky Mountains',\n       'Colorado Plateau', 'Sierra Nevada', 'Sierra Nevada'], dtype=object)</pre></li><li>beginDate(station)datetime64[ns]1979-10-01 ... 2005-10-01<pre>array(['1979-10-01T00:00:00.000000000', '1979-10-01T00:00:00.000000000',\n       '1978-10-01T00:00:00.000000000', '1993-10-01T00:00:00.000000000',\n       '2011-01-01T00:00:00.000000000', '1981-10-01T00:00:00.000000000',\n       '1978-10-01T00:00:00.000000000', '2011-01-01T00:00:00.000000000',\n       '1974-10-01T00:00:00.000000000', '1967-08-01T00:00:00.000000000',\n       '1978-10-01T00:00:00.000000000', '2017-09-30T00:00:00.000000000',\n       '1976-10-01T00:00:00.000000000', '1991-10-01T00:00:00.000000000',\n       '2004-10-01T00:00:00.000000000', '2012-10-01T00:00:00.000000000',\n       '1984-10-01T00:00:00.000000000', '2004-10-01T00:00:00.000000000',\n       '1978-10-01T00:00:00.000000000', '1978-10-01T00:00:00.000000000',\n       '1980-10-01T00:00:00.000000000', '2005-10-01T00:00:00.000000000',\n       '2009-10-01T00:00:00.000000000', '1980-10-01T00:00:00.000000000',\n       '1993-10-01T00:00:00.000000000', '2007-10-01T00:00:00.000000000',\n       '1979-10-01T00:00:00.000000000', '1967-10-01T00:00:00.000000000',\n       '1967-10-01T00:00:00.000000000', '2008-08-21T13:00:00.000000000',\n       '1968-10-01T00:00:00.000000000', '1980-10-01T00:00:00.000000000',\n       '1988-10-01T00:00:00.000000000', '1978-09-30T00:00:00.000000000',\n       '2011-10-01T00:00:00.000000000', '1988-06-20T00:00:00.000000000',\n       '1995-09-01T00:00:00.000000000', '2016-10-01T00:00:00.000000000',\n       '1979-10-01T00:00:00.000000000', '2006-10-01T00:00:00.000000000',\n...\n       '2015-10-02T13:00:00.000000000', '2002-10-01T00:00:00.000000000',\n       '2000-07-01T00:00:00.000000000',                           'NaT',\n       '2004-10-01T00:00:00.000000000', '2002-10-17T00:00:00.000000000',\n       '1978-10-01T00:00:00.000000000', '1979-10-01T00:00:00.000000000',\n       '1978-10-01T00:00:00.000000000', '1971-10-01T00:00:00.000000000',\n       '1983-10-01T00:00:00.000000000', '1976-10-01T00:00:00.000000000',\n       '1979-10-01T00:00:00.000000000', '1985-10-01T00:00:00.000000000',\n       '1979-10-01T00:00:00.000000000', '2014-06-10T00:00:00.000000000',\n       '2003-09-25T00:00:00.000000000', '2007-08-28T00:00:00.000000000',\n       '1985-10-01T00:00:00.000000000', '1979-10-01T00:00:00.000000000',\n       '1979-10-01T00:00:00.000000000', '2005-10-01T00:00:00.000000000',\n       '1978-10-01T00:00:00.000000000', '1985-09-30T00:00:00.000000000',\n       '1980-06-12T00:00:00.000000000', '1987-09-30T00:00:00.000000000',\n                                 'NaT', '1978-10-01T00:00:00.000000000',\n       '1965-10-01T00:00:00.000000000', '1979-10-01T00:00:00.000000000',\n       '2004-10-01T00:00:00.000000000', '1980-07-23T00:00:00.000000000',\n       '1979-10-01T00:00:00.000000000', '2011-10-01T00:00:00.000000000',\n       '1978-10-01T00:00:00.000000000', '1979-10-01T00:00:00.000000000',\n       '1980-08-08T00:00:00.000000000', '2007-12-01T00:00:00.000000000',\n       '2005-10-01T00:00:00.000000000'], dtype='datetime64[ns]')</pre></li><li>endDate(station)datetime64[ns]2024-04-03 ... 2024-04-03<pre>array(['2024-04-03T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2022-09-27T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2100-01-01T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2023-04-06T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-02T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2100-01-01T00:00:00.000000000',\n...\n       '2100-01-01T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-02T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2100-01-01T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-02T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000', '2024-04-03T00:00:00.000000000',\n       '2024-04-03T00:00:00.000000000'], dtype='datetime64[ns]')</pre></li><li>csvData(station)boolTrue True True ... True True True<pre>array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n...\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True])</pre></li><li>geometry(station)objectPOINT (-121.97982025146484 43.51...<pre>array([&lt;POINT (-121.98 43.512)&gt;, &lt;POINT (-105.569 40.208)&gt;,\n       &lt;POINT (-107.806 37.651)&gt;, &lt;POINT (-121.568 47.358)&gt;,\n       &lt;POINT (-119.201 37.164)&gt;, &lt;POINT (-147.8 64.85)&gt;,\n       &lt;POINT (-123.373 45.545)&gt;, &lt;POINT (-120.204 38.921)&gt;,\n       &lt;POINT (-113.326 45.884)&gt;, &lt;POINT (-109.179 44.027)&gt;,\n       &lt;POINT (-110.949 40.678)&gt;, &lt;POINT (-115.083 41.864)&gt;,\n       &lt;POINT (-113.501 45.165)&gt;, &lt;POINT (-106.549 39.292)&gt;,\n       &lt;POINT (-119.808 38.561)&gt;, &lt;POINT (-111.218 40.675)&gt;,\n       &lt;POINT (-110.202 43.131)&gt;, &lt;POINT (-118.938 37.183)&gt;,\n       &lt;POINT (-121.945 44.435)&gt;, &lt;POINT (-107.061 44.403)&gt;,\n       &lt;POINT (-114.956 39.132)&gt;, &lt;POINT (-119.879 38.033)&gt;,\n       &lt;POINT (-110.851 40.985)&gt;, &lt;POINT (-109.446 43.277)&gt;,\n       &lt;POINT (-109.217 33.691)&gt;, &lt;POINT (-110.434 39.677)&gt;,\n       &lt;POINT (-105.578 42.28)&gt;, &lt;POINT (-112.193 46.435)&gt;,\n       &lt;POINT (-119.234 38.077)&gt;, &lt;POINT (-122.216 45.904)&gt;,\n       &lt;POINT (-115.819 48.975)&gt;, &lt;POINT (-119.895 39.316)&gt;,\n       &lt;POINT (-105.232 37.353)&gt;, &lt;POINT (-115.666 43.932)&gt;,\n       &lt;POINT (-117.588 40.884)&gt;, &lt;POINT (-111.533 40.624)&gt;,\n       &lt;POINT (-106.595 40.229)&gt;, &lt;POINT (-122.887 41.024)&gt;,\n       &lt;POINT (-106.781 40.534)&gt;, &lt;POINT (-121.534 46.87)&gt;,\n...\n       &lt;POINT (-134.864 58.697)&gt;, &lt;POINT (-121.93 48.825)&gt;,\n       &lt;POINT (-117.542 46.183)&gt;, &lt;POINT (-120.367 39.325)&gt;,\n       &lt;POINT (-119.259 37.911)&gt;, &lt;POINT (-111.61 40.283)&gt;,\n       &lt;POINT (-114.714 43.875)&gt;, &lt;POINT (-114.193 42.164)&gt;,\n       &lt;POINT (-121.704 45.464)&gt;, &lt;POINT (-108.945 33.736)&gt;,\n       &lt;POINT (-115.844 39.564)&gt;, &lt;POINT (-110.249 45.272)&gt;,\n       &lt;POINT (-123.299 45.527)&gt;, &lt;POINT (-117.089 47.879)&gt;,\n       &lt;POINT (-114.673 43.877)&gt;, &lt;POINT (-119.866 48.585)&gt;,\n       &lt;POINT (-107.87 33.008)&gt;, &lt;POINT (-105.851 38.293)&gt;,\n       &lt;POINT (-107.236 39.999)&gt;, &lt;POINT (-109.915 44.734)&gt;,\n       &lt;POINT (-108.195 37.892)&gt;, &lt;POINT (-119.654 38.332)&gt;,\n       &lt;POINT (-119.916 38.924)&gt;, &lt;POINT (-107.357 39.765)&gt;,\n       &lt;POINT (-110.693 40.549)&gt;, &lt;POINT (-110.577 44.369)&gt;,\n       &lt;POINT (-121.322 39.813)&gt;, &lt;POINT (-110.746 39.892)&gt;,\n       &lt;POINT (-111.406 34.457)&gt;, &lt;POINT (-114.269 44.842)&gt;,\n       &lt;POINT (-120.042 38.711)&gt;, &lt;POINT (-112.393 38.484)&gt;,\n       &lt;POINT (-117.851 46.119)&gt;, &lt;POINT (-114.628 39.558)&gt;,\n       &lt;POINT (-106.835 37.486)&gt;, &lt;POINT (-107.288 39.129)&gt;,\n       &lt;POINT (-109.272 38.482)&gt;, &lt;POINT (-120.68 39.622)&gt;,\n       &lt;POINT (-119.672 38.046)&gt;], dtype=object)</pre></li><li>WY(time)int641909 1955 1955 ... 2024 2024 2024<pre>array([1909, 1955, 1955, ..., 2024, 2024, 2024])</pre></li><li>DOWY(time)int64195 62 63 64 65 ... 166 167 168 169<pre>array([195,  62,  63, ..., 167, 168, 169])</pre></li></ul></li><li>Data variables: (6)<ul><li>TAVG(station, time)float64nan nan nan nan ... -1.1 0.0 nan<pre>array([[ nan,  nan,  nan, ...,  3. ,  4.2,  nan],\n       [ nan,  nan,  nan, ..., -1.1, -1.8,  nan],\n       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n       ...,\n       [ nan,  nan,  nan, ..., -0.1, -1.7,  nan],\n       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n       [ nan,  nan,  nan, ..., -1.1,  0. ,  nan]])</pre></li><li>TMIN(station, time)float64nan nan nan nan ... -3.9 -5.0 nan<pre>array([[ nan,  nan,  nan, ..., -3.9, -2.9,  nan],\n       [ nan,  nan,  nan, ..., -6.2, -7.6,  nan],\n       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n       ...,\n       [ nan,  nan,  nan, ..., -3.7, -4.9,  nan],\n       [ nan,  nan,  nan, ..., -2.2, -2.8,  nan],\n       [ nan,  nan,  nan, ..., -3.9, -5. ,  nan]])</pre></li><li>TMAX(station, time)float64nan nan nan nan ... 0.0 3.3 7.2 nan<pre>array([[ nan,  nan,  nan, ..., 13. , 15.2,  nan],\n       [ nan,  nan,  nan, ...,  6. ,  4.2,  nan],\n       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n       ...,\n       [ nan,  nan,  nan, ...,  3.2,  2.5,  nan],\n       [ nan,  nan,  nan, ...,  6.1, 10. ,  nan],\n       [ nan,  nan,  nan, ...,  3.3,  7.2,  nan]])</pre></li><li>SNWD(station, time)float64nan nan nan ... 2.311 2.286 2.235<pre>array([[   nan,    nan,    nan, ..., 1.27  , 1.2192, 1.1938],\n       [   nan,    nan,    nan, ..., 1.0668, 0.8128, 0.7366],\n       [   nan,    nan,    nan, ...,    nan,    nan,    nan],\n       ...,\n       [   nan,    nan,    nan, ..., 1.0414, 1.0922, 1.2954],\n       [   nan,    nan,    nan, ..., 3.2004, 3.1496, 3.0988],\n       [   nan,    nan,    nan, ..., 2.3114, 2.286 , 2.2352]])</pre></li><li>WTEQ(station, time)float64nan nan nan ... 0.8352 0.8354<pre>array([[   nan,    nan,    nan, ..., 0.4521, 0.4445, 0.4369],\n       [   nan,    nan,    nan, ..., 0.1676, 0.1702, 0.1702],\n       [   nan,    nan,    nan, ...,    nan,    nan,    nan],\n       ...,\n       [   nan,    nan,    nan, ..., 0.3073, 0.3124, 0.3378],\n       [   nan,    nan,    nan, ..., 1.2187, 1.2174, 1.2243],\n       [   nan,    nan,    nan, ..., 0.8331, 0.8352, 0.8354]])</pre></li><li>PRCPSA(station, time)float64nan nan nan nan ... nan nan nan nan<pre>array([[   nan,    nan,    nan, ..., 0.    , 0.    ,    nan],\n       [   nan,    nan,    nan, ..., 0.0025, 0.    ,    nan],\n       [   nan,    nan,    nan, ...,    nan,    nan,    nan],\n       ...,\n       [   nan,    nan,    nan, ..., 0.0076, 0.0254,    nan],\n       [   nan,    nan,    nan, ...,    nan,    nan,    nan],\n       [   nan,    nan,    nan, ...,    nan,    nan,    nan]])</pre></li></ul></li><li>Indexes: (1)<ul><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['1909-04-13', '1954-12-01', '1954-12-02', '1954-12-03',\n               '1954-12-04', '1954-12-05', '1954-12-06', '1954-12-07',\n               '1954-12-08', '1954-12-09',\n               ...\n               '2024-03-08', '2024-03-09', '2024-03-10', '2024-03-11',\n               '2024-03-12', '2024-03-13', '2024-03-14', '2024-03-15',\n               '2024-03-16', '2024-03-17'],\n              dtype='datetime64[ns]', name='time', length=23826, freq=None))</pre></li></ul></li><li>Attributes: (0)</li></ul> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/automatic_weather_station_examples/#automatic-weather-station-examples","title":"Automatic weather station examples\u00b6","text":"<p>Eric Gagliano (egagli@uw.edu) Updated: April 1st, 2024</p>"},{"location":"examples/automatic_weather_station_examples/#view-all-snotel-ccss-stations","title":"View all SNOTEL &amp; CCSS stations\u00b6","text":"<ul> <li>the SNOwpack TELemetry (SNOTEL) network includes over 800 automated weather stations in the Western U.S. for mountain snowpack observation</li> <li>the CCSS program manages a network of 130 automated snow sensors located in the Szierra Nevada and Shasta-Trinity Mountains</li> </ul>"},{"location":"examples/automatic_weather_station_examples/#get-an-up-to-date-geodataframe-of-all-active-snotel-and-ccss-stations","title":"Get an up to date GeoDataFrame of all active SNOTEL and CCSS stations\u00b6","text":""},{"location":"examples/automatic_weather_station_examples/#use-geopandas-geodataframeexplore-on-the-all_stations-geodataframe-to-interactively-view-the-stations","title":"Use geopandas <code>GeoDataFrame.explore()</code> on the <code>all_stations</code> geodataframe to interactively view the stations\u00b6","text":"<ul> <li>color by network: red is SNOTEL, blue is CCSS.</li> </ul>"},{"location":"examples/automatic_weather_station_examples/#get-data-for-a-singular-site-is-our-winter-on-track-with-the-historical-record-at-the-paradise-wa-snotel-station","title":"Get data for a singular site: Is our winter on track with the historical record at the Paradise, WA SNOTEL station?\u00b6","text":"<ul> <li>check out information about the SNOTEL station near Mt. Rainier at Paradise, WA</li> <li>cool plots available at the Northwest River Forecast Center website</li> </ul>"},{"location":"examples/automatic_weather_station_examples/#select-a-station-code-which-you-can-find-in-this-interactive-plot-or-by-other-means","title":"Select a station code (which you can find in this interactive plot, or by other means)\u00b6","text":"<ul> <li>for SNOTEL stations, this will be of the form {unique number}_{two letter state abbreviation}_SNTL (e.g. 679_WA_SNTL).</li> <li>for CCSS stations, this will be a three letter code (e.g. BLK).</li> </ul>"},{"location":"examples/automatic_weather_station_examples/#try-a-simple-plot-of-snow-depth-and-swe","title":"Try a simple plot of snow depth and SWE\u00b6","text":"<ul> <li>select the column of interest and use pandas built in <code>Series.plot()</code></li> </ul>"},{"location":"examples/automatic_weather_station_examples/#try-a-more-complex-plot-that-shows-current-snow-depth-against-statistics-calculated-from-the-entire-time-series-for-each-day-of-water-year","title":"Try a more complex plot that shows current snow depth against statistics calculated from the entire time series for each day of water year\u00b6","text":"<ul> <li>water year is conceptual 12 month period used to describe when the bulk of precipitation falls, mostly used for hydrology attribution<ul> <li>in the northern hemisphere, we usually define the water year to start October 1st and go until September 30th (e.g. water year 2017: October 1st, 2016 - September 30th, 2017)</li> <li>so October 1st is DOWY 1</li> </ul> </li> <li>try a function like <code>easysnowdata.utils.datetime_to_DOWY()</code> to convert datetimes to day of water year and add a dedicated DOWY column<ul> <li>this function should account for leap years</li> </ul> </li> <li>then use pandas groupby functionality to calculate stats per DOWY</li> <li>plot these stats<ul> <li>thanks David Shean for the plot inspiration!</li> </ul> </li> </ul>"},{"location":"examples/automatic_weather_station_examples/#read-a-variable-from-a-list-of-stations-does-the-snotel-network-and-ccss-network-list-the-same-station","title":"Read a variable from a list of stations: Does the SNOTEL network and CCSS network list the same station?\u00b6","text":"<ul> <li>no controversy here, but i noticed that a station name was repeated</li> <li>perhaps both networks have data from the same station accessible</li> <li>might make sense if they are co-managed in some way?</li> </ul>"},{"location":"examples/automatic_weather_station_examples/#create-a-list-of-the-stations-we-are-interested-in-and-pass-it-in-to-our-get_data-function","title":"Create a list of the stations we are interested in and pass it in to our get_data() function\u00b6","text":""},{"location":"examples/automatic_weather_station_examples/#plot-the-two-stations-on-the-same-axis","title":"Plot the two stations on the same axis\u00b6","text":"<ul> <li>if we properly set the index as the datetime, and we used <code>parse_dates=True</code>, these should line up!</li> </ul>"},{"location":"examples/automatic_weather_station_examples/#these-look-oddly-similar-lets-check-out-their-correlation","title":"These look oddly similar... let's check out their correlation\u00b6","text":"<ul> <li>convenient built in <code>DataFrame.corr()</code></li> </ul>"},{"location":"examples/automatic_weather_station_examples/#lets-see-where-they-exist-spatially","title":"Let's see where they exist spatially\u00b6","text":"<ul> <li>select the stations by index and reproject to UTM 11N</li> <li>use <code>contextily</code> for a basemap</li> </ul>"},{"location":"examples/automatic_weather_station_examples/#looks-like-some-of-the-ccss-stations-have-natural-resources-conservation-service-as-their-operator","title":"Look's like some of the CCSS stations have \"Natural Resources Conservation Service\" as their operator\u00b6","text":"<ul> <li>Let's check which stations these are!</li> <li>Let's plot these shared stations in red, and not shared in blue</li> </ul>"},{"location":"examples/automatic_weather_station_examples/#read-a-variable-using-a-geodataframe-how-extraordinary-was-the-california-2023-snowpack","title":"Read a variable using a geodataframe: How extraordinary was the California 2023 snowpack?\u00b6","text":"<ul> <li>the Sierra Nevada received a historic amount of snow in 2023</li> <li>let's explore the magnitude of this season by comparing to the median snow pack</li> </ul>"},{"location":"examples/automatic_weather_station_examples/#lets-bring-in-only-ccss-stations","title":"Let's bring in only CCSS stations\u00b6","text":"<ul> <li>Filter the <code>all_stations</code> geodataframe with <code>network == CCSS</code>, and pass the filtered geodatframe to the get_data() function.</li> </ul>"},{"location":"examples/automatic_weather_station_examples/#lets-check-out-the-percent-of-normal-snow-depth-for-april-1st-2023","title":"Let's check out the percent of normal snow depth for April 1st, 2023\u00b6","text":"<ul> <li>let's add a DOWY column to the <code>ccssStations.WTEQ</code> dataframe like before, groupby DOWY, apply a median, and divide the observation on April 1st, 2023 by the DOWY 183 (April 1) median<ul> <li>add these percent normal values back to <code>ccssStations.stations</code></li> </ul> </li> <li>will need to do some slight cleaning to get rid of NaNs, Infs, physically impossible values...</li> </ul>"},{"location":"examples/automatic_weather_station_examples/#view-the-values-in-order","title":"View the values in order...\u00b6","text":"<ul> <li>use <code>.sort_values()</code> function to get an idea of percent normal snow depth values</li> <li><code>DataFrame.head()</code> and <code>DataFrame.tail()</code> to see highest and lowest percent normal snow depth values</li> </ul>"},{"location":"examples/automatic_weather_station_examples/#plot-the-percent-of-normal-snow-depths-for-april-1st-2023","title":"Plot the percent of normal snow depths for April 1st, 2023\u00b6","text":"<ul> <li>add elevation plot to the right with horizontal dashed line at 100% (normal)</li> </ul>"},{"location":"examples/automatic_weather_station_examples/#read-a-variable-from-all-csvs-by-looping-over-the-entire-geodataframe-has-the-date-of-maximum-swe-changed-in-the-western-us","title":"Read a variable from all CSVs by looping over the entire geodataframe: Has the date of maximum SWE changed in the Western US?\u00b6","text":"<ul> <li>Snowmelt timing can be an important indicator of regional climate change, and the snowmelt timing of the Western U.S. is projected to shift earlier in the year by up to 1 month by 2050 (Barnett et al., 2005; Stewart, 2009), with a corresponding snowpack loss equivalent to a 25% decrease in streamflow from snowmelt (Siirila-Woodburn et al., 2021).</li> <li>Let's explore trends in maximum SWE timing using SNOTEL and CCSS stations</li> </ul>"},{"location":"examples/automatic_weather_station_examples/#this-time-we-will-get-swe-at-every-station","title":"This time we will get SWE at every station\u00b6","text":"<ul> <li>might take a minute to load in almost 1000 CSVs...</li> <li>store SWE for all stations in <code>all_stations_swe_df</code></li> </ul>"},{"location":"examples/automatic_weather_station_examples/#prepare-the-data","title":"Prepare the data\u00b6","text":"<ul> <li>prepare and clean <code>all_stations_swe_df</code>:<ul> <li>filter to start in WY 1967 (the first year with more than one station) and end with WY 2023</li> <li>add water year column</li> <li>remove any negative SWE measurements</li> <li>for consistency with similar analyses, following the methodology of Evan 2019 and US EPA 2021:<ul> <li>set any change of greater magnitude than 20cm to NaN</li> <li>if there are more than 30 days of missing data during November-April, don't use that water year</li> <li>if SWE is zero during every day of Jan/Feb/March, don't use that water year</li> <li>only use stations with continuous data from WY 1982<ul> <li>i do this only for the all data bulk calculation so we have a common reference frame, but for station level analysis i instead impose a 30 year or longer record rule</li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"examples/automatic_weather_station_examples/#calculate-and-plot-trend-in-dowy-of-max-swe-for-all-data","title":"Calculate and plot trend in DOWY of max SWE for all data\u00b6","text":"<ul> <li>use <code>DataFrame.groupby()</code> to find the date of max SWE per year and convert to a DOWY value, store in <code>all_stations_dowy_max_swe_df</code></li> <li>calculate slope and intercept of linear regression using <code>np.polyfit()</code> on a melted version of</li> <li>obtain statistics for each year using <code>DataFrame.describe()</code></li> </ul>"},{"location":"examples/automatic_weather_station_examples/#check-out-trend-at-each-station-seperately","title":"Check out trend at each station seperately\u00b6","text":"<ul> <li>calculate the linear trend in DOWY of max SWE only for stations with over 30 years of data, store in our original <code>all_stations_gdf</code><ul> <li>out of 971 stations with SWE data, 645 meet this criteria</li> </ul> </li> <li>plot the trend for each station and plot the trends on a histogram</li> </ul>"},{"location":"examples/automatic_weather_station_examples/#lets-analyze-these-trends-by-mountain-range","title":"Let's analyze these trends by mountain range\u00b6","text":"<ul> <li>we can <code>DataFrame.groupby()</code> our geodataframe by mountain range to calculate mountain range specific stats, store in <code>mountain_range_trend_df</code></li> <li>mountain ranges with more stations (and more spatial coverage) are probably more trustworthy</li> </ul>"},{"location":"examples/automatic_weather_station_examples/#lets-visualize-this-on-a-map","title":"Let's visualize this on a map\u00b6","text":"<ul> <li>add spatial information to <code>mountain_range_trend_df</code> using <code>DataFrame.join()</code> with mountain range geometries from GMBA Mountain Inventory v2</li> <li>ceate both a static plot with counts and medians and create an interactive plot so we can explore the trends across mountain ranges and stations</li> </ul>"},{"location":"examples/automatic_weather_station_examples/#what-if-we-want-to-check-out-all-available-daily-variables-at-all-snotel-and-ccss-stations-for-all-time","title":"What if we want to check out all available daily variables at all SNOTEL and CCSS stations for all time?\u00b6","text":"<ul> <li>Let's check the data out as an xarray object!</li> </ul>"},{"location":"examples/how_easy/","title":"How easy","text":"In\u00a0[1]: Copied! <pre>import easysnowdata\n</pre> import easysnowdata In\u00a0[2]: Copied! <pre>bbox = (-122.0, 46.7, -121.5, 47.0)\nsnow_classification_da = easysnowdata.remote_sensing.get_esa_worldcover(bbox)\n#snow_classification_da\n</pre> bbox = (-122.0, 46.7, -121.5, 47.0) snow_classification_da = easysnowdata.remote_sensing.get_esa_worldcover(bbox) #snow_classification_da In\u00a0[3]: Copied! <pre>f,ax = snow_classification_da.attrs['example_plot'](snow_classification_da)\n</pre> f,ax = snow_classification_da.attrs['example_plot'](snow_classification_da) In\u00a0[4]: Copied! <pre>s2 = easysnowdata.remote_sensing.Sentinel2(\n    bbox_input=bbox,\n    start_date=\"2022-07-21\",\n    end_date=\"2022-07-31\",\n    resolution=80,\n)\n#s2.data\n</pre> s2 = easysnowdata.remote_sensing.Sentinel2(     bbox_input=bbox,     start_date=\"2022-07-21\",     end_date=\"2022-07-31\",     resolution=80, ) #s2.data <pre>Data searched. Access the returned seach with the .search attribute.\nData retrieved. Access with the .data attribute. Data CRS: WGS 84 / UTM zone 10N.\nNodata values removed from the data. In doing so, all bands converted to float32. To turn this behavior off, set remove_nodata=False.\nData acquired after January 25th, 2022 harmonized to old baseline. To override this behavior, set harmonize_to_old=False.\nData scaled to float reflectance. To turn this behavior off, set scale_data=False.\nMetadata retrieved. Access with the .metadata attribute.\n</pre> In\u00a0[5]: Copied! <pre>s2.get_rgb()\n</pre> s2.get_rgb() <pre>RGB data retrieved.\nAccess with the following attributes:\n.rgb for raw RGB,\n.rgba for RGBA,\n.rgb_percentile for percentile RGB,\n.rgb_clahe for CLAHE RGB.\nYou can pass in percentile_kwargs and clahe_kwargs to adjust RGB calculations, check documentation for options.\n</pre> In\u00a0[6]: Copied! <pre>s2.rgb_clahe.plot.imshow(col='time',col_wrap=3)\n</pre> s2.rgb_clahe.plot.imshow(col='time',col_wrap=3) <pre>/home/eric/miniconda3/envs/easysnowdata/lib/python3.10/site-packages/rasterio/warp.py:344: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n  _reproject(\n</pre> Out[6]: <pre>&lt;xarray.plot.facetgrid.FacetGrid at 0x7f68575bdd50&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/how_easy/#how-easy-to-use-is-easysnowdata","title":"How easy to use is easysnowdata?\u00b6","text":""},{"location":"examples/hydroclimatology_examples/","title":"Hydroclimatology examples","text":"In\u00a0[1]: Copied! <pre># this block is for developing the module, comment out when using the module, and uncomment import easysnowdata\n%load_ext autoreload\n%autoreload 2\n%aimport easysnowdata\n</pre> # this block is for developing the module, comment out when using the module, and uncomment import easysnowdata %load_ext autoreload %autoreload 2 %aimport easysnowdata In\u00a0[2]: Copied! <pre>#import easysnowdata\nimport geopandas as gpd\nimport xarray as xr\nfrom easysnowdata.utils import convert_bbox_to_geodataframe\nimport json\nimport ee\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport contextily as ctx\nimport rioxarray as rxr\n</pre> #import easysnowdata import geopandas as gpd import xarray as xr from easysnowdata.utils import convert_bbox_to_geodataframe import json import ee import matplotlib.pyplot as plt import numpy as np import contextily as ctx import rioxarray as rxr  In\u00a0[3]: Copied! <pre>ee.Authenticate()  # need to figure out https://developers.google.com/earth-engine/guides/auth\nee.Initialize(opt_url=\"https://earthengine-highvolume.googleapis.com\")\n</pre> ee.Authenticate()  # need to figure out https://developers.google.com/earth-engine/guides/auth ee.Initialize(opt_url=\"https://earthengine-highvolume.googleapis.com\") In\u00a0[4]: Copied! <pre>bbox_gdf = gpd.read_file(\n    \"https://github.com/egagli/easysnowdata/raw/main/docs/examples/mt_rainier.geojson\"\n)\n</pre> bbox_gdf = gpd.read_file(     \"https://github.com/egagli/easysnowdata/raw/main/docs/examples/mt_rainier.geojson\" ) In\u00a0[5]: Copied! <pre>koppen_geiger_da = easysnowdata.hydroclimatology.get_koppen_geiger_classes(resolution=\"0.1 degree\")\n#koppen_geiger_da\n</pre> koppen_geiger_da = easysnowdata.hydroclimatology.get_koppen_geiger_classes(resolution=\"0.1 degree\") #koppen_geiger_da <pre>No spatial subsetting because bbox_input was not provided.\n</pre> In\u00a0[6]: Copied! <pre>f,ax = koppen_geiger_da.attrs['example_plot'](koppen_geiger_da)\n</pre> f,ax = koppen_geiger_da.attrs['example_plot'](koppen_geiger_da) In\u00a0[7]: Copied! <pre>koppen_geiger_da = easysnowdata.hydroclimatology.get_koppen_geiger_classes(bbox_input=bbox_gdf,resolution=\"1 km\")\n#koppen_geiger_da\n</pre> koppen_geiger_da = easysnowdata.hydroclimatology.get_koppen_geiger_classes(bbox_input=bbox_gdf,resolution=\"1 km\") #koppen_geiger_da In\u00a0[8]: Copied! <pre>f,ax = koppen_geiger_da.attrs['example_plot'](koppen_geiger_da)\n</pre> f,ax = koppen_geiger_da.attrs['example_plot'](koppen_geiger_da) <p>This might take a moment...</p> In\u00a0[9]: Copied! <pre>huc02_gdf = easysnowdata.hydroclimatology.get_huc_geometries(huc_level=\"02\")\n</pre> huc02_gdf = easysnowdata.hydroclimatology.get_huc_geometries(huc_level=\"02\") <pre>No spatial subsetting because bbox_input was not provided.\n</pre> In\u00a0[10]: Copied! <pre># huc02_gdf.explore()\n</pre> # huc02_gdf.explore() In\u00a0[11]: Copied! <pre>huc02_gdf = easysnowdata.hydroclimatology.get_huc_geometries(\n    bbox_input=bbox_gdf, huc_level=\"02\"\n)\nhuc04_gdf = easysnowdata.hydroclimatology.get_huc_geometries(\n    bbox_input=bbox_gdf, huc_level=\"04\"\n)\nhuc06_gdf = easysnowdata.hydroclimatology.get_huc_geometries(\n    bbox_input=bbox_gdf, huc_level=\"06\"\n)\nhuc08_gdf = easysnowdata.hydroclimatology.get_huc_geometries(\n    bbox_input=bbox_gdf, huc_level=\"08\"\n)\nhuc10_gdf = easysnowdata.hydroclimatology.get_huc_geometries(\n    bbox_input=bbox_gdf, huc_level=\"10\"\n)\nhuc12_gdf = easysnowdata.hydroclimatology.get_huc_geometries(\n    bbox_input=bbox_gdf, huc_level=\"12\"\n)\n</pre> huc02_gdf = easysnowdata.hydroclimatology.get_huc_geometries(     bbox_input=bbox_gdf, huc_level=\"02\" ) huc04_gdf = easysnowdata.hydroclimatology.get_huc_geometries(     bbox_input=bbox_gdf, huc_level=\"04\" ) huc06_gdf = easysnowdata.hydroclimatology.get_huc_geometries(     bbox_input=bbox_gdf, huc_level=\"06\" ) huc08_gdf = easysnowdata.hydroclimatology.get_huc_geometries(     bbox_input=bbox_gdf, huc_level=\"08\" ) huc10_gdf = easysnowdata.hydroclimatology.get_huc_geometries(     bbox_input=bbox_gdf, huc_level=\"10\" ) huc12_gdf = easysnowdata.hydroclimatology.get_huc_geometries(     bbox_input=bbox_gdf, huc_level=\"12\" ) In\u00a0[12]: Copied! <pre>f, axs = plt.subplots(1, 2, figsize=(15, 7))\n\nfor ax in axs:\n    huc02_gdf.plot(ax=ax, color=\"none\", edgecolor=\"red\", linewidth=2, label=\"HUC02\")\n    huc04_gdf.plot(ax=ax, color=\"none\", edgecolor=\"orange\", linewidth=2, label=\"HUC04\")\n    huc06_gdf.plot(ax=ax, color=\"none\", edgecolor=\"yellow\", linewidth=2, label=\"HUC06\")\n    huc08_gdf.plot(ax=ax, color=\"none\", edgecolor=\"green\", linewidth=2, label=\"HUC08\")\n    huc10_gdf.plot(ax=ax, color=\"none\", edgecolor=\"blue\", linewidth=2, label=\"HUC10\")\n    huc12_gdf.plot(ax=ax, color=\"none\", edgecolor=\"purple\", linewidth=2, label=\"HUC12\")\n    bbox_gdf.plot(ax=ax, color=\"none\", edgecolor=\"black\", linewidth=3, label=\"bbox\")\n\nctx.add_basemap(axs[0], crs=huc02_gdf.crs)\n\naxs[1].set_xlim(-122.5, -121.1)\naxs[1].set_ylim(46.4, 47.3)\nctx.add_basemap(axs[1], crs=huc02_gdf.crs)\n\n\n# Create a legend for the HUC levels\nfrom matplotlib.lines import Line2D\n\nlegend_elements = [\n    Line2D([0], [0], color=\"black\", lw=2, label=\"bbox\"),\n    Line2D([0], [0], color=\"red\", lw=2, label=\"HUC02\"),\n    Line2D([0], [0], color=\"orange\", lw=2, label=\"HUC04\"),\n    Line2D([0], [0], color=\"yellow\", lw=2, label=\"HUC06\"),\n    Line2D([0], [0], color=\"green\", lw=2, label=\"HUC08\"),\n    Line2D([0], [0], color=\"blue\", lw=2, label=\"HUC10\"),\n    Line2D([0], [0], color=\"purple\", lw=2, label=\"HUC12\"),\n]\nfor ax in axs:\n    ax.legend(handles=legend_elements)\n\nf.tight_layout()\nf.suptitle(\"HUC geometries\")\n</pre> f, axs = plt.subplots(1, 2, figsize=(15, 7))  for ax in axs:     huc02_gdf.plot(ax=ax, color=\"none\", edgecolor=\"red\", linewidth=2, label=\"HUC02\")     huc04_gdf.plot(ax=ax, color=\"none\", edgecolor=\"orange\", linewidth=2, label=\"HUC04\")     huc06_gdf.plot(ax=ax, color=\"none\", edgecolor=\"yellow\", linewidth=2, label=\"HUC06\")     huc08_gdf.plot(ax=ax, color=\"none\", edgecolor=\"green\", linewidth=2, label=\"HUC08\")     huc10_gdf.plot(ax=ax, color=\"none\", edgecolor=\"blue\", linewidth=2, label=\"HUC10\")     huc12_gdf.plot(ax=ax, color=\"none\", edgecolor=\"purple\", linewidth=2, label=\"HUC12\")     bbox_gdf.plot(ax=ax, color=\"none\", edgecolor=\"black\", linewidth=3, label=\"bbox\")  ctx.add_basemap(axs[0], crs=huc02_gdf.crs)  axs[1].set_xlim(-122.5, -121.1) axs[1].set_ylim(46.4, 47.3) ctx.add_basemap(axs[1], crs=huc02_gdf.crs)   # Create a legend for the HUC levels from matplotlib.lines import Line2D  legend_elements = [     Line2D([0], [0], color=\"black\", lw=2, label=\"bbox\"),     Line2D([0], [0], color=\"red\", lw=2, label=\"HUC02\"),     Line2D([0], [0], color=\"orange\", lw=2, label=\"HUC04\"),     Line2D([0], [0], color=\"yellow\", lw=2, label=\"HUC06\"),     Line2D([0], [0], color=\"green\", lw=2, label=\"HUC08\"),     Line2D([0], [0], color=\"blue\", lw=2, label=\"HUC10\"),     Line2D([0], [0], color=\"purple\", lw=2, label=\"HUC12\"), ] for ax in axs:     ax.legend(handles=legend_elements)  f.tight_layout() f.suptitle(\"HUC geometries\") Out[12]: <pre>Text(0.5, 0.98, 'HUC geometries')</pre> In\u00a0[13]: Copied! <pre>global_hydroBASINS_level4_gdf = easysnowdata.hydroclimatology.get_hydroBASINS(regions='all',level=4)\n</pre> global_hydroBASINS_level4_gdf = easysnowdata.hydroclimatology.get_hydroBASINS(regions='all',level=4) <pre>Getting geometries for Africa...\nAfrica takes a bit longer because we have to temporarily save the file due to read issue...\nGetting geometries for Arctic...\nGetting geometries for Asia...\nGetting geometries for Australia...\nGetting geometries for Europe...\nGetting geometries for Greenland...\nGetting geometries for North America...\nGetting geometries for South America...\nGetting geometries for Siberia...\n</pre> In\u00a0[14]: Copied! <pre>f,ax=plt.subplots(figsize=(12,7))\nglobal_hydroBASINS_level4_gdf.plot(ax=ax,column='HYBAS_ID')\nax.set_title('Global HydroBASINS Level 4')\n</pre> f,ax=plt.subplots(figsize=(12,7)) global_hydroBASINS_level4_gdf.plot(ax=ax,column='HYBAS_ID') ax.set_title('Global HydroBASINS Level 4') Out[14]: <pre>Text(0.5, 1.0, 'Global HydroBASINS Level 4')</pre> In\u00a0[15]: Copied! <pre>grdc_basins_gdf = easysnowdata.hydroclimatology.get_grdc_major_river_basins_of_the_world()\n</pre> grdc_basins_gdf = easysnowdata.hydroclimatology.get_grdc_major_river_basins_of_the_world() <pre>No spatial subsetting because bbox_input was not provided.\n</pre> In\u00a0[16]: Copied! <pre>f, ax = plt.subplots(figsize=(12, 7))\ngrdc_basins_gdf.to_crs(epsg=3857).plot(ax=ax, column='NAME',cmap='tab20')\nctx.add_basemap(ax, source=ctx.providers.CartoDB.DarkMatter)\nax.set_title(\"GRDC Major River Basins of the World\")\n</pre> f, ax = plt.subplots(figsize=(12, 7)) grdc_basins_gdf.to_crs(epsg=3857).plot(ax=ax, column='NAME',cmap='tab20') ctx.add_basemap(ax, source=ctx.providers.CartoDB.DarkMatter) ax.set_title(\"GRDC Major River Basins of the World\") Out[16]: <pre>Text(0.5, 1.0, 'GRDC Major River Basins of the World')</pre> In\u00a0[17]: Copied! <pre>era5_global_ds = easysnowdata.hydroclimatology.get_era5(version=\"ERA5\",cadence=\"HOURLY\")\nera5_global_ds\n</pre> era5_global_ds = easysnowdata.hydroclimatology.get_era5(version=\"ERA5\",cadence=\"HOURLY\") era5_global_ds Out[17]: <pre>&lt;xarray.Dataset&gt; Size: 2PB\nDimensions:                                                          (\n                                                                      time: 744384,\n                                                                      latitude: 721,\n                                                                      longitude: 1440,\n                                                                      level: 37)\nCoordinates:\n  * latitude                                                         (latitude) float32 3kB ...\n  * level                                                            (level) int64 296B ...\n  * time                                                             (time) datetime64[ns] 6MB ...\n    spatial_ref                                                      int64 8B 0\n  * longitude                                                        (longitude) float32 6kB ...\nData variables: (12/273)\n    100m_u_component_of_wind                                         (time, latitude, longitude) float32 3TB ...\n    100m_v_component_of_wind                                         (time, latitude, longitude) float32 3TB ...\n    10m_u_component_of_neutral_wind                                  (time, latitude, longitude) float32 3TB ...\n    10m_u_component_of_wind                                          (time, latitude, longitude) float32 3TB ...\n    10m_v_component_of_neutral_wind                                  (time, latitude, longitude) float32 3TB ...\n    10m_v_component_of_wind                                          (time, latitude, longitude) float32 3TB ...\n    ...                                                               ...\n    wave_spectral_directional_width_for_swell                        (time, latitude, longitude) float32 3TB ...\n    wave_spectral_directional_width_for_wind_waves                   (time, latitude, longitude) float32 3TB ...\n    wave_spectral_kurtosis                                           (time, latitude, longitude) float32 3TB ...\n    wave_spectral_peakedness                                         (time, latitude, longitude) float32 3TB ...\n    wave_spectral_skewness                                           (time, latitude, longitude) float32 3TB ...\n    zero_degree_level                                                (time, latitude, longitude) float32 3TB ...\nAttributes:\n    valid_time_start:  1940-01-01\n    last_updated:      2025-02-23 12:13:20.255008+00:00\n    valid_time_stop:   2024-11-30\n    data_citation:     Carver, Robert W, and Merose, Alex. (2023): ARCO-ERA5:...\n    source:            Google Cloud Storage (ARCO-ERA5)\n    version:           ERA5\n    cadence:           HOURLY</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>time: 744384</li><li>latitude: 721</li><li>longitude: 1440</li><li>level: 37</li></ul></li><li>Coordinates: (5)<ul><li>latitude(latitude)float3290.0 89.75 89.5 ... -89.75 -90.0long_name :latitudeunits :degrees_north<pre>array([ 90.  ,  89.75,  89.5 , ..., -89.5 , -89.75, -90.  ], dtype=float32)</pre></li><li>level(level)int641 2 3 5 7 ... 900 925 950 975 1000long_name :levelunits :Hectopascal(hPa)<pre>array([   1,    2,    3,    5,    7,   10,   20,   30,   50,   70,  100,  125,\n        150,  175,  200,  225,  250,  300,  350,  400,  450,  500,  550,  600,\n        650,  700,  750,  775,  800,  825,  850,  875,  900,  925,  950,  975,\n       1000])</pre></li><li>time(time)datetime64[ns]1940-01-01 ... 2024-11-30T23:00:00<pre>array(['1940-01-01T00:00:00.000000000', '1940-01-01T01:00:00.000000000',\n       '1940-01-01T02:00:00.000000000', ..., '2024-11-30T21:00:00.000000000',\n       '2024-11-30T22:00:00.000000000', '2024-11-30T23:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li><li>spatial_ref()int640crs_wkt :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984grid_mapping_name :latitude_longitudespatial_ref :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]<pre>array(0)</pre></li><li>longitude(longitude)float32-180.0 -179.8 ... 179.5 179.8long_name :longitudeunits :degrees_east<pre>array([-180.  , -179.75, -179.5 , ...,  179.25,  179.5 ,  179.75],\n      dtype=float32)</pre></li></ul></li><li>Data variables: (273)<ul><li>100m_u_component_of_wind(time, latitude, longitude)float32...long_name :100 metre U wind componentshort_name :u100units :m s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>100m_v_component_of_wind(time, latitude, longitude)float32...long_name :100 metre V wind componentshort_name :v100units :m s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>10m_u_component_of_neutral_wind(time, latitude, longitude)float32...long_name :Neutral wind at 10 m u-componentshort_name :u10nunits :m s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>10m_u_component_of_wind(time, latitude, longitude)float32...long_name :10 metre U wind componentshort_name :u10units :m s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>10m_v_component_of_neutral_wind(time, latitude, longitude)float32...long_name :Neutral wind at 10 m v-componentshort_name :v10nunits :m s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>10m_v_component_of_wind(time, latitude, longitude)float32...long_name :10 metre V wind componentshort_name :v10units :m s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>10m_wind_gust_since_previous_post_processing(time, latitude, longitude)float32...long_name :10 metre wind gust since previous post-processingshort_name :fg10units :m s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>2m_dewpoint_temperature(time, latitude, longitude)float32...long_name :2 metre dewpoint temperatureshort_name :d2munits :K<pre>[772849244160 values with dtype=float32]</pre></li><li>2m_temperature(time, latitude, longitude)float32...long_name :2 metre temperatureshort_name :t2munits :K<pre>[772849244160 values with dtype=float32]</pre></li><li>air_density_over_the_oceans(time, latitude, longitude)float32...long_name :Air density over the oceansshort_name :p140209units :kg m**-3<pre>[772849244160 values with dtype=float32]</pre></li><li>angle_of_sub_gridscale_orography(time, latitude, longitude)float32...long_name :Angle of sub-gridscale orographyshort_name :anorunits :radians<pre>[772849244160 values with dtype=float32]</pre></li><li>anisotropy_of_sub_gridscale_orography(time, latitude, longitude)float32...long_name :Anisotropy of sub-gridscale orographyshort_name :isorunits :~<pre>[772849244160 values with dtype=float32]</pre></li><li>benjamin_feir_index(time, latitude, longitude)float32...long_name :Benjamin-Feir indexshort_name :bfiunits :dimensionless<pre>[772849244160 values with dtype=float32]</pre></li><li>boundary_layer_dissipation(time, latitude, longitude)float32...long_name :Boundary layer dissipationshort_name :bldstandard_name :kinetic_energy_dissipation_in_atmosphere_boundary_layerunits :J m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>boundary_layer_height(time, latitude, longitude)float32...long_name :Boundary layer heightshort_name :blhunits :m<pre>[772849244160 values with dtype=float32]</pre></li><li>charnock(time, latitude, longitude)float32...long_name :Charnockshort_name :chnkunits :~<pre>[772849244160 values with dtype=float32]</pre></li><li>clear_sky_direct_solar_radiation_at_surface(time, latitude, longitude)float32...long_name :Clear-sky direct solar radiation at surfaceshort_name :cdirunits :J m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>cloud_base_height(time, latitude, longitude)float32...long_name :Cloud base heightshort_name :cbhunits :m<pre>[772849244160 values with dtype=float32]</pre></li><li>coefficient_of_drag_with_waves(time, latitude, longitude)float32...long_name :Coefficient of drag with wavesshort_name :cdwwunits :dimensionless<pre>[772849244160 values with dtype=float32]</pre></li><li>convective_available_potential_energy(time, latitude, longitude)float32...long_name :Convective available potential energyshort_name :capeunits :J kg**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>convective_inhibition(time, latitude, longitude)float32...long_name :Convective inhibitionshort_name :cinunits :J kg**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>convective_precipitation(time, latitude, longitude)float32...long_name :Convective precipitationshort_name :cpstandard_name :lwe_thickness_of_convective_precipitation_amountunits :m<pre>[772849244160 values with dtype=float32]</pre></li><li>convective_rain_rate(time, latitude, longitude)float32...long_name :Convective rain rateshort_name :crrunits :kg m**-2 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>convective_snowfall(time, latitude, longitude)float32...long_name :Convective snowfallshort_name :csfunits :m of water equivalent<pre>[772849244160 values with dtype=float32]</pre></li><li>convective_snowfall_rate_water_equivalent(time, latitude, longitude)float32...long_name :Convective snowfall rate water equivalentshort_name :csfrunits :kg m**-2 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>downward_uv_radiation_at_the_surface(time, latitude, longitude)float32...long_name :Downward UV radiation at the surfaceshort_name :uvbunits :J m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>duct_base_height(time, latitude, longitude)float32...long_name :Duct base heightshort_name :dctbunits :m<pre>[772849244160 values with dtype=float32]</pre></li><li>eastward_gravity_wave_surface_stress(time, latitude, longitude)float32...long_name :Eastward gravity wave surface stressshort_name :lgwsunits :N m**-2 s<pre>[772849244160 values with dtype=float32]</pre></li><li>eastward_turbulent_surface_stress(time, latitude, longitude)float32...long_name :Eastward turbulent surface stressshort_name :ewssstandard_name :surface_downward_eastward_stressunits :N m**-2 s<pre>[772849244160 values with dtype=float32]</pre></li><li>evaporation(time, latitude, longitude)float32...long_name :Evaporationshort_name :estandard_name :lwe_thickness_of_water_evaporation_amountunits :m of water equivalent<pre>[772849244160 values with dtype=float32]</pre></li><li>forecast_albedo(time, latitude, longitude)float32...long_name :Forecast albedoshort_name :falunits :(0 - 1)<pre>[772849244160 values with dtype=float32]</pre></li><li>forecast_logarithm_of_surface_roughness_for_heat(time, latitude, longitude)float32...long_name :Forecast logarithm of surface roughness for heatshort_name :flsrunits :~<pre>[772849244160 values with dtype=float32]</pre></li><li>forecast_surface_roughness(time, latitude, longitude)float32...long_name :Forecast surface roughnessshort_name :fsrunits :m<pre>[772849244160 values with dtype=float32]</pre></li><li>fraction_of_cloud_cover(time, level, latitude, longitude)float32...long_name :Fraction of cloud covershort_name :ccunits :(0 - 1)<pre>[28595422033920 values with dtype=float32]</pre></li><li>free_convective_velocity_over_the_oceans(time, latitude, longitude)float32...long_name :Free convective velocity over the oceansshort_name :p140208units :m s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>friction_velocity(time, latitude, longitude)float32...long_name :Friction velocityshort_name :zustunits :m s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>geopotential(time, level, latitude, longitude)float32...long_name :Geopotentialshort_name :zstandard_name :geopotentialunits :m**2 s**-2<pre>[28595422033920 values with dtype=float32]</pre></li><li>geopotential_at_surface(time, latitude, longitude)float32...long_name :Geopotentialshort_name :zstandard_name :geopotentialunits :m**2 s**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>gravity_wave_dissipation(time, latitude, longitude)float32...long_name :Gravity wave dissipationshort_name :gwdunits :J m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>high_cloud_cover(time, latitude, longitude)float32...long_name :High cloud covershort_name :hccunits :(0 - 1)<pre>[772849244160 values with dtype=float32]</pre></li><li>high_vegetation_cover(time, latitude, longitude)float32...long_name :High vegetation covershort_name :cvhunits :(0 - 1)<pre>[772849244160 values with dtype=float32]</pre></li><li>ice_temperature_layer_1(time, latitude, longitude)float32...long_name :Ice temperature layer 1short_name :istl1units :K<pre>[772849244160 values with dtype=float32]</pre></li><li>ice_temperature_layer_2(time, latitude, longitude)float32...long_name :Ice temperature layer 2short_name :istl2units :K<pre>[772849244160 values with dtype=float32]</pre></li><li>ice_temperature_layer_3(time, latitude, longitude)float32...long_name :Ice temperature layer 3short_name :istl3units :K<pre>[772849244160 values with dtype=float32]</pre></li><li>ice_temperature_layer_4(time, latitude, longitude)float32...long_name :Ice temperature layer 4short_name :istl4units :K<pre>[772849244160 values with dtype=float32]</pre></li><li>instantaneous_10m_wind_gust(time, latitude, longitude)float32...long_name :Instantaneous 10 metre wind gustshort_name :i10fgunits :m s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>instantaneous_eastward_turbulent_surface_stress(time, latitude, longitude)float32...long_name :Instantaneous eastward turbulent surface stressshort_name :iewsunits :N m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>instantaneous_large_scale_surface_precipitation_fraction(time, latitude, longitude)float32...long_name :Instantaneous large-scale surface precipitation fractionshort_name :ilspfunits :(0 - 1)<pre>[772849244160 values with dtype=float32]</pre></li><li>instantaneous_moisture_flux(time, latitude, longitude)float32...long_name :Instantaneous moisture fluxshort_name :ieunits :kg m**-2 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>instantaneous_northward_turbulent_surface_stress(time, latitude, longitude)float32...long_name :Instantaneous northward turbulent surface stressshort_name :inssunits :N m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>instantaneous_surface_sensible_heat_flux(time, latitude, longitude)float32...long_name :Instantaneous surface sensible heat fluxshort_name :ishfunits :W m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>k_index(time, latitude, longitude)float32...long_name :K indexshort_name :kxunits :K<pre>[772849244160 values with dtype=float32]</pre></li><li>lake_bottom_temperature(time, latitude, longitude)float32...long_name :Lake bottom temperatureshort_name :lbltunits :K<pre>[772849244160 values with dtype=float32]</pre></li><li>lake_cover(time, latitude, longitude)float32...long_name :Lake covershort_name :clunits :(0 - 1)<pre>[772849244160 values with dtype=float32]</pre></li><li>lake_depth(time, latitude, longitude)float32...long_name :Lake total depthshort_name :dlunits :m<pre>[772849244160 values with dtype=float32]</pre></li><li>lake_ice_depth(time, latitude, longitude)float32...long_name :Lake ice total depthshort_name :licdunits :m<pre>[772849244160 values with dtype=float32]</pre></li><li>lake_ice_temperature(time, latitude, longitude)float32...long_name :Lake ice surface temperatureshort_name :lictunits :K<pre>[772849244160 values with dtype=float32]</pre></li><li>lake_mix_layer_depth(time, latitude, longitude)float32...long_name :Lake mix-layer depthshort_name :lmldunits :m<pre>[772849244160 values with dtype=float32]</pre></li><li>lake_mix_layer_temperature(time, latitude, longitude)float32...long_name :Lake mix-layer temperatureshort_name :lmltunits :K<pre>[772849244160 values with dtype=float32]</pre></li><li>lake_shape_factor(time, latitude, longitude)float32...long_name :Lake shape factorshort_name :lshfunits :dimensionless<pre>[772849244160 values with dtype=float32]</pre></li><li>lake_total_layer_temperature(time, latitude, longitude)float32...long_name :Lake total layer temperatureshort_name :ltltunits :K<pre>[772849244160 values with dtype=float32]</pre></li><li>land_sea_mask(time, latitude, longitude)float32...long_name :Land-sea maskshort_name :lsmstandard_name :land_binary_maskunits :(0 - 1)<pre>[772849244160 values with dtype=float32]</pre></li><li>large_scale_precipitation(time, latitude, longitude)float32...long_name :Large-scale precipitationshort_name :lspstandard_name :lwe_thickness_of_stratiform_precipitation_amountunits :m<pre>[772849244160 values with dtype=float32]</pre></li><li>large_scale_precipitation_fraction(time, latitude, longitude)float32...long_name :Large-scale precipitation fractionshort_name :lspfunits :s<pre>[772849244160 values with dtype=float32]</pre></li><li>large_scale_rain_rate(time, latitude, longitude)float32...long_name :Large scale rain rateshort_name :lsrrunits :kg m**-2 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>large_scale_snowfall(time, latitude, longitude)float32...long_name :Large-scale snowfallshort_name :lsfunits :m of water equivalent<pre>[772849244160 values with dtype=float32]</pre></li><li>large_scale_snowfall_rate_water_equivalent(time, latitude, longitude)float32...long_name :Large scale snowfall rate water equivalentshort_name :lssfrunits :kg m**-2 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>leaf_area_index_high_vegetation(time, latitude, longitude)float32...long_name :Leaf area index, high vegetationshort_name :lai_hvunits :m**2 m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>leaf_area_index_low_vegetation(time, latitude, longitude)float32...long_name :Leaf area index, low vegetationshort_name :lai_lvunits :m**2 m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>low_cloud_cover(time, latitude, longitude)float32...long_name :Low cloud covershort_name :lccunits :(0 - 1)<pre>[772849244160 values with dtype=float32]</pre></li><li>low_vegetation_cover(time, latitude, longitude)float32...long_name :Low vegetation covershort_name :cvlunits :(0 - 1)<pre>[772849244160 values with dtype=float32]</pre></li><li>maximum_2m_temperature_since_previous_post_processing(time, latitude, longitude)float32...long_name :Maximum temperature at 2 metres since previous post-processingshort_name :mx2tunits :K<pre>[772849244160 values with dtype=float32]</pre></li><li>maximum_individual_wave_height(time, latitude, longitude)float32...long_name :Maximum individual wave heightshort_name :hmaxunits :m<pre>[772849244160 values with dtype=float32]</pre></li><li>maximum_total_precipitation_rate_since_previous_post_processing(time, latitude, longitude)float32...long_name :Maximum total precipitation rate since previous post-processingshort_name :mxtprunits :kg m**-2 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_boundary_layer_dissipation(time, latitude, longitude)float32...long_name :Mean boundary layer dissipationshort_name :mbldunits :W m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_convective_precipitation_rate(time, latitude, longitude)float32...long_name :Mean convective precipitation rateshort_name :mcprunits :kg m**-2 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_convective_snowfall_rate(time, latitude, longitude)float32...long_name :Mean convective snowfall rateshort_name :mcsrunits :kg m**-2 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_direction_of_total_swell(time, latitude, longitude)float32...long_name :Mean direction of total swellshort_name :mdtsunits :degrees<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_direction_of_wind_waves(time, latitude, longitude)float32...long_name :Mean direction of wind wavesshort_name :mdwwunits :degrees<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_eastward_gravity_wave_surface_stress(time, latitude, longitude)float32...long_name :Mean eastward gravity wave surface stressshort_name :megwssunits :N m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_eastward_turbulent_surface_stress(time, latitude, longitude)float32...long_name :Mean eastward turbulent surface stressshort_name :metssunits :N m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_evaporation_rate(time, latitude, longitude)float32...long_name :Mean evaporation rateshort_name :merunits :kg m**-2 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_gravity_wave_dissipation(time, latitude, longitude)float32...long_name :Mean gravity wave dissipationshort_name :mgwdunits :W m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_large_scale_precipitation_fraction(time, latitude, longitude)float32...long_name :Mean large-scale precipitation fractionshort_name :mlspfunits :Proportion<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_large_scale_precipitation_rate(time, latitude, longitude)float32...long_name :Mean large-scale precipitation rateshort_name :mlsprunits :kg m**-2 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_large_scale_snowfall_rate(time, latitude, longitude)float32...long_name :Mean large-scale snowfall rateshort_name :mlssrunits :kg m**-2 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_northward_gravity_wave_surface_stress(time, latitude, longitude)float32...long_name :Mean northward gravity wave surface stressshort_name :mngwssunits :N m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_northward_turbulent_surface_stress(time, latitude, longitude)float32...long_name :Mean northward turbulent surface stressshort_name :mntssunits :N m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_period_of_total_swell(time, latitude, longitude)float32...long_name :Mean period of total swellshort_name :mptsunits :s<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_period_of_wind_waves(time, latitude, longitude)float32...long_name :Mean period of wind wavesshort_name :mpwwunits :s<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_potential_evaporation_rate(time, latitude, longitude)float32...long_name :Mean potential evaporation rateshort_name :mperunits :kg m**-2 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_runoff_rate(time, latitude, longitude)float32...long_name :Mean runoff rateshort_name :mrorunits :kg m**-2 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_sea_level_pressure(time, latitude, longitude)float32...long_name :Mean sea level pressureshort_name :mslstandard_name :air_pressure_at_mean_sea_levelunits :Pa<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_snow_evaporation_rate(time, latitude, longitude)float32...long_name :Mean snow evaporation rateshort_name :mserunits :kg m**-2 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_snowfall_rate(time, latitude, longitude)float32...long_name :Mean snowfall rateshort_name :msrunits :kg m**-2 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_snowmelt_rate(time, latitude, longitude)float32...long_name :Mean snowmelt rateshort_name :msmrunits :kg m**-2 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_square_slope_of_waves(time, latitude, longitude)float32...long_name :Mean square slope of wavesshort_name :msqsunits :dimensionless<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_sub_surface_runoff_rate(time, latitude, longitude)float32...long_name :Mean sub-surface runoff rateshort_name :mssrorunits :kg m**-2 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_surface_direct_short_wave_radiation_flux(time, latitude, longitude)float32...long_name :Mean surface direct short-wave radiation fluxshort_name :msdrswrfunits :W m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_surface_direct_short_wave_radiation_flux_clear_sky(time, latitude, longitude)float32...long_name :Mean surface direct short-wave radiation flux, clear skyshort_name :msdrswrfcsunits :W m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_surface_downward_long_wave_radiation_flux(time, latitude, longitude)float32...long_name :Mean surface downward long-wave radiation fluxshort_name :msdwlwrfunits :W m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_surface_downward_long_wave_radiation_flux_clear_sky(time, latitude, longitude)float32...long_name :Mean surface downward long-wave radiation flux, clear skyshort_name :msdwlwrfcsunits :W m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_surface_downward_short_wave_radiation_flux(time, latitude, longitude)float32...long_name :Mean surface downward short-wave radiation fluxshort_name :msdwswrfunits :W m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_surface_downward_short_wave_radiation_flux_clear_sky(time, latitude, longitude)float32...long_name :Mean surface downward short-wave radiation flux, clear skyshort_name :msdwswrfcsunits :W m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_surface_downward_uv_radiation_flux(time, latitude, longitude)float32...long_name :Mean surface downward UV radiation fluxshort_name :msdwuvrfunits :W m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_surface_latent_heat_flux(time, latitude, longitude)float32...long_name :Mean surface latent heat fluxshort_name :mslhfunits :W m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_surface_net_long_wave_radiation_flux(time, latitude, longitude)float32...long_name :Mean surface net long-wave radiation fluxshort_name :msnlwrfunits :W m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_surface_net_long_wave_radiation_flux_clear_sky(time, latitude, longitude)float32...long_name :Mean surface net long-wave radiation flux, clear skyshort_name :msnlwrfcsunits :W m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_surface_net_short_wave_radiation_flux(time, latitude, longitude)float32...long_name :Mean surface net short-wave radiation fluxshort_name :msnswrfunits :W m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_surface_net_short_wave_radiation_flux_clear_sky(time, latitude, longitude)float32...long_name :Mean surface net short-wave radiation flux, clear skyshort_name :msnswrfcsunits :W m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_surface_runoff_rate(time, latitude, longitude)float32...long_name :Mean surface runoff rateshort_name :msrorunits :kg m**-2 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_surface_sensible_heat_flux(time, latitude, longitude)float32...long_name :Mean surface sensible heat fluxshort_name :msshfunits :W m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_top_downward_short_wave_radiation_flux(time, latitude, longitude)float32...long_name :Mean top downward short-wave radiation fluxshort_name :mtdwswrfunits :W m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_top_net_long_wave_radiation_flux(time, latitude, longitude)float32...long_name :Mean top net long-wave radiation fluxshort_name :mtnlwrfunits :W m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_top_net_long_wave_radiation_flux_clear_sky(time, latitude, longitude)float32...long_name :Mean top net long-wave radiation flux, clear skyshort_name :mtnlwrfcsunits :W m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_top_net_short_wave_radiation_flux(time, latitude, longitude)float32...long_name :Mean top net short-wave radiation fluxshort_name :mtnswrfunits :W m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_top_net_short_wave_radiation_flux_clear_sky(time, latitude, longitude)float32...long_name :Mean top net short-wave radiation flux, clear skyshort_name :mtnswrfcsunits :W m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_total_precipitation_rate(time, latitude, longitude)float32...long_name :Mean total precipitation rateshort_name :mtprunits :kg m**-2 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_vertical_gradient_of_refractivity_inside_trapping_layer(time, latitude, longitude)float32...long_name :Mean vertical gradient of refractivity inside trapping layershort_name :dndzaunits :m**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_vertically_integrated_moisture_divergence(time, latitude, longitude)float32...long_name :Mean vertically integrated moisture divergenceshort_name :mvimdunits :kg m**-2 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_wave_direction(time, latitude, longitude)float32...long_name :Mean wave directionshort_name :mwdunits :Degree true<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_wave_direction_of_first_swell_partition(time, latitude, longitude)float32...long_name :Mean wave direction of first swell partitionshort_name :p140122units :degrees<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_wave_direction_of_second_swell_partition(time, latitude, longitude)float32...long_name :Mean wave direction of second swell partitionshort_name :p140125units :degrees<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_wave_direction_of_third_swell_partition(time, latitude, longitude)float32...long_name :Mean wave direction of third swell partitionshort_name :p140128units :degrees<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_wave_period(time, latitude, longitude)float32...long_name :Mean wave periodshort_name :mwpunits :s<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_wave_period_based_on_first_moment(time, latitude, longitude)float32...long_name :Mean wave period based on first momentshort_name :mp1units :s<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_wave_period_based_on_first_moment_for_swell(time, latitude, longitude)float32...long_name :Mean wave period based on first moment for swellshort_name :p1psunits :s<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_wave_period_based_on_first_moment_for_wind_waves(time, latitude, longitude)float32...long_name :Mean wave period based on first moment for wind wavesshort_name :p1wwunits :s<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_wave_period_based_on_second_moment_for_swell(time, latitude, longitude)float32...long_name :Mean wave period based on second moment for swellshort_name :p2psunits :s<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_wave_period_based_on_second_moment_for_wind_waves(time, latitude, longitude)float32...long_name :Mean wave period based on second moment for wind wavesshort_name :p2wwunits :s<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_wave_period_of_first_swell_partition(time, latitude, longitude)float32...long_name :Mean wave period of first swell partitionshort_name :p140123units :s<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_wave_period_of_second_swell_partition(time, latitude, longitude)float32...long_name :Mean wave period of second swell partitionshort_name :p140126units :s<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_wave_period_of_third_swell_partition(time, latitude, longitude)float32...long_name :Mean wave period of third swell partitionshort_name :p140129units :s<pre>[772849244160 values with dtype=float32]</pre></li><li>mean_zero_crossing_wave_period(time, latitude, longitude)float32...long_name :Mean zero-crossing wave periodshort_name :mp2units :s<pre>[772849244160 values with dtype=float32]</pre></li><li>medium_cloud_cover(time, latitude, longitude)float32...long_name :Medium cloud covershort_name :mccunits :(0 - 1)<pre>[772849244160 values with dtype=float32]</pre></li><li>minimum_2m_temperature_since_previous_post_processing(time, latitude, longitude)float32...long_name :Minimum temperature at 2 metres since previous post-processingshort_name :mn2tunits :K<pre>[772849244160 values with dtype=float32]</pre></li><li>minimum_total_precipitation_rate_since_previous_post_processing(time, latitude, longitude)float32...long_name :Minimum total precipitation rate since previous post-processingshort_name :mntprunits :kg m**-2 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>minimum_vertical_gradient_of_refractivity_inside_trapping_layer(time, latitude, longitude)float32...long_name :Minimum vertical gradient of refractivity inside trapping layershort_name :dndznunits :m**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>model_bathymetry(time, latitude, longitude)float32...long_name :Model bathymetryshort_name :wmbunits :m<pre>[772849244160 values with dtype=float32]</pre></li><li>near_ir_albedo_for_diffuse_radiation(time, latitude, longitude)float32...long_name :Near IR albedo for diffuse radiationshort_name :alnidunits :(0 - 1)<pre>[772849244160 values with dtype=float32]</pre></li><li>near_ir_albedo_for_direct_radiation(time, latitude, longitude)float32...long_name :Near IR albedo for direct radiationshort_name :alnipunits :(0 - 1)<pre>[772849244160 values with dtype=float32]</pre></li><li>normalized_energy_flux_into_ocean(time, latitude, longitude)float32...long_name :Normalized energy flux into oceanshort_name :phiocunits :dimensionless<pre>[772849244160 values with dtype=float32]</pre></li><li>normalized_energy_flux_into_waves(time, latitude, longitude)float32...long_name :Normalized energy flux into wavesshort_name :phiawunits :dimensionless<pre>[772849244160 values with dtype=float32]</pre></li><li>normalized_stress_into_ocean(time, latitude, longitude)float32...long_name :Normalized stress into oceanshort_name :tauocunits :dimensionless<pre>[772849244160 values with dtype=float32]</pre></li><li>northward_gravity_wave_surface_stress(time, latitude, longitude)float32...long_name :Northward gravity wave surface stressshort_name :mgwsunits :N m**-2 s<pre>[772849244160 values with dtype=float32]</pre></li><li>northward_turbulent_surface_stress(time, latitude, longitude)float32...long_name :Northward turbulent surface stressshort_name :nsssstandard_name :surface_downward_northward_stressunits :N m**-2 s<pre>[772849244160 values with dtype=float32]</pre></li><li>ocean_surface_stress_equivalent_10m_neutral_wind_direction(time, latitude, longitude)float32...long_name :10 metre wind directionshort_name :dwiunits :degrees<pre>[772849244160 values with dtype=float32]</pre></li><li>ocean_surface_stress_equivalent_10m_neutral_wind_speed(time, latitude, longitude)float32...long_name :10 metre wind speedshort_name :windunits :m s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>ozone_mass_mixing_ratio(time, level, latitude, longitude)float32...long_name :Ozone mass mixing ratioshort_name :o3standard_name :mass_fraction_of_ozone_in_airunits :kg kg**-1<pre>[28595422033920 values with dtype=float32]</pre></li><li>peak_wave_period(time, latitude, longitude)float32...long_name :Peak wave periodshort_name :pp1dunits :s<pre>[772849244160 values with dtype=float32]</pre></li><li>period_corresponding_to_maximum_individual_wave_height(time, latitude, longitude)float32...long_name :Period corresponding to maximum individual wave heightshort_name :tmaxunits :s<pre>[772849244160 values with dtype=float32]</pre></li><li>potential_evaporation(time, latitude, longitude)float32...long_name :Potential evaporationshort_name :pevunits :m<pre>[772849244160 values with dtype=float32]</pre></li><li>potential_vorticity(time, level, latitude, longitude)float32...long_name :Potential vorticityshort_name :pvunits :K m**2 kg**-1 s**-1<pre>[28595422033920 values with dtype=float32]</pre></li><li>precipitation_type(time, latitude, longitude)float32...long_name :Precipitation typeshort_name :ptypeunits :code table (4.201)<pre>[772849244160 values with dtype=float32]</pre></li><li>runoff(time, latitude, longitude)float32...long_name :Runoffshort_name :rounits :m<pre>[772849244160 values with dtype=float32]</pre></li><li>sea_ice_cover(time, latitude, longitude)float32...long_name :Sea ice area fractionshort_name :siconcstandard_name :sea_ice_area_fractionunits :(0 - 1)<pre>[772849244160 values with dtype=float32]</pre></li><li>sea_surface_temperature(time, latitude, longitude)float32...long_name :Sea surface temperatureshort_name :sstunits :K<pre>[772849244160 values with dtype=float32]</pre></li><li>significant_height_of_combined_wind_waves_and_swell(time, latitude, longitude)float32...long_name :Significant height of combined wind waves and swellshort_name :swhunits :m<pre>[772849244160 values with dtype=float32]</pre></li><li>significant_height_of_total_swell(time, latitude, longitude)float32...long_name :Significant height of total swellshort_name :shtsunits :m<pre>[772849244160 values with dtype=float32]</pre></li><li>significant_height_of_wind_waves(time, latitude, longitude)float32...long_name :Significant height of wind wavesshort_name :shwwunits :m<pre>[772849244160 values with dtype=float32]</pre></li><li>significant_wave_height_of_first_swell_partition(time, latitude, longitude)float32...long_name :Significant wave height of first swell partitionshort_name :p140121units :m<pre>[772849244160 values with dtype=float32]</pre></li><li>significant_wave_height_of_second_swell_partition(time, latitude, longitude)float32...long_name :Significant wave height of second swell partitionshort_name :p140124units :m<pre>[772849244160 values with dtype=float32]</pre></li><li>significant_wave_height_of_third_swell_partition(time, latitude, longitude)float32...long_name :Significant wave height of third swell partitionshort_name :p140127units :m<pre>[772849244160 values with dtype=float32]</pre></li><li>skin_reservoir_content(time, latitude, longitude)float32...long_name :Skin reservoir contentshort_name :srcunits :m of water equivalent<pre>[772849244160 values with dtype=float32]</pre></li><li>skin_temperature(time, latitude, longitude)float32...long_name :Skin temperatureshort_name :sktunits :K<pre>[772849244160 values with dtype=float32]</pre></li><li>slope_of_sub_gridscale_orography(time, latitude, longitude)float32...long_name :Slope of sub-gridscale orographyshort_name :slorunits :~<pre>[772849244160 values with dtype=float32]</pre></li><li>snow_albedo(time, latitude, longitude)float32...long_name :Snow albedoshort_name :asnunits :(0 - 1)<pre>[772849244160 values with dtype=float32]</pre></li><li>snow_density(time, latitude, longitude)float32...long_name :Snow densityshort_name :rsnunits :kg m**-3<pre>[772849244160 values with dtype=float32]</pre></li><li>snow_depth(time, latitude, longitude)float32...long_name :Snow depthshort_name :sdstandard_name :lwe_thickness_of_surface_snow_amountunits :m of water equivalent<pre>[772849244160 values with dtype=float32]</pre></li><li>snow_evaporation(time, latitude, longitude)float32...long_name :Snow evaporationshort_name :esunits :m of water equivalent<pre>[772849244160 values with dtype=float32]</pre></li><li>snowfall(time, latitude, longitude)float32...long_name :Snowfallshort_name :sfstandard_name :lwe_thickness_of_snowfall_amountunits :m of water equivalent<pre>[772849244160 values with dtype=float32]</pre></li><li>snowmelt(time, latitude, longitude)float32...long_name :Snowmeltshort_name :smltunits :m of water equivalent<pre>[772849244160 values with dtype=float32]</pre></li><li>soil_temperature_level_1(time, latitude, longitude)float32...long_name :Soil temperature level 1short_name :stl1standard_name :surface_temperatureunits :K<pre>[772849244160 values with dtype=float32]</pre></li><li>soil_temperature_level_2(time, latitude, longitude)float32...long_name :Soil temperature level 2short_name :stl2units :K<pre>[772849244160 values with dtype=float32]</pre></li><li>soil_temperature_level_3(time, latitude, longitude)float32...long_name :Soil temperature level 3short_name :stl3units :K<pre>[772849244160 values with dtype=float32]</pre></li><li>soil_temperature_level_4(time, latitude, longitude)float32...long_name :Soil temperature level 4short_name :stl4units :K<pre>[772849244160 values with dtype=float32]</pre></li><li>soil_type(time, latitude, longitude)float32...long_name :Soil typeshort_name :sltunits :~<pre>[772849244160 values with dtype=float32]</pre></li><li>specific_cloud_ice_water_content(time, level, latitude, longitude)float32...long_name :Specific cloud ice water contentshort_name :ciwcunits :kg kg**-1<pre>[28595422033920 values with dtype=float32]</pre></li><li>specific_cloud_liquid_water_content(time, level, latitude, longitude)float32...long_name :Specific cloud liquid water contentshort_name :clwcunits :kg kg**-1<pre>[28595422033920 values with dtype=float32]</pre></li><li>specific_humidity(time, level, latitude, longitude)float32...long_name :Specific humidityshort_name :qstandard_name :specific_humidityunits :kg kg**-1<pre>[28595422033920 values with dtype=float32]</pre></li><li>standard_deviation_of_filtered_subgrid_orography(time, latitude, longitude)float32...long_name :Standard deviation of filtered subgrid orographyshort_name :sdforunits :m<pre>[772849244160 values with dtype=float32]</pre></li><li>standard_deviation_of_orography(time, latitude, longitude)float32...long_name :Standard deviation of orographyshort_name :sdorunits :m<pre>[772849244160 values with dtype=float32]</pre></li><li>sub_surface_runoff(time, latitude, longitude)float32...long_name :Sub-surface runoffshort_name :ssrounits :m<pre>[772849244160 values with dtype=float32]</pre></li><li>surface_latent_heat_flux(time, latitude, longitude)float32...long_name :Surface latent heat fluxshort_name :slhfstandard_name :surface_upward_latent_heat_fluxunits :J m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>surface_net_solar_radiation(time, latitude, longitude)float32...long_name :Surface net solar radiationshort_name :ssrstandard_name :surface_net_downward_shortwave_fluxunits :J m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>surface_net_solar_radiation_clear_sky(time, latitude, longitude)float32...long_name :Surface net solar radiation, clear skyshort_name :ssrcstandard_name :surface_net_downward_shortwave_flux_assuming_clear_skyunits :J m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>surface_net_thermal_radiation(time, latitude, longitude)float32...long_name :Surface net thermal radiationshort_name :strstandard_name :surface_net_upward_longwave_fluxunits :J m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>surface_net_thermal_radiation_clear_sky(time, latitude, longitude)float32...long_name :Surface net thermal radiation, clear skyshort_name :strcstandard_name :surface_net_downward_longwave_flux_assuming_clear_skyunits :J m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>surface_pressure(time, latitude, longitude)float32...long_name :Surface pressureshort_name :spstandard_name :surface_air_pressureunits :Pa<pre>[772849244160 values with dtype=float32]</pre></li><li>surface_runoff(time, latitude, longitude)float32...long_name :Surface runoffshort_name :srounits :m<pre>[772849244160 values with dtype=float32]</pre></li><li>surface_sensible_heat_flux(time, latitude, longitude)float32...long_name :Surface sensible heat fluxshort_name :sshfstandard_name :surface_upward_sensible_heat_fluxunits :J m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>surface_solar_radiation_downward_clear_sky(time, latitude, longitude)float32...long_name :Surface solar radiation downward clear-skyshort_name :ssrdcunits :J m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>surface_solar_radiation_downwards(time, latitude, longitude)float32...long_name :Surface solar radiation downwardsshort_name :ssrdstandard_name :surface_downwelling_shortwave_flux_in_airunits :J m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>surface_thermal_radiation_downward_clear_sky(time, latitude, longitude)float32...long_name :Surface thermal radiation downward clear-skyshort_name :strdcunits :J m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>surface_thermal_radiation_downwards(time, latitude, longitude)float32...long_name :Surface thermal radiation downwardsshort_name :strdunits :J m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>temperature(time, level, latitude, longitude)float32...long_name :Temperatureshort_name :tstandard_name :air_temperatureunits :K<pre>[28595422033920 values with dtype=float32]</pre></li><li>temperature_of_snow_layer(time, latitude, longitude)float32...long_name :Temperature of snow layershort_name :tsnstandard_name :temperature_in_surface_snowunits :K<pre>[772849244160 values with dtype=float32]</pre></li><li>toa_incident_solar_radiation(time, latitude, longitude)float32...long_name :TOA incident solar radiationshort_name :tisrunits :J m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>top_net_solar_radiation(time, latitude, longitude)float32...long_name :Top net solar radiationshort_name :tsrstandard_name :toa_net_upward_shortwave_fluxunits :J m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>top_net_solar_radiation_clear_sky(time, latitude, longitude)float32...long_name :Top net solar radiation, clear skyshort_name :tsrcunits :J m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>top_net_thermal_radiation(time, latitude, longitude)float32...long_name :Top net thermal radiationshort_name :ttrstandard_name :toa_outgoing_longwave_fluxunits :J m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>top_net_thermal_radiation_clear_sky(time, latitude, longitude)float32...long_name :Top net thermal radiation, clear skyshort_name :ttrcunits :J m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>total_cloud_cover(time, latitude, longitude)float32...long_name :Total cloud covershort_name :tccstandard_name :cloud_area_fractionunits :(0 - 1)<pre>[772849244160 values with dtype=float32]</pre></li><li>total_column_cloud_ice_water(time, latitude, longitude)float32...long_name :Total column cloud ice watershort_name :tciwunits :kg m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>total_column_cloud_liquid_water(time, latitude, longitude)float32...long_name :Total column cloud liquid watershort_name :tclwunits :kg m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>total_column_ozone(time, latitude, longitude)float32...long_name :Total column ozoneshort_name :tco3standard_name :atmosphere_mass_content_of_ozoneunits :kg m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>total_column_rain_water(time, latitude, longitude)float32...long_name :Total column rain watershort_name :tcrwunits :kg m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>total_column_snow_water(time, latitude, longitude)float32...long_name :Total column snow watershort_name :tcswunits :kg m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>total_column_supercooled_liquid_water(time, latitude, longitude)float32...long_name :Total column supercooled liquid watershort_name :tcslwunits :kg m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>total_column_water(time, latitude, longitude)float32...long_name :Total column watershort_name :tcwunits :kg m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>total_column_water_vapour(time, latitude, longitude)float32...long_name :Total column vertically-integrated water vapourshort_name :tcwvstandard_name :lwe_thickness_of_atmosphere_mass_content_of_water_vaporunits :kg m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>total_precipitation(time, latitude, longitude)float32...long_name :Total precipitationshort_name :tpunits :m<pre>[772849244160 values with dtype=float32]</pre></li><li>total_sky_direct_solar_radiation_at_surface(time, latitude, longitude)float32...long_name :Total sky direct solar radiation at surfaceshort_name :fdirunits :J m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>total_totals_index(time, latitude, longitude)float32...long_name :Total totals indexshort_name :totalxunits :K<pre>[772849244160 values with dtype=float32]</pre></li><li>trapping_layer_base_height(time, latitude, longitude)float32...long_name :Trapping layer base heightshort_name :tplbunits :m<pre>[772849244160 values with dtype=float32]</pre></li><li>trapping_layer_top_height(time, latitude, longitude)float32...long_name :Trapping layer top heightshort_name :tpltunits :m<pre>[772849244160 values with dtype=float32]</pre></li><li>type_of_high_vegetation(time, latitude, longitude)float32...long_name :Type of high vegetationshort_name :tvhunits :~<pre>[772849244160 values with dtype=float32]</pre></li><li>type_of_low_vegetation(time, latitude, longitude)float32...long_name :Type of low vegetationshort_name :tvlunits :~<pre>[772849244160 values with dtype=float32]</pre></li><li>u_component_of_wind(time, level, latitude, longitude)float32...long_name :U component of windshort_name :ustandard_name :eastward_windunits :m s**-1<pre>[28595422033920 values with dtype=float32]</pre></li><li>u_component_stokes_drift(time, latitude, longitude)float32...long_name :U-component stokes driftshort_name :ustunits :m s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>uv_visible_albedo_for_diffuse_radiation(time, latitude, longitude)float32...long_name :UV visible albedo for diffuse radiationshort_name :aluvdunits :(0 - 1)<pre>[772849244160 values with dtype=float32]</pre></li><li>uv_visible_albedo_for_direct_radiation(time, latitude, longitude)float32...long_name :UV visible albedo for direct radiationshort_name :aluvpunits :(0 - 1)<pre>[772849244160 values with dtype=float32]</pre></li><li>v_component_of_wind(time, level, latitude, longitude)float32...long_name :V component of windshort_name :vstandard_name :northward_windunits :m s**-1<pre>[28595422033920 values with dtype=float32]</pre></li><li>v_component_stokes_drift(time, latitude, longitude)float32...long_name :V-component stokes driftshort_name :vstunits :m s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_divergence_of_cloud_frozen_water_flux(time, latitude, longitude)float32...long_name :Vertical integral of divergence of cloud frozen water fluxshort_name :p80.162units :kg m**-2 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_divergence_of_cloud_liquid_water_flux(time, latitude, longitude)float32...long_name :Vertical integral of divergence of cloud liquid water fluxshort_name :p79.162units :kg m**-2 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_divergence_of_geopotential_flux(time, latitude, longitude)float32...long_name :Vertical integral of divergence of geopotential fluxshort_name :p85.162units :W m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_divergence_of_kinetic_energy_flux(time, latitude, longitude)float32...long_name :Vertical integral of divergence of kinetic energy fluxshort_name :p82.162units :W m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_divergence_of_mass_flux(time, latitude, longitude)float32...long_name :Vertical integral of divergence of mass fluxshort_name :p81.162units :kg m**-2 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_divergence_of_moisture_flux(time, latitude, longitude)float32...long_name :Vertical integral of divergence of moisture fluxshort_name :p84.162units :kg m**-2 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_divergence_of_ozone_flux(time, latitude, longitude)float32...long_name :Vertical integral of divergence of ozone fluxshort_name :p87.162units :kg m**-2 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_divergence_of_thermal_energy_flux(time, latitude, longitude)float32...long_name :Vertical integral of divergence of thermal energy fluxshort_name :p83.162units :W m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_divergence_of_total_energy_flux(time, latitude, longitude)float32...long_name :Vertical integral of divergence of total energy fluxshort_name :p86.162units :W m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_eastward_cloud_frozen_water_flux(time, latitude, longitude)float32...long_name :Vertical integral of eastward cloud frozen water fluxshort_name :p90.162units :kg m**-1 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_eastward_cloud_liquid_water_flux(time, latitude, longitude)float32...long_name :Vertical integral of eastward cloud liquid water fluxshort_name :p88.162units :kg m**-1 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_eastward_geopotential_flux(time, latitude, longitude)float32...long_name :Vertical integral of eastward geopotential fluxshort_name :p73.162units :W m**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_eastward_heat_flux(time, latitude, longitude)float32...long_name :Vertical integral of eastward heat fluxshort_name :p69.162units :W m**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_eastward_kinetic_energy_flux(time, latitude, longitude)float32...long_name :Vertical integral of eastward kinetic energy fluxshort_name :p67.162units :W m**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_eastward_mass_flux(time, latitude, longitude)float32...long_name :Vertical integral of eastward mass fluxshort_name :p65.162units :kg m**-1 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_eastward_ozone_flux(time, latitude, longitude)float32...long_name :Vertical integral of eastward ozone fluxshort_name :p77.162units :kg m**-1 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_eastward_total_energy_flux(time, latitude, longitude)float32...long_name :Vertical integral of eastward total energy fluxshort_name :p75.162units :W m**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_eastward_water_vapour_flux(time, latitude, longitude)float32...long_name :Vertical integral of eastward water vapour fluxshort_name :p71.162units :kg m**-1 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_energy_conversion(time, latitude, longitude)float32...long_name :Vertical integral of energy conversionshort_name :p64.162units :W m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_kinetic_energy(time, latitude, longitude)float32...long_name :Vertical integral of kinetic energyshort_name :p59.162units :J m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_mass_of_atmosphere(time, latitude, longitude)float32...long_name :Vertical integral of mass of atmosphereshort_name :p53.162units :kg m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_mass_tendency(time, latitude, longitude)float32...long_name :Vertical integral of mass tendencyshort_name :p92.162units :kg m**-2 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_northward_cloud_frozen_water_flux(time, latitude, longitude)float32...long_name :Vertical integral of northward cloud frozen water flux short_name :p91.162units :kg m**-1 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_northward_cloud_liquid_water_flux(time, latitude, longitude)float32...long_name :Vertical integral of northward cloud liquid water fluxshort_name :p89.162units :kg m**-1 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_northward_geopotential_flux(time, latitude, longitude)float32...long_name :Vertical integral of northward geopotential fluxshort_name :p74.162units :W m**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_northward_heat_flux(time, latitude, longitude)float32...long_name :Vertical integral of northward heat fluxshort_name :p70.162units :W m**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_northward_kinetic_energy_flux(time, latitude, longitude)float32...long_name :Vertical integral of northward kinetic energy fluxshort_name :p68.162units :W m**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_northward_mass_flux(time, latitude, longitude)float32...long_name :Vertical integral of northward mass fluxshort_name :p66.162units :kg m**-1 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_northward_ozone_flux(time, latitude, longitude)float32...long_name :Vertical integral of northward ozone fluxshort_name :p78.162units :kg m**-1 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_northward_total_energy_flux(time, latitude, longitude)float32...long_name :Vertical integral of northward total energy fluxshort_name :p76.162units :W m**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_northward_water_vapour_flux(time, latitude, longitude)float32...long_name :Vertical integral of northward water vapour fluxshort_name :p72.162units :kg m**-1 s**-1<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_potential_and_internal_energy(time, latitude, longitude)float32...long_name :Vertical integral of potential+internal energyshort_name :p61.162units :J m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_potential_internal_and_latent_energy(time, latitude, longitude)float32...long_name :Vertical integral of potential+internal+latent energyshort_name :p62.162units :J m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_temperature(time, latitude, longitude)float32...long_name :Vertical integral of temperatureshort_name :p54.162units :K kg m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_thermal_energy(time, latitude, longitude)float32...long_name :Vertical integral of thermal energyshort_name :p60.162units :J m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_integral_of_total_energy(time, latitude, longitude)float32...long_name :Vertical integral of total energyshort_name :p63.162units :J m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>vertical_velocity(time, level, latitude, longitude)float32...long_name :Vertical velocityshort_name :wstandard_name :lagrangian_tendency_of_air_pressureunits :Pa s**-1<pre>[28595422033920 values with dtype=float32]</pre></li><li>vertically_integrated_moisture_divergence(time, latitude, longitude)float32...long_name :Vertically integrated moisture divergenceshort_name :vimdunits :kg m**-2<pre>[772849244160 values with dtype=float32]</pre></li><li>volumetric_soil_water_layer_1(time, latitude, longitude)float32...long_name :Volumetric soil water layer 1short_name :swvl1units :m**3 m**-3<pre>[772849244160 values with dtype=float32]</pre></li><li>volumetric_soil_water_layer_2(time, latitude, longitude)float32...long_name :Volumetric soil water layer 2short_name :swvl2units :m**3 m**-3<pre>[772849244160 values with dtype=float32]</pre></li><li>volumetric_soil_water_layer_3(time, latitude, longitude)float32...long_name :Volumetric soil water layer 3short_name :swvl3units :m**3 m**-3<pre>[772849244160 values with dtype=float32]</pre></li><li>volumetric_soil_water_layer_4(time, latitude, longitude)float32...long_name :Volumetric soil water layer 4short_name :swvl4units :m**3 m**-3<pre>[772849244160 values with dtype=float32]</pre></li><li>wave_spectral_directional_width(time, latitude, longitude)float32...long_name :Wave spectral directional widthshort_name :wdwunits :radians<pre>[772849244160 values with dtype=float32]</pre></li><li>wave_spectral_directional_width_for_swell(time, latitude, longitude)float32...long_name :Wave spectral directional width for swellshort_name :dwpsunits :radians<pre>[772849244160 values with dtype=float32]</pre></li><li>wave_spectral_directional_width_for_wind_waves(time, latitude, longitude)float32...long_name :Wave spectral directional width for wind wavesshort_name :dwwwunits :radians<pre>[772849244160 values with dtype=float32]</pre></li><li>wave_spectral_kurtosis(time, latitude, longitude)float32...long_name :Wave spectral kurtosisshort_name :wskunits :dimensionless<pre>[772849244160 values with dtype=float32]</pre></li><li>wave_spectral_peakedness(time, latitude, longitude)float32...long_name :Wave spectral peakednessshort_name :wspunits :dimensionless<pre>[772849244160 values with dtype=float32]</pre></li><li>wave_spectral_skewness(time, latitude, longitude)float32...long_name :Wave Spectral Skewnessshort_name :wssunits :dimensionless<pre>[772849244160 values with dtype=float32]</pre></li><li>zero_degree_level(time, latitude, longitude)float32...long_name :0 degrees C isothermal level (atm)short_name :deg0lunits :m<pre>[772849244160 values with dtype=float32]</pre></li></ul></li><li>Indexes: (4)<ul><li>latitudePandasIndex<pre>PandasIndex(Index([  90.0,  89.75,   89.5,  89.25,   89.0,  88.75,   88.5,  88.25,   88.0,\n        87.75,\n       ...\n       -87.75,  -88.0, -88.25,  -88.5, -88.75,  -89.0, -89.25,  -89.5, -89.75,\n        -90.0],\n      dtype='float32', name='latitude', length=721))</pre></li><li>levelPandasIndex<pre>PandasIndex(Index([   1,    2,    3,    5,    7,   10,   20,   30,   50,   70,  100,  125,\n        150,  175,  200,  225,  250,  300,  350,  400,  450,  500,  550,  600,\n        650,  700,  750,  775,  800,  825,  850,  875,  900,  925,  950,  975,\n       1000],\n      dtype='int64', name='level'))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['1940-01-01 00:00:00', '1940-01-01 01:00:00',\n               '1940-01-01 02:00:00', '1940-01-01 03:00:00',\n               '1940-01-01 04:00:00', '1940-01-01 05:00:00',\n               '1940-01-01 06:00:00', '1940-01-01 07:00:00',\n               '1940-01-01 08:00:00', '1940-01-01 09:00:00',\n               ...\n               '2024-11-30 14:00:00', '2024-11-30 15:00:00',\n               '2024-11-30 16:00:00', '2024-11-30 17:00:00',\n               '2024-11-30 18:00:00', '2024-11-30 19:00:00',\n               '2024-11-30 20:00:00', '2024-11-30 21:00:00',\n               '2024-11-30 22:00:00', '2024-11-30 23:00:00'],\n              dtype='datetime64[ns]', name='time', length=744384, freq=None))</pre></li><li>longitudePandasIndex<pre>PandasIndex(Index([ -180.0, -179.75,  -179.5, -179.25,  -179.0, -178.75,  -178.5, -178.25,\n        -178.0, -177.75,\n       ...\n         177.5,  177.75,   178.0,  178.25,   178.5,  178.75,   179.0,  179.25,\n         179.5,  179.75],\n      dtype='float32', name='longitude', length=1440))</pre></li></ul></li><li>Attributes: (7)valid_time_start :1940-01-01last_updated :2025-02-23 12:13:20.255008+00:00valid_time_stop :2024-11-30data_citation :Carver, Robert W, and Merose, Alex. (2023): ARCO-ERA5: An Analysis-Ready Cloud-Optimized Reanalysis Dataset. 22nd Conf. on AI for Env. Science, Denver, CO, Amer. Meteo. Soc, 4A.1, https://ams.confex.com/ams/103ANNUAL/meetingapp.cgi/Paper/415842source :Google Cloud Storage (ARCO-ERA5)version :ERA5cadence :HOURLY</li></ul> In\u00a0[18]: Copied! <pre>f, ax = plt.subplots()\nera5_global_ds[\"2m_temperature\"].sel(time=\"2020-05-26\").mean(dim=\"time\").plot.imshow(ax=ax)\nf.suptitle(\"ERA5 2m Temperature on 2020-05-26\")\n</pre> f, ax = plt.subplots() era5_global_ds[\"2m_temperature\"].sel(time=\"2020-05-26\").mean(dim=\"time\").plot.imshow(ax=ax) f.suptitle(\"ERA5 2m Temperature on 2020-05-26\") Out[18]: <pre>Text(0.5, 0.98, 'ERA5 2m Temperature on 2020-05-26')</pre> In\u00a0[19]: Copied! <pre>era5_land_ds = easysnowdata.hydroclimatology.get_era5(bbox_input=bbox_gdf,\n                                                         version=\"ERA5_LAND\",\n                                                        cadence=\"DAILY\",\n                                                        start_date=\"2020-10-01\",\n                                                        end_date=\"2021-09-30\")\nera5_land_ds\n</pre> era5_land_ds = easysnowdata.hydroclimatology.get_era5(bbox_input=bbox_gdf,                                                          version=\"ERA5_LAND\",                                                         cadence=\"DAILY\",                                                         start_date=\"2020-10-01\",                                                         end_date=\"2021-09-30\") era5_land_ds Out[19]: <pre>&lt;xarray.Dataset&gt; Size: 3MB\nDimensions:                                                    (time: 365,\n                                                                longitude: 4,\n                                                                latitude: 3)\nCoordinates:\n  * time                                                       (time) datetime64[ns] 3kB ...\n  * longitude                                                  (longitude) float64 32B ...\n  * latitude                                                   (latitude) float64 24B ...\nData variables: (12/150)\n    dewpoint_temperature_2m                                    (time, latitude, longitude) float32 18kB ...\n    temperature_2m                                             (time, latitude, longitude) float32 18kB ...\n    skin_temperature                                           (time, latitude, longitude) float32 18kB ...\n    soil_temperature_level_1                                   (time, latitude, longitude) float32 18kB ...\n    soil_temperature_level_2                                   (time, latitude, longitude) float32 18kB ...\n    soil_temperature_level_3                                   (time, latitude, longitude) float32 18kB ...\n    ...                                                         ...\n    total_precipitation_min                                    (time, latitude, longitude) float32 18kB ...\n    total_precipitation_max                                    (time, latitude, longitude) float32 18kB ...\n    leaf_area_index_high_vegetation_min                        (time, latitude, longitude) float32 18kB ...\n    leaf_area_index_high_vegetation_max                        (time, latitude, longitude) float32 18kB ...\n    leaf_area_index_low_vegetation_min                         (time, latitude, longitude) float32 18kB ...\n    leaf_area_index_low_vegetation_max                         (time, latitude, longitude) float32 18kB ...\nAttributes:\n    crs:            EPSG:4326\n    data_citation:  Hersbach, H., Bell, B., Berrisford, P., et al. (2020). Th...\n    version:        ERA5_LAND\n    cadence:        DAILY\n    source:         Google Earth Engine</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>time: 365</li><li>longitude: 4</li><li>latitude: 3</li></ul></li><li>Coordinates: (3)<ul><li>time(time)datetime64[ns]2020-10-01 ... 2021-09-30<pre>array(['2020-10-01T00:00:00.000000000', '2020-10-02T00:00:00.000000000',\n       '2020-10-03T00:00:00.000000000', ..., '2021-09-28T00:00:00.000000000',\n       '2021-09-29T00:00:00.000000000', '2021-09-30T00:00:00.000000000'],\n      dtype='datetime64[ns]')</pre></li><li>longitude(longitude)float64-121.9 -121.8 -121.7 -121.6<pre>array([-121.89225, -121.79225, -121.69225, -121.59225])</pre></li><li>latitude(latitude)float6446.95 46.85 46.75<pre>array([46.947282, 46.847282, 46.747282])</pre></li></ul></li><li>Data variables: (150)<ul><li>dewpoint_temperature_2m(time, latitude, longitude)float32...id :dewpoint_temperature_2mdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>temperature_2m(time, latitude, longitude)float32...id :temperature_2mdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>skin_temperature(time, latitude, longitude)float32...id :skin_temperaturedata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>soil_temperature_level_1(time, latitude, longitude)float32...id :soil_temperature_level_1data_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>soil_temperature_level_2(time, latitude, longitude)float32...id :soil_temperature_level_2data_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>soil_temperature_level_3(time, latitude, longitude)float32...id :soil_temperature_level_3data_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>soil_temperature_level_4(time, latitude, longitude)float32...id :soil_temperature_level_4data_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>lake_bottom_temperature(time, latitude, longitude)float32...id :lake_bottom_temperaturedata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>lake_ice_depth(time, latitude, longitude)float32...id :lake_ice_depthdata_type :{'type': 'PixelType', 'precision': 'float'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>lake_ice_temperature(time, latitude, longitude)float32...id :lake_ice_temperaturedata_type :{'type': 'PixelType', 'precision': 'float'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>lake_mix_layer_depth(time, latitude, longitude)float32...id :lake_mix_layer_depthdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>lake_mix_layer_temperature(time, latitude, longitude)float32...id :lake_mix_layer_temperaturedata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>lake_shape_factor(time, latitude, longitude)float32...id :lake_shape_factordata_type :{'type': 'PixelType', 'precision': 'float'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>lake_total_layer_temperature(time, latitude, longitude)float32...id :lake_total_layer_temperaturedata_type :{'type': 'PixelType', 'precision': 'float'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>snow_albedo(time, latitude, longitude)float32...id :snow_albedodata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>snow_cover(time, latitude, longitude)float32...id :snow_coverdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>snow_density(time, latitude, longitude)float32...id :snow_densitydata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>snow_depth(time, latitude, longitude)float32...id :snow_depthdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>snow_depth_water_equivalent(time, latitude, longitude)float32...id :snow_depth_water_equivalentdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>snowfall_sum(time, latitude, longitude)float32...id :snowfall_sumdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>snowmelt_sum(time, latitude, longitude)float32...id :snowmelt_sumdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>temperature_of_snow_layer(time, latitude, longitude)float32...id :temperature_of_snow_layerdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>skin_reservoir_content(time, latitude, longitude)float32...id :skin_reservoir_contentdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>volumetric_soil_water_layer_1(time, latitude, longitude)float32...id :volumetric_soil_water_layer_1data_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>volumetric_soil_water_layer_2(time, latitude, longitude)float32...id :volumetric_soil_water_layer_2data_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>volumetric_soil_water_layer_3(time, latitude, longitude)float32...id :volumetric_soil_water_layer_3data_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>volumetric_soil_water_layer_4(time, latitude, longitude)float32...id :volumetric_soil_water_layer_4data_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>forecast_albedo(time, latitude, longitude)float32...id :forecast_albedodata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>surface_latent_heat_flux_sum(time, latitude, longitude)float32...id :surface_latent_heat_flux_sumdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>surface_net_solar_radiation_sum(time, latitude, longitude)float32...id :surface_net_solar_radiation_sumdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>surface_net_thermal_radiation_sum(time, latitude, longitude)float32...id :surface_net_thermal_radiation_sumdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>surface_sensible_heat_flux_sum(time, latitude, longitude)float32...id :surface_sensible_heat_flux_sumdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>surface_solar_radiation_downwards_sum(time, latitude, longitude)float32...id :surface_solar_radiation_downwards_sumdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>surface_thermal_radiation_downwards_sum(time, latitude, longitude)float32...id :surface_thermal_radiation_downwards_sumdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>evaporation_from_bare_soil_sum(time, latitude, longitude)float32...id :evaporation_from_bare_soil_sumdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>evaporation_from_open_water_surfaces_excluding_oceans_sum(time, latitude, longitude)float32...id :evaporation_from_open_water_surfaces_excluding_oceans_sumdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>evaporation_from_the_top_of_canopy_sum(time, latitude, longitude)float32...id :evaporation_from_the_top_of_canopy_sumdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>evaporation_from_vegetation_transpiration_sum(time, latitude, longitude)float32...id :evaporation_from_vegetation_transpiration_sumdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>potential_evaporation_sum(time, latitude, longitude)float32...id :potential_evaporation_sumdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>runoff_sum(time, latitude, longitude)float32...id :runoff_sumdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>snow_evaporation_sum(time, latitude, longitude)float32...id :snow_evaporation_sumdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>sub_surface_runoff_sum(time, latitude, longitude)float32...id :sub_surface_runoff_sumdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>surface_runoff_sum(time, latitude, longitude)float32...id :surface_runoff_sumdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>total_evaporation_sum(time, latitude, longitude)float32...id :total_evaporation_sumdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>u_component_of_wind_10m(time, latitude, longitude)float32...id :u_component_of_wind_10mdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>v_component_of_wind_10m(time, latitude, longitude)float32...id :v_component_of_wind_10mdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>surface_pressure(time, latitude, longitude)float32...id :surface_pressuredata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>total_precipitation_sum(time, latitude, longitude)float32...id :total_precipitation_sumdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>leaf_area_index_high_vegetation(time, latitude, longitude)float32...id :leaf_area_index_high_vegetationdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>leaf_area_index_low_vegetation(time, latitude, longitude)float32...id :leaf_area_index_low_vegetationdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>dewpoint_temperature_2m_min(time, latitude, longitude)float32...id :dewpoint_temperature_2m_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>dewpoint_temperature_2m_max(time, latitude, longitude)float32...id :dewpoint_temperature_2m_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>temperature_2m_min(time, latitude, longitude)float32...id :temperature_2m_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>temperature_2m_max(time, latitude, longitude)float32...id :temperature_2m_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>skin_temperature_min(time, latitude, longitude)float32...id :skin_temperature_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>skin_temperature_max(time, latitude, longitude)float32...id :skin_temperature_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>soil_temperature_level_1_min(time, latitude, longitude)float32...id :soil_temperature_level_1_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>soil_temperature_level_1_max(time, latitude, longitude)float32...id :soil_temperature_level_1_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>soil_temperature_level_2_min(time, latitude, longitude)float32...id :soil_temperature_level_2_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>soil_temperature_level_2_max(time, latitude, longitude)float32...id :soil_temperature_level_2_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>soil_temperature_level_3_min(time, latitude, longitude)float32...id :soil_temperature_level_3_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>soil_temperature_level_3_max(time, latitude, longitude)float32...id :soil_temperature_level_3_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>soil_temperature_level_4_min(time, latitude, longitude)float32...id :soil_temperature_level_4_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>soil_temperature_level_4_max(time, latitude, longitude)float32...id :soil_temperature_level_4_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>lake_bottom_temperature_min(time, latitude, longitude)float32...id :lake_bottom_temperature_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>lake_bottom_temperature_max(time, latitude, longitude)float32...id :lake_bottom_temperature_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>lake_ice_depth_min(time, latitude, longitude)float32...id :lake_ice_depth_mindata_type :{'type': 'PixelType', 'precision': 'float'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>lake_ice_depth_max(time, latitude, longitude)float32...id :lake_ice_depth_maxdata_type :{'type': 'PixelType', 'precision': 'float'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>lake_ice_temperature_min(time, latitude, longitude)float32...id :lake_ice_temperature_mindata_type :{'type': 'PixelType', 'precision': 'float'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>lake_ice_temperature_max(time, latitude, longitude)float32...id :lake_ice_temperature_maxdata_type :{'type': 'PixelType', 'precision': 'float'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>lake_mix_layer_depth_min(time, latitude, longitude)float32...id :lake_mix_layer_depth_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>lake_mix_layer_depth_max(time, latitude, longitude)float32...id :lake_mix_layer_depth_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>lake_mix_layer_temperature_min(time, latitude, longitude)float32...id :lake_mix_layer_temperature_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>lake_mix_layer_temperature_max(time, latitude, longitude)float32...id :lake_mix_layer_temperature_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>lake_shape_factor_min(time, latitude, longitude)float32...id :lake_shape_factor_mindata_type :{'type': 'PixelType', 'precision': 'float'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>lake_shape_factor_max(time, latitude, longitude)float32...id :lake_shape_factor_maxdata_type :{'type': 'PixelType', 'precision': 'float'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>lake_total_layer_temperature_min(time, latitude, longitude)float32...id :lake_total_layer_temperature_mindata_type :{'type': 'PixelType', 'precision': 'float'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>lake_total_layer_temperature_max(time, latitude, longitude)float32...id :lake_total_layer_temperature_maxdata_type :{'type': 'PixelType', 'precision': 'float'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>snow_albedo_min(time, latitude, longitude)float32...id :snow_albedo_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>snow_albedo_max(time, latitude, longitude)float32...id :snow_albedo_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>snow_cover_min(time, latitude, longitude)float32...id :snow_cover_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>snow_cover_max(time, latitude, longitude)float32...id :snow_cover_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>snow_density_min(time, latitude, longitude)float32...id :snow_density_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>snow_density_max(time, latitude, longitude)float32...id :snow_density_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>snow_depth_min(time, latitude, longitude)float32...id :snow_depth_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>snow_depth_max(time, latitude, longitude)float32...id :snow_depth_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>snow_depth_water_equivalent_min(time, latitude, longitude)float32...id :snow_depth_water_equivalent_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>snow_depth_water_equivalent_max(time, latitude, longitude)float32...id :snow_depth_water_equivalent_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>snowfall_min(time, latitude, longitude)float32...id :snowfall_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>snowfall_max(time, latitude, longitude)float32...id :snowfall_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>snowmelt_min(time, latitude, longitude)float32...id :snowmelt_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>snowmelt_max(time, latitude, longitude)float32...id :snowmelt_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>temperature_of_snow_layer_min(time, latitude, longitude)float32...id :temperature_of_snow_layer_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>temperature_of_snow_layer_max(time, latitude, longitude)float32...id :temperature_of_snow_layer_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>skin_reservoir_content_min(time, latitude, longitude)float32...id :skin_reservoir_content_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>skin_reservoir_content_max(time, latitude, longitude)float32...id :skin_reservoir_content_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>volumetric_soil_water_layer_1_min(time, latitude, longitude)float32...id :volumetric_soil_water_layer_1_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>volumetric_soil_water_layer_1_max(time, latitude, longitude)float32...id :volumetric_soil_water_layer_1_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>volumetric_soil_water_layer_2_min(time, latitude, longitude)float32...id :volumetric_soil_water_layer_2_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>volumetric_soil_water_layer_2_max(time, latitude, longitude)float32...id :volumetric_soil_water_layer_2_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>volumetric_soil_water_layer_3_min(time, latitude, longitude)float32...id :volumetric_soil_water_layer_3_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>volumetric_soil_water_layer_3_max(time, latitude, longitude)float32...id :volumetric_soil_water_layer_3_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>volumetric_soil_water_layer_4_min(time, latitude, longitude)float32...id :volumetric_soil_water_layer_4_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>volumetric_soil_water_layer_4_max(time, latitude, longitude)float32...id :volumetric_soil_water_layer_4_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>forecast_albedo_min(time, latitude, longitude)float32...id :forecast_albedo_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>forecast_albedo_max(time, latitude, longitude)float32...id :forecast_albedo_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>surface_latent_heat_flux_min(time, latitude, longitude)float32...id :surface_latent_heat_flux_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>surface_latent_heat_flux_max(time, latitude, longitude)float32...id :surface_latent_heat_flux_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>surface_net_solar_radiation_min(time, latitude, longitude)float32...id :surface_net_solar_radiation_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>surface_net_solar_radiation_max(time, latitude, longitude)float32...id :surface_net_solar_radiation_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>surface_net_thermal_radiation_min(time, latitude, longitude)float32...id :surface_net_thermal_radiation_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>surface_net_thermal_radiation_max(time, latitude, longitude)float32...id :surface_net_thermal_radiation_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>surface_sensible_heat_flux_min(time, latitude, longitude)float32...id :surface_sensible_heat_flux_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>surface_sensible_heat_flux_max(time, latitude, longitude)float32...id :surface_sensible_heat_flux_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>surface_solar_radiation_downwards_min(time, latitude, longitude)float32...id :surface_solar_radiation_downwards_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>surface_solar_radiation_downwards_max(time, latitude, longitude)float32...id :surface_solar_radiation_downwards_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>surface_thermal_radiation_downwards_min(time, latitude, longitude)float32...id :surface_thermal_radiation_downwards_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>surface_thermal_radiation_downwards_max(time, latitude, longitude)float32...id :surface_thermal_radiation_downwards_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>evaporation_from_bare_soil_min(time, latitude, longitude)float32...id :evaporation_from_bare_soil_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>evaporation_from_bare_soil_max(time, latitude, longitude)float32...id :evaporation_from_bare_soil_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>evaporation_from_open_water_surfaces_excluding_oceans_min(time, latitude, longitude)float32...id :evaporation_from_open_water_surfaces_excluding_oceans_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>evaporation_from_open_water_surfaces_excluding_oceans_max(time, latitude, longitude)float32...id :evaporation_from_open_water_surfaces_excluding_oceans_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>evaporation_from_the_top_of_canopy_min(time, latitude, longitude)float32...id :evaporation_from_the_top_of_canopy_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>evaporation_from_the_top_of_canopy_max(time, latitude, longitude)float32...id :evaporation_from_the_top_of_canopy_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>evaporation_from_vegetation_transpiration_min(time, latitude, longitude)float32...id :evaporation_from_vegetation_transpiration_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>evaporation_from_vegetation_transpiration_max(time, latitude, longitude)float32...id :evaporation_from_vegetation_transpiration_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>potential_evaporation_min(time, latitude, longitude)float32...id :potential_evaporation_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>potential_evaporation_max(time, latitude, longitude)float32...id :potential_evaporation_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>runoff_min(time, latitude, longitude)float32...id :runoff_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>runoff_max(time, latitude, longitude)float32...id :runoff_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>snow_evaporation_min(time, latitude, longitude)float32...id :snow_evaporation_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>snow_evaporation_max(time, latitude, longitude)float32...id :snow_evaporation_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>sub_surface_runoff_min(time, latitude, longitude)float32...id :sub_surface_runoff_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>sub_surface_runoff_max(time, latitude, longitude)float32...id :sub_surface_runoff_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>surface_runoff_min(time, latitude, longitude)float32...id :surface_runoff_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>surface_runoff_max(time, latitude, longitude)float32...id :surface_runoff_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>total_evaporation_min(time, latitude, longitude)float32...id :total_evaporation_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>total_evaporation_max(time, latitude, longitude)float32...id :total_evaporation_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>u_component_of_wind_10m_min(time, latitude, longitude)float32...id :u_component_of_wind_10m_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>u_component_of_wind_10m_max(time, latitude, longitude)float32...id :u_component_of_wind_10m_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>v_component_of_wind_10m_min(time, latitude, longitude)float32...id :v_component_of_wind_10m_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>v_component_of_wind_10m_max(time, latitude, longitude)float32...id :v_component_of_wind_10m_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>surface_pressure_min(time, latitude, longitude)float32...id :surface_pressure_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>surface_pressure_max(time, latitude, longitude)float32...id :surface_pressure_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>total_precipitation_min(time, latitude, longitude)float32...id :total_precipitation_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>total_precipitation_max(time, latitude, longitude)float32...id :total_precipitation_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>leaf_area_index_high_vegetation_min(time, latitude, longitude)float32...id :leaf_area_index_high_vegetation_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>leaf_area_index_high_vegetation_max(time, latitude, longitude)float32...id :leaf_area_index_high_vegetation_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>leaf_area_index_low_vegetation_min(time, latitude, longitude)float32...id :leaf_area_index_low_vegetation_mindata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li><li>leaf_area_index_low_vegetation_max(time, latitude, longitude)float32...id :leaf_area_index_low_vegetation_maxdata_type :{'type': 'PixelType', 'precision': 'double'}dimensions :[3601, 1801]crs :EPSG:4326crs_transform :[0.1, 0, -180.05, 0, -0.1, 90.05]<pre>[4380 values with dtype=float32]</pre></li></ul></li><li>Indexes: (3)<ul><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2020-10-01', '2020-10-02', '2020-10-03', '2020-10-04',\n               '2020-10-05', '2020-10-06', '2020-10-07', '2020-10-08',\n               '2020-10-09', '2020-10-10',\n               ...\n               '2021-09-21', '2021-09-22', '2021-09-23', '2021-09-24',\n               '2021-09-25', '2021-09-26', '2021-09-27', '2021-09-28',\n               '2021-09-29', '2021-09-30'],\n              dtype='datetime64[ns]', name='time', length=365, freq=None))</pre></li><li>longitudePandasIndex<pre>PandasIndex(Index([-121.8922497580812, -121.7922497580812, -121.6922497580812,\n       -121.59224975808121],\n      dtype='float64', name='longitude'))</pre></li><li>latitudePandasIndex<pre>PandasIndex(Index([46.94728202951897, 46.84728202951897, 46.74728202951897], dtype='float64', name='latitude'))</pre></li></ul></li><li>Attributes: (5)crs :EPSG:4326data_citation :Hersbach, H., Bell, B., Berrisford, P., et al. (2020). The ERA5 global reanalysis. Quarterly Journal of the Royal Meteorological Society, 146(730), 1999-2049.version :ERA5_LANDcadence :DAILYsource :Google Earth Engine</li></ul> In\u00a0[20]: Copied! <pre>f,axs=plt.subplots(1,2,figsize=(15,7))\n\nera5_land_ds[\"snow_depth_water_equivalent\"].max(dim=\"time\").plot.imshow(ax=axs[0],cmap='Blues',cbar_kwargs={'label':'Snow Depth Water Equivalent (m)'})\nera5_land_ds[\"snow_depth_water_equivalent\"].mean(dim=[\"latitude\",\"longitude\"]).plot(ax=axs[1])\nbbox_gdf.plot(ax=axs[0], color=\"none\", edgecolor=\"red\", linewidth=3)\n\naxs[0].set_title(\"Max Snow Depth Water Equivalent\")\naxs[1].set_title(\"Mean Snow Depth Water Equivalent\")\n\nf.suptitle(\"ERA5-Land Snow Depth Water Equivalent\\nMt. Rainier, WY2021\")\nf.tight_layout()\n</pre> f,axs=plt.subplots(1,2,figsize=(15,7))  era5_land_ds[\"snow_depth_water_equivalent\"].max(dim=\"time\").plot.imshow(ax=axs[0],cmap='Blues',cbar_kwargs={'label':'Snow Depth Water Equivalent (m)'}) era5_land_ds[\"snow_depth_water_equivalent\"].mean(dim=[\"latitude\",\"longitude\"]).plot(ax=axs[1]) bbox_gdf.plot(ax=axs[0], color=\"none\", edgecolor=\"red\", linewidth=3)  axs[0].set_title(\"Max Snow Depth Water Equivalent\") axs[1].set_title(\"Mean Snow Depth Water Equivalent\")  f.suptitle(\"ERA5-Land Snow Depth Water Equivalent\\nMt. Rainier, WY2021\") f.tight_layout() In\u00a0[21]: Copied! <pre>snow_reanalysis_da = easysnowdata.hydroclimatology.get_ucla_snow_reanalysis(\n    bbox_gdf,\n    start_date=\"2020-10-01\",\n    end_date=\"2021-09-30\",\n    variable=\"SWE_Post\",\n    stats=\"mean\",\n)\n</pre> snow_reanalysis_da = easysnowdata.hydroclimatology.get_ucla_snow_reanalysis(     bbox_gdf,     start_date=\"2020-10-01\",     end_date=\"2021-09-30\",     variable=\"SWE_Post\",     stats=\"mean\", ) <pre>QUEUEING TASKS | :   0%|          | 0/2 [00:00&lt;?, ?it/s]</pre> <pre>PROCESSING TASKS | :   0%|          | 0/2 [00:00&lt;?, ?it/s]</pre> <pre>COLLECTING RESULTS | :   0%|          | 0/2 [00:00&lt;?, ?it/s]</pre> In\u00a0[22]: Copied! <pre>f = snow_reanalysis_da.isel(time=slice(0, 365, 30)).plot.imshow(\n    col=\"time\",\n    col_wrap=5,\n    cmap=\"Blues\",\n    vmin=0,\n    vmax=3,\n)\n\nf.fig.suptitle(\"UCLA SWE reanalysis\")\n</pre> f = snow_reanalysis_da.isel(time=slice(0, 365, 30)).plot.imshow(     col=\"time\",     col_wrap=5,     cmap=\"Blues\",     vmin=0,     vmax=3, )  f.fig.suptitle(\"UCLA SWE reanalysis\") Out[22]: <pre>Text(0.5, 0.98, 'UCLA SWE reanalysis')</pre>"},{"location":"examples/hydroclimatology_examples/#testing-examples-from-hydroclimatology","title":"Testing examples from hydroclimatology\u00b6","text":""},{"location":"examples/hydroclimatology_examples/#koppen-geiger-climate-classification","title":"Koppen Geiger Climate Classification\u00b6","text":""},{"location":"examples/hydroclimatology_examples/#huc02-geometries","title":"HUC02 geometries\u00b6","text":""},{"location":"examples/hydroclimatology_examples/#get-huc-geometries-given-a-bounding-box","title":"Get HUC geometries given a bounding box\u00b6","text":""},{"location":"examples/hydroclimatology_examples/#hydrobasins-geometries","title":"HydroBASINS geometries\u00b6","text":""},{"location":"examples/hydroclimatology_examples/#gdrc-major-river-basins-of-the-world","title":"GDRC Major River Basins of the World\u00b6","text":""},{"location":"examples/hydroclimatology_examples/#era5-hourly-atmospheric-reanalysis-on-google-cloud-storage","title":"ERA5 hourly atmospheric reanalysis on google cloud storage\u00b6","text":""},{"location":"examples/hydroclimatology_examples/#era5-and-era5-land-atmospheric-reanalysis-on-google-earth-engine","title":"ERA5 and ERA5-Land atmospheric reanalysis on google earth engine\u00b6","text":""},{"location":"examples/hydroclimatology_examples/#ucla-snow-reanalysis","title":"UCLA snow reanalysis\u00b6","text":""},{"location":"examples/remote_sensing_examples/","title":"Remote sensing examples","text":"In\u00a0[1]: Copied! <pre>#!mamba env create -f '../../environment.yml'\n#!mamba env update -f '../../environment.yml' --prune\n</pre> #!mamba env create -f '../../environment.yml' #!mamba env update -f '../../environment.yml' --prune In\u00a0[1]: Copied! <pre># this block is for developing the module, comment out when using the module, and uncomment import easysnowdata\n%load_ext autoreload\n%autoreload 2\n%aimport easysnowdata\n</pre> # this block is for developing the module, comment out when using the module, and uncomment import easysnowdata %load_ext autoreload %autoreload 2 %aimport easysnowdata In\u00a0[2]: Copied! <pre>#import easysnowdata\nimport geopandas as gpd\nimport rioxarray as rxr\nimport xarray as xr\nimport shapely\nimport dask\nimport pystac_client\nimport planetary_computer\nimport odc.stac\nimport matplotlib.pyplot as plt\nimport matplotlib.colors\nimport datetime\nimport pandas as pd\nimport numpy as np\nimport contextily as ctx\nimport rasterio as rio\n\nimport datetime\n\ntoday = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n</pre> #import easysnowdata import geopandas as gpd import rioxarray as rxr import xarray as xr import shapely import dask import pystac_client import planetary_computer import odc.stac import matplotlib.pyplot as plt import matplotlib.colors import datetime import pandas as pd import numpy as np import contextily as ctx import rasterio as rio  import datetime  today = datetime.datetime.now().strftime(\"%Y-%m-%d\") In\u00a0[3]: Copied! <pre>bbox_gdf = gpd.read_file(\n    \"https://github.com/egagli/easysnowdata/raw/main/docs/examples/mt_rainier.geojson\"\n)\n</pre> bbox_gdf = gpd.read_file(     \"https://github.com/egagli/easysnowdata/raw/main/docs/examples/mt_rainier.geojson\" ) In\u00a0[34]: Copied! <pre>forest_cover_fraction_da = easysnowdata.remote_sensing.get_forest_cover_fraction(bbox_gdf)\n#forest_cover_fraction_da\n</pre> forest_cover_fraction_da = easysnowdata.remote_sensing.get_forest_cover_fraction(bbox_gdf) #forest_cover_fraction_da In\u00a0[35]: Copied! <pre>f,ax = forest_cover_fraction_da.attrs['example_plot'](forest_cover_fraction_da)\n</pre> f,ax = forest_cover_fraction_da.attrs['example_plot'](forest_cover_fraction_da) In\u00a0[6]: Copied! <pre>snow_classification_da = easysnowdata.remote_sensing.get_seasonal_snow_classification(bbox_gdf)\n#snow_classification_da\n</pre> snow_classification_da = easysnowdata.remote_sensing.get_seasonal_snow_classification(bbox_gdf) #snow_classification_da In\u00a0[7]: Copied! <pre>f,ax = snow_classification_da.attrs['example_plot'](snow_classification_da)\n</pre> f,ax = snow_classification_da.attrs['example_plot'](snow_classification_da) In\u00a0[36]: Copied! <pre>mountain_snow_da = easysnowdata.remote_sensing.get_seasonal_mountain_snow_mask(bbox_gdf)\n#mountain_snow_da\n</pre> mountain_snow_da = easysnowdata.remote_sensing.get_seasonal_mountain_snow_mask(bbox_gdf) #mountain_snow_da <pre>This function takes a moment, getting zipped file from zenodo...\n</pre> In\u00a0[37]: Copied! <pre>f, ax = mountain_snow_da.attrs['example_plot'](mountain_snow_da)\n</pre> f, ax = mountain_snow_da.attrs['example_plot'](mountain_snow_da) In\u00a0[10]: Copied! <pre>worldcover_da = easysnowdata.remote_sensing.get_esa_worldcover(bbox_gdf)\n#worldcover_da\n</pre> worldcover_da = easysnowdata.remote_sensing.get_esa_worldcover(bbox_gdf) #worldcover_da In\u00a0[11]: Copied! <pre>f, ax = worldcover_da.attrs['example_plot'](worldcover_da)\n</pre> f, ax = worldcover_da.attrs['example_plot'](worldcover_da) In\u00a0[7]: Copied! <pre>nlcd_landcover_da = easysnowdata.remote_sensing.get_nlcd_landcover(bbox_gdf, layer='landcover')\n#nlcd_landcover_da\n</pre> nlcd_landcover_da = easysnowdata.remote_sensing.get_nlcd_landcover(bbox_gdf, layer='landcover') #nlcd_landcover_da In\u00a0[8]: Copied! <pre>nlcd_landcover_da.attrs['example_plot'](nlcd_landcover_da)\n</pre> nlcd_landcover_da.attrs['example_plot'](nlcd_landcover_da) Out[8]: <pre>(&lt;Figure size 2400x3000 with 1 Axes&gt;,\n &lt;Axes: title={'center': 'NLCD Landcover (2021)'}, xlabel='x', ylabel='y'&gt;)</pre> In\u00a0[12]: Copied! <pre>s2 = easysnowdata.remote_sensing.Sentinel2(\n    bbox_input=bbox_gdf,\n    start_date=\"2024-05-31\",\n    end_date=\"2024-07-07\",\n    catalog_choice=\"planetarycomputer\", # can also choose \"earthsearch\". one might be faster than the other depending on where you are running the code\n    resolution=80,\n)\n#s2.data\n</pre> s2 = easysnowdata.remote_sensing.Sentinel2(     bbox_input=bbox_gdf,     start_date=\"2024-05-31\",     end_date=\"2024-07-07\",     catalog_choice=\"planetarycomputer\", # can also choose \"earthsearch\". one might be faster than the other depending on where you are running the code     resolution=80, ) #s2.data <pre>Data searched. Access the returned seach with the .search attribute.\nData retrieved. Access with the .data attribute. Data CRS: WGS 84 / UTM zone 10N.\nNodata values removed from the data. In doing so, all bands converted to float32. To turn this behavior off, set remove_nodata=False.\nData acquired after January 25th, 2022 harmonized to old baseline. To override this behavior, set harmonize_to_old=False.\nData scaled to float reflectance. To turn this behavior off, set scale_data=False.\nMetadata retrieved. Access with the .metadata attribute.\n</pre> In\u00a0[13]: Copied! <pre>s2.get_rgb()\n#s2.rgb\n#s2.rgba\n#s2.rgb_percentile\n#s2.rgb_clahe\n</pre> s2.get_rgb() #s2.rgb #s2.rgba #s2.rgb_percentile #s2.rgb_clahe <pre>/home/eric/miniconda3/envs/easysnowdata/lib/python3.10/site-packages/odc/geo/_rgba.py:56: RuntimeWarning: invalid value encountered in cast\n  return x.astype(\"uint8\")\n</pre> <pre>/home/eric/miniconda3/envs/easysnowdata/lib/python3.10/site-packages/odc/geo/_rgba.py:56: RuntimeWarning: invalid value encountered in cast\n  return x.astype(\"uint8\")\n</pre> <pre>RGB data retrieved.\nAccess with the following attributes:\n.rgb for raw RGB,\n.rgba for RGBA,\n.rgb_percentile for percentile RGB,\n.rgb_clahe for CLAHE RGB.\nYou can pass in percentile_kwargs and clahe_kwargs to adjust RGB calculations, check documentation for options.\n</pre> In\u00a0[14]: Copied! <pre>f = s2.rgba.plot.imshow(col='time',col_wrap=5, robust=False)\n\nfor ax, time, in zip(f.axs.flat, s2.rgba.time.values):\n    local_time = pd.to_datetime(time).tz_localize('UTC').tz_convert('America/Los_Angeles')\n    ax.set_title(f'{local_time.strftime(\"%B %d, %Y\")}\\n{local_time.strftime(\"%I:%M%p\")}')\n    ax.axis('off')\n    ax.set_aspect('equal')\n    \nf.fig.tight_layout()\nf.fig.dpi = 300\nf.fig.suptitle('Sentinel-2 RGBA', fontsize=16, y=1.02)\n</pre> f = s2.rgba.plot.imshow(col='time',col_wrap=5, robust=False)  for ax, time, in zip(f.axs.flat, s2.rgba.time.values):     local_time = pd.to_datetime(time).tz_localize('UTC').tz_convert('America/Los_Angeles')     ax.set_title(f'{local_time.strftime(\"%B %d, %Y\")}\\n{local_time.strftime(\"%I:%M%p\")}')     ax.axis('off')     ax.set_aspect('equal')      f.fig.tight_layout() f.fig.dpi = 300 f.fig.suptitle('Sentinel-2 RGBA', fontsize=16, y=1.02) <pre>/home/eric/miniconda3/envs/easysnowdata/lib/python3.10/site-packages/rasterio/warp.py:344: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n  _reproject(\n</pre> Out[14]: <pre>Text(0.5, 1.02, 'Sentinel-2 RGBA')</pre> In\u00a0[15]: Copied! <pre>f = s2.rgb_clahe.plot.imshow(col='time',col_wrap=5, robust=False)\n\nfor ax, time, in zip(f.axs.flat, s2.rgb.time.values):\n    local_time = pd.to_datetime(time).tz_localize('UTC').tz_convert('America/Los_Angeles')\n    ax.set_title(f'{local_time.strftime(\"%B %d, %Y\")}\\n{local_time.strftime(\"%I:%M%p\")}')\n    ax.axis('off')\n    ax.set_aspect('equal')\n    \nf.fig.tight_layout()\nf.fig.dpi = 300\nf.fig.suptitle('Sentinel-2 RGB w/ clahe equalization', fontsize=16, y=1.02)\n</pre> f = s2.rgb_clahe.plot.imshow(col='time',col_wrap=5, robust=False)  for ax, time, in zip(f.axs.flat, s2.rgb.time.values):     local_time = pd.to_datetime(time).tz_localize('UTC').tz_convert('America/Los_Angeles')     ax.set_title(f'{local_time.strftime(\"%B %d, %Y\")}\\n{local_time.strftime(\"%I:%M%p\")}')     ax.axis('off')     ax.set_aspect('equal')      f.fig.tight_layout() f.fig.dpi = 300 f.fig.suptitle('Sentinel-2 RGB w/ clahe equalization', fontsize=16, y=1.02) Out[15]: <pre>Text(0.5, 1.02, 'Sentinel-2 RGB w/ clahe equalization')</pre> In\u00a0[16]: Copied! <pre>f,axs = plt.subplots(1,3,figsize=(12,7))\n\ns2.rgba.isel(time=0).plot.imshow(ax=axs[0])\naxs[0].set_title('RGBA')\ns2.rgb_percentile.isel(time=0).plot.imshow(ax=axs[1])\naxs[1].set_title('RGB w/ percentile stretch')\ns2.rgb_clahe.isel(time=0).plot.imshow(ax=axs[2])\naxs[2].set_title('RGB w/ clahe equalization')\n\nfor ax in axs:\n    ax.axis('off')\n    ax.set_aspect('equal')\n\nf.tight_layout()\n</pre> f,axs = plt.subplots(1,3,figsize=(12,7))  s2.rgba.isel(time=0).plot.imshow(ax=axs[0]) axs[0].set_title('RGBA') s2.rgb_percentile.isel(time=0).plot.imshow(ax=axs[1]) axs[1].set_title('RGB w/ percentile stretch') s2.rgb_clahe.isel(time=0).plot.imshow(ax=axs[2]) axs[2].set_title('RGB w/ clahe equalization')  for ax in axs:     ax.axis('off')     ax.set_aspect('equal')  f.tight_layout() In\u00a0[17]: Copied! <pre>s2.get_ndvi()\n#s2.ndvi\n</pre> s2.get_ndvi() #s2.ndvi <pre>NDVI data calculated. Access with the .ndvi attribute.\n</pre> In\u00a0[18]: Copied! <pre>f = s2.ndvi.plot.imshow(col='time',col_wrap=5)\n\nfor ax, time, in zip(f.axs.flat, s2.ndvi.time.values):\n    local_time = pd.to_datetime(time).tz_localize('UTC').tz_convert('America/Los_Angeles')\n    ax.set_title(f'{local_time.strftime(\"%B %d, %Y\")}\\n{local_time.strftime(\"%I:%M%p\")}')\n    ax.axis('off')\n    ax.set_aspect('equal')\n\nf.fig.suptitle('Sentinel-2 NDVI time series',fontsize=16,y=1.02)\n</pre> f = s2.ndvi.plot.imshow(col='time',col_wrap=5)  for ax, time, in zip(f.axs.flat, s2.ndvi.time.values):     local_time = pd.to_datetime(time).tz_localize('UTC').tz_convert('America/Los_Angeles')     ax.set_title(f'{local_time.strftime(\"%B %d, %Y\")}\\n{local_time.strftime(\"%I:%M%p\")}')     ax.axis('off')     ax.set_aspect('equal')  f.fig.suptitle('Sentinel-2 NDVI time series',fontsize=16,y=1.02) Out[18]: <pre>Text(0.5, 1.02, 'Sentinel-2 NDVI time series')</pre> In\u00a0[19]: Copied! <pre>#s2.data.scl\n</pre> #s2.data.scl In\u00a0[20]: Copied! <pre>f, ax = s2.data.scl.attrs['example_plot'](s2.data.scl.sel(time='2024-05-31',method='nearest'))\n</pre> f, ax = s2.data.scl.attrs['example_plot'](s2.data.scl.sel(time='2024-05-31',method='nearest')) In\u00a0[21]: Copied! <pre>f, ax = s2.data.scl.attrs['example_plot'](s2.data.scl)\n</pre> f, ax = s2.data.scl.attrs['example_plot'](s2.data.scl) In\u00a0[22]: Copied! <pre>s2.mask_data()\n</pre> s2.mask_data() <pre>Removed pixels with the following scene classification values:\nNo Data (Missing data)\nSaturated or defective pixel\nTopographic casted shadows\nCloud shadows\nCloud medium probability\nCloud high probability\nThin cirrus\n</pre> In\u00a0[23]: Copied! <pre># get rgb again, now with masked data\ns2.get_rgb()\n#s2.rgb_clahe\n</pre> # get rgb again, now with masked data s2.get_rgb() #s2.rgb_clahe <pre>RGB data retrieved.\nAccess with the following attributes:\n.rgb for raw RGB,\n.rgba for RGBA,\n.rgb_percentile for percentile RGB,\n.rgb_clahe for CLAHE RGB.\nYou can pass in percentile_kwargs and clahe_kwargs to adjust RGB calculations, check documentation for options.\n</pre> In\u00a0[24]: Copied! <pre>f = s2.rgb_clahe.plot.imshow(col='time',col_wrap=5, robust=True)\n\nfor ax, time, in zip(f.axs.flat, s2.rgb.time.values):\n    local_time = pd.to_datetime(time).tz_localize('UTC').tz_convert('America/Los_Angeles')\n    ax.set_title(f'{local_time.strftime(\"%B %d, %Y\")}\\n{local_time.strftime(\"%I:%M%p\")}')\n    ax.axis('off')\n    ax.set_aspect('equal')\n    \nf.fig.tight_layout()\nf.fig.dpi = 300\nf.fig.suptitle('Sentinel-2 RGB w/ clahe equalization', fontsize=16, y=1.02)\n</pre> f = s2.rgb_clahe.plot.imshow(col='time',col_wrap=5, robust=True)  for ax, time, in zip(f.axs.flat, s2.rgb.time.values):     local_time = pd.to_datetime(time).tz_localize('UTC').tz_convert('America/Los_Angeles')     ax.set_title(f'{local_time.strftime(\"%B %d, %Y\")}\\n{local_time.strftime(\"%I:%M%p\")}')     ax.axis('off')     ax.set_aspect('equal')      f.fig.tight_layout() f.fig.dpi = 300 f.fig.suptitle('Sentinel-2 RGB w/ clahe equalization', fontsize=16, y=1.02) Out[24]: <pre>Text(0.5, 1.02, 'Sentinel-2 RGB w/ clahe equalization')</pre> In\u00a0[25]: Copied! <pre>s2.get_ndsi()\n#s2.ndsi\n</pre> s2.get_ndsi() #s2.ndsi <pre>NDSI data calculated. Access with the .ndsi attribute.\n</pre> In\u00a0[26]: Copied! <pre>f = s2.ndsi.plot.imshow(col='time',col_wrap=5)\n\nfor ax, time, in zip(f.axs.flat, s2.ndsi.time.values):\n    local_time = pd.to_datetime(time).tz_localize('UTC').tz_convert('America/Los_Angeles')\n    ax.set_title(f'{local_time.strftime(\"%B %d, %Y\")}\\n{local_time.strftime(\"%I:%M%p\")}')\n    ax.axis('off')\n    ax.set_aspect('equal')\n\nf.fig.dpi = 300\nf.fig.suptitle('Sentinel-2 NDSI time series',fontsize=16,y=1.02)\n</pre> f = s2.ndsi.plot.imshow(col='time',col_wrap=5)  for ax, time, in zip(f.axs.flat, s2.ndsi.time.values):     local_time = pd.to_datetime(time).tz_localize('UTC').tz_convert('America/Los_Angeles')     ax.set_title(f'{local_time.strftime(\"%B %d, %Y\")}\\n{local_time.strftime(\"%I:%M%p\")}')     ax.axis('off')     ax.set_aspect('equal')  f.fig.dpi = 300 f.fig.suptitle('Sentinel-2 NDSI time series',fontsize=16,y=1.02) Out[26]: <pre>Text(0.5, 1.02, 'Sentinel-2 NDSI time series')</pre> In\u00a0[27]: Copied! <pre>s1 = easysnowdata.remote_sensing.Sentinel1(\n    bbox_input=bbox_gdf, start_date=\"2022-07-01\", end_date=\"2022-07-31\", resolution=80\n)\n#s1.data\n</pre> s1 = easysnowdata.remote_sensing.Sentinel1(     bbox_input=bbox_gdf, start_date=\"2022-07-01\", end_date=\"2022-07-31\", resolution=80 ) #s1.data <pre>Data searched. Access the returned seach with the .search attribute.\nData retrieved. Access with the .data attribute. Data CRS: WGS 84 / UTM zone 10N.\nMetadata retrieved. Access with the .metadata attribute.\nFalsely low scenes and border noise removed from the data.\nAdded relative orbit number and orbit state as coordinates to the data.\nLinear power units converted to dB. Convert back to linear power units using the .db_to_linear() method.\n</pre> In\u00a0[28]: Copied! <pre>f = s1.data['vv'].plot.imshow(col='time',col_wrap=5, vmin=-15, vmax=2, cmap='gray')\n\nfor ax, time, in zip(f.axs.flat, s1.data['vv'].time.values):\n    local_time = pd.to_datetime(time).tz_localize('UTC').tz_convert('America/Los_Angeles')\n    ax.set_title(f'{local_time.strftime(\"%B %d, %Y\")}\\n{local_time.strftime(\"%I:%M%p\")}')\n    ax.axis('off')\n    ax.set_aspect('equal')\n\nf.fig.suptitle('Sentinel-1 RTC backscatter time series',fontsize=16,y=1.02)\n</pre> f = s1.data['vv'].plot.imshow(col='time',col_wrap=5, vmin=-15, vmax=2, cmap='gray')  for ax, time, in zip(f.axs.flat, s1.data['vv'].time.values):     local_time = pd.to_datetime(time).tz_localize('UTC').tz_convert('America/Los_Angeles')     ax.set_title(f'{local_time.strftime(\"%B %d, %Y\")}\\n{local_time.strftime(\"%I:%M%p\")}')     ax.axis('off')     ax.set_aspect('equal')  f.fig.suptitle('Sentinel-1 RTC backscatter time series',fontsize=16,y=1.02) Out[28]: <pre>Text(0.5, 1.02, 'Sentinel-1 RTC backscatter time series')</pre> In\u00a0[29]: Copied! <pre>f, ax = plt.subplots(figsize=(10, 10))\n\ns1.metadata.plot(\n    \"sat:relative_orbit\",\n    ax=ax,\n    edgecolor=\"black\",\n    categorical=True,\n    legend=True,\n    alpha=0.2,\n)\nbbox_gdf.plot(ax=ax, edgecolor=\"black\", facecolor=\"none\")\nctx.add_basemap(ax, crs=s1.metadata.crs, source=ctx.providers.Esri.WorldImagery)\n</pre> f, ax = plt.subplots(figsize=(10, 10))  s1.metadata.plot(     \"sat:relative_orbit\",     ax=ax,     edgecolor=\"black\",     categorical=True,     legend=True,     alpha=0.2, ) bbox_gdf.plot(ax=ax, edgecolor=\"black\", facecolor=\"none\") ctx.add_basemap(ax, crs=s1.metadata.crs, source=ctx.providers.Esri.WorldImagery) In\u00a0[30]: Copied! <pre># !CPL_VSIL_CURL_USE_HEAD=FALSE\n# !GDAL_DISABLE_READDIR_ON_OPEN=YES\n# !GDAL_HTTP_COOKIEJAR=/tmp/cookies.txt\n# !GDAL_HTTP_COOKIEFILE=/tmp/cookies.txt\n\n# from osgeo import gdal\n# gdal.SetConfigOption('GDAL_HTTP_COOKIEFILE','~/cookies.txt')\n# gdal.SetConfigOption('GDAL_HTTP_COOKIEJAR', '~/cookies.txt')\n# gdal.SetConfigOption('GDAL_DISABLE_READDIR_ON_OPEN','EMPTY_DIR') #gdal.SetConfigOption('GDAL_DISABLE_READDIR_ON_OPEN','YES') EMPTY_DIR\n# gdal.SetConfigOption('CPL_VSIL_CURL_ALLOWED_EXTENSIONS','TIF')\n# gdal.SetConfigOption('GDAL_HTTP_UNSAFESSL', 'YES')\n# gdal.SetConfigOption('GDAL_HTTP_NETRC','True')\n</pre> # !CPL_VSIL_CURL_USE_HEAD=FALSE # !GDAL_DISABLE_READDIR_ON_OPEN=YES # !GDAL_HTTP_COOKIEJAR=/tmp/cookies.txt # !GDAL_HTTP_COOKIEFILE=/tmp/cookies.txt  # from osgeo import gdal # gdal.SetConfigOption('GDAL_HTTP_COOKIEFILE','~/cookies.txt') # gdal.SetConfigOption('GDAL_HTTP_COOKIEJAR', '~/cookies.txt') # gdal.SetConfigOption('GDAL_DISABLE_READDIR_ON_OPEN','EMPTY_DIR') #gdal.SetConfigOption('GDAL_DISABLE_READDIR_ON_OPEN','YES') EMPTY_DIR # gdal.SetConfigOption('CPL_VSIL_CURL_ALLOWED_EXTENSIONS','TIF') # gdal.SetConfigOption('GDAL_HTTP_UNSAFESSL', 'YES') # gdal.SetConfigOption('GDAL_HTTP_NETRC','True') In\u00a0[\u00a0]: Copied! <pre>hls = easysnowdata.remote_sensing.HLS(\n    bbox_input=bbox_gdf,\n    start_date=\"2022-07-01\",\n    end_date=\"2022-07-31\",\n    resolution=60, \n)\n\n#hls.data\n</pre> hls = easysnowdata.remote_sensing.HLS(     bbox_input=bbox_gdf,     start_date=\"2022-07-01\",     end_date=\"2022-07-31\",     resolution=60,  )  #hls.data <pre>Data searched. Access the returned seach with the .search_landsat or .search_sentinel attribute.\nData retrieved. Access with the .data attribute. Data CRS: WGS 84 / UTM zone 10N.\nNodata values removed from the data. In doing so, all bands converted to float32. To turn this behavior off, set remove_nodata=False.\nData scaled to reflectance. Access with the .data attribute. To turn this behavior off, set scale_data=False.\n</pre> In\u00a0[32]: Copied! <pre>hls.get_rgb()\n#hls.rgb\n</pre> hls.get_rgb() #hls.rgb <pre>RGB data retrieved.\nAccess with the following attributes:\n.rgb for raw RGB,\n.rgba for RGBA,\n.rgb_percentile for percentile RGB,\n.rgb_clahe for CLAHE RGB.\nYou can pass in percentile_kwargs and clahe_kwargs to adjust RGB calculations, check documentation for options.\n</pre> In\u00a0[33]: Copied! <pre>f,axs = plt.subplots(1,3,figsize=(12,7))\n\nhls.rgba.isel(time=0).plot.imshow(ax=axs[0])\naxs[0].set_title('RGBA')\nhls.rgb_percentile.isel(time=0).plot.imshow(ax=axs[1])\naxs[1].set_title('RGB w/ percentile stretch')\nhls.rgb_clahe.isel(time=0).plot.imshow(ax=axs[2])\naxs[2].set_title('RGB w/ clahe equalization')\n\nfor ax in axs:\n    ax.axis('off')\n    ax.set_aspect('equal')\n\nf.tight_layout()\n</pre> f,axs = plt.subplots(1,3,figsize=(12,7))  hls.rgba.isel(time=0).plot.imshow(ax=axs[0]) axs[0].set_title('RGBA') hls.rgb_percentile.isel(time=0).plot.imshow(ax=axs[1]) axs[1].set_title('RGB w/ percentile stretch') hls.rgb_clahe.isel(time=0).plot.imshow(ax=axs[2]) axs[2].set_title('RGB w/ clahe equalization')  for ax in axs:     ax.axis('off')     ax.set_aspect('equal')  f.tight_layout() In\u00a0[41]: Copied! <pre>f = hls.rgb_percentile.plot.imshow(col='time',col_wrap=5,)\n\n# for ax, time, platform in zip(f.axes.flat, hls.rgb.time.values, hls.rgb.platform.values): commented out because of HLS metadata issue that makes platform retrieval impossible, that is being fixed: https://forum.earthdata.nasa.gov/viewtopic.php?p=20578#p20578\n#     local_time = pd.to_datetime(time).tz_localize('UTC').tz_convert('America/Los_Angeles')\n#     ax.set_title(f'{local_time.strftime(\"%B %d, %Y\")}\\n{local_time.strftime(\"%I:%M%p\")}\\n{platform}')\n#     ax.axis('off')\n#     ax.set_aspect('equal')\n\nfor ax, time in zip(f.axes.flat, hls.rgb_percentile.time.values):\n    local_time = pd.to_datetime(time).tz_localize('UTC').tz_convert('America/Los_Angeles')\n    ax.set_title(f'{local_time.strftime(\"%B %d, %Y\")}\\n{local_time.strftime(\"%I:%M%p\")}')\n    ax.axis('off')\n    ax.set_aspect('equal')\n\nf.fig.subplots_adjust(hspace=0.3)\nf.fig.suptitle('Harmonized Landsat Sentinel-2 (HLS) time series\\nw/ percentile stretch',fontsize=16,y=1.04)\n</pre> f = hls.rgb_percentile.plot.imshow(col='time',col_wrap=5,)  # for ax, time, platform in zip(f.axes.flat, hls.rgb.time.values, hls.rgb.platform.values): commented out because of HLS metadata issue that makes platform retrieval impossible, that is being fixed: https://forum.earthdata.nasa.gov/viewtopic.php?p=20578#p20578 #     local_time = pd.to_datetime(time).tz_localize('UTC').tz_convert('America/Los_Angeles') #     ax.set_title(f'{local_time.strftime(\"%B %d, %Y\")}\\n{local_time.strftime(\"%I:%M%p\")}\\n{platform}') #     ax.axis('off') #     ax.set_aspect('equal')  for ax, time in zip(f.axes.flat, hls.rgb_percentile.time.values):     local_time = pd.to_datetime(time).tz_localize('UTC').tz_convert('America/Los_Angeles')     ax.set_title(f'{local_time.strftime(\"%B %d, %Y\")}\\n{local_time.strftime(\"%I:%M%p\")}')     ax.axis('off')     ax.set_aspect('equal')  f.fig.subplots_adjust(hspace=0.3) f.fig.suptitle('Harmonized Landsat Sentinel-2 (HLS) time series\\nw/ percentile stretch',fontsize=16,y=1.04) Out[41]: <pre>Text(0.5, 1.04, 'Harmonized Landsat Sentinel-2 (HLS) time series\\nw/ percentile stretch')</pre> In\u00a0[42]: Copied! <pre>mod10a1 = easysnowdata.remote_sensing.MODIS_snow(bbox_gdf, start_date='2022-07-01', end_date='2022-07-31', data_product='MOD10A1')\n</pre> mod10a1 = easysnowdata.remote_sensing.MODIS_snow(bbox_gdf, start_date='2022-07-01', end_date='2022-07-31', data_product='MOD10A1') <pre>Data retrieved. Access with the .data attribute.\n</pre> In\u00a0[43]: Copied! <pre>mod10a1.data\n</pre> mod10a1.data Out[43]: <pre>&lt;xarray.Dataset&gt; Size: 4MB\nDimensions:                             (y: 66, x: 167, time: 31)\nCoordinates:\n  * y                                   (y) float64 528B 5.226e+06 ... 5.196e+06\n  * x                                   (x) float64 1kB -9.294e+06 ... -9.217...\n    spatial_ref                         int32 4B 0\n  * time                                (time) datetime64[ns] 248B 2022-07-01...\nData variables:\n    hdf                                 (time, y, x) float32 1MB dask.array&lt;chunksize=(1, 66, 167), meta=np.ndarray&gt;\n    NDSI                                (time, y, x) int16 683kB dask.array&lt;chunksize=(1, 66, 167), meta=np.ndarray&gt;\n    orbit_pnt                           (time, y, x) uint8 342kB dask.array&lt;chunksize=(1, 66, 167), meta=np.ndarray&gt;\n    granule_pnt                         (time, y, x) uint8 342kB dask.array&lt;chunksize=(1, 66, 167), meta=np.ndarray&gt;\n    NDSI_Snow_Cover                     (time, y, x) uint8 342kB dask.array&lt;chunksize=(1, 66, 167), meta=np.ndarray&gt;\n    Snow_Albedo_Daily_Tile              (time, y, x) uint8 342kB dask.array&lt;chunksize=(1, 66, 167), meta=np.ndarray&gt;\n    NDSI_Snow_Cover_Basic_QA            (time, y, x) uint8 342kB dask.array&lt;chunksize=(1, 66, 167), meta=np.ndarray&gt;\n    NDSI_Snow_Cover_Algorithm_Flags_QA  (time, y, x) uint8 342kB dask.array&lt;chunksize=(1, 66, 167), meta=np.ndarray&gt;</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>y: 66</li><li>x: 167</li><li>time: 31</li></ul></li><li>Coordinates: (4)<ul><li>y(y)float645.226e+06 5.225e+06 ... 5.196e+06units :Meterresolution :-463.31271652750013crs :PROJCS[\"unnamed\",GEOGCS[\"Unknown datum based upon the custom spheroid\",DATUM[\"Not specified (based on custom spheroid)\",SPHEROID[\"Custom spheroid\",6371007.181,0]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]]],PROJECTION[\"Sinusoidal\"],PARAMETER[\"longitude_of_center\",0],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"Meter\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]<pre>array([5225935.786072, 5225472.473355, 5225009.160639, 5224545.847922,\n       5224082.535206, 5223619.222489, 5223155.909773, 5222692.597056,\n       5222229.28434 , 5221765.971623, 5221302.658907, 5220839.34619 ,\n       5220376.033474, 5219912.720757, 5219449.408041, 5218986.095324,\n       5218522.782607, 5218059.469891, 5217596.157174, 5217132.844458,\n       5216669.531741, 5216206.219025, 5215742.906308, 5215279.593592,\n       5214816.280875, 5214352.968159, 5213889.655442, 5213426.342726,\n       5212963.030009, 5212499.717293, 5212036.404576, 5211573.09186 ,\n       5211109.779143, 5210646.466427, 5210183.15371 , 5209719.840993,\n       5209256.528277, 5208793.21556 , 5208329.902844, 5207866.590127,\n       5207403.277411, 5206939.964694, 5206476.651978, 5206013.339261,\n       5205550.026545, 5205086.713828, 5204623.401112, 5204160.088395,\n       5203696.775679, 5203233.462962, 5202770.150246, 5202306.837529,\n       5201843.524813, 5201380.212096, 5200916.899379, 5200453.586663,\n       5199990.273946, 5199526.96123 , 5199063.648513, 5198600.335797,\n       5198137.02308 , 5197673.710364, 5197210.397647, 5196747.084931,\n       5196283.772214, 5195820.459498])</pre></li><li>x(x)float64-9.294e+06 ... -9.217e+06units :Meterresolution :463.3127165279165crs :PROJCS[\"unnamed\",GEOGCS[\"Unknown datum based upon the custom spheroid\",DATUM[\"Not specified (based on custom spheroid)\",SPHEROID[\"Custom spheroid\",6371007.181,0]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]]],PROJECTION[\"Sinusoidal\"],PARAMETER[\"longitude_of_center\",0],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"Meter\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]<pre>array([-9294284.749908, -9293821.437192, -9293358.124475, -9292894.811759,\n       -9292431.499042, -9291968.186326, -9291504.873609, -9291041.560893,\n       -9290578.248176, -9290114.93546 , -9289651.622743, -9289188.310026,\n       -9288724.99731 , -9288261.684593, -9287798.371877, -9287335.05916 ,\n       -9286871.746444, -9286408.433727, -9285945.121011, -9285481.808294,\n       -9285018.495578, -9284555.182861, -9284091.870145, -9283628.557428,\n       -9283165.244712, -9282701.931995, -9282238.619279, -9281775.306562,\n       -9281311.993845, -9280848.681129, -9280385.368412, -9279922.055696,\n       -9279458.742979, -9278995.430263, -9278532.117546, -9278068.80483 ,\n       -9277605.492113, -9277142.179397, -9276678.86668 , -9276215.553964,\n       -9275752.241247, -9275288.928531, -9274825.615814, -9274362.303098,\n       -9273898.990381, -9273435.677665, -9272972.364948, -9272509.052231,\n       -9272045.739515, -9271582.426798, -9271119.114082, -9270655.801365,\n       -9270192.488649, -9269729.175932, -9269265.863216, -9268802.550499,\n       -9268339.237783, -9267875.925066, -9267412.61235 , -9266949.299633,\n       -9266485.986917, -9266022.6742  , -9265559.361484, -9265096.048767,\n       -9264632.73605 , -9264169.423334, -9263706.110617, -9263242.797901,\n       -9262779.485184, -9262316.172468, -9261852.859751, -9261389.547035,\n       -9260926.234318, -9260462.921602, -9259999.608885, -9259536.296169,\n       -9259072.983452, -9258609.670736, -9258146.358019, -9257683.045303,\n       -9257219.732586, -9256756.41987 , -9256293.107153, -9255829.794436,\n       -9255366.48172 , -9254903.169003, -9254439.856287, -9253976.54357 ,\n       -9253513.230854, -9253049.918137, -9252586.605421, -9252123.292704,\n       -9251659.979988, -9251196.667271, -9250733.354555, -9250270.041838,\n       -9249806.729122, -9249343.416405, -9248880.103689, -9248416.790972,\n       -9247953.478255, -9247490.165539, -9247026.852822, -9246563.540106,\n       -9246100.227389, -9245636.914673, -9245173.601956, -9244710.28924 ,\n       -9244246.976523, -9243783.663807, -9243320.35109 , -9242857.038374,\n       -9242393.725657, -9241930.412941, -9241467.100224, -9241003.787508,\n       -9240540.474791, -9240077.162075, -9239613.849358, -9239150.536641,\n       -9238687.223925, -9238223.911208, -9237760.598492, -9237297.285775,\n       -9236833.973059, -9236370.660342, -9235907.347626, -9235444.034909,\n       -9234980.722193, -9234517.409476, -9234054.09676 , -9233590.784043,\n       -9233127.471327, -9232664.15861 , -9232200.845894, -9231737.533177,\n       -9231274.22046 , -9230810.907744, -9230347.595027, -9229884.282311,\n       -9229420.969594, -9228957.656878, -9228494.344161, -9228031.031445,\n       -9227567.718728, -9227104.406012, -9226641.093295, -9226177.780579,\n       -9225714.467862, -9225251.155146, -9224787.842429, -9224324.529713,\n       -9223861.216996, -9223397.904279, -9222934.591563, -9222471.278846,\n       -9222007.96613 , -9221544.653413, -9221081.340697, -9220618.02798 ,\n       -9220154.715264, -9219691.402547, -9219228.089831, -9218764.777114,\n       -9218301.464398, -9217838.151681, -9217374.838965])</pre></li><li>spatial_ref()int320spatial_ref :PROJCRS[\"unnamed\",BASEGEOGCRS[\"Unknown datum based upon the custom spheroid\",DATUM[\"Not specified (based on custom spheroid)\",ELLIPSOID[\"Custom spheroid\",6371007.181,0,LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433,ID[\"EPSG\",9122]]]],CONVERSION[\"unnamed\",METHOD[\"Sinusoidal\"],PARAMETER[\"Longitude of natural origin\",0,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",0,LENGTHUNIT[\"Meter\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",0,LENGTHUNIT[\"Meter\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"easting\",east,ORDER[1],LENGTHUNIT[\"Meter\",1]],AXIS[\"northing\",north,ORDER[2],LENGTHUNIT[\"Meter\",1]]]crs_wkt :PROJCRS[\"unnamed\",BASEGEOGCRS[\"Unknown datum based upon the custom spheroid\",DATUM[\"Not specified (based on custom spheroid)\",ELLIPSOID[\"Custom spheroid\",6371007.181,0,LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433,ID[\"EPSG\",9122]]]],CONVERSION[\"unnamed\",METHOD[\"Sinusoidal\"],PARAMETER[\"Longitude of natural origin\",0,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",0,LENGTHUNIT[\"Meter\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",0,LENGTHUNIT[\"Meter\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"easting\",east,ORDER[1],LENGTHUNIT[\"Meter\",1]],AXIS[\"northing\",north,ORDER[2],LENGTHUNIT[\"Meter\",1]]]semi_major_axis :6371007.181semi_minor_axis :6371007.181inverse_flattening :0.0reference_ellipsoid_name :Custom spheroidlongitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :Unknown datum based upon the custom spheroidhorizontal_datum_name :Not specified (based on custom spheroid)projected_crs_name :unnamedgrid_mapping_name :sinusoidallongitude_of_projection_origin :0.0false_easting :0.0false_northing :0.0GeoTransform :-9294516.406266532838344573974609 463.31271652791650694780401 0 5226167.442430201917886734008789 0 -463.312716527500128904648591<pre>array(0, dtype=int32)</pre></li><li>time(time)datetime64[ns]2022-07-01 ... 2022-07-31<pre>array(['2022-07-01T00:00:00.000000000', '2022-07-02T00:00:00.000000000',\n       '2022-07-03T00:00:00.000000000', '2022-07-04T00:00:00.000000000',\n       '2022-07-05T00:00:00.000000000', '2022-07-06T00:00:00.000000000',\n       '2022-07-07T00:00:00.000000000', '2022-07-08T00:00:00.000000000',\n       '2022-07-09T00:00:00.000000000', '2022-07-10T00:00:00.000000000',\n       '2022-07-11T00:00:00.000000000', '2022-07-12T00:00:00.000000000',\n       '2022-07-13T00:00:00.000000000', '2022-07-14T00:00:00.000000000',\n       '2022-07-15T00:00:00.000000000', '2022-07-16T00:00:00.000000000',\n       '2022-07-17T00:00:00.000000000', '2022-07-18T00:00:00.000000000',\n       '2022-07-19T00:00:00.000000000', '2022-07-20T00:00:00.000000000',\n       '2022-07-21T00:00:00.000000000', '2022-07-22T00:00:00.000000000',\n       '2022-07-23T00:00:00.000000000', '2022-07-24T00:00:00.000000000',\n       '2022-07-25T00:00:00.000000000', '2022-07-26T00:00:00.000000000',\n       '2022-07-27T00:00:00.000000000', '2022-07-28T00:00:00.000000000',\n       '2022-07-29T00:00:00.000000000', '2022-07-30T00:00:00.000000000',\n       '2022-07-31T00:00:00.000000000'], dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (8)<ul><li>hdf(time, y, x)float32dask.array&lt;chunksize=(1, 66, 167), meta=np.ndarray&gt;  Array   Chunk   Bytes   1.30 MiB   43.05 kiB   Shape   (31, 66, 167)   (1, 66, 167)   Dask graph   31 chunks in 3 graph layers   Data type   float32 numpy.ndarray  167 66 31 </li><li>NDSI(time, y, x)int16dask.array&lt;chunksize=(1, 66, 167), meta=np.ndarray&gt;  Array   Chunk   Bytes   667.35 kiB   21.53 kiB   Shape   (31, 66, 167)   (1, 66, 167)   Dask graph   31 chunks in 3 graph layers   Data type   int16 numpy.ndarray  167 66 31 </li><li>orbit_pnt(time, y, x)uint8dask.array&lt;chunksize=(1, 66, 167), meta=np.ndarray&gt;  Array   Chunk   Bytes   333.67 kiB   10.76 kiB   Shape   (31, 66, 167)   (1, 66, 167)   Dask graph   31 chunks in 3 graph layers   Data type   uint8 numpy.ndarray  167 66 31 </li><li>granule_pnt(time, y, x)uint8dask.array&lt;chunksize=(1, 66, 167), meta=np.ndarray&gt;  Array   Chunk   Bytes   333.67 kiB   10.76 kiB   Shape   (31, 66, 167)   (1, 66, 167)   Dask graph   31 chunks in 3 graph layers   Data type   uint8 numpy.ndarray  167 66 31 </li><li>NDSI_Snow_Cover(time, y, x)uint8dask.array&lt;chunksize=(1, 66, 167), meta=np.ndarray&gt;  Array   Chunk   Bytes   333.67 kiB   10.76 kiB   Shape   (31, 66, 167)   (1, 66, 167)   Dask graph   31 chunks in 3 graph layers   Data type   uint8 numpy.ndarray  167 66 31 </li><li>Snow_Albedo_Daily_Tile(time, y, x)uint8dask.array&lt;chunksize=(1, 66, 167), meta=np.ndarray&gt;  Array   Chunk   Bytes   333.67 kiB   10.76 kiB   Shape   (31, 66, 167)   (1, 66, 167)   Dask graph   31 chunks in 3 graph layers   Data type   uint8 numpy.ndarray  167 66 31 </li><li>NDSI_Snow_Cover_Basic_QA(time, y, x)uint8dask.array&lt;chunksize=(1, 66, 167), meta=np.ndarray&gt;  Array   Chunk   Bytes   333.67 kiB   10.76 kiB   Shape   (31, 66, 167)   (1, 66, 167)   Dask graph   31 chunks in 3 graph layers   Data type   uint8 numpy.ndarray  167 66 31 </li><li>NDSI_Snow_Cover_Algorithm_Flags_QA(time, y, x)uint8dask.array&lt;chunksize=(1, 66, 167), meta=np.ndarray&gt;  Array   Chunk   Bytes   333.67 kiB   10.76 kiB   Shape   (31, 66, 167)   (1, 66, 167)   Dask graph   31 chunks in 3 graph layers   Data type   uint8 numpy.ndarray  167 66 31 </li></ul></li><li>Indexes: (3)<ul><li>yPandasIndex<pre>PandasIndex(Index([ 5225935.786071938,  5225472.473355411,  5225009.160638884,\n        5224545.847922356,  5224082.535205828,  5223619.222489301,\n        5223155.909772773,  5222692.597056246, 5222229.2843397185,\n        5221765.971623191,  5221302.658906664,  5220839.346190136,\n        5220376.033473608,  5219912.720757081,  5219449.408040553,\n        5218986.095324026,  5218522.782607499,  5218059.469890971,\n        5217596.157174444,  5217132.844457916,  5216669.531741388,\n        5216206.219024861,  5215742.906308333,  5215279.593591806,\n        5214816.280875279,  5214352.968158751,  5213889.655442224,\n        5213426.342725696,  5212963.030009168,  5212499.717292641,\n        5212036.404576113,  5211573.091859586,  5211109.779143059,\n        5210646.466426531,  5210183.153710003,  5209719.840993476,\n        5209256.528276948,  5208793.215560421, 5208329.9028438935,\n        5207866.590127366,  5207403.277410839,  5206939.964694311,\n        5206476.651977783,  5206013.339261256,  5205550.026544728,\n        5205086.713828201,  5204623.401111674,  5204160.088395146,\n        5203696.775678619,  5203233.462962091,  5202770.150245563,\n        5202306.837529036,  5201843.524812508, 5201380.2120959805,\n        5200916.899379454,  5200453.586662926,  5199990.273946399,\n        5199526.961229871,  5199063.648513343,  5198600.335796816,\n        5198137.023080288,  5197673.710363761,  5197210.397647234,\n        5196747.084930706,  5196283.772214178,  5195820.459497651],\n      dtype='float64', name='y'))</pre></li><li>xPandasIndex<pre>PandasIndex(Index([-9294284.749908268,  -9293821.43719174, -9293358.124475213,\n       -9292894.811758684, -9292431.499042157, -9291968.186325628,\n       -9291504.873609101, -9291041.560892573, -9290578.248176046,\n       -9290114.935459517,\n       ...\n       -9221544.653413385, -9221081.340696858,  -9220618.02798033,\n       -9220154.715263803, -9219691.402547274, -9219228.089830747,\n       -9218764.777114218,  -9218301.46439769, -9217838.151681162,\n       -9217374.838964634],\n      dtype='float64', name='x', length=167))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2022-07-01', '2022-07-02', '2022-07-03', '2022-07-04',\n               '2022-07-05', '2022-07-06', '2022-07-07', '2022-07-08',\n               '2022-07-09', '2022-07-10', '2022-07-11', '2022-07-12',\n               '2022-07-13', '2022-07-14', '2022-07-15', '2022-07-16',\n               '2022-07-17', '2022-07-18', '2022-07-19', '2022-07-20',\n               '2022-07-21', '2022-07-22', '2022-07-23', '2022-07-24',\n               '2022-07-25', '2022-07-26', '2022-07-27', '2022-07-28',\n               '2022-07-29', '2022-07-30', '2022-07-31'],\n              dtype='datetime64[ns]', name='time', freq=None))</pre></li></ul></li><li>Attributes: (0)</li></ul> In\u00a0[44]: Copied! <pre>f= mod10a1.data['NDSI_Snow_Cover'].rio.reproject_match(hls.data, resampling=rio.enums.Resampling.nearest).where(lambda x: x &lt;= 100).plot.imshow(\n    col=\"time\", col_wrap=6, vmin=0, vmax=100, cmap='Blues'\n)\n\nfor ax, time, in zip(f.axs.flat, mod10a1.data.time.values):\n    ax.set_title(f'{pd.to_datetime(time).strftime(\"%B %d, %Y\")}')\n    ax.axis('off')\n    ax.set_aspect('equal')\n\nf.fig.suptitle('MODIS MOD10A1 daily NDSI snow cover',fontsize=16,y=1.02)\n</pre> f= mod10a1.data['NDSI_Snow_Cover'].rio.reproject_match(hls.data, resampling=rio.enums.Resampling.nearest).where(lambda x: x &lt;= 100).plot.imshow(     col=\"time\", col_wrap=6, vmin=0, vmax=100, cmap='Blues' )  for ax, time, in zip(f.axs.flat, mod10a1.data.time.values):     ax.set_title(f'{pd.to_datetime(time).strftime(\"%B %d, %Y\")}')     ax.axis('off')     ax.set_aspect('equal')  f.fig.suptitle('MODIS MOD10A1 daily NDSI snow cover',fontsize=16,y=1.02) Out[44]: <pre>Text(0.5, 1.02, 'MODIS MOD10A1 daily NDSI snow cover')</pre> In\u00a0[55]: Copied! <pre>mod10a2 = easysnowdata.remote_sensing.MODIS_snow(bbox_gdf, start_date='2022-07-01', end_date='2022-07-31', data_product='MOD10A2')\n</pre> mod10a2 = easysnowdata.remote_sensing.MODIS_snow(bbox_gdf, start_date='2022-07-01', end_date='2022-07-31', data_product='MOD10A2') <pre>Data retrieved. Access with the .data attribute.\n</pre> In\u00a0[56]: Copied! <pre>mod10a2.get_binary_snow()\n</pre> mod10a2.get_binary_snow() <pre>Binary snow map calculated. Access with the .binary_snow attribute.\n</pre> In\u00a0[57]: Copied! <pre>mod10a2.binary_snow.rio.crs\n</pre> mod10a2.binary_snow.rio.crs Out[57]: <pre>CRS.from_wkt('PROJCS[\"unnamed\",GEOGCS[\"Unknown datum based upon the custom spheroid\",DATUM[\"Not specified (based on custom spheroid)\",SPHEROID[\"Custom spheroid\",6371007.181,0]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]]],PROJECTION[\"Sinusoidal\"],PARAMETER[\"longitude_of_center\",0],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"Meter\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]')</pre> In\u00a0[58]: Copied! <pre>f= mod10a2.binary_snow.rio.reproject_match(hls.data, resampling=rio.enums.Resampling.nearest).plot.imshow(\n    col=\"time\", col_wrap=6, cmap='Blues'\n)\n\nfor ax, time, in zip(f.axs.flat, mod10a2.binary_snow.time.values):\n    ax.set_title(f'{pd.to_datetime(time).strftime(\"%B %d, %Y\")}')\n    ax.axis('off')\n    ax.set_aspect('equal')\n\nf.fig.suptitle('MODIS MOD10A2 8-day snow cover',fontsize=16,y=1.04)\n</pre> f= mod10a2.binary_snow.rio.reproject_match(hls.data, resampling=rio.enums.Resampling.nearest).plot.imshow(     col=\"time\", col_wrap=6, cmap='Blues' )  for ax, time, in zip(f.axs.flat, mod10a2.binary_snow.time.values):     ax.set_title(f'{pd.to_datetime(time).strftime(\"%B %d, %Y\")}')     ax.axis('off')     ax.set_aspect('equal')  f.fig.suptitle('MODIS MOD10A2 8-day snow cover',fontsize=16,y=1.04) Out[58]: <pre>Text(0.5, 1.04, 'MODIS MOD10A2 8-day snow cover')</pre> In\u00a0[59]: Copied! <pre>mod10a1f = easysnowdata.remote_sensing.MODIS_snow(bbox_gdf, start_date='2022-07-01', end_date='2022-07-31', data_product='MOD10A1F')\n#NDSI&gt;10 is snow\n</pre> mod10a1f = easysnowdata.remote_sensing.MODIS_snow(bbox_gdf, start_date='2022-07-01', end_date='2022-07-31', data_product='MOD10A1F') #NDSI&gt;10 is snow <pre>Granules found: 31\n Getting 31 granules, approx download size: 0.03 GB\n</pre> <pre>QUEUEING TASKS | :   0%|          | 0/31 [00:00&lt;?, ?it/s]</pre> <pre>File MOD10A1F.A2022182.h09v04.061.2022184060608.hdf already downloaded\nFile MOD10A1F.A2022183.h09v04.061.2022185043746.hdf already downloaded\nFile MOD10A1F.A2022184.h09v04.061.2022186055009.hdf already downloaded\nFile MOD10A1F.A2022185.h09v04.061.2022187234249.hdf already downloaded\nFile MOD10A1F.A2022186.h09v04.061.2022188071311.hdf already downloaded\nFile MOD10A1F.A2022187.h09v04.061.2022189044231.hdf already downloaded\nFile MOD10A1F.A2022188.h09v04.061.2022190054810.hdf already downloaded\nFile MOD10A1F.A2022189.h09v04.061.2022191062150.hdf already downloaded\nFile MOD10A1F.A2022190.h09v04.061.2022192033749.hdf already downloaded\nFile MOD10A1F.A2022191.h09v04.061.2022193061917.hdf already downloaded\nFile MOD10A1F.A2022192.h09v04.061.2022194154602.hdf already downloaded\nFile MOD10A1F.A2022193.h09v04.061.2022195213955.hdf already downloaded\nFile MOD10A1F.A2022194.h09v04.061.2022196065818.hdf already downloaded\nFile MOD10A1F.A2022195.h09v04.061.2022197050019.hdf already downloaded\nFile MOD10A1F.A2022196.h09v04.061.2022198043034.hdf already downloaded\nFile MOD10A1F.A2022197.h09v04.061.2022199044930.hdf already downloaded\nFile MOD10A1F.A2022198.h09v04.061.2022201021512.hdf already downloaded\nFile MOD10A1F.A2022199.h09v04.061.2022201063018.hdf already downloaded\nFile MOD10A1F.A2022200.h09v04.061.2022202070115.hdf already downloaded\nFile MOD10A1F.A2022202.h09v04.061.2022204074301.hdf already downloaded\nFile MOD10A1F.A2022201.h09v04.061.2022203064434.hdf already downloaded\nFile MOD10A1F.A2022204.h09v04.061.2022206074037.hdf already downloaded\nFile MOD10A1F.A2022205.h09v04.061.2022207080913.hdf already downloaded\nFile MOD10A1F.A2022206.h09v04.061.2022208051744.hdf already downloaded\nFile MOD10A1F.A2022207.h09v04.061.2022209055609.hdf already downloaded\nFile MOD10A1F.A2022203.h09v04.061.2022205045351.hdf already downloaded\nFile MOD10A1F.A2022208.h09v04.061.2022210065049.hdf already downloaded\nFile MOD10A1F.A2022209.h09v04.061.2022215090148.hdf already downloaded\nFile MOD10A1F.A2022210.h09v04.061.2022215090828.hdf already downloaded\nFile MOD10A1F.A2022211.h09v04.061.2022215091517.hdf already downloaded\nFile MOD10A1F.A2022212.h09v04.061.2022215092248.hdf already downloaded\n</pre> <pre>PROCESSING TASKS | :   0%|          | 0/31 [00:00&lt;?, ?it/s]</pre> <pre>COLLECTING RESULTS | :   0%|          | 0/31 [00:00&lt;?, ?it/s]</pre> <pre>Data retrieved. Access with the .data attribute.\n</pre> In\u00a0[60]: Copied! <pre>f= mod10a1f.data.rio.reproject_match(hls.data, resampling=rio.enums.Resampling.nearest).where(lambda x: x &lt;= 100).plot.imshow(\n    col=\"time\", col_wrap=6, vmin=0, vmax=100, cmap='Blues'\n)\n\nfor ax, time, in zip(f.axs.flat, mod10a1f.data.time.values):\n    ax.set_title(f'{pd.to_datetime(time).strftime(\"%B %d, %Y\")}')\n    ax.axis('off')\n    ax.set_aspect('equal')\n\nf.fig.suptitle('MODIS MOD10A1F cloud-gap-filled NDSI snow cover',fontsize=16,y=1.02)\n</pre> f= mod10a1f.data.rio.reproject_match(hls.data, resampling=rio.enums.Resampling.nearest).where(lambda x: x &lt;= 100).plot.imshow(     col=\"time\", col_wrap=6, vmin=0, vmax=100, cmap='Blues' )  for ax, time, in zip(f.axs.flat, mod10a1f.data.time.values):     ax.set_title(f'{pd.to_datetime(time).strftime(\"%B %d, %Y\")}')     ax.axis('off')     ax.set_aspect('equal')  f.fig.suptitle('MODIS MOD10A1F cloud-gap-filled NDSI snow cover',fontsize=16,y=1.02) Out[60]: <pre>Text(0.5, 1.02, 'MODIS MOD10A1F cloud-gap-filled NDSI snow cover')</pre> In\u00a0[43]: Copied! <pre># list(bbox_gdf.total_bounds)\n\n# !pip install --upgrade xee\n\n# import xee\n\n# !earthengine authenticate --quiet\n\n# import ee\n\n# ee.Initialize(opt_url=\"https://earthengine-highvolume.googleapis.com\")\n\n# bbox_ee = ee.Geometry.Rectangle(153.0, -43.0, 154.0, -42.0)\n# bbox_ee = ee.Geometry.Rectangle(*list(bbox_gdf.total_bounds))\n\n# bbox_ee = ee.Geometry.BBox(*list(bbox_gdf.total_bounds))\n\n# bbox_ee.Polygon()\n\n# ic.first().select(0).projection()\n\n# ic = ee.ImageCollection(\"JAXA/ALOS/PALSAR-2/Level2_2/ScanSAR\").filterDate(\n#     \"2022-07-01\", \"2022-07-31\"\n# )\n# ds = xr.open_dataset(\n#     ic,\n#     geometry=bbox_ee,\n#     projection=ic.first().select(0).projection(),\n#     crs=\"EPSG:4326\",\n#     engine=\"ee\",\n#     scale=0.01,\n# )\n\n# ds\n\n# ds[\"HH\"].isel(time=1).plot()\n\n# def dn_to_db(dn):\n#     db = 10 * np.log10(dn**2) - 83\n#     return db\n\n# ds[\"HH\"].map_blocks(dn_to_db)\n# ds[\"HH\"].isel(time=0)\n# ds.time.values[0:10]\n</pre> # list(bbox_gdf.total_bounds)  # !pip install --upgrade xee  # import xee  # !earthengine authenticate --quiet  # import ee  # ee.Initialize(opt_url=\"https://earthengine-highvolume.googleapis.com\")  # bbox_ee = ee.Geometry.Rectangle(153.0, -43.0, 154.0, -42.0) # bbox_ee = ee.Geometry.Rectangle(*list(bbox_gdf.total_bounds))  # bbox_ee = ee.Geometry.BBox(*list(bbox_gdf.total_bounds))  # bbox_ee.Polygon()  # ic.first().select(0).projection()  # ic = ee.ImageCollection(\"JAXA/ALOS/PALSAR-2/Level2_2/ScanSAR\").filterDate( #     \"2022-07-01\", \"2022-07-31\" # ) # ds = xr.open_dataset( #     ic, #     geometry=bbox_ee, #     projection=ic.first().select(0).projection(), #     crs=\"EPSG:4326\", #     engine=\"ee\", #     scale=0.01, # )  # ds  # ds[\"HH\"].isel(time=1).plot()  # def dn_to_db(dn): #     db = 10 * np.log10(dn**2) - 83 #     return db  # ds[\"HH\"].map_blocks(dn_to_db) # ds[\"HH\"].isel(time=0) # ds.time.values[0:10]"},{"location":"examples/remote_sensing_examples/#testing-examples-from-remote_sensing","title":"Testing examples from remote_sensing\u00b6","text":""},{"location":"examples/remote_sensing_examples/#copernicus-global-land-service-forest-cover-fraction","title":"Copernicus Global Land Service forest cover fraction\u00b6","text":""},{"location":"examples/remote_sensing_examples/#sturm-liston-2021-seasonal-snow-classification","title":"Sturm &amp; Liston 2021 seasonal snow classification\u00b6","text":""},{"location":"examples/remote_sensing_examples/","title":"\u00b6","text":""},{"location":"examples/remote_sensing_examples/#wrzesien-et-al-2019-global-seasonal-mountain-snow-mask","title":"Wrzesien et al 2019 global seasonal mountain snow mask\u00b6","text":""},{"location":"examples/remote_sensing_examples/#esa-worldcover","title":"ESA WorldCover\u00b6","text":""},{"location":"examples/remote_sensing_examples/#nlcd-landcover-2021","title":"NLCD Landcover 2021\u00b6","text":""},{"location":"examples/remote_sensing_examples/#sentinel-2","title":"Sentinel-2\u00b6","text":""},{"location":"examples/remote_sensing_examples/#get-sentinel-2-rgb-imagery","title":"Get Sentinel-2 RGB imagery\u00b6","text":""},{"location":"examples/remote_sensing_examples/#get-sentinel-2-band-indicies-ndsi-ndvi-ndwi-evi-ndbi-implemented","title":"Get Sentinel-2 band indicies (NDSI, NDVI, NDWI, EVI, NDBI implemented)\u00b6","text":""},{"location":"examples/remote_sensing_examples/#clouds-get-in-the-way-lets-check-out-the-scene-classification-layer-scl","title":"Clouds get in the way! Let's check out the scene classification layer (SCL)\u00b6","text":""},{"location":"examples/remote_sensing_examples/#lets-say-we-want-to-view-cloud-free-images-or-calculate-ndsi-while-mitigating-clouds-we-can-do-that-by-masking-our-data-based-on-the-scl-lets-mask-the-data-we-are-not-interested-in-you-can-mask-data-by-passing-boolean-values-to-mask_data-by-default-no-data-saturated-pixels-topographic-shadows-cloud-shadows-cloud-medium-probability-cloud-high-probability-and-thin-cirrus-are-all-removed","title":"Let's say we want to view cloud free images or calculate NDSI while mitigating clouds. We can do that by masking our data based on the SCL. Let's mask the data we are not interested in. You can mask data by passing boolean values to .mask_data(). By default, no data, saturated pixels, topographic shadows, cloud shadows, cloud medium probability, cloud high probability, and thin cirrus are all removed.\u00b6","text":""},{"location":"examples/remote_sensing_examples/#sentinel-1","title":"Sentinel-1\u00b6","text":""},{"location":"examples/remote_sensing_examples/#harmonized-landsat-sentinel-2-v20","title":"Harmonized Landsat Sentinel-2 v2.0\u00b6","text":""},{"location":"examples/remote_sensing_examples/#modisterra-snow-cover-mod10a1-daily-mod10a2-8-day-mod10a1f-daily-cloud-gap-filled","title":"MODIS/Terra Snow Cover: MOD10A1 (Daily), MOD10A2 (8-Day), MOD10A1F (Daily cloud-gap-filled)\u00b6","text":""},{"location":"examples/remote_sensing_examples/#palsar-2","title":"PALSAR-2\u00b6","text":""},{"location":"examples/sentinel2_planetarycomputer_vs_earthaccess/","title":"Sentinel2 planetarycomputer vs earthaccess","text":"<p>planetary computer sentinel-2-l2a</p> <p>earthaccess sentinel-2-l2a and sentinel-2-c1-l2a</p> <p>earthaccess will eventually shift to just sentinel-2-c1-l2a, waiting for processing. status here</p> <p>offset issues</p> In\u00a0[1]: Copied! <pre>import easysnowdata\nimport numpy as np\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport pystac_client\nimport pandas as pd\n</pre> import easysnowdata import numpy as np import geopandas as gpd import matplotlib.pyplot as plt import pystac_client import pandas as pd In\u00a0[2]: Copied! <pre>bbox_gdf = gpd.read_file(\n    \"https://github.com/egagli/easysnowdata/raw/main/docs/examples/mt_rainier.geojson\"\n)\n</pre> bbox_gdf = gpd.read_file(     \"https://github.com/egagli/easysnowdata/raw/main/docs/examples/mt_rainier.geojson\" ) In\u00a0[3]: Copied! <pre># the earthsearch sentinel-2-l2a catalog already applies harmonization, easysnowdata will not apply it again\ns2_es = easysnowdata.remote_sensing.Sentinel2(\n    bbox_input=bbox_gdf,\n    start_date=\"2024-05-31\",\n    end_date=\"2024-07-07\",\n    catalog_choice=\"earthsearch\", \n    resolution=80,\n)\ns2_es.data\n</pre> # the earthsearch sentinel-2-l2a catalog already applies harmonization, easysnowdata will not apply it again s2_es = easysnowdata.remote_sensing.Sentinel2(     bbox_input=bbox_gdf,     start_date=\"2024-05-31\",     end_date=\"2024-07-07\",     catalog_choice=\"earthsearch\",      resolution=80, ) s2_es.data <pre>Data searched. Access the returned seach with the .search attribute.\nData retrieved. Access with the .data attribute. Data CRS: WGS 84 / UTM zone 10N.\nNodata values removed from the data. In doing so, all bands converted to float32. To turn this behavior off, set remove_nodata=False.\nSince sentinel-2-l2a on earthsearch is used, harmonization step is not needed.\nData scaled to float reflectance. To turn this behavior off, set scale_data=False.\nMetadata retrieved. Access with the .metadata attribute.\n</pre> Out[3]: <pre>&lt;xarray.Dataset&gt; Size: 142MB\nDimensions:      (y: 380, x: 389, time: 15)\nCoordinates:\n  * y            (y) float64 3kB 5.206e+06 5.206e+06 ... 5.176e+06 5.176e+06\n  * x            (x) float64 3kB 5.804e+05 5.805e+05 ... 6.114e+05 6.115e+05\n    spatial_ref  int32 4B 32610\n  * time         (time) datetime64[ns] 120B 2024-05-31T19:11:23.919000 ... 20...\nData variables: (12/16)\n    coastal      (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    blue         (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    green        (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    red          (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    rededge      (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    rededge2     (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    ...           ...\n    swir16       (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    swir22       (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    aot          (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    scl          (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    wvp          (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    visual       (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\nAttributes:\n    band_info:       {'B01': {'name': 'coastal', 'description': 'Coastal aero...\n    scl_class_info:  {0: {'name': 'No Data (Missing data)', 'color': '#000000...</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>y: 380</li><li>x: 389</li><li>time: 15</li></ul></li><li>Coordinates: (4)<ul><li>y(y)float645.206e+06 5.206e+06 ... 5.176e+06units :metreresolution :-80.0crs :EPSG:32610<pre>array([5205880., 5205800., 5205720., ..., 5175720., 5175640., 5175560.])</pre></li><li>x(x)float645.804e+05 5.805e+05 ... 6.115e+05units :metreresolution :80.0crs :EPSG:32610<pre>array([580440., 580520., 580600., ..., 611320., 611400., 611480.])</pre></li><li>spatial_ref()int3232610spatial_ref :PROJCRS[\"WGS 84 / UTM zone 10N\",BASEGEOGCRS[\"WGS 84\",ENSEMBLE[\"World Geodetic System 1984 ensemble\",MEMBER[\"World Geodetic System 1984 (Transit)\"],MEMBER[\"World Geodetic System 1984 (G730)\"],MEMBER[\"World Geodetic System 1984 (G873)\"],MEMBER[\"World Geodetic System 1984 (G1150)\"],MEMBER[\"World Geodetic System 1984 (G1674)\"],MEMBER[\"World Geodetic System 1984 (G1762)\"],MEMBER[\"World Geodetic System 1984 (G2139)\"],MEMBER[\"World Geodetic System 1984 (G2296)\"],ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]],ENSEMBLEACCURACY[2.0]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"UTM zone 10N\",METHOD[\"Transverse Mercator\",ID[\"EPSG\",9807]],PARAMETER[\"Latitude of natural origin\",0,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",-123,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"Scale factor at natural origin\",0.9996,SCALEUNIT[\"unity\",1],ID[\"EPSG\",8805]],PARAMETER[\"False easting\",500000,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",0,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1]],USAGE[SCOPE[\"Navigation and medium accuracy spatial referencing.\"],AREA[\"Between 126\u00b0W and 120\u00b0W, northern hemisphere between equator and 84\u00b0N, onshore and offshore. Canada - British Columbia (BC); Northwest Territories (NWT); Nunavut; Yukon. United States (USA) - Alaska (AK).\"],BBOX[0,-126,84,-120]],ID[\"EPSG\",32610]]crs_wkt :PROJCRS[\"WGS 84 / UTM zone 10N\",BASEGEOGCRS[\"WGS 84\",ENSEMBLE[\"World Geodetic System 1984 ensemble\",MEMBER[\"World Geodetic System 1984 (Transit)\"],MEMBER[\"World Geodetic System 1984 (G730)\"],MEMBER[\"World Geodetic System 1984 (G873)\"],MEMBER[\"World Geodetic System 1984 (G1150)\"],MEMBER[\"World Geodetic System 1984 (G1674)\"],MEMBER[\"World Geodetic System 1984 (G1762)\"],MEMBER[\"World Geodetic System 1984 (G2139)\"],MEMBER[\"World Geodetic System 1984 (G2296)\"],ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]],ENSEMBLEACCURACY[2.0]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"UTM zone 10N\",METHOD[\"Transverse Mercator\",ID[\"EPSG\",9807]],PARAMETER[\"Latitude of natural origin\",0,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",-123,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"Scale factor at natural origin\",0.9996,SCALEUNIT[\"unity\",1],ID[\"EPSG\",8805]],PARAMETER[\"False easting\",500000,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",0,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1]],USAGE[SCOPE[\"Navigation and medium accuracy spatial referencing.\"],AREA[\"Between 126\u00b0W and 120\u00b0W, northern hemisphere between equator and 84\u00b0N, onshore and offshore. Canada - British Columbia (BC); Northwest Territories (NWT); Nunavut; Yukon. United States (USA) - Alaska (AK).\"],BBOX[0,-126,84,-120]],ID[\"EPSG\",32610]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984 ensembleprojected_crs_name :WGS 84 / UTM zone 10Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-123.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996GeoTransform :580400 80 0 5205920 0 -80<pre>array(32610, dtype=int32)</pre></li><li>time(time)datetime64[ns]2024-05-31T19:11:23.919000 ... 2...<pre>array(['2024-05-31T19:11:23.919000000', '2024-06-03T19:21:19.212000000',\n       '2024-06-05T19:11:28.475000000', '2024-06-08T19:21:23.072000000',\n       '2024-06-10T19:11:26.430000000', '2024-06-13T19:21:20.440000000',\n       '2024-06-15T19:11:29.145000000', '2024-06-18T19:21:22.678000000',\n       '2024-06-20T19:11:25.258000000', '2024-06-23T19:21:20.295000000',\n       '2024-06-25T19:11:26.660000000', '2024-06-28T19:21:20.283000000',\n       '2024-06-30T19:11:27.111000000', '2024-07-03T19:21:21.015000000',\n       '2024-07-05T19:11:26.784000000'], dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (16)<ul><li>coastal(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 7 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>blue(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 7 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>green(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 7 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>red(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 7 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>rededge(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 7 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>rededge2(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 7 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>rededge3(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 7 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>nir(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 7 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>nir08(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 7 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>nir09(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 7 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>swir16(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 7 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>swir22(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 7 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>aot(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 7 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>scl(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;example_plot :&lt;bound method Sentinel2.plot_scl of &lt;easysnowdata.remote_sensing.Sentinel2 object at 0x7f201acd7160&gt;&gt;class_info :{0: {'name': 'No Data (Missing data)', 'color': '#000000'}, 1: {'name': 'Saturated or defective pixel', 'color': '#ff0000'}, 2: {'name': 'Topographic casted shadows', 'color': '#2f2f2f'}, 3: {'name': 'Cloud shadows', 'color': '#643200'}, 4: {'name': 'Vegetation', 'color': '#00a000'}, 5: {'name': 'Not-vegetated', 'color': '#ffe65a'}, 6: {'name': 'Water', 'color': '#0000ff'}, 7: {'name': 'Unclassified', 'color': '#808080'}, 8: {'name': 'Cloud medium probability', 'color': '#c0c0c0'}, 9: {'name': 'Cloud high probability', 'color': '#ffffff'}, 10: {'name': 'Thin cirrus', 'color': '#64c8ff'}, 11: {'name': 'Snow or ice', 'color': '#ff96ff'}}cmap :&lt;matplotlib.colors.ListedColormap object at 0x7f201acd72e0&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 7 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>wvp(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 7 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>visual(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 7 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li></ul></li><li>Indexes: (3)<ul><li>yPandasIndex<pre>PandasIndex(Index([5205880.0, 5205800.0, 5205720.0, 5205640.0, 5205560.0, 5205480.0,\n       5205400.0, 5205320.0, 5205240.0, 5205160.0,\n       ...\n       5176280.0, 5176200.0, 5176120.0, 5176040.0, 5175960.0, 5175880.0,\n       5175800.0, 5175720.0, 5175640.0, 5175560.0],\n      dtype='float64', name='y', length=380))</pre></li><li>xPandasIndex<pre>PandasIndex(Index([580440.0, 580520.0, 580600.0, 580680.0, 580760.0, 580840.0, 580920.0,\n       581000.0, 581080.0, 581160.0,\n       ...\n       610760.0, 610840.0, 610920.0, 611000.0, 611080.0, 611160.0, 611240.0,\n       611320.0, 611400.0, 611480.0],\n      dtype='float64', name='x', length=389))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2024-05-31 19:11:23.919000', '2024-06-03 19:21:19.212000',\n               '2024-06-05 19:11:28.475000', '2024-06-08 19:21:23.072000',\n               '2024-06-10 19:11:26.430000', '2024-06-13 19:21:20.440000',\n               '2024-06-15 19:11:29.145000', '2024-06-18 19:21:22.678000',\n               '2024-06-20 19:11:25.258000', '2024-06-23 19:21:20.295000',\n               '2024-06-25 19:11:26.660000', '2024-06-28 19:21:20.283000',\n               '2024-06-30 19:11:27.111000', '2024-07-03 19:21:21.015000',\n               '2024-07-05 19:11:26.784000'],\n              dtype='datetime64[ns]', name='time', freq=None))</pre></li></ul></li><li>Attributes: (2)band_info :{'B01': {'name': 'coastal', 'description': 'Coastal aerosol, 442.7 nm (S2A), 442.3 nm (S2B)', 'resolution': '60m', 'scale': '0.0001'}, 'B02': {'name': 'blue', 'description': 'Blue, 492.4 nm (S2A), 492.1 nm (S2B)', 'resolution': '10m', 'scale': '0.0001'}, 'B03': {'name': 'green', 'description': 'Green, 559.8 nm (S2A), 559.0 nm (S2B)', 'resolution': '10m', 'scale': '0.0001'}, 'B04': {'name': 'red', 'description': 'Red, 664.6 nm (S2A), 665.0 nm (S2B)', 'resolution': '10m', 'scale': '0.0001'}, 'B05': {'name': 'rededge', 'description': 'Vegetation red edge, 704.1 nm (S2A), 703.8 nm (S2B)', 'resolution': '20m', 'scale': '0.0001'}, 'B06': {'name': 'rededge2', 'description': 'Vegetation red edge, 740.5 nm (S2A), 739.1 nm (S2B)', 'resolution': '20m', 'scale': '0.0001'}, 'B07': {'name': 'rededge3', 'description': 'Vegetation red edge, 782.8 nm (S2A), 779.7 nm (S2B)', 'resolution': '20m', 'scale': '0.0001'}, 'B08': {'name': 'nir', 'description': 'NIR, 832.8 nm (S2A), 833.0 nm (S2B)', 'resolution': '10m', 'scale': '0.0001'}, 'B8A': {'name': 'nir08', 'description': 'Narrow NIR, 864.7 nm (S2A), 864.0 nm (S2B)', 'resolution': '20m', 'scale': '0.0001'}, 'B09': {'name': 'nir09', 'description': 'Water vapour, 945.1 nm (S2A), 943.2 nm (S2B)', 'resolution': '60m', 'scale': '0.0001'}, 'B11': {'name': 'swir16', 'description': 'SWIR, 1613.7 nm (S2A), 1610.4 nm (S2B)', 'resolution': '20m', 'scale': '0.0001'}, 'B12': {'name': 'swir22', 'description': 'SWIR, 2202.4 nm (S2A), 2185.7 nm (S2B)', 'resolution': '20m', 'scale': '0.0001'}, 'AOT': {'name': 'aot', 'description': 'Aerosol Optical Thickness map, based on Sen2Cor processor', 'resolution': '10m', 'scale': '1'}, 'SCL': {'name': 'scl', 'description': 'Scene classification data, based on Sen2Cor processor', 'resolution': '20m', 'scale': '1'}, 'WVP': {'name': 'wvp', 'description': 'Water Vapour map', 'resolution': '10m', 'scale': '1'}, 'visual': {'name': 'visual', 'description': 'True color image', 'resolution': '10m', 'scale': '0.0001'}}scl_class_info :{0: {'name': 'No Data (Missing data)', 'color': '#000000'}, 1: {'name': 'Saturated or defective pixel', 'color': '#ff0000'}, 2: {'name': 'Topographic casted shadows', 'color': '#2f2f2f'}, 3: {'name': 'Cloud shadows', 'color': '#643200'}, 4: {'name': 'Vegetation', 'color': '#00a000'}, 5: {'name': 'Not-vegetated', 'color': '#ffe65a'}, 6: {'name': 'Water', 'color': '#0000ff'}, 7: {'name': 'Unclassified', 'color': '#808080'}, 8: {'name': 'Cloud medium probability', 'color': '#c0c0c0'}, 9: {'name': 'Cloud high probability', 'color': '#ffffff'}, 10: {'name': 'Thin cirrus', 'color': '#64c8ff'}, 11: {'name': 'Snow or ice', 'color': '#ff96ff'}}</li></ul> In\u00a0[4]: Copied! <pre># the earthsearch sentinel-2-c1-l2a catalog does not apply harmonization, easysnowdata will apply to automatically to relevant scenes\ns2_es_c1 = easysnowdata.remote_sensing.Sentinel2(\n    bbox_input=bbox_gdf,\n    start_date=\"2024-05-31\",\n    end_date=\"2024-07-07\",\n    catalog_choice=\"earthsearch\", \n    collection=\"sentinel-2-c1-l2a\", \n    resolution=80,\n)\ns2_es_c1.data\n</pre> # the earthsearch sentinel-2-c1-l2a catalog does not apply harmonization, easysnowdata will apply to automatically to relevant scenes s2_es_c1 = easysnowdata.remote_sensing.Sentinel2(     bbox_input=bbox_gdf,     start_date=\"2024-05-31\",     end_date=\"2024-07-07\",     catalog_choice=\"earthsearch\",      collection=\"sentinel-2-c1-l2a\",      resolution=80, ) s2_es_c1.data <pre>Data searched. Access the returned seach with the .search attribute.\nData retrieved. Access with the .data attribute. Data CRS: WGS 84 / UTM zone 10N.\nNodata values removed from the data. In doing so, all bands converted to float32. To turn this behavior off, set remove_nodata=False.\nData acquired after January 25th, 2022 harmonized to old baseline. To override this behavior, set harmonize_to_old=False.\nData scaled to float reflectance. To turn this behavior off, set scale_data=False.\nMetadata retrieved. Access with the .metadata attribute.\n</pre> Out[4]: <pre>&lt;xarray.Dataset&gt; Size: 142MB\nDimensions:      (time: 15, y: 380, x: 389)\nCoordinates:\n  * y            (y) float64 3kB 5.206e+06 5.206e+06 ... 5.176e+06 5.176e+06\n  * x            (x) float64 3kB 5.804e+05 5.805e+05 ... 6.114e+05 6.115e+05\n    spatial_ref  int32 4B 32610\n  * time         (time) datetime64[ns] 120B 2024-05-31T19:11:23.919000 ... 20...\nData variables: (12/16)\n    coastal      (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    blue         (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    green        (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    red          (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    rededge      (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    rededge2     (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    ...           ...\n    swir16       (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    swir22       (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    aot          (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    scl          (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    wvp          (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    visual       (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\nAttributes:\n    band_info:       {'B01': {'name': 'coastal', 'description': 'Coastal aero...\n    scl_class_info:  {0: {'name': 'No Data (Missing data)', 'color': '#000000...</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>time: 15</li><li>y: 380</li><li>x: 389</li></ul></li><li>Coordinates: (4)<ul><li>y(y)float645.206e+06 5.206e+06 ... 5.176e+06units :metreresolution :-80.0crs :EPSG:32610<pre>array([5205880., 5205800., 5205720., ..., 5175720., 5175640., 5175560.])</pre></li><li>x(x)float645.804e+05 5.805e+05 ... 6.115e+05units :metreresolution :80.0crs :EPSG:32610<pre>array([580440., 580520., 580600., ..., 611320., 611400., 611480.])</pre></li><li>spatial_ref()int3232610spatial_ref :PROJCRS[\"WGS 84 / UTM zone 10N\",BASEGEOGCRS[\"WGS 84\",ENSEMBLE[\"World Geodetic System 1984 ensemble\",MEMBER[\"World Geodetic System 1984 (Transit)\"],MEMBER[\"World Geodetic System 1984 (G730)\"],MEMBER[\"World Geodetic System 1984 (G873)\"],MEMBER[\"World Geodetic System 1984 (G1150)\"],MEMBER[\"World Geodetic System 1984 (G1674)\"],MEMBER[\"World Geodetic System 1984 (G1762)\"],MEMBER[\"World Geodetic System 1984 (G2139)\"],MEMBER[\"World Geodetic System 1984 (G2296)\"],ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]],ENSEMBLEACCURACY[2.0]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"UTM zone 10N\",METHOD[\"Transverse Mercator\",ID[\"EPSG\",9807]],PARAMETER[\"Latitude of natural origin\",0,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",-123,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"Scale factor at natural origin\",0.9996,SCALEUNIT[\"unity\",1],ID[\"EPSG\",8805]],PARAMETER[\"False easting\",500000,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",0,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1]],USAGE[SCOPE[\"Navigation and medium accuracy spatial referencing.\"],AREA[\"Between 126\u00b0W and 120\u00b0W, northern hemisphere between equator and 84\u00b0N, onshore and offshore. Canada - British Columbia (BC); Northwest Territories (NWT); Nunavut; Yukon. United States (USA) - Alaska (AK).\"],BBOX[0,-126,84,-120]],ID[\"EPSG\",32610]]crs_wkt :PROJCRS[\"WGS 84 / UTM zone 10N\",BASEGEOGCRS[\"WGS 84\",ENSEMBLE[\"World Geodetic System 1984 ensemble\",MEMBER[\"World Geodetic System 1984 (Transit)\"],MEMBER[\"World Geodetic System 1984 (G730)\"],MEMBER[\"World Geodetic System 1984 (G873)\"],MEMBER[\"World Geodetic System 1984 (G1150)\"],MEMBER[\"World Geodetic System 1984 (G1674)\"],MEMBER[\"World Geodetic System 1984 (G1762)\"],MEMBER[\"World Geodetic System 1984 (G2139)\"],MEMBER[\"World Geodetic System 1984 (G2296)\"],ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]],ENSEMBLEACCURACY[2.0]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"UTM zone 10N\",METHOD[\"Transverse Mercator\",ID[\"EPSG\",9807]],PARAMETER[\"Latitude of natural origin\",0,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",-123,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"Scale factor at natural origin\",0.9996,SCALEUNIT[\"unity\",1],ID[\"EPSG\",8805]],PARAMETER[\"False easting\",500000,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",0,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1]],USAGE[SCOPE[\"Navigation and medium accuracy spatial referencing.\"],AREA[\"Between 126\u00b0W and 120\u00b0W, northern hemisphere between equator and 84\u00b0N, onshore and offshore. Canada - British Columbia (BC); Northwest Territories (NWT); Nunavut; Yukon. United States (USA) - Alaska (AK).\"],BBOX[0,-126,84,-120]],ID[\"EPSG\",32610]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984 ensembleprojected_crs_name :WGS 84 / UTM zone 10Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-123.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996GeoTransform :580400 80 0 5205920 0 -80<pre>array(32610, dtype=int32)</pre></li><li>time(time)datetime64[ns]2024-05-31T19:11:23.919000 ... 2...<pre>array(['2024-05-31T19:11:23.919000000', '2024-06-03T19:21:19.212000000',\n       '2024-06-05T19:11:28.475000000', '2024-06-08T19:21:23.072000000',\n       '2024-06-10T19:11:26.430000000', '2024-06-13T19:21:20.440000000',\n       '2024-06-15T19:11:29.145000000', '2024-06-18T19:21:22.678000000',\n       '2024-06-20T19:11:25.258000000', '2024-06-23T19:21:20.295000000',\n       '2024-06-25T19:11:26.660000000', '2024-06-28T19:21:20.283000000',\n       '2024-06-30T19:11:27.111000000', '2024-07-03T19:21:21.015000000',\n       '2024-07-05T19:11:26.784000000'], dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (16)<ul><li>coastal(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 9 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>blue(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 9 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>green(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 9 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>red(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 9 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>rededge(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 9 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>rededge2(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 9 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>rededge3(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 9 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>nir(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 9 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>nir08(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 9 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>nir09(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 9 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>swir16(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 9 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>swir22(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 9 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>aot(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 7 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>scl(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;example_plot :&lt;bound method Sentinel2.plot_scl of &lt;easysnowdata.remote_sensing.Sentinel2 object at 0x7f2019d25840&gt;&gt;class_info :{0: {'name': 'No Data (Missing data)', 'color': '#000000'}, 1: {'name': 'Saturated or defective pixel', 'color': '#ff0000'}, 2: {'name': 'Topographic casted shadows', 'color': '#2f2f2f'}, 3: {'name': 'Cloud shadows', 'color': '#643200'}, 4: {'name': 'Vegetation', 'color': '#00a000'}, 5: {'name': 'Not-vegetated', 'color': '#ffe65a'}, 6: {'name': 'Water', 'color': '#0000ff'}, 7: {'name': 'Unclassified', 'color': '#808080'}, 8: {'name': 'Cloud medium probability', 'color': '#c0c0c0'}, 9: {'name': 'Cloud high probability', 'color': '#ffffff'}, 10: {'name': 'Thin cirrus', 'color': '#64c8ff'}, 11: {'name': 'Snow or ice', 'color': '#ff96ff'}}cmap :&lt;matplotlib.colors.ListedColormap object at 0x7f2019d39750&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 7 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>wvp(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 7 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>visual(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 7 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li></ul></li><li>Indexes: (3)<ul><li>yPandasIndex<pre>PandasIndex(Index([5205880.0, 5205800.0, 5205720.0, 5205640.0, 5205560.0, 5205480.0,\n       5205400.0, 5205320.0, 5205240.0, 5205160.0,\n       ...\n       5176280.0, 5176200.0, 5176120.0, 5176040.0, 5175960.0, 5175880.0,\n       5175800.0, 5175720.0, 5175640.0, 5175560.0],\n      dtype='float64', name='y', length=380))</pre></li><li>xPandasIndex<pre>PandasIndex(Index([580440.0, 580520.0, 580600.0, 580680.0, 580760.0, 580840.0, 580920.0,\n       581000.0, 581080.0, 581160.0,\n       ...\n       610760.0, 610840.0, 610920.0, 611000.0, 611080.0, 611160.0, 611240.0,\n       611320.0, 611400.0, 611480.0],\n      dtype='float64', name='x', length=389))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2024-05-31 19:11:23.919000', '2024-06-03 19:21:19.212000',\n               '2024-06-05 19:11:28.475000', '2024-06-08 19:21:23.072000',\n               '2024-06-10 19:11:26.430000', '2024-06-13 19:21:20.440000',\n               '2024-06-15 19:11:29.145000', '2024-06-18 19:21:22.678000',\n               '2024-06-20 19:11:25.258000', '2024-06-23 19:21:20.295000',\n               '2024-06-25 19:11:26.660000', '2024-06-28 19:21:20.283000',\n               '2024-06-30 19:11:27.111000', '2024-07-03 19:21:21.015000',\n               '2024-07-05 19:11:26.784000'],\n              dtype='datetime64[ns]', name='time', freq=None))</pre></li></ul></li><li>Attributes: (2)band_info :{'B01': {'name': 'coastal', 'description': 'Coastal aerosol, 442.7 nm (S2A), 442.3 nm (S2B)', 'resolution': '60m', 'scale': '0.0001'}, 'B02': {'name': 'blue', 'description': 'Blue, 492.4 nm (S2A), 492.1 nm (S2B)', 'resolution': '10m', 'scale': '0.0001'}, 'B03': {'name': 'green', 'description': 'Green, 559.8 nm (S2A), 559.0 nm (S2B)', 'resolution': '10m', 'scale': '0.0001'}, 'B04': {'name': 'red', 'description': 'Red, 664.6 nm (S2A), 665.0 nm (S2B)', 'resolution': '10m', 'scale': '0.0001'}, 'B05': {'name': 'rededge', 'description': 'Vegetation red edge, 704.1 nm (S2A), 703.8 nm (S2B)', 'resolution': '20m', 'scale': '0.0001'}, 'B06': {'name': 'rededge2', 'description': 'Vegetation red edge, 740.5 nm (S2A), 739.1 nm (S2B)', 'resolution': '20m', 'scale': '0.0001'}, 'B07': {'name': 'rededge3', 'description': 'Vegetation red edge, 782.8 nm (S2A), 779.7 nm (S2B)', 'resolution': '20m', 'scale': '0.0001'}, 'B08': {'name': 'nir', 'description': 'NIR, 832.8 nm (S2A), 833.0 nm (S2B)', 'resolution': '10m', 'scale': '0.0001'}, 'B8A': {'name': 'nir08', 'description': 'Narrow NIR, 864.7 nm (S2A), 864.0 nm (S2B)', 'resolution': '20m', 'scale': '0.0001'}, 'B09': {'name': 'nir09', 'description': 'Water vapour, 945.1 nm (S2A), 943.2 nm (S2B)', 'resolution': '60m', 'scale': '0.0001'}, 'B11': {'name': 'swir16', 'description': 'SWIR, 1613.7 nm (S2A), 1610.4 nm (S2B)', 'resolution': '20m', 'scale': '0.0001'}, 'B12': {'name': 'swir22', 'description': 'SWIR, 2202.4 nm (S2A), 2185.7 nm (S2B)', 'resolution': '20m', 'scale': '0.0001'}, 'AOT': {'name': 'aot', 'description': 'Aerosol Optical Thickness map, based on Sen2Cor processor', 'resolution': '10m', 'scale': '1'}, 'SCL': {'name': 'scl', 'description': 'Scene classification data, based on Sen2Cor processor', 'resolution': '20m', 'scale': '1'}, 'WVP': {'name': 'wvp', 'description': 'Water Vapour map', 'resolution': '10m', 'scale': '1'}, 'visual': {'name': 'visual', 'description': 'True color image', 'resolution': '10m', 'scale': '0.0001'}}scl_class_info :{0: {'name': 'No Data (Missing data)', 'color': '#000000'}, 1: {'name': 'Saturated or defective pixel', 'color': '#ff0000'}, 2: {'name': 'Topographic casted shadows', 'color': '#2f2f2f'}, 3: {'name': 'Cloud shadows', 'color': '#643200'}, 4: {'name': 'Vegetation', 'color': '#00a000'}, 5: {'name': 'Not-vegetated', 'color': '#ffe65a'}, 6: {'name': 'Water', 'color': '#0000ff'}, 7: {'name': 'Unclassified', 'color': '#808080'}, 8: {'name': 'Cloud medium probability', 'color': '#c0c0c0'}, 9: {'name': 'Cloud high probability', 'color': '#ffffff'}, 10: {'name': 'Thin cirrus', 'color': '#64c8ff'}, 11: {'name': 'Snow or ice', 'color': '#ff96ff'}}</li></ul> In\u00a0[5]: Copied! <pre># the planetarycomputer sentinel-2-c1-l2a catalog does not apply harmonization, easysnowdata will apply to automatically to relevant scenes\ns2_pc = easysnowdata.remote_sensing.Sentinel2(\n    bbox_input=bbox_gdf,\n    start_date=\"2024-05-31\",\n    end_date=\"2024-07-07\",\n    catalog_choice=\"planetarycomputer\",\n    resolution=80,\n)\ns2_pc.data\n</pre> # the planetarycomputer sentinel-2-c1-l2a catalog does not apply harmonization, easysnowdata will apply to automatically to relevant scenes s2_pc = easysnowdata.remote_sensing.Sentinel2(     bbox_input=bbox_gdf,     start_date=\"2024-05-31\",     end_date=\"2024-07-07\",     catalog_choice=\"planetarycomputer\",     resolution=80, ) s2_pc.data <pre>Data searched. Access the returned seach with the .search attribute.\nData retrieved. Access with the .data attribute. Data CRS: WGS 84 / UTM zone 10N.\nNodata values removed from the data. In doing so, all bands converted to float32. To turn this behavior off, set remove_nodata=False.\nData acquired after January 25th, 2022 harmonized to old baseline. To override this behavior, set harmonize_to_old=False.\nData scaled to float reflectance. To turn this behavior off, set scale_data=False.\nMetadata retrieved. Access with the .metadata attribute.\n</pre> Out[5]: <pre>&lt;xarray.Dataset&gt; Size: 142MB\nDimensions:      (time: 15, y: 380, x: 389)\nCoordinates:\n  * y            (y) float64 3kB 5.206e+06 5.206e+06 ... 5.176e+06 5.176e+06\n  * x            (x) float64 3kB 5.804e+05 5.805e+05 ... 6.114e+05 6.115e+05\n    spatial_ref  int32 4B 32610\n  * time         (time) datetime64[ns] 120B 2024-05-31T18:59:19.024000 ... 20...\nData variables: (12/16)\n    coastal      (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    blue         (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    green        (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    red          (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    rededge      (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    rededge2     (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    ...           ...\n    swir16       (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    swir22       (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    aot          (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    scl          (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    wvp          (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\n    visual       (time, y, x) float32 9MB dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;\nAttributes:\n    band_info:       {'B01': {'name': 'coastal', 'description': 'Coastal aero...\n    scl_class_info:  {0: {'name': 'No Data (Missing data)', 'color': '#000000...</pre>xarray.Dataset<ul><li>Dimensions:<ul><li>time: 15</li><li>y: 380</li><li>x: 389</li></ul></li><li>Coordinates: (4)<ul><li>y(y)float645.206e+06 5.206e+06 ... 5.176e+06units :metreresolution :-80.0crs :EPSG:32610<pre>array([5205880., 5205800., 5205720., ..., 5175720., 5175640., 5175560.])</pre></li><li>x(x)float645.804e+05 5.805e+05 ... 6.115e+05units :metreresolution :80.0crs :EPSG:32610<pre>array([580440., 580520., 580600., ..., 611320., 611400., 611480.])</pre></li><li>spatial_ref()int3232610spatial_ref :PROJCRS[\"WGS 84 / UTM zone 10N\",BASEGEOGCRS[\"WGS 84\",ENSEMBLE[\"World Geodetic System 1984 ensemble\",MEMBER[\"World Geodetic System 1984 (Transit)\"],MEMBER[\"World Geodetic System 1984 (G730)\"],MEMBER[\"World Geodetic System 1984 (G873)\"],MEMBER[\"World Geodetic System 1984 (G1150)\"],MEMBER[\"World Geodetic System 1984 (G1674)\"],MEMBER[\"World Geodetic System 1984 (G1762)\"],MEMBER[\"World Geodetic System 1984 (G2139)\"],MEMBER[\"World Geodetic System 1984 (G2296)\"],ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]],ENSEMBLEACCURACY[2.0]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"UTM zone 10N\",METHOD[\"Transverse Mercator\",ID[\"EPSG\",9807]],PARAMETER[\"Latitude of natural origin\",0,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",-123,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"Scale factor at natural origin\",0.9996,SCALEUNIT[\"unity\",1],ID[\"EPSG\",8805]],PARAMETER[\"False easting\",500000,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",0,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1]],USAGE[SCOPE[\"Navigation and medium accuracy spatial referencing.\"],AREA[\"Between 126\u00b0W and 120\u00b0W, northern hemisphere between equator and 84\u00b0N, onshore and offshore. Canada - British Columbia (BC); Northwest Territories (NWT); Nunavut; Yukon. United States (USA) - Alaska (AK).\"],BBOX[0,-126,84,-120]],ID[\"EPSG\",32610]]crs_wkt :PROJCRS[\"WGS 84 / UTM zone 10N\",BASEGEOGCRS[\"WGS 84\",ENSEMBLE[\"World Geodetic System 1984 ensemble\",MEMBER[\"World Geodetic System 1984 (Transit)\"],MEMBER[\"World Geodetic System 1984 (G730)\"],MEMBER[\"World Geodetic System 1984 (G873)\"],MEMBER[\"World Geodetic System 1984 (G1150)\"],MEMBER[\"World Geodetic System 1984 (G1674)\"],MEMBER[\"World Geodetic System 1984 (G1762)\"],MEMBER[\"World Geodetic System 1984 (G2139)\"],MEMBER[\"World Geodetic System 1984 (G2296)\"],ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]],ENSEMBLEACCURACY[2.0]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"UTM zone 10N\",METHOD[\"Transverse Mercator\",ID[\"EPSG\",9807]],PARAMETER[\"Latitude of natural origin\",0,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",-123,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"Scale factor at natural origin\",0.9996,SCALEUNIT[\"unity\",1],ID[\"EPSG\",8805]],PARAMETER[\"False easting\",500000,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",0,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1]],USAGE[SCOPE[\"Navigation and medium accuracy spatial referencing.\"],AREA[\"Between 126\u00b0W and 120\u00b0W, northern hemisphere between equator and 84\u00b0N, onshore and offshore. Canada - British Columbia (BC); Northwest Territories (NWT); Nunavut; Yukon. United States (USA) - Alaska (AK).\"],BBOX[0,-126,84,-120]],ID[\"EPSG\",32610]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984 ensembleprojected_crs_name :WGS 84 / UTM zone 10Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-123.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996GeoTransform :580400 80 0 5205920 0 -80<pre>array(32610, dtype=int32)</pre></li><li>time(time)datetime64[ns]2024-05-31T18:59:19.024000 ... 2...<pre>array(['2024-05-31T18:59:19.024000000', '2024-06-03T19:09:19.024000000',\n       '2024-06-05T18:59:21.024000000', '2024-06-08T19:09:21.024000000',\n       '2024-06-10T18:59:19.024000000', '2024-06-13T19:09:19.024000000',\n       '2024-06-15T18:59:21.024000000', '2024-06-18T19:09:21.024000000',\n       '2024-06-20T18:59:19.024000000', '2024-06-23T19:09:19.024000000',\n       '2024-06-25T18:59:41.024000000', '2024-06-28T19:09:21.024000000',\n       '2024-06-30T18:59:19.024000000', '2024-07-03T19:09:19.024000000',\n       '2024-07-05T18:59:21.024000000'], dtype='datetime64[ns]')</pre></li></ul></li><li>Data variables: (16)<ul><li>coastal(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 9 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>blue(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 9 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>green(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 9 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>red(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 9 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>rededge(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 9 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>rededge2(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 9 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>rededge3(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 9 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>nir(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 9 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>nir08(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 9 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>nir09(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 9 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>swir16(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 9 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>swir22(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 9 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>aot(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 7 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>scl(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;example_plot :&lt;bound method Sentinel2.plot_scl of &lt;easysnowdata.remote_sensing.Sentinel2 object at 0x7f20184a7100&gt;&gt;class_info :{0: {'name': 'No Data (Missing data)', 'color': '#000000'}, 1: {'name': 'Saturated or defective pixel', 'color': '#ff0000'}, 2: {'name': 'Topographic casted shadows', 'color': '#2f2f2f'}, 3: {'name': 'Cloud shadows', 'color': '#643200'}, 4: {'name': 'Vegetation', 'color': '#00a000'}, 5: {'name': 'Not-vegetated', 'color': '#ffe65a'}, 6: {'name': 'Water', 'color': '#0000ff'}, 7: {'name': 'Unclassified', 'color': '#808080'}, 8: {'name': 'Cloud medium probability', 'color': '#c0c0c0'}, 9: {'name': 'Cloud high probability', 'color': '#ffffff'}, 10: {'name': 'Thin cirrus', 'color': '#64c8ff'}, 11: {'name': 'Snow or ice', 'color': '#ff96ff'}}cmap :&lt;matplotlib.colors.ListedColormap object at 0x7f2019d27760&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 7 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>wvp(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 7 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li><li>visual(time, y, x)float32dask.array&lt;chunksize=(1, 380, 389), meta=np.ndarray&gt;  Array   Chunk   Bytes   8.46 MiB   577.42 kiB   Shape   (15, 380, 389)   (1, 380, 389)   Dask graph   15 chunks in 7 graph layers   Data type   float32 numpy.ndarray  389 380 15 </li></ul></li><li>Indexes: (3)<ul><li>yPandasIndex<pre>PandasIndex(Index([5205880.0, 5205800.0, 5205720.0, 5205640.0, 5205560.0, 5205480.0,\n       5205400.0, 5205320.0, 5205240.0, 5205160.0,\n       ...\n       5176280.0, 5176200.0, 5176120.0, 5176040.0, 5175960.0, 5175880.0,\n       5175800.0, 5175720.0, 5175640.0, 5175560.0],\n      dtype='float64', name='y', length=380))</pre></li><li>xPandasIndex<pre>PandasIndex(Index([580440.0, 580520.0, 580600.0, 580680.0, 580760.0, 580840.0, 580920.0,\n       581000.0, 581080.0, 581160.0,\n       ...\n       610760.0, 610840.0, 610920.0, 611000.0, 611080.0, 611160.0, 611240.0,\n       611320.0, 611400.0, 611480.0],\n      dtype='float64', name='x', length=389))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2024-05-31 18:59:19.024000', '2024-06-03 19:09:19.024000',\n               '2024-06-05 18:59:21.024000', '2024-06-08 19:09:21.024000',\n               '2024-06-10 18:59:19.024000', '2024-06-13 19:09:19.024000',\n               '2024-06-15 18:59:21.024000', '2024-06-18 19:09:21.024000',\n               '2024-06-20 18:59:19.024000', '2024-06-23 19:09:19.024000',\n               '2024-06-25 18:59:41.024000', '2024-06-28 19:09:21.024000',\n               '2024-06-30 18:59:19.024000', '2024-07-03 19:09:19.024000',\n               '2024-07-05 18:59:21.024000'],\n              dtype='datetime64[ns]', name='time', freq=None))</pre></li></ul></li><li>Attributes: (2)band_info :{'B01': {'name': 'coastal', 'description': 'Coastal aerosol, 442.7 nm (S2A), 442.3 nm (S2B)', 'resolution': '60m', 'scale': '0.0001'}, 'B02': {'name': 'blue', 'description': 'Blue, 492.4 nm (S2A), 492.1 nm (S2B)', 'resolution': '10m', 'scale': '0.0001'}, 'B03': {'name': 'green', 'description': 'Green, 559.8 nm (S2A), 559.0 nm (S2B)', 'resolution': '10m', 'scale': '0.0001'}, 'B04': {'name': 'red', 'description': 'Red, 664.6 nm (S2A), 665.0 nm (S2B)', 'resolution': '10m', 'scale': '0.0001'}, 'B05': {'name': 'rededge', 'description': 'Vegetation red edge, 704.1 nm (S2A), 703.8 nm (S2B)', 'resolution': '20m', 'scale': '0.0001'}, 'B06': {'name': 'rededge2', 'description': 'Vegetation red edge, 740.5 nm (S2A), 739.1 nm (S2B)', 'resolution': '20m', 'scale': '0.0001'}, 'B07': {'name': 'rededge3', 'description': 'Vegetation red edge, 782.8 nm (S2A), 779.7 nm (S2B)', 'resolution': '20m', 'scale': '0.0001'}, 'B08': {'name': 'nir', 'description': 'NIR, 832.8 nm (S2A), 833.0 nm (S2B)', 'resolution': '10m', 'scale': '0.0001'}, 'B8A': {'name': 'nir08', 'description': 'Narrow NIR, 864.7 nm (S2A), 864.0 nm (S2B)', 'resolution': '20m', 'scale': '0.0001'}, 'B09': {'name': 'nir09', 'description': 'Water vapour, 945.1 nm (S2A), 943.2 nm (S2B)', 'resolution': '60m', 'scale': '0.0001'}, 'B11': {'name': 'swir16', 'description': 'SWIR, 1613.7 nm (S2A), 1610.4 nm (S2B)', 'resolution': '20m', 'scale': '0.0001'}, 'B12': {'name': 'swir22', 'description': 'SWIR, 2202.4 nm (S2A), 2185.7 nm (S2B)', 'resolution': '20m', 'scale': '0.0001'}, 'AOT': {'name': 'aot', 'description': 'Aerosol Optical Thickness map, based on Sen2Cor processor', 'resolution': '10m', 'scale': '1'}, 'SCL': {'name': 'scl', 'description': 'Scene classification data, based on Sen2Cor processor', 'resolution': '20m', 'scale': '1'}, 'WVP': {'name': 'wvp', 'description': 'Water Vapour map', 'resolution': '10m', 'scale': '1'}, 'visual': {'name': 'visual', 'description': 'True color image', 'resolution': '10m', 'scale': '0.0001'}}scl_class_info :{0: {'name': 'No Data (Missing data)', 'color': '#000000'}, 1: {'name': 'Saturated or defective pixel', 'color': '#ff0000'}, 2: {'name': 'Topographic casted shadows', 'color': '#2f2f2f'}, 3: {'name': 'Cloud shadows', 'color': '#643200'}, 4: {'name': 'Vegetation', 'color': '#00a000'}, 5: {'name': 'Not-vegetated', 'color': '#ffe65a'}, 6: {'name': 'Water', 'color': '#0000ff'}, 7: {'name': 'Unclassified', 'color': '#808080'}, 8: {'name': 'Cloud medium probability', 'color': '#c0c0c0'}, 9: {'name': 'Cloud high probability', 'color': '#ffffff'}, 10: {'name': 'Thin cirrus', 'color': '#64c8ff'}, 11: {'name': 'Snow or ice', 'color': '#ff96ff'}}</li></ul> In\u00a0[6]: Copied! <pre>red_es = s2_es.data.red.isel(time=0).compute()\nred_values_es = red_es.values.flatten()\n\nred_es_c1 = s2_es_c1.data.red.isel(time=0).compute()\nred_values_es_c1 = red_es_c1.values.flatten()\n\nred_pc = s2_pc.data.red.isel(time=0).compute()\nred_values_pc = red_pc.values.flatten()\n</pre> red_es = s2_es.data.red.isel(time=0).compute() red_values_es = red_es.values.flatten()  red_es_c1 = s2_es_c1.data.red.isel(time=0).compute() red_values_es_c1 = red_es_c1.values.flatten()  red_pc = s2_pc.data.red.isel(time=0).compute() red_values_pc = red_pc.values.flatten() In\u00a0[7]: Copied! <pre>f,axs=plt.subplots(1,3,figsize=(17,5),dpi=300, sharex=True,sharey=True)\n\nred_es.plot(ax=axs[0],vmin=0,vmax=1.3)\naxs[0].set_title(\"EarthSearch [sentinel-2-l2a]\")\n\nred_es_c1.plot(ax=axs[1],vmin=0,vmax=1.3)\naxs[1].set_title(\"EarthSearch [sentinel-2-c1-l2a]\")\n\nred_pc.plot(ax=axs[2],vmin=0,vmax=1.3)\naxs[2].set_title(\"Planetary Computer\")\n\n\nfor ax in axs:\n    ax.set_aspect(\"equal\")\n    ax.axis('off')\n</pre> f,axs=plt.subplots(1,3,figsize=(17,5),dpi=300, sharex=True,sharey=True)  red_es.plot(ax=axs[0],vmin=0,vmax=1.3) axs[0].set_title(\"EarthSearch [sentinel-2-l2a]\")  red_es_c1.plot(ax=axs[1],vmin=0,vmax=1.3) axs[1].set_title(\"EarthSearch [sentinel-2-c1-l2a]\")  red_pc.plot(ax=axs[2],vmin=0,vmax=1.3) axs[2].set_title(\"Planetary Computer\")   for ax in axs:     ax.set_aspect(\"equal\")     ax.axis('off') In\u00a0[8]: Copied! <pre>f,axs=plt.subplots(3,1,sharex=True, figsize=(10,6))\n\naxs[0].hist(red_values_es, bins=100, color=\"r\", alpha=0.5, label=\"red\")\naxs[0].set_title(\"EarthSearch [sentinel-2-l2a]\")\n\naxs[1].hist(red_values_es_c1, bins=100, color=\"r\", alpha=0.5, label=\"red\")\naxs[1].set_title(\"EarthSearch [sentinel-2-c1-l2a]\")\n\naxs[2].hist(red_values_pc, bins=100, color=\"r\", alpha=0.5, label=\"red\")\naxs[2].set_title(\"Planetary Computer\")\n</pre> f,axs=plt.subplots(3,1,sharex=True, figsize=(10,6))  axs[0].hist(red_values_es, bins=100, color=\"r\", alpha=0.5, label=\"red\") axs[0].set_title(\"EarthSearch [sentinel-2-l2a]\")  axs[1].hist(red_values_es_c1, bins=100, color=\"r\", alpha=0.5, label=\"red\") axs[1].set_title(\"EarthSearch [sentinel-2-c1-l2a]\")  axs[2].hist(red_values_pc, bins=100, color=\"r\", alpha=0.5, label=\"red\") axs[2].set_title(\"Planetary Computer\") Out[8]: <pre>Text(0.5, 1.0, 'Planetary Computer')</pre> In\u00a0[9]: Copied! <pre>for catalog,values in zip([\"EarthSearch [sentinel-2-l2a]\",\"EarthSearch [sentinel-2-c1-l2a]\",\"Planetary Computer\"],[red_values_es,red_values_es_c1,red_values_pc]):\n    print(f'{catalog}:\\nmin: {np.nanmin(values)}\\nmax: {np.nanmax(values)}\\nmean: {np.nanmean(values)}\\nmedian: {np.nanmedian(values)}\\nstd: {np.nanstd(values)}')\n    print('--------------------------------------')\n</pre> for catalog,values in zip([\"EarthSearch [sentinel-2-l2a]\",\"EarthSearch [sentinel-2-c1-l2a]\",\"Planetary Computer\"],[red_values_es,red_values_es_c1,red_values_pc]):     print(f'{catalog}:\\nmin: {np.nanmin(values)}\\nmax: {np.nanmax(values)}\\nmean: {np.nanmean(values)}\\nmedian: {np.nanmedian(values)}\\nstd: {np.nanstd(values)}')     print('--------------------------------------') <pre>EarthSearch [sentinel-2-l2a]:\nmin: 9.999999747378752e-05\nmax: 1.226099967956543\nmean: 0.27552714943885803\nmedian: 0.06889999657869339\nstd: 0.3256163001060486\n--------------------------------------\nEarthSearch [sentinel-2-c1-l2a]:\nmin: 0.0\nmax: 1.3184999227523804\nmean: 0.2744519114494324\nmedian: 0.06579999625682831\nstd: 0.32932907342910767\n--------------------------------------\nPlanetary Computer:\nmin: 0.0\nmax: 1.6401000022888184\nmean: 0.2732629179954529\nmedian: 0.05719999969005585\nstd: 0.3429371118545532\n--------------------------------------\n</pre> In\u00a0[10]: Copied! <pre>s2_es.get_rgb()\ns2_es_c1.get_rgb()\ns2_pc.get_rgb()\n</pre> s2_es.get_rgb() s2_es_c1.get_rgb() s2_pc.get_rgb() <pre>RGB data retrieved.\nAccess with the following attributes:\n.rgb for raw RGB,\n.rgba for RGBA,\n.rgb_percentile for percentile RGB,\n.rgb_clahe for CLAHE RGB.\nYou can pass in percentile_kwargs and clahe_kwargs to adjust RGB calculations, check documentation for options.\nRGB data retrieved.\nAccess with the following attributes:\n.rgb for raw RGB,\n.rgba for RGBA,\n.rgb_percentile for percentile RGB,\n.rgb_clahe for CLAHE RGB.\nYou can pass in percentile_kwargs and clahe_kwargs to adjust RGB calculations, check documentation for options.\nRGB data retrieved.\nAccess with the following attributes:\n.rgb for raw RGB,\n.rgba for RGBA,\n.rgb_percentile for percentile RGB,\n.rgb_clahe for CLAHE RGB.\nYou can pass in percentile_kwargs and clahe_kwargs to adjust RGB calculations, check documentation for options.\n</pre> <pre>/home/eric/miniconda3/envs/easysnowdata/lib/python3.10/site-packages/rasterio/warp.py:344: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n  _reproject(\n</pre> In\u00a0[11]: Copied! <pre>f,axs=plt.subplots(1,3,figsize=(17,5),dpi=300, sharex=True,sharey=True)\n\ns2_es.rgb.isel(time=0).plot.imshow(ax=axs[0],robust=True)\naxs[0].set_title(\"EarthSearch [sentinel-2-l2a]\")\n\ns2_es_c1.rgb.isel(time=0).plot.imshow(ax=axs[1],robust=True)\naxs[1].set_title(\"EarthSearch [sentinel-2-c1-l2a]\")\n\ns2_pc.rgb.isel(time=0).plot.imshow(ax=axs[2],robust=True)\naxs[2].set_title(\"Planetary Computer\")\n\n\nfor ax in axs:\n    ax.set_aspect(\"equal\")\n    ax.axis('off')\n</pre> f,axs=plt.subplots(1,3,figsize=(17,5),dpi=300, sharex=True,sharey=True)  s2_es.rgb.isel(time=0).plot.imshow(ax=axs[0],robust=True) axs[0].set_title(\"EarthSearch [sentinel-2-l2a]\")  s2_es_c1.rgb.isel(time=0).plot.imshow(ax=axs[1],robust=True) axs[1].set_title(\"EarthSearch [sentinel-2-c1-l2a]\")  s2_pc.rgb.isel(time=0).plot.imshow(ax=axs[2],robust=True) axs[2].set_title(\"Planetary Computer\")   for ax in axs:     ax.set_aspect(\"equal\")     ax.axis('off') In\u00a0[12]: Copied! <pre>f,axs=plt.subplots(1,3,figsize=(17,5),dpi=300, sharex=True,sharey=True)\n\ns2_es.rgb_clahe.isel(time=0).plot.imshow(ax=axs[0],robust=True)\naxs[0].set_title(\"EarthSearch [sentinel-2-l2a]\")\n\ns2_es_c1.rgb_clahe.isel(time=0).plot.imshow(ax=axs[1],robust=True)\naxs[1].set_title(\"EarthSearch [sentinel-2-c1-l2a]\")\n\ns2_pc.rgb_clahe.isel(time=0).plot.imshow(ax=axs[2],robust=True)\naxs[2].set_title(\"Planetary Computer\")\n\n\nfor ax in axs:\n    ax.set_aspect(\"equal\")\n    ax.axis('off')\n</pre> f,axs=plt.subplots(1,3,figsize=(17,5),dpi=300, sharex=True,sharey=True)  s2_es.rgb_clahe.isel(time=0).plot.imshow(ax=axs[0],robust=True) axs[0].set_title(\"EarthSearch [sentinel-2-l2a]\")  s2_es_c1.rgb_clahe.isel(time=0).plot.imshow(ax=axs[1],robust=True) axs[1].set_title(\"EarthSearch [sentinel-2-c1-l2a]\")  s2_pc.rgb_clahe.isel(time=0).plot.imshow(ax=axs[2],robust=True) axs[2].set_title(\"Planetary Computer\")   for ax in axs:     ax.set_aspect(\"equal\")     ax.axis('off') In\u00a0[13]: Copied! <pre>%%time\ns2_es = easysnowdata.remote_sensing.Sentinel2(\n    bbox_input=bbox_gdf,\n    start_date=\"2024-01-01\",\n    end_date=\"2024-09-30\",\n    catalog_choice=\"earthsearch\", \n    resolution=80,\n)\ns2_es.data['red'].compute()\n</pre> %%time s2_es = easysnowdata.remote_sensing.Sentinel2(     bbox_input=bbox_gdf,     start_date=\"2024-01-01\",     end_date=\"2024-09-30\",     catalog_choice=\"earthsearch\",      resolution=80, ) s2_es.data['red'].compute() <pre>Data searched. Access the returned seach with the .search attribute.\nData retrieved. Access with the .data attribute. Data CRS: WGS 84 / UTM zone 10N.\nNodata values removed from the data. In doing so, all bands converted to float32. To turn this behavior off, set remove_nodata=False.\nSince sentinel-2-l2a on earthsearch is used, harmonization step is not needed.\nData scaled to float reflectance. To turn this behavior off, set scale_data=False.\nMetadata retrieved. Access with the .metadata attribute.\nCPU times: user 15.3 s, sys: 3.23 s, total: 18.6 s\nWall time: 3min 19s\n</pre> Out[13]: <pre>&lt;xarray.DataArray 'red' (time: 109, y: 380, x: 389)&gt; Size: 64MB\narray([[[0.5392    , 0.5367    , 0.5361    , ..., 0.7388    ,\n         0.726     , 0.7132    ],\n        [0.53709996, 0.5329    , 0.53319997, ..., 0.7499    ,\n         0.73469996, 0.72099996],\n        [0.536     , 0.5323    , 0.5352    , ..., 0.7637    ,\n         0.7489    , 0.73579997],\n        ...,\n        [0.8339    , 0.8348    , 0.83489996, ..., 0.50119996,\n         0.5       , 0.5062    ],\n        [0.83419997, 0.8332    , 0.83089995, ..., 0.5026    ,\n         0.4944    , 0.50119996],\n        [0.8323    , 0.8308    , 0.8285    , ..., 0.5027    ,\n         0.49449998, 0.4982    ]],\n\n       [[0.534     , 0.54249996, 0.5554    , ...,        nan,\n                nan,        nan],\n        [0.52959996, 0.52959996, 0.5434    , ...,        nan,\n                nan,        nan],\n        [0.5248    , 0.524     , 0.5352    , ...,        nan,\n                nan,        nan],\n...\n        [0.13849999, 0.153     , 0.175     , ...,        nan,\n                nan,        nan],\n        [0.1485    , 0.1699    , 0.188     , ...,        nan,\n                nan,        nan],\n        [0.1698    , 0.1848    , 0.18259999, ...,        nan,\n                nan,        nan]],\n\n       [[0.0295    , 0.0309    , 0.0248    , ..., 0.0096    ,\n         0.0099    , 0.0397    ],\n        [0.0161    , 0.0147    , 0.0112    , ..., 0.0096    ,\n         0.0142    , 0.0466    ],\n        [0.0109    , 0.0099    , 0.0083    , ..., 0.0097    ,\n         0.019     , 0.0482    ],\n        ...,\n        [0.0145    , 0.0144    , 0.0151    , ..., 0.0127    ,\n         0.0141    , 0.0136    ],\n        [0.0152    , 0.0165    , 0.0152    , ..., 0.0162    ,\n         0.0182    , 0.0181    ],\n        [0.0135    , 0.0122    , 0.0128    , ..., 0.0184    ,\n         0.019     , 0.0226    ]]], dtype=float32)\nCoordinates:\n  * y            (y) float64 3kB 5.206e+06 5.206e+06 ... 5.176e+06 5.176e+06\n  * x            (x) float64 3kB 5.804e+05 5.805e+05 ... 6.114e+05 6.115e+05\n    spatial_ref  int32 4B 32610\n  * time         (time) datetime64[ns] 872B 2024-01-02T19:11:23.801000 ... 20...</pre>xarray.DataArray'red'<ul><li>time: 109</li><li>y: 380</li><li>x: 389</li></ul><ul><li>0.5392 0.5367 0.5361 0.5315 0.529 ... 0.0144 0.0184 0.019 0.0226<pre>array([[[0.5392    , 0.5367    , 0.5361    , ..., 0.7388    ,\n         0.726     , 0.7132    ],\n        [0.53709996, 0.5329    , 0.53319997, ..., 0.7499    ,\n         0.73469996, 0.72099996],\n        [0.536     , 0.5323    , 0.5352    , ..., 0.7637    ,\n         0.7489    , 0.73579997],\n        ...,\n        [0.8339    , 0.8348    , 0.83489996, ..., 0.50119996,\n         0.5       , 0.5062    ],\n        [0.83419997, 0.8332    , 0.83089995, ..., 0.5026    ,\n         0.4944    , 0.50119996],\n        [0.8323    , 0.8308    , 0.8285    , ..., 0.5027    ,\n         0.49449998, 0.4982    ]],\n\n       [[0.534     , 0.54249996, 0.5554    , ...,        nan,\n                nan,        nan],\n        [0.52959996, 0.52959996, 0.5434    , ...,        nan,\n                nan,        nan],\n        [0.5248    , 0.524     , 0.5352    , ...,        nan,\n                nan,        nan],\n...\n        [0.13849999, 0.153     , 0.175     , ...,        nan,\n                nan,        nan],\n        [0.1485    , 0.1699    , 0.188     , ...,        nan,\n                nan,        nan],\n        [0.1698    , 0.1848    , 0.18259999, ...,        nan,\n                nan,        nan]],\n\n       [[0.0295    , 0.0309    , 0.0248    , ..., 0.0096    ,\n         0.0099    , 0.0397    ],\n        [0.0161    , 0.0147    , 0.0112    , ..., 0.0096    ,\n         0.0142    , 0.0466    ],\n        [0.0109    , 0.0099    , 0.0083    , ..., 0.0097    ,\n         0.019     , 0.0482    ],\n        ...,\n        [0.0145    , 0.0144    , 0.0151    , ..., 0.0127    ,\n         0.0141    , 0.0136    ],\n        [0.0152    , 0.0165    , 0.0152    , ..., 0.0162    ,\n         0.0182    , 0.0181    ],\n        [0.0135    , 0.0122    , 0.0128    , ..., 0.0184    ,\n         0.019     , 0.0226    ]]], dtype=float32)</pre></li><li>Coordinates: (4)<ul><li>y(y)float645.206e+06 5.206e+06 ... 5.176e+06units :metreresolution :-80.0crs :EPSG:32610<pre>array([5205880., 5205800., 5205720., ..., 5175720., 5175640., 5175560.])</pre></li><li>x(x)float645.804e+05 5.805e+05 ... 6.115e+05units :metreresolution :80.0crs :EPSG:32610<pre>array([580440., 580520., 580600., ..., 611320., 611400., 611480.])</pre></li><li>spatial_ref()int3232610spatial_ref :PROJCRS[\"WGS 84 / UTM zone 10N\",BASEGEOGCRS[\"WGS 84\",ENSEMBLE[\"World Geodetic System 1984 ensemble\",MEMBER[\"World Geodetic System 1984 (Transit)\"],MEMBER[\"World Geodetic System 1984 (G730)\"],MEMBER[\"World Geodetic System 1984 (G873)\"],MEMBER[\"World Geodetic System 1984 (G1150)\"],MEMBER[\"World Geodetic System 1984 (G1674)\"],MEMBER[\"World Geodetic System 1984 (G1762)\"],MEMBER[\"World Geodetic System 1984 (G2139)\"],MEMBER[\"World Geodetic System 1984 (G2296)\"],ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]],ENSEMBLEACCURACY[2.0]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"UTM zone 10N\",METHOD[\"Transverse Mercator\",ID[\"EPSG\",9807]],PARAMETER[\"Latitude of natural origin\",0,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",-123,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"Scale factor at natural origin\",0.9996,SCALEUNIT[\"unity\",1],ID[\"EPSG\",8805]],PARAMETER[\"False easting\",500000,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",0,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1]],USAGE[SCOPE[\"Navigation and medium accuracy spatial referencing.\"],AREA[\"Between 126\u00b0W and 120\u00b0W, northern hemisphere between equator and 84\u00b0N, onshore and offshore. Canada - British Columbia (BC); Northwest Territories (NWT); Nunavut; Yukon. United States (USA) - Alaska (AK).\"],BBOX[0,-126,84,-120]],ID[\"EPSG\",32610]]crs_wkt :PROJCRS[\"WGS 84 / UTM zone 10N\",BASEGEOGCRS[\"WGS 84\",ENSEMBLE[\"World Geodetic System 1984 ensemble\",MEMBER[\"World Geodetic System 1984 (Transit)\"],MEMBER[\"World Geodetic System 1984 (G730)\"],MEMBER[\"World Geodetic System 1984 (G873)\"],MEMBER[\"World Geodetic System 1984 (G1150)\"],MEMBER[\"World Geodetic System 1984 (G1674)\"],MEMBER[\"World Geodetic System 1984 (G1762)\"],MEMBER[\"World Geodetic System 1984 (G2139)\"],MEMBER[\"World Geodetic System 1984 (G2296)\"],ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]],ENSEMBLEACCURACY[2.0]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"UTM zone 10N\",METHOD[\"Transverse Mercator\",ID[\"EPSG\",9807]],PARAMETER[\"Latitude of natural origin\",0,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",-123,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"Scale factor at natural origin\",0.9996,SCALEUNIT[\"unity\",1],ID[\"EPSG\",8805]],PARAMETER[\"False easting\",500000,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",0,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1]],USAGE[SCOPE[\"Navigation and medium accuracy spatial referencing.\"],AREA[\"Between 126\u00b0W and 120\u00b0W, northern hemisphere between equator and 84\u00b0N, onshore and offshore. Canada - British Columbia (BC); Northwest Territories (NWT); Nunavut; Yukon. United States (USA) - Alaska (AK).\"],BBOX[0,-126,84,-120]],ID[\"EPSG\",32610]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984 ensembleprojected_crs_name :WGS 84 / UTM zone 10Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-123.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996GeoTransform :580400 80 0 5205920 0 -80<pre>array(32610, dtype=int32)</pre></li><li>time(time)datetime64[ns]2024-01-02T19:11:23.801000 ... 2...<pre>array(['2024-01-02T19:11:23.801000000', '2024-01-05T19:21:17.103000000',\n       '2024-01-07T19:11:19.035000000', '2024-01-10T19:21:12.330000000',\n       '2024-01-12T19:11:21.274000000', '2024-01-15T19:21:16.275000000',\n       '2024-01-17T19:11:14.589000000', '2024-01-20T19:21:09.586000000',\n       '2024-01-22T19:11:22.461000000', '2024-01-25T19:21:16.260000000',\n       '2024-01-27T19:11:17.950000000', '2024-01-30T19:21:12.854000000',\n       '2024-02-01T19:11:22.201000000', '2024-02-04T19:21:15.811000000',\n       '2024-02-06T19:11:19.118000000', '2024-02-09T19:21:13.735000000',\n       '2024-02-11T19:11:23.996000000', '2024-02-14T19:21:18.433000000',\n       '2024-02-16T19:11:21.135000000', '2024-02-19T19:21:15.382000000',\n       '2024-02-21T19:11:23.739000000', '2024-02-24T19:21:17.101000000',\n       '2024-02-26T19:11:22.430000000', '2024-02-29T19:21:17.225000000',\n       '2024-03-02T19:11:20.145000000', '2024-03-05T19:21:12.712000000',\n       '2024-03-07T19:11:23.797000000', '2024-03-10T19:21:17.564000000',\n       '2024-03-12T19:11:20.147000000', '2024-03-15T19:21:15.693000000',\n       '2024-03-17T19:11:23.716000000', '2024-03-20T19:21:18.322000000',\n       '2024-03-22T19:11:23.574000000', '2024-03-25T19:21:17.763000000',\n       '2024-03-27T19:11:23.622000000', '2024-03-30T19:21:16.679000000',\n       '2024-04-01T19:11:22.061000000', '2024-04-04T19:21:15.208000000',\n       '2024-04-06T19:11:21.547000000', '2024-04-09T19:21:17.383000000',\n       '2024-04-11T19:11:23.492000000', '2024-04-14T19:21:18.106000000',\n       '2024-04-16T19:11:29.694000000', '2024-04-19T19:21:20.538000000',\n       '2024-04-21T19:11:23.501000000', '2024-04-24T19:21:16.088000000',\n       '2024-04-26T19:11:25.518000000', '2024-04-29T19:21:19.949000000',\n       '2024-05-01T19:11:23.381000000', '2024-05-04T19:21:17.928000000',\n       '2024-05-06T19:11:25.826000000', '2024-05-09T19:21:20.029000000',\n       '2024-05-11T19:11:23.610000000', '2024-05-14T19:21:16.256000000',\n       '2024-05-16T19:11:25.658000000', '2024-05-19T19:21:18.518000000',\n       '2024-05-21T19:11:22.679000000', '2024-05-24T19:21:17.259000000',\n       '2024-05-26T19:11:25.204000000', '2024-05-29T19:21:19.721000000',\n       '2024-05-31T19:11:23.919000000', '2024-06-03T19:21:19.212000000',\n       '2024-06-05T19:11:28.475000000', '2024-06-08T19:21:23.072000000',\n       '2024-06-10T19:11:26.430000000', '2024-06-13T19:21:20.440000000',\n       '2024-06-15T19:11:29.145000000', '2024-06-18T19:21:22.678000000',\n       '2024-06-20T19:11:25.258000000', '2024-06-23T19:21:20.295000000',\n       '2024-06-25T19:11:26.660000000', '2024-06-28T19:21:20.283000000',\n       '2024-06-30T19:11:27.111000000', '2024-07-03T19:21:21.015000000',\n       '2024-07-05T19:11:26.784000000', '2024-07-08T19:21:20.679000000',\n       '2024-07-10T19:11:25.290000000', '2024-07-13T19:21:19.844000000',\n       '2024-07-15T19:11:24.845000000', '2024-07-18T19:21:17.931000000',\n       '2024-07-20T19:11:26.708000000', '2024-07-23T19:21:20.538000000',\n       '2024-07-25T19:11:25.636000000', '2024-07-28T19:21:20.012000000',\n       '2024-07-30T19:11:24.305000000', '2024-08-02T19:21:18.414000000',\n       '2024-08-04T19:11:25.367000000', '2024-08-07T19:21:18.432000000',\n       '2024-08-09T19:11:27.244000000', '2024-08-12T19:21:21.541000000',\n       '2024-08-14T19:11:24.469000000', '2024-08-17T19:21:17.623000000',\n       '2024-08-19T19:11:24.519000000', '2024-08-22T19:21:16.632000000',\n       '2024-08-24T19:11:20.938000000', '2024-08-27T19:21:15.674000000',\n       '2024-08-29T19:11:25.608000000', '2024-09-01T19:21:20.100000000',\n       '2024-09-03T19:11:23.227000000', '2024-09-06T19:21:17.248000000',\n       '2024-09-08T19:11:25.495000000', '2024-09-11T19:21:18.464000000',\n       '2024-09-13T19:11:21.460000000', '2024-09-16T19:21:17.247000000',\n       '2024-09-18T19:11:19.027000000', '2024-09-21T19:21:14.010000000',\n       '2024-09-23T19:11:24.883000000', '2024-09-26T19:21:23.027000000',\n       '2024-09-28T19:11:26.093000000'], dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (3)<ul><li>yPandasIndex<pre>PandasIndex(Index([5205880.0, 5205800.0, 5205720.0, 5205640.0, 5205560.0, 5205480.0,\n       5205400.0, 5205320.0, 5205240.0, 5205160.0,\n       ...\n       5176280.0, 5176200.0, 5176120.0, 5176040.0, 5175960.0, 5175880.0,\n       5175800.0, 5175720.0, 5175640.0, 5175560.0],\n      dtype='float64', name='y', length=380))</pre></li><li>xPandasIndex<pre>PandasIndex(Index([580440.0, 580520.0, 580600.0, 580680.0, 580760.0, 580840.0, 580920.0,\n       581000.0, 581080.0, 581160.0,\n       ...\n       610760.0, 610840.0, 610920.0, 611000.0, 611080.0, 611160.0, 611240.0,\n       611320.0, 611400.0, 611480.0],\n      dtype='float64', name='x', length=389))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2024-01-02 19:11:23.801000', '2024-01-05 19:21:17.103000',\n               '2024-01-07 19:11:19.035000', '2024-01-10 19:21:12.330000',\n               '2024-01-12 19:11:21.274000', '2024-01-15 19:21:16.275000',\n               '2024-01-17 19:11:14.589000', '2024-01-20 19:21:09.586000',\n               '2024-01-22 19:11:22.461000', '2024-01-25 19:21:16.260000',\n               ...\n               '2024-09-06 19:21:17.248000', '2024-09-08 19:11:25.495000',\n               '2024-09-11 19:21:18.464000', '2024-09-13 19:11:21.460000',\n               '2024-09-16 19:21:17.247000', '2024-09-18 19:11:19.027000',\n               '2024-09-21 19:21:14.010000', '2024-09-23 19:11:24.883000',\n               '2024-09-26 19:21:23.027000', '2024-09-28 19:11:26.093000'],\n              dtype='datetime64[ns]', name='time', length=109, freq=None))</pre></li></ul></li><li>Attributes: (0)</li></ul> In\u00a0[14]: Copied! <pre>%%time\ns2_es_c1 = easysnowdata.remote_sensing.Sentinel2(\n    bbox_input=bbox_gdf,\n    start_date=\"2024-01-01\",\n    end_date=\"2024-09-30\",\n    catalog_choice=\"earthsearch\", \n    collection=\"sentinel-2-c1-l2a\", \n    resolution=80,\n)\ns2_es_c1.data['red'].compute()\n</pre> %%time s2_es_c1 = easysnowdata.remote_sensing.Sentinel2(     bbox_input=bbox_gdf,     start_date=\"2024-01-01\",     end_date=\"2024-09-30\",     catalog_choice=\"earthsearch\",      collection=\"sentinel-2-c1-l2a\",      resolution=80, ) s2_es_c1.data['red'].compute() <pre>Data searched. Access the returned seach with the .search attribute.\nData retrieved. Access with the .data attribute. Data CRS: WGS 84 / UTM zone 10N.\nNodata values removed from the data. In doing so, all bands converted to float32. To turn this behavior off, set remove_nodata=False.\nData acquired after January 25th, 2022 harmonized to old baseline. To override this behavior, set harmonize_to_old=False.\nData scaled to float reflectance. To turn this behavior off, set scale_data=False.\nMetadata retrieved. Access with the .metadata attribute.\nCPU times: user 15 s, sys: 2.78 s, total: 17.8 s\nWall time: 3min 1s\n</pre> Out[14]: <pre>&lt;xarray.DataArray 'red' (time: 109, y: 380, x: 389)&gt; Size: 64MB\narray([[[0.53999996, 0.5374    , 0.53819996, ..., 0.7341    ,\n         0.72209996, 0.7112    ],\n        [0.53859997, 0.5336    , 0.53279996, ..., 0.74549997,\n         0.72959995, 0.7147    ],\n        [0.5362    , 0.5315    , 0.53499997, ..., 0.75659996,\n         0.743     , 0.732     ],\n        ...,\n        [0.83419997, 0.8359    , 0.8351    , ..., 0.5006    ,\n         0.4998    , 0.5096    ],\n        [0.8341    , 0.8333    , 0.831     , ..., 0.5001    ,\n         0.4917    , 0.5028    ],\n        [0.8321    , 0.8312    , 0.8278    , ..., 0.5008    ,\n         0.4939    , 0.5002    ]],\n\n       [[0.53069997, 0.5432    , 0.5557    , ...,        nan,\n                nan,        nan],\n        [0.5331    , 0.5312    , 0.5441    , ...,        nan,\n                nan,        nan],\n        [0.5202    , 0.5189    , 0.5318    , ...,        nan,\n                nan,        nan],\n...\n        [0.1383    , 0.14999999, 0.17549999, ...,        nan,\n                nan,        nan],\n        [0.14729999, 0.17029999, 0.19029999, ...,        nan,\n                nan,        nan],\n        [0.1713    , 0.1875    , 0.1832    , ...,        nan,\n                nan,        nan]],\n\n       [[0.0324    , 0.0368    , 0.0309    , ..., 0.0093    ,\n         0.0097    , 0.0507    ],\n        [0.0185    , 0.0169    , 0.0124    , ..., 0.0095    ,\n         0.0141    , 0.0575    ],\n        [0.0102    , 0.0102    , 0.0084    , ..., 0.0088    ,\n         0.0213    , 0.0541    ],\n        ...,\n        [0.0107    , 0.0086    , 0.0106    , ..., 0.0126    ,\n         0.0144    , 0.0134    ],\n        [0.0167    , 0.0172    , 0.0136    , ..., 0.0177    ,\n         0.0182    , 0.0198    ],\n        [0.0137    , 0.0108    , 0.0122    , ..., 0.0215    ,\n         0.0158    , 0.0246    ]]], dtype=float32)\nCoordinates:\n  * y            (y) float64 3kB 5.206e+06 5.206e+06 ... 5.176e+06 5.176e+06\n  * x            (x) float64 3kB 5.804e+05 5.805e+05 ... 6.114e+05 6.115e+05\n    spatial_ref  int32 4B 32610\n  * time         (time) datetime64[ns] 872B 2024-01-02T19:11:23.801000 ... 20...</pre>xarray.DataArray'red'<ul><li>time: 109</li><li>y: 380</li><li>x: 389</li></ul><ul><li>0.54 0.5374 0.5382 0.5324 0.5293 ... 0.0142 0.0215 0.0158 0.0246<pre>array([[[0.53999996, 0.5374    , 0.53819996, ..., 0.7341    ,\n         0.72209996, 0.7112    ],\n        [0.53859997, 0.5336    , 0.53279996, ..., 0.74549997,\n         0.72959995, 0.7147    ],\n        [0.5362    , 0.5315    , 0.53499997, ..., 0.75659996,\n         0.743     , 0.732     ],\n        ...,\n        [0.83419997, 0.8359    , 0.8351    , ..., 0.5006    ,\n         0.4998    , 0.5096    ],\n        [0.8341    , 0.8333    , 0.831     , ..., 0.5001    ,\n         0.4917    , 0.5028    ],\n        [0.8321    , 0.8312    , 0.8278    , ..., 0.5008    ,\n         0.4939    , 0.5002    ]],\n\n       [[0.53069997, 0.5432    , 0.5557    , ...,        nan,\n                nan,        nan],\n        [0.5331    , 0.5312    , 0.5441    , ...,        nan,\n                nan,        nan],\n        [0.5202    , 0.5189    , 0.5318    , ...,        nan,\n                nan,        nan],\n...\n        [0.1383    , 0.14999999, 0.17549999, ...,        nan,\n                nan,        nan],\n        [0.14729999, 0.17029999, 0.19029999, ...,        nan,\n                nan,        nan],\n        [0.1713    , 0.1875    , 0.1832    , ...,        nan,\n                nan,        nan]],\n\n       [[0.0324    , 0.0368    , 0.0309    , ..., 0.0093    ,\n         0.0097    , 0.0507    ],\n        [0.0185    , 0.0169    , 0.0124    , ..., 0.0095    ,\n         0.0141    , 0.0575    ],\n        [0.0102    , 0.0102    , 0.0084    , ..., 0.0088    ,\n         0.0213    , 0.0541    ],\n        ...,\n        [0.0107    , 0.0086    , 0.0106    , ..., 0.0126    ,\n         0.0144    , 0.0134    ],\n        [0.0167    , 0.0172    , 0.0136    , ..., 0.0177    ,\n         0.0182    , 0.0198    ],\n        [0.0137    , 0.0108    , 0.0122    , ..., 0.0215    ,\n         0.0158    , 0.0246    ]]], dtype=float32)</pre></li><li>Coordinates: (4)<ul><li>y(y)float645.206e+06 5.206e+06 ... 5.176e+06units :metreresolution :-80.0crs :EPSG:32610<pre>array([5205880., 5205800., 5205720., ..., 5175720., 5175640., 5175560.])</pre></li><li>x(x)float645.804e+05 5.805e+05 ... 6.115e+05units :metreresolution :80.0crs :EPSG:32610<pre>array([580440., 580520., 580600., ..., 611320., 611400., 611480.])</pre></li><li>spatial_ref()int3232610spatial_ref :PROJCRS[\"WGS 84 / UTM zone 10N\",BASEGEOGCRS[\"WGS 84\",ENSEMBLE[\"World Geodetic System 1984 ensemble\",MEMBER[\"World Geodetic System 1984 (Transit)\"],MEMBER[\"World Geodetic System 1984 (G730)\"],MEMBER[\"World Geodetic System 1984 (G873)\"],MEMBER[\"World Geodetic System 1984 (G1150)\"],MEMBER[\"World Geodetic System 1984 (G1674)\"],MEMBER[\"World Geodetic System 1984 (G1762)\"],MEMBER[\"World Geodetic System 1984 (G2139)\"],MEMBER[\"World Geodetic System 1984 (G2296)\"],ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]],ENSEMBLEACCURACY[2.0]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"UTM zone 10N\",METHOD[\"Transverse Mercator\",ID[\"EPSG\",9807]],PARAMETER[\"Latitude of natural origin\",0,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",-123,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"Scale factor at natural origin\",0.9996,SCALEUNIT[\"unity\",1],ID[\"EPSG\",8805]],PARAMETER[\"False easting\",500000,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",0,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1]],USAGE[SCOPE[\"Navigation and medium accuracy spatial referencing.\"],AREA[\"Between 126\u00b0W and 120\u00b0W, northern hemisphere between equator and 84\u00b0N, onshore and offshore. Canada - British Columbia (BC); Northwest Territories (NWT); Nunavut; Yukon. United States (USA) - Alaska (AK).\"],BBOX[0,-126,84,-120]],ID[\"EPSG\",32610]]crs_wkt :PROJCRS[\"WGS 84 / UTM zone 10N\",BASEGEOGCRS[\"WGS 84\",ENSEMBLE[\"World Geodetic System 1984 ensemble\",MEMBER[\"World Geodetic System 1984 (Transit)\"],MEMBER[\"World Geodetic System 1984 (G730)\"],MEMBER[\"World Geodetic System 1984 (G873)\"],MEMBER[\"World Geodetic System 1984 (G1150)\"],MEMBER[\"World Geodetic System 1984 (G1674)\"],MEMBER[\"World Geodetic System 1984 (G1762)\"],MEMBER[\"World Geodetic System 1984 (G2139)\"],MEMBER[\"World Geodetic System 1984 (G2296)\"],ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]],ENSEMBLEACCURACY[2.0]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"UTM zone 10N\",METHOD[\"Transverse Mercator\",ID[\"EPSG\",9807]],PARAMETER[\"Latitude of natural origin\",0,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",-123,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"Scale factor at natural origin\",0.9996,SCALEUNIT[\"unity\",1],ID[\"EPSG\",8805]],PARAMETER[\"False easting\",500000,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",0,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1]],USAGE[SCOPE[\"Navigation and medium accuracy spatial referencing.\"],AREA[\"Between 126\u00b0W and 120\u00b0W, northern hemisphere between equator and 84\u00b0N, onshore and offshore. Canada - British Columbia (BC); Northwest Territories (NWT); Nunavut; Yukon. United States (USA) - Alaska (AK).\"],BBOX[0,-126,84,-120]],ID[\"EPSG\",32610]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984 ensembleprojected_crs_name :WGS 84 / UTM zone 10Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-123.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996GeoTransform :580400 80 0 5205920 0 -80<pre>array(32610, dtype=int32)</pre></li><li>time(time)datetime64[ns]2024-01-02T19:11:23.801000 ... 2...<pre>array(['2024-01-02T19:11:23.801000000', '2024-01-05T19:21:17.103000000',\n       '2024-01-07T19:11:19.035000000', '2024-01-10T19:21:12.330000000',\n       '2024-01-12T19:11:21.274000000', '2024-01-15T19:21:16.275000000',\n       '2024-01-17T19:11:14.589000000', '2024-01-20T19:21:09.586000000',\n       '2024-01-22T19:11:22.461000000', '2024-01-25T19:21:16.260000000',\n       '2024-01-27T19:11:17.950000000', '2024-01-30T19:21:12.854000000',\n       '2024-02-01T19:11:22.201000000', '2024-02-04T19:21:15.811000000',\n       '2024-02-06T19:11:19.118000000', '2024-02-09T19:21:13.735000000',\n       '2024-02-11T19:11:23.996000000', '2024-02-14T19:21:18.433000000',\n       '2024-02-16T19:11:21.135000000', '2024-02-19T19:21:15.382000000',\n       '2024-02-21T19:11:23.739000000', '2024-02-24T19:21:17.101000000',\n       '2024-02-26T19:11:22.430000000', '2024-02-29T19:21:17.225000000',\n       '2024-03-02T19:11:20.145000000', '2024-03-05T19:21:12.712000000',\n       '2024-03-07T19:11:23.797000000', '2024-03-10T19:21:17.564000000',\n       '2024-03-12T19:11:20.147000000', '2024-03-15T19:21:15.693000000',\n       '2024-03-17T19:11:23.716000000', '2024-03-20T19:21:18.322000000',\n       '2024-03-22T19:11:23.574000000', '2024-03-25T19:21:17.763000000',\n       '2024-03-27T19:11:23.622000000', '2024-03-30T19:21:16.679000000',\n       '2024-04-01T19:11:22.061000000', '2024-04-04T19:21:15.208000000',\n       '2024-04-06T19:11:21.547000000', '2024-04-09T19:21:17.383000000',\n       '2024-04-11T19:11:23.492000000', '2024-04-14T19:21:18.106000000',\n       '2024-04-16T19:11:29.694000000', '2024-04-19T19:21:20.538000000',\n       '2024-04-21T19:11:23.501000000', '2024-04-24T19:21:16.088000000',\n       '2024-04-26T19:11:25.518000000', '2024-04-29T19:21:19.949000000',\n       '2024-05-01T19:11:23.381000000', '2024-05-04T19:21:17.928000000',\n       '2024-05-06T19:11:25.826000000', '2024-05-09T19:21:20.029000000',\n       '2024-05-11T19:11:23.610000000', '2024-05-14T19:21:16.256000000',\n       '2024-05-16T19:11:25.658000000', '2024-05-19T19:21:18.518000000',\n       '2024-05-21T19:11:22.679000000', '2024-05-24T19:21:17.259000000',\n       '2024-05-26T19:11:25.204000000', '2024-05-29T19:21:19.721000000',\n       '2024-05-31T19:11:23.919000000', '2024-06-03T19:21:19.212000000',\n       '2024-06-05T19:11:28.475000000', '2024-06-08T19:21:23.072000000',\n       '2024-06-10T19:11:26.430000000', '2024-06-13T19:21:20.440000000',\n       '2024-06-15T19:11:29.145000000', '2024-06-18T19:21:22.678000000',\n       '2024-06-20T19:11:25.258000000', '2024-06-23T19:21:20.295000000',\n       '2024-06-25T19:11:26.660000000', '2024-06-28T19:21:20.283000000',\n       '2024-06-30T19:11:27.111000000', '2024-07-03T19:21:21.015000000',\n       '2024-07-05T19:11:26.784000000', '2024-07-08T19:21:20.679000000',\n       '2024-07-10T19:11:25.290000000', '2024-07-13T19:21:19.844000000',\n       '2024-07-15T19:11:24.845000000', '2024-07-18T19:21:17.931000000',\n       '2024-07-20T19:11:26.708000000', '2024-07-23T19:21:20.538000000',\n       '2024-07-25T19:11:25.636000000', '2024-07-28T19:21:20.012000000',\n       '2024-07-30T19:11:24.305000000', '2024-08-02T19:21:18.414000000',\n       '2024-08-04T19:11:25.367000000', '2024-08-07T19:21:18.432000000',\n       '2024-08-09T19:11:27.244000000', '2024-08-12T19:21:21.541000000',\n       '2024-08-14T19:11:24.469000000', '2024-08-17T19:21:17.623000000',\n       '2024-08-19T19:11:24.519000000', '2024-08-22T19:21:16.632000000',\n       '2024-08-24T19:11:20.938000000', '2024-08-27T19:21:15.674000000',\n       '2024-08-29T19:11:25.608000000', '2024-09-01T19:21:20.100000000',\n       '2024-09-03T19:11:23.227000000', '2024-09-06T19:21:17.248000000',\n       '2024-09-08T19:11:25.495000000', '2024-09-11T19:21:18.464000000',\n       '2024-09-13T19:11:21.460000000', '2024-09-16T19:21:17.247000000',\n       '2024-09-18T19:11:19.027000000', '2024-09-21T19:21:14.010000000',\n       '2024-09-23T19:11:24.883000000', '2024-09-26T19:21:23.027000000',\n       '2024-09-28T19:11:26.093000000'], dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (3)<ul><li>yPandasIndex<pre>PandasIndex(Index([5205880.0, 5205800.0, 5205720.0, 5205640.0, 5205560.0, 5205480.0,\n       5205400.0, 5205320.0, 5205240.0, 5205160.0,\n       ...\n       5176280.0, 5176200.0, 5176120.0, 5176040.0, 5175960.0, 5175880.0,\n       5175800.0, 5175720.0, 5175640.0, 5175560.0],\n      dtype='float64', name='y', length=380))</pre></li><li>xPandasIndex<pre>PandasIndex(Index([580440.0, 580520.0, 580600.0, 580680.0, 580760.0, 580840.0, 580920.0,\n       581000.0, 581080.0, 581160.0,\n       ...\n       610760.0, 610840.0, 610920.0, 611000.0, 611080.0, 611160.0, 611240.0,\n       611320.0, 611400.0, 611480.0],\n      dtype='float64', name='x', length=389))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2024-01-02 19:11:23.801000', '2024-01-05 19:21:17.103000',\n               '2024-01-07 19:11:19.035000', '2024-01-10 19:21:12.330000',\n               '2024-01-12 19:11:21.274000', '2024-01-15 19:21:16.275000',\n               '2024-01-17 19:11:14.589000', '2024-01-20 19:21:09.586000',\n               '2024-01-22 19:11:22.461000', '2024-01-25 19:21:16.260000',\n               ...\n               '2024-09-06 19:21:17.248000', '2024-09-08 19:11:25.495000',\n               '2024-09-11 19:21:18.464000', '2024-09-13 19:11:21.460000',\n               '2024-09-16 19:21:17.247000', '2024-09-18 19:11:19.027000',\n               '2024-09-21 19:21:14.010000', '2024-09-23 19:11:24.883000',\n               '2024-09-26 19:21:23.027000', '2024-09-28 19:11:26.093000'],\n              dtype='datetime64[ns]', name='time', length=109, freq=None))</pre></li></ul></li><li>Attributes: (0)</li></ul> In\u00a0[15]: Copied! <pre>%%time\ns2_pc = easysnowdata.remote_sensing.Sentinel2(\n    bbox_input=bbox_gdf,\n    start_date=\"2024-01-01\",\n    end_date=\"2024-09-30\",\n    catalog_choice=\"planetarycomputer\",\n    resolution=80,\n)\ns2_pc.data['red'].compute()\n</pre> %%time s2_pc = easysnowdata.remote_sensing.Sentinel2(     bbox_input=bbox_gdf,     start_date=\"2024-01-01\",     end_date=\"2024-09-30\",     catalog_choice=\"planetarycomputer\",     resolution=80, ) s2_pc.data['red'].compute() <pre>Data searched. Access the returned seach with the .search attribute.\nData retrieved. Access with the .data attribute. Data CRS: WGS 84 / UTM zone 10N.\nNodata values removed from the data. In doing so, all bands converted to float32. To turn this behavior off, set remove_nodata=False.\nData acquired after January 25th, 2022 harmonized to old baseline. To override this behavior, set harmonize_to_old=False.\nData scaled to float reflectance. To turn this behavior off, set scale_data=False.\nMetadata retrieved. Access with the .metadata attribute.\nCPU times: user 9.05 s, sys: 641 ms, total: 9.7 s\nWall time: 55.6 s\n</pre> Out[15]: <pre>&lt;xarray.DataArray 'red' (time: 106, y: 380, x: 389)&gt; Size: 63MB\narray([[[0.5244    , 0.5209    , 0.5239    , ..., 0.7245    ,\n         0.71459997, 0.70199996],\n        [0.52419996, 0.5169    , 0.5153    , ..., 0.7385    ,\n         0.7249    , 0.7026    ],\n        [0.52      , 0.514     , 0.5203    , ..., 0.74939996,\n         0.73579997, 0.7285    ],\n        ...,\n        [0.83629996, 0.83779997, 0.84209996, ..., 0.43519998,\n         0.43789998, 0.4387    ],\n        [0.8373    , 0.8391    , 0.831     , ..., 0.4432    ,\n         0.42589998, 0.4362    ],\n        [0.8368    , 0.83809996, 0.83379996, ..., 0.44079998,\n         0.4251    , 0.42729998]],\n\n       [[0.49229997, 0.5177    , 0.52599996, ...,        nan,\n                nan,        nan],\n        [0.5098    , 0.5015    , 0.50729996, ...,        nan,\n                nan,        nan],\n        [0.48169997, 0.477     , 0.4978    , ...,        nan,\n                nan,        nan],\n...\n        [0.1345    , 0.14389999, 0.1672    , ...,        nan,\n                nan,        nan],\n        [0.1401    , 0.1564    , 0.1917    , ...,        nan,\n                nan,        nan],\n        [0.1585    , 0.1874    , 0.1963    , ...,        nan,\n                nan,        nan]],\n\n       [[0.0265    , 0.0386    , 0.0328    , ..., 0.0108    ,\n         0.0068    , 0.0244    ],\n        [0.0185    , 0.0142    , 0.012     , ..., 0.0101    ,\n         0.0052    , 0.0526    ],\n        [0.0101    , 0.0102    , 0.0063    , ..., 0.0087    ,\n         0.0026    , 0.0694    ],\n        ...,\n        [0.018     , 0.0025    , 0.0101    , ..., 0.011     ,\n         0.0127    , 0.0142    ],\n        [0.0137    , 0.0266    , 0.0179    , ..., 0.0116    ,\n         0.0231    , 0.0099    ],\n        [0.0138    , 0.0071    , 0.011     , ..., 0.0192    ,\n         0.0193    , 0.028     ]]], dtype=float32)\nCoordinates:\n  * y            (y) float64 3kB 5.206e+06 5.206e+06 ... 5.176e+06 5.176e+06\n  * x            (x) float64 3kB 5.804e+05 5.805e+05 ... 6.114e+05 6.115e+05\n    spatial_ref  int32 4B 32610\n  * time         (time) datetime64[ns] 848B 2024-01-02T19:08:09.024000 ... 20...</pre>xarray.DataArray'red'<ul><li>time: 106</li><li>y: 380</li><li>x: 389</li></ul><ul><li>0.5244 0.5209 0.5239 0.5163 0.5117 ... 0.0154 0.0192 0.0193 0.028<pre>array([[[0.5244    , 0.5209    , 0.5239    , ..., 0.7245    ,\n         0.71459997, 0.70199996],\n        [0.52419996, 0.5169    , 0.5153    , ..., 0.7385    ,\n         0.7249    , 0.7026    ],\n        [0.52      , 0.514     , 0.5203    , ..., 0.74939996,\n         0.73579997, 0.7285    ],\n        ...,\n        [0.83629996, 0.83779997, 0.84209996, ..., 0.43519998,\n         0.43789998, 0.4387    ],\n        [0.8373    , 0.8391    , 0.831     , ..., 0.4432    ,\n         0.42589998, 0.4362    ],\n        [0.8368    , 0.83809996, 0.83379996, ..., 0.44079998,\n         0.4251    , 0.42729998]],\n\n       [[0.49229997, 0.5177    , 0.52599996, ...,        nan,\n                nan,        nan],\n        [0.5098    , 0.5015    , 0.50729996, ...,        nan,\n                nan,        nan],\n        [0.48169997, 0.477     , 0.4978    , ...,        nan,\n                nan,        nan],\n...\n        [0.1345    , 0.14389999, 0.1672    , ...,        nan,\n                nan,        nan],\n        [0.1401    , 0.1564    , 0.1917    , ...,        nan,\n                nan,        nan],\n        [0.1585    , 0.1874    , 0.1963    , ...,        nan,\n                nan,        nan]],\n\n       [[0.0265    , 0.0386    , 0.0328    , ..., 0.0108    ,\n         0.0068    , 0.0244    ],\n        [0.0185    , 0.0142    , 0.012     , ..., 0.0101    ,\n         0.0052    , 0.0526    ],\n        [0.0101    , 0.0102    , 0.0063    , ..., 0.0087    ,\n         0.0026    , 0.0694    ],\n        ...,\n        [0.018     , 0.0025    , 0.0101    , ..., 0.011     ,\n         0.0127    , 0.0142    ],\n        [0.0137    , 0.0266    , 0.0179    , ..., 0.0116    ,\n         0.0231    , 0.0099    ],\n        [0.0138    , 0.0071    , 0.011     , ..., 0.0192    ,\n         0.0193    , 0.028     ]]], dtype=float32)</pre></li><li>Coordinates: (4)<ul><li>y(y)float645.206e+06 5.206e+06 ... 5.176e+06units :metreresolution :-80.0crs :EPSG:32610<pre>array([5205880., 5205800., 5205720., ..., 5175720., 5175640., 5175560.])</pre></li><li>x(x)float645.804e+05 5.805e+05 ... 6.115e+05units :metreresolution :80.0crs :EPSG:32610<pre>array([580440., 580520., 580600., ..., 611320., 611400., 611480.])</pre></li><li>spatial_ref()int3232610spatial_ref :PROJCRS[\"WGS 84 / UTM zone 10N\",BASEGEOGCRS[\"WGS 84\",ENSEMBLE[\"World Geodetic System 1984 ensemble\",MEMBER[\"World Geodetic System 1984 (Transit)\"],MEMBER[\"World Geodetic System 1984 (G730)\"],MEMBER[\"World Geodetic System 1984 (G873)\"],MEMBER[\"World Geodetic System 1984 (G1150)\"],MEMBER[\"World Geodetic System 1984 (G1674)\"],MEMBER[\"World Geodetic System 1984 (G1762)\"],MEMBER[\"World Geodetic System 1984 (G2139)\"],MEMBER[\"World Geodetic System 1984 (G2296)\"],ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]],ENSEMBLEACCURACY[2.0]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"UTM zone 10N\",METHOD[\"Transverse Mercator\",ID[\"EPSG\",9807]],PARAMETER[\"Latitude of natural origin\",0,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",-123,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"Scale factor at natural origin\",0.9996,SCALEUNIT[\"unity\",1],ID[\"EPSG\",8805]],PARAMETER[\"False easting\",500000,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",0,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1]],USAGE[SCOPE[\"Navigation and medium accuracy spatial referencing.\"],AREA[\"Between 126\u00b0W and 120\u00b0W, northern hemisphere between equator and 84\u00b0N, onshore and offshore. Canada - British Columbia (BC); Northwest Territories (NWT); Nunavut; Yukon. United States (USA) - Alaska (AK).\"],BBOX[0,-126,84,-120]],ID[\"EPSG\",32610]]crs_wkt :PROJCRS[\"WGS 84 / UTM zone 10N\",BASEGEOGCRS[\"WGS 84\",ENSEMBLE[\"World Geodetic System 1984 ensemble\",MEMBER[\"World Geodetic System 1984 (Transit)\"],MEMBER[\"World Geodetic System 1984 (G730)\"],MEMBER[\"World Geodetic System 1984 (G873)\"],MEMBER[\"World Geodetic System 1984 (G1150)\"],MEMBER[\"World Geodetic System 1984 (G1674)\"],MEMBER[\"World Geodetic System 1984 (G1762)\"],MEMBER[\"World Geodetic System 1984 (G2139)\"],MEMBER[\"World Geodetic System 1984 (G2296)\"],ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]],ENSEMBLEACCURACY[2.0]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"UTM zone 10N\",METHOD[\"Transverse Mercator\",ID[\"EPSG\",9807]],PARAMETER[\"Latitude of natural origin\",0,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",-123,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"Scale factor at natural origin\",0.9996,SCALEUNIT[\"unity\",1],ID[\"EPSG\",8805]],PARAMETER[\"False easting\",500000,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",0,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1]],USAGE[SCOPE[\"Navigation and medium accuracy spatial referencing.\"],AREA[\"Between 126\u00b0W and 120\u00b0W, northern hemisphere between equator and 84\u00b0N, onshore and offshore. Canada - British Columbia (BC); Northwest Territories (NWT); Nunavut; Yukon. United States (USA) - Alaska (AK).\"],BBOX[0,-126,84,-120]],ID[\"EPSG\",32610]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984 ensembleprojected_crs_name :WGS 84 / UTM zone 10Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-123.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996GeoTransform :580400 80 0 5205920 0 -80<pre>array(32610, dtype=int32)</pre></li><li>time(time)datetime64[ns]2024-01-02T19:08:09.024000 ... 2...<pre>array(['2024-01-02T19:08:09.024000000', '2024-01-05T19:18:09.024000000',\n       '2024-01-07T19:07:51.024000000', '2024-01-10T19:17:51.024000000',\n       '2024-01-12T19:07:49.024000000', '2024-01-15T19:17:39.024000000',\n       '2024-01-17T19:07:21.024000000', '2024-01-20T19:17:11.024000000',\n       '2024-01-22T19:07:09.024000000', '2024-01-25T19:16:59.024000000',\n       '2024-01-27T19:06:41.024000000', '2024-01-30T19:16:31.024000000',\n       '2024-02-01T19:06:19.024000000', '2024-02-04T19:16:09.024000000',\n       '2024-02-06T19:05:51.024000000', '2024-02-09T19:15:41.024000000',\n       '2024-02-11T19:05:29.024000000', '2024-02-14T19:15:09.024000000',\n       '2024-02-16T19:04:51.024000000', '2024-02-19T19:14:31.024000000',\n       '2024-02-21T19:04:19.024000000', '2024-02-24T19:13:59.024000000',\n       '2024-02-26T19:03:41.024000000', '2024-02-29T19:13:31.024000000',\n       '2024-03-02T19:03:09.024000000', '2024-03-05T19:12:49.024000000',\n       '2024-03-07T19:02:31.024000000', '2024-03-10T19:12:11.024000000',\n       '2024-03-12T19:00:59.024000000', '2024-03-15T19:10:39.024000000',\n       '2024-03-17T19:01:21.024000000', '2024-03-20T19:11:01.024000000',\n       '2024-03-22T18:59:49.024000000', '2024-03-25T19:09:39.024000000',\n       '2024-03-27T19:00:11.024000000', '2024-03-30T19:09:51.024000000',\n       '2024-04-01T18:59:29.024000000', '2024-04-04T19:09:19.024000000',\n       '2024-04-06T18:59:11.024000000', '2024-04-09T19:09:11.024000000',\n       '2024-04-11T18:59:19.024000000', '2024-04-14T19:09:19.024000000',\n       '2024-04-16T18:59:21.024000000', '2024-04-19T19:09:21.024000000',\n       '2024-04-21T18:59:19.024000000', '2024-04-24T19:09:09.024000000',\n       '2024-04-26T18:59:21.024000000', '2024-04-29T19:09:21.024000000',\n       '2024-05-01T18:59:19.024000000', '2024-05-04T19:09:19.024000000',\n       '2024-05-06T18:59:21.024000000', '2024-05-09T19:09:21.024000000',\n       '2024-05-11T18:59:19.024000000', '2024-05-14T19:09:09.024000000',\n       '2024-05-16T18:59:21.024000000', '2024-05-19T19:09:11.024000000',\n       '2024-05-21T18:59:19.024000000', '2024-05-24T19:09:09.024000000',\n       '2024-05-26T18:59:21.024000000', '2024-05-29T19:09:21.024000000',\n       '2024-05-31T18:59:19.024000000', '2024-06-03T19:09:19.024000000',\n       '2024-06-05T18:59:21.024000000', '2024-06-08T19:09:21.024000000',\n       '2024-06-10T18:59:19.024000000', '2024-06-13T19:09:19.024000000',\n       '2024-06-15T18:59:21.024000000', '2024-06-18T19:09:21.024000000',\n       '2024-06-20T18:59:19.024000000', '2024-06-23T19:09:19.024000000',\n       '2024-06-25T18:59:41.024000000', '2024-06-28T19:09:21.024000000',\n       '2024-06-30T18:59:19.024000000', '2024-07-03T19:09:19.024000000',\n       '2024-07-05T18:59:21.024000000', '2024-07-08T19:09:21.024000000',\n       '2024-07-10T18:59:19.024000000', '2024-07-13T19:09:19.024000000',\n       '2024-07-15T18:59:21.024000000', '2024-07-18T19:09:11.024000000',\n       '2024-07-20T18:59:19.024000000', '2024-07-23T19:09:19.024000000',\n       '2024-07-25T18:59:21.024000000', '2024-07-28T19:09:21.024000000',\n       '2024-07-30T18:59:19.024000000', '2024-08-02T19:09:19.024000000',\n       '2024-08-04T18:59:21.024000000', '2024-08-07T19:09:11.024000000',\n       '2024-08-09T18:59:19.024000000', '2024-08-12T19:09:19.024000000',\n       '2024-08-14T18:59:21.024000000', '2024-08-17T19:09:11.024000000',\n       '2024-08-19T18:59:19.024000000', '2024-08-22T19:09:09.024000000',\n       '2024-08-24T18:59:11.024000000', '2024-08-27T19:09:11.024000000',\n       '2024-08-29T18:59:19.024000000', '2024-09-01T19:09:19.024000000',\n       '2024-09-03T18:59:21.024000000', '2024-09-06T19:09:21.024000000',\n       '2024-09-08T18:59:19.024000000', '2024-09-11T19:09:19.024000000',\n       '2024-09-21T19:10:09.024000000', '2024-09-23T19:01:21.024000000',\n       '2024-09-26T19:11:51.024000000', '2024-09-28T19:00:59.024000000'],\n      dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (3)<ul><li>yPandasIndex<pre>PandasIndex(Index([5205880.0, 5205800.0, 5205720.0, 5205640.0, 5205560.0, 5205480.0,\n       5205400.0, 5205320.0, 5205240.0, 5205160.0,\n       ...\n       5176280.0, 5176200.0, 5176120.0, 5176040.0, 5175960.0, 5175880.0,\n       5175800.0, 5175720.0, 5175640.0, 5175560.0],\n      dtype='float64', name='y', length=380))</pre></li><li>xPandasIndex<pre>PandasIndex(Index([580440.0, 580520.0, 580600.0, 580680.0, 580760.0, 580840.0, 580920.0,\n       581000.0, 581080.0, 581160.0,\n       ...\n       610760.0, 610840.0, 610920.0, 611000.0, 611080.0, 611160.0, 611240.0,\n       611320.0, 611400.0, 611480.0],\n      dtype='float64', name='x', length=389))</pre></li><li>timePandasIndex<pre>PandasIndex(DatetimeIndex(['2024-01-02 19:08:09.024000', '2024-01-05 19:18:09.024000',\n               '2024-01-07 19:07:51.024000', '2024-01-10 19:17:51.024000',\n               '2024-01-12 19:07:49.024000', '2024-01-15 19:17:39.024000',\n               '2024-01-17 19:07:21.024000', '2024-01-20 19:17:11.024000',\n               '2024-01-22 19:07:09.024000', '2024-01-25 19:16:59.024000',\n               ...\n               '2024-08-29 18:59:19.024000', '2024-09-01 19:09:19.024000',\n               '2024-09-03 18:59:21.024000', '2024-09-06 19:09:21.024000',\n               '2024-09-08 18:59:19.024000', '2024-09-11 19:09:19.024000',\n               '2024-09-21 19:10:09.024000', '2024-09-23 19:01:21.024000',\n               '2024-09-26 19:11:51.024000', '2024-09-28 19:00:59.024000'],\n              dtype='datetime64[ns]', name='time', length=106, freq=None))</pre></li></ul></li><li>Attributes: (0)</li></ul> In\u00a0[16]: Copied! <pre>catalogs = [\"earthsearch sentinel-2-l2a\",\"earthsearch sentinel-2-c1-l2a\",\"planetarycomputer sentinel-2-l2a\"]\nprovider_urls = [\"https://earth-search.aws.element84.com/v1\",\"https://earth-search.aws.element84.com/v1\",\"https://planetarycomputer.microsoft.com/api/stac/v1\"]\ncollections = [\"sentinel-2-l2a\",\"sentinel-2-c1-l2a\",\"sentinel-2-l2a\"]\nstart_date = \"2015-01-01\"\nend_date = \"2024-09-29\"\n</pre> catalogs = [\"earthsearch sentinel-2-l2a\",\"earthsearch sentinel-2-c1-l2a\",\"planetarycomputer sentinel-2-l2a\"] provider_urls = [\"https://earth-search.aws.element84.com/v1\",\"https://earth-search.aws.element84.com/v1\",\"https://planetarycomputer.microsoft.com/api/stac/v1\"] collections = [\"sentinel-2-l2a\",\"sentinel-2-c1-l2a\",\"sentinel-2-l2a\"] start_date = \"2015-01-01\" end_date = \"2024-09-29\" In\u00a0[17]: Copied! <pre>dates_df = pd.DataFrame(index=pd.RangeIndex(10000), columns=catalogs)\n\nfor catalog,provider_url,collection in zip(catalogs,provider_urls,collections):\n    print(f\"Searching {catalog} catalog...\")\n    catalog_client = pystac_client.Client.open(provider_url)\n    search = catalog_client.search(\n        collections=[collection],\n        bbox=bbox_gdf.total_bounds,\n        datetime=(start_date, end_date),\n    )\n\n    dates = [item['properties']['datetime'] for item in search.item_collection_as_dict()['features']]\n    dates_df.loc[range(len(dates)),catalog] = dates\n\ndates_df = dates_df.dropna(how='all')\n\nfor col in dates_df.columns:\n    dates_df[col] = pd.to_datetime(dates_df[col],format='mixed')\n</pre> dates_df = pd.DataFrame(index=pd.RangeIndex(10000), columns=catalogs)  for catalog,provider_url,collection in zip(catalogs,provider_urls,collections):     print(f\"Searching {catalog} catalog...\")     catalog_client = pystac_client.Client.open(provider_url)     search = catalog_client.search(         collections=[collection],         bbox=bbox_gdf.total_bounds,         datetime=(start_date, end_date),     )      dates = [item['properties']['datetime'] for item in search.item_collection_as_dict()['features']]     dates_df.loc[range(len(dates)),catalog] = dates  dates_df = dates_df.dropna(how='all')  for col in dates_df.columns:     dates_df[col] = pd.to_datetime(dates_df[col],format='mixed') <pre>Searching earthsearch sentinel-2-l2a catalog...\nSearching earthsearch sentinel-2-c1-l2a catalog...\nSearching planetarycomputer sentinel-2-l2a catalog...\n</pre> In\u00a0[18]: Copied! <pre>dates_df\n</pre> dates_df Out[18]: earthsearch sentinel-2-l2a earthsearch sentinel-2-c1-l2a planetarycomputer sentinel-2-l2a 0 2024-09-28 19:11:41.566000+00:00 2024-09-28 19:11:41.566000+00:00 2024-09-28 19:00:59.024000+00:00 1 2024-09-28 19:11:38.095000+00:00 2024-09-28 19:11:38.095000+00:00 2024-09-28 19:00:59.024000+00:00 2 2024-09-28 19:11:27.971000+00:00 2024-09-28 19:11:27.971000+00:00 2024-09-28 19:00:59.024000+00:00 3 2024-09-28 19:11:26.093000+00:00 2024-09-28 19:11:26.093000+00:00 2024-09-28 19:00:59.024000+00:00 4 2024-09-26 19:21:39.284000+00:00 2024-09-26 19:21:39.284000+00:00 2024-09-26 19:11:51.024000+00:00 ... ... ... ... 5437 2017-01-06 19:17:54.459000+00:00 NaT NaT 5438 2017-01-03 19:09:49.303000+00:00 NaT NaT 5439 2017-01-03 19:09:49.303000+00:00 NaT NaT 5440 2017-01-03 19:09:49.303000+00:00 NaT NaT 5441 2017-01-03 19:09:49.303000+00:00 NaT NaT <p>5442 rows \u00d7 3 columns</p> In\u00a0[19]: Copied! <pre>f,ax=plt.subplots(figsize=(20,7))\ndates_df.groupby([dates_df[catalogs[0]].dt.year, dates_df[catalogs[0]].dt.month]).count().plot(ax=ax,kind=\"bar\", legend=True)\n</pre> f,ax=plt.subplots(figsize=(20,7)) dates_df.groupby([dates_df[catalogs[0]].dt.year, dates_df[catalogs[0]].dt.month]).count().plot(ax=ax,kind=\"bar\", legend=True) Out[19]: <pre>&lt;Axes: xlabel='earthsearch sentinel-2-l2a,earthsearch sentinel-2-l2a'&gt;</pre> <p>As of the time of writing (september 2024), for our bounding box, the earthsearch (element84) sentinel-2-l2a collection covers the widest collections of dates [january 2017 - present]. Planetary Computer's sentinel-2-l2a collection comes in next, covering [july 2019 - present]. Finally, the earthsearch (element84) sentinel-2-c1-l2a collection covers [september 2020 - present]. At the moment, all collections are being actively updated with new scenes. The earthsearch sentinel-2-c1-l2a collection is actively being backfilled. Once backfill is complete, the earthsearch sentinel-2-l2a collection will be retired. Check the status here. Anecdotally (me), in terms of data quality, I've found planetary computer's sentinel-2-l2a collection best for visual inspection, though it seems to contain more data artifacts relative to the other collections. A more rigorous comparison would look at the scenes in many areas at full resolution but also across the different overview levels, being mindful of resampling techniques, scaling, visualization, etc. Often, I've found the download on planetarycomputer to be faster than earthsearch. Overall, I think each collection has its own strengths and weaknesses (at the time).</p>"},{"location":"examples/sentinel2_planetarycomputer_vs_earthaccess/#showing-the-difference-between-the-planetary-computer-s2-collection-and-the-earthaccess-s2-collections","title":"Showing the difference between the planetary computer S2 collection and the earthaccess S2 collections\u00b6","text":""},{"location":"examples/sentinel2_planetarycomputer_vs_earthaccess/#first-lets-check-the-scene-quality-and-values","title":"First let's check the scene quality and values\u00b6","text":""},{"location":"examples/sentinel2_planetarycomputer_vs_earthaccess/#now-lets-check-the-search-and-download-times","title":"Now let's check the search and download times\u00b6","text":""},{"location":"examples/sentinel2_planetarycomputer_vs_earthaccess/#which-dates-are-available-for-the-different-collections","title":"Which dates are available for the different collections?\u00b6","text":""},{"location":"examples/topography_examples/","title":"Topography examples","text":"In\u00a0[\u00a0]: Copied! <pre>#!mamba env create -f '../../environment.yml'\n#!mamba env update -f '../../environment.yml' --prune\n</pre> #!mamba env create -f '../../environment.yml' #!mamba env update -f '../../environment.yml' --prune In\u00a0[1]: Copied! <pre># this block is for developing the module, comment out when using the module, and uncomment import easysnowdata\n%load_ext autoreload\n%autoreload 2\n%aimport easysnowdata\n</pre> # this block is for developing the module, comment out when using the module, and uncomment import easysnowdata %load_ext autoreload %autoreload 2 %aimport easysnowdata In\u00a0[2]: Copied! <pre>import geopandas as gpd\nimport rioxarray as rxr\nimport xarray as xr\nimport shapely\nimport dask\nimport pystac_client\nimport planetary_computer\nimport odc.stac\nimport matplotlib.pyplot as plt\nimport matplotlib.colors\nimport datetime\n</pre> import geopandas as gpd import rioxarray as rxr import xarray as xr import shapely import dask import pystac_client import planetary_computer import odc.stac import matplotlib.pyplot as plt import matplotlib.colors import datetime In\u00a0[3]: Copied! <pre>bbox_gdf = gpd.read_file('https://github.com/egagli/sar_snowmelt_timing/raw/main/input/shapefiles/mt_rainier.geojson')\n</pre> bbox_gdf = gpd.read_file('https://github.com/egagli/sar_snowmelt_timing/raw/main/input/shapefiles/mt_rainier.geojson') In\u00a0[4]: Copied! <pre>%%time\ncop30_dem = easysnowdata.topography.get_copernicus_dem(bbox_gdf)\ncop30_dem\n</pre> %%time cop30_dem = easysnowdata.topography.get_copernicus_dem(bbox_gdf) cop30_dem <pre>CPU times: user 19.3 ms, sys: 9.33 ms, total: 28.6 ms\nWall time: 1.9 s\n</pre> Out[4]: <pre>&lt;xarray.DataArray 'data' (latitude: 563, longitude: 828)&gt; Size: 2MB\ndask.array&lt;getitem, shape=(563, 828), dtype=float32, chunksize=(563, 828), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * latitude     (latitude) float64 5kB 46.95 46.95 46.95 ... 46.79 46.79 46.79\n  * longitude    (longitude) float64 7kB -121.9 -121.9 -121.9 ... -121.6 -121.6\n    spatial_ref  int32 4B 4326\n    time         datetime64[ns] 8B 2021-04-22</pre>xarray.DataArray'data'<ul><li>latitude: 563</li><li>longitude: 828</li></ul><ul><li>dask.array&lt;chunksize=(563, 828), meta=np.ndarray&gt;  Array   Chunk   Bytes   1.78 MiB   1.78 MiB   Shape   (563, 828)   (563, 828)   Dask graph   1 chunks in 4 graph layers   Data type   float32 numpy.ndarray  828 563 </li><li>Coordinates: (4)<ul><li>latitude(latitude)float6446.95 46.95 46.95 ... 46.79 46.79units :degrees_northresolution :-0.0002777777777777778crs :EPSG:4326<pre>array([46.949444, 46.949167, 46.948889, ..., 46.793889, 46.793611, 46.793333])</pre></li><li>longitude(longitude)float64-121.9 -121.9 ... -121.6 -121.6units :degrees_eastresolution :0.0002777777777777778crs :EPSG:4326<pre>array([-121.872778, -121.8725  , -121.872222, ..., -121.643611, -121.643333,\n       -121.643056])</pre></li><li>spatial_ref()int324326spatial_ref :GEOGCRS[\"WGS 84\",ENSEMBLE[\"World Geodetic System 1984 ensemble\",MEMBER[\"World Geodetic System 1984 (Transit)\"],MEMBER[\"World Geodetic System 1984 (G730)\"],MEMBER[\"World Geodetic System 1984 (G873)\"],MEMBER[\"World Geodetic System 1984 (G1150)\"],MEMBER[\"World Geodetic System 1984 (G1674)\"],MEMBER[\"World Geodetic System 1984 (G1762)\"],MEMBER[\"World Geodetic System 1984 (G2139)\"],MEMBER[\"World Geodetic System 1984 (G2296)\"],ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]],ENSEMBLEACCURACY[2.0]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],CS[ellipsoidal,2],AXIS[\"geodetic latitude (Lat)\",north,ORDER[1],ANGLEUNIT[\"degree\",0.0174532925199433]],AXIS[\"geodetic longitude (Lon)\",east,ORDER[2],ANGLEUNIT[\"degree\",0.0174532925199433]],USAGE[SCOPE[\"Horizontal component of 3D system.\"],AREA[\"World.\"],BBOX[-90,-180,90,180]],ID[\"EPSG\",4326]]crs_wkt :GEOGCRS[\"WGS 84\",ENSEMBLE[\"World Geodetic System 1984 ensemble\",MEMBER[\"World Geodetic System 1984 (Transit)\"],MEMBER[\"World Geodetic System 1984 (G730)\"],MEMBER[\"World Geodetic System 1984 (G873)\"],MEMBER[\"World Geodetic System 1984 (G1150)\"],MEMBER[\"World Geodetic System 1984 (G1674)\"],MEMBER[\"World Geodetic System 1984 (G1762)\"],MEMBER[\"World Geodetic System 1984 (G2139)\"],MEMBER[\"World Geodetic System 1984 (G2296)\"],ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]],ENSEMBLEACCURACY[2.0]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],CS[ellipsoidal,2],AXIS[\"geodetic latitude (Lat)\",north,ORDER[1],ANGLEUNIT[\"degree\",0.0174532925199433]],AXIS[\"geodetic longitude (Lon)\",east,ORDER[2],ANGLEUNIT[\"degree\",0.0174532925199433]],USAGE[SCOPE[\"Horizontal component of 3D system.\"],AREA[\"World.\"],BBOX[-90,-180,90,180]],ID[\"EPSG\",4326]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984 ensemblegrid_mapping_name :latitude_longitudeGeoTransform :-121.872916666666668561447295 0.000277777777777777777537 0 46.949583333333336554460402 0 -0.000277777777777777777537<pre>array(4326, dtype=int32)</pre></li><li>time()datetime64[ns]2021-04-22<pre>array('2021-04-22T00:00:00.000000000', dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (2)<ul><li>latitudePandasIndex<pre>PandasIndex(Index([46.949444444444445,  46.94916666666667,  46.94888888888889,\n        46.94861111111111,  46.94833333333334, 46.948055555555555,\n        46.94777777777778,            46.9475,  46.94722222222222,\n        46.94694444444445,\n       ...\n       46.795833333333334,  46.79555555555556,  46.79527777777778,\n                   46.795,  46.79472222222223, 46.794444444444444,\n        46.79416666666667,  46.79388888888889,  46.79361111111111,\n        46.79333333333334],\n      dtype='float64', name='latitude', length=563))</pre></li><li>longitudePandasIndex<pre>PandasIndex(Index([-121.87277777777778,           -121.8725, -121.87222222222223,\n       -121.87194444444445, -121.87166666666667,  -121.8713888888889,\n       -121.87111111111112, -121.87083333333334, -121.87055555555557,\n       -121.87027777777779,\n       ...\n       -121.64555555555556, -121.64527777777778, -121.64500000000001,\n       -121.64472222222223, -121.64444444444445, -121.64416666666668,\n        -121.6438888888889, -121.64361111111111, -121.64333333333335,\n       -121.64305555555556],\n      dtype='float64', name='longitude', length=828))</pre></li></ul></li><li>Attributes: (0)</li></ul> In\u00a0[5]: Copied! <pre>%%time\ncop90_dem = easysnowdata.topography.get_copernicus_dem(bbox_gdf, resolution=90)\ncop90_dem\n</pre> %%time cop90_dem = easysnowdata.topography.get_copernicus_dem(bbox_gdf, resolution=90) cop90_dem <pre>CPU times: user 13.1 ms, sys: 9.52 ms, total: 22.6 ms\nWall time: 1.17 s\n</pre> Out[5]: <pre>&lt;xarray.DataArray 'data' (latitude: 188, longitude: 276)&gt; Size: 208kB\ndask.array&lt;getitem, shape=(188, 276), dtype=float32, chunksize=(188, 276), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * latitude     (latitude) float64 2kB 46.95 46.95 46.95 ... 46.8 46.79 46.79\n  * longitude    (longitude) float64 2kB -121.9 -121.9 -121.9 ... -121.6 -121.6\n    spatial_ref  int32 4B 4326\n    time         datetime64[ns] 8B 2021-04-22</pre>xarray.DataArray'data'<ul><li>latitude: 188</li><li>longitude: 276</li></ul><ul><li>dask.array&lt;chunksize=(188, 276), meta=np.ndarray&gt;  Array   Chunk   Bytes   202.69 kiB   202.69 kiB   Shape   (188, 276)   (188, 276)   Dask graph   1 chunks in 4 graph layers   Data type   float32 numpy.ndarray  276 188 </li><li>Coordinates: (4)<ul><li>latitude(latitude)float6446.95 46.95 46.95 ... 46.79 46.79units :degrees_northresolution :-0.0008333333333333334crs :EPSG:4326<pre>array([46.949167, 46.948333, 46.9475  , 46.946667, 46.945833, 46.945   ,\n       46.944167, 46.943333, 46.9425  , 46.941667, 46.940833, 46.94    ,\n       46.939167, 46.938333, 46.9375  , 46.936667, 46.935833, 46.935   ,\n       46.934167, 46.933333, 46.9325  , 46.931667, 46.930833, 46.93    ,\n       46.929167, 46.928333, 46.9275  , 46.926667, 46.925833, 46.925   ,\n       46.924167, 46.923333, 46.9225  , 46.921667, 46.920833, 46.92    ,\n       46.919167, 46.918333, 46.9175  , 46.916667, 46.915833, 46.915   ,\n       46.914167, 46.913333, 46.9125  , 46.911667, 46.910833, 46.91    ,\n       46.909167, 46.908333, 46.9075  , 46.906667, 46.905833, 46.905   ,\n       46.904167, 46.903333, 46.9025  , 46.901667, 46.900833, 46.9     ,\n       46.899167, 46.898333, 46.8975  , 46.896667, 46.895833, 46.895   ,\n       46.894167, 46.893333, 46.8925  , 46.891667, 46.890833, 46.89    ,\n       46.889167, 46.888333, 46.8875  , 46.886667, 46.885833, 46.885   ,\n       46.884167, 46.883333, 46.8825  , 46.881667, 46.880833, 46.88    ,\n       46.879167, 46.878333, 46.8775  , 46.876667, 46.875833, 46.875   ,\n       46.874167, 46.873333, 46.8725  , 46.871667, 46.870833, 46.87    ,\n       46.869167, 46.868333, 46.8675  , 46.866667, 46.865833, 46.865   ,\n       46.864167, 46.863333, 46.8625  , 46.861667, 46.860833, 46.86    ,\n       46.859167, 46.858333, 46.8575  , 46.856667, 46.855833, 46.855   ,\n       46.854167, 46.853333, 46.8525  , 46.851667, 46.850833, 46.85    ,\n       46.849167, 46.848333, 46.8475  , 46.846667, 46.845833, 46.845   ,\n       46.844167, 46.843333, 46.8425  , 46.841667, 46.840833, 46.84    ,\n       46.839167, 46.838333, 46.8375  , 46.836667, 46.835833, 46.835   ,\n       46.834167, 46.833333, 46.8325  , 46.831667, 46.830833, 46.83    ,\n       46.829167, 46.828333, 46.8275  , 46.826667, 46.825833, 46.825   ,\n       46.824167, 46.823333, 46.8225  , 46.821667, 46.820833, 46.82    ,\n       46.819167, 46.818333, 46.8175  , 46.816667, 46.815833, 46.815   ,\n       46.814167, 46.813333, 46.8125  , 46.811667, 46.810833, 46.81    ,\n       46.809167, 46.808333, 46.8075  , 46.806667, 46.805833, 46.805   ,\n       46.804167, 46.803333, 46.8025  , 46.801667, 46.800833, 46.8     ,\n       46.799167, 46.798333, 46.7975  , 46.796667, 46.795833, 46.795   ,\n       46.794167, 46.793333])</pre></li><li>longitude(longitude)float64-121.9 -121.9 ... -121.6 -121.6units :degrees_eastresolution :0.0008333333333333334crs :EPSG:4326<pre>array([-121.8725  , -121.871667, -121.870833, ..., -121.645   , -121.644167,\n       -121.643333])</pre></li><li>spatial_ref()int324326spatial_ref :GEOGCRS[\"WGS 84\",ENSEMBLE[\"World Geodetic System 1984 ensemble\",MEMBER[\"World Geodetic System 1984 (Transit)\"],MEMBER[\"World Geodetic System 1984 (G730)\"],MEMBER[\"World Geodetic System 1984 (G873)\"],MEMBER[\"World Geodetic System 1984 (G1150)\"],MEMBER[\"World Geodetic System 1984 (G1674)\"],MEMBER[\"World Geodetic System 1984 (G1762)\"],MEMBER[\"World Geodetic System 1984 (G2139)\"],MEMBER[\"World Geodetic System 1984 (G2296)\"],ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]],ENSEMBLEACCURACY[2.0]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],CS[ellipsoidal,2],AXIS[\"geodetic latitude (Lat)\",north,ORDER[1],ANGLEUNIT[\"degree\",0.0174532925199433]],AXIS[\"geodetic longitude (Lon)\",east,ORDER[2],ANGLEUNIT[\"degree\",0.0174532925199433]],USAGE[SCOPE[\"Horizontal component of 3D system.\"],AREA[\"World.\"],BBOX[-90,-180,90,180]],ID[\"EPSG\",4326]]crs_wkt :GEOGCRS[\"WGS 84\",ENSEMBLE[\"World Geodetic System 1984 ensemble\",MEMBER[\"World Geodetic System 1984 (Transit)\"],MEMBER[\"World Geodetic System 1984 (G730)\"],MEMBER[\"World Geodetic System 1984 (G873)\"],MEMBER[\"World Geodetic System 1984 (G1150)\"],MEMBER[\"World Geodetic System 1984 (G1674)\"],MEMBER[\"World Geodetic System 1984 (G1762)\"],MEMBER[\"World Geodetic System 1984 (G2139)\"],MEMBER[\"World Geodetic System 1984 (G2296)\"],ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]],ENSEMBLEACCURACY[2.0]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],CS[ellipsoidal,2],AXIS[\"geodetic latitude (Lat)\",north,ORDER[1],ANGLEUNIT[\"degree\",0.0174532925199433]],AXIS[\"geodetic longitude (Lon)\",east,ORDER[2],ANGLEUNIT[\"degree\",0.0174532925199433]],USAGE[SCOPE[\"Horizontal component of 3D system.\"],AREA[\"World.\"],BBOX[-90,-180,90,180]],ID[\"EPSG\",4326]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984 ensemblegrid_mapping_name :latitude_longitudeGeoTransform :-121.872916666666668561447295 0.000833333333333333386821 0 46.949583333333336554460402 0 -0.000833333333333333386821<pre>array(4326, dtype=int32)</pre></li><li>time()datetime64[ns]2021-04-22<pre>array('2021-04-22T00:00:00.000000000', dtype='datetime64[ns]')</pre></li></ul></li><li>Indexes: (2)<ul><li>latitudePandasIndex<pre>PandasIndex(Index([ 46.94916666666667,  46.94833333333334, 46.947500000000005,\n        46.94666666666667,  46.94583333333334,             46.945,\n        46.94416666666667, 46.943333333333335,            46.9425,\n        46.94166666666667,\n       ...\n        46.80083333333334, 46.800000000000004,  46.79916666666667,\n        46.79833333333334,  46.79750000000001,  46.79666666666667,\n       46.795833333333334,             46.795,  46.79416666666667,\n        46.79333333333334],\n      dtype='float64', name='latitude', length=188))</pre></li><li>longitudePandasIndex<pre>PandasIndex(Index([          -121.8725, -121.87166666666667, -121.87083333333334,\n                   -121.87, -121.86916666666667, -121.86833333333334,\n                 -121.8675, -121.86666666666667, -121.86583333333334,\n       -121.86500000000001,\n       ...\n       -121.65083333333334,             -121.65, -121.64916666666667,\n       -121.64833333333334, -121.64750000000001, -121.64666666666668,\n       -121.64583333333333,            -121.645, -121.64416666666666,\n       -121.64333333333333],\n      dtype='float64', name='longitude', length=276))</pre></li></ul></li><li>Attributes: (0)</li></ul> In\u00a0[7]: Copied! <pre>f,ax=plt.subplots(1,2,figsize=(12,5))\n\ncop30_dem.plot(ax=ax[0],cmap='terrain')\ncop90_dem.plot(ax=ax[1],cmap='terrain')\n\n\nax[0].set_title('Copernicus 30m DEM')\nax[1].set_title('Copernicus 90m DEM')\n</pre> f,ax=plt.subplots(1,2,figsize=(12,5))  cop30_dem.plot(ax=ax[0],cmap='terrain') cop90_dem.plot(ax=ax[1],cmap='terrain')   ax[0].set_title('Copernicus 30m DEM') ax[1].set_title('Copernicus 90m DEM') Out[7]: <pre>Text(0.5, 1.0, 'Copernicus 90m DEM')</pre> In\u00a0[3]: Copied! <pre># %%time\n# dsm_3dep = easysnowdata.topography.get_3dep_dem(bbox_gdf,dem_type='DTM')\n# dsm_3dep.item_collection()\n</pre> # %%time # dsm_3dep = easysnowdata.topography.get_3dep_dem(bbox_gdf,dem_type='DTM') # dsm_3dep.item_collection() In\u00a0[4]: Copied! <pre># !pip install -q py3dep\n# import py3dep\n</pre> # !pip install -q py3dep # import py3dep In\u00a0[5]: Copied! <pre># py3dep.get_map('DEM',geometry=bbox_gdf.geometry[0],resolution=10).plot()\n</pre> # py3dep.get_map('DEM',geometry=bbox_gdf.geometry[0],resolution=10).plot() In\u00a0[6]: Copied! <pre># tuple(bbox_gdf.bounds.values[0])\n</pre> # tuple(bbox_gdf.bounds.values[0]) In\u00a0[7]: Copied! <pre># py3dep.query_3dep_sources(tuple(bbox_gdf.bounds.values[0]))\n</pre> # py3dep.query_3dep_sources(tuple(bbox_gdf.bounds.values[0])) In\u00a0[8]: Copied! <pre># py3dep.check_3dep_availability(tuple(bbox_gdf.bounds.values[0]))\n</pre> # py3dep.check_3dep_availability(tuple(bbox_gdf.bounds.values[0])) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/topography_examples/#testing-examples-from-topography","title":"Testing examples from topography\u00b6","text":""},{"location":"examples/topography_examples/#copernicus-dem","title":"Copernicus DEM\u00b6","text":""}]}